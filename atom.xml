<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小火箭的博客</title>
  
  <subtitle>愿世界和平！！！</subtitle>
  <link href="https://www.xiemingzhao.com/atom.xml" rel="self"/>
  
  <link href="https://www.xiemingzhao.com/"/>
  <updated>2025-01-12T12:48:46.662Z</updated>
  <id>https://www.xiemingzhao.com/</id>
  
  <author>
    <name>小火箭</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深度学习中的激活函数们</title>
    <link href="https://www.xiemingzhao.com/posts/activefunc.html"/>
    <id>https://www.xiemingzhao.com/posts/activefunc.html</id>
    <published>2020-06-17T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.662Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>本文参考多方资料总结了一下当前在深度模型中常遇到的几种激活函数。</p><p>在神经网络中，激活函数主要有两个用途：</p><ul><li>引入非线性</li><li>充分组合特征</li></ul><p>其中<strong>非线性</strong>激活函数允许网络复制复杂的非线性行为。正如绝大多数神经网络借助某种形式的梯度下降进行优化，激活函数需要是<strong>可微分</strong>（或者至少是几乎完全可微分的）。此外，复杂的激活函数也许产生一些梯度消失或爆炸的问题。因此，神经网络倾向于部署若干个特定的激活函数（identity、sigmoid、ReLU 及其变体）。<br>因此，神经网络中激励函数的作用通俗上讲就是将多个线性输入转换为非线性的关系。如果不使用激励函数的话，神经网络的每层都只是做线性变换，即使是多层输入叠加后也还是线性变换。通过激励函数引入非线性因素后，使神经网络的表达能力更强了。</p><span id="more"></span><h2 id="2-常见激活函数"><a href="#2-常见激活函数" class="headerlink" title="2 常见激活函数"></a>2 常见激活函数</h2><p>下面是多个激活函数的图示及其一阶导数，图的右侧是一些与神经网络相关的属性。</p><p>单调性（Montonic）： 单调性使得在激活函数处的梯度方向不会经常改变，从而让训练更容易收敛</p><p>连续性（Continuous）：个人认为作者想表达可微性，可微性保证了在优化中梯度的可计算性</p><p>非饱和性（saturation）：饱和指的是在某些区间梯度接近于零（即梯度消失），使得参数无法继续更新的问题。</p><p>在深度神经网络中，前面层上的梯度是来自于后面层上梯度的乘乘积。当存在过多的层次时，就出现了内在本质上的不稳定场景，如梯度消失和梯度爆炸</p><p>梯度消失（Vanishing Gradient）：某些区间梯度接近于零；前面的层比后面的层梯度变化更小，故变化更慢，从而引起了梯度消失问题</p><p>梯度爆炸(Exploding Gradient):  某些区间梯度接近于无穷大或者权重过大；前面层比后面层梯度变化更快，会引起梯度爆炸问题</p><h3 id="2-1-Step"><a href="#2-1-Step" class="headerlink" title="2.1 Step"></a>2.1 Step</h3><p>它的函数和倒数表达式是：</p><script type="math/tex; mode=display">f(x)=\left\{\begin{matrix}   1 \quad for \ x \ge 0 \\    0 \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">f'(x)=\left\{\begin{matrix}   0 \quad for \ x \ne 0 \\    ? \quad for \ x = 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc1.png" alt="activefunc1"></p><p>激活函数 Step 更倾向于理论而不是实际，它模仿了生物神经元要么全有要么全无的属性。它无法应用于神经网络，因为其导数是 0（除了零点导数无定义以外），这意味着基于梯度的优化方法并不可行。</p><h3 id="2-2-Identity"><a href="#2-2-Identity" class="headerlink" title="2.2 Identity"></a>2.2 Identity</h3><script type="math/tex; mode=display">Identity(x)=x</script><script type="math/tex; mode=display">Identity'(x)=1</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc2.png" alt="activefunc2"><br>通过激活函数 Identity，节点的输入等于输出。它完美适合于潜在行为是线性（与线性回归相似）的任务。当存在非线性，单独使用该激活函数是不够的，但它依然可以在最终输出节点上作为激活函数用于回归任务。</p><h3 id="2-3-ReLU"><a href="#2-3-ReLU" class="headerlink" title="2.3 ReLU"></a>2.3 ReLU</h3><script type="math/tex; mode=display">ReLU(x)=\left\{\begin{matrix}   x \quad for \ x \ge 0 \\    0 \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">ReLU'(x)=\left\{\begin{matrix}   1 \quad for \ x \ge 0 \\    0 \quad for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc4.png" alt="activefunc4"></p><p>修正线性单元（Rectified linear unit，ReLU）是神经网络中最常用的激活函数。</p><p>优点：<br>1，解决了gradient vanishing （梯度消失）问题（在正区间）<br>2，计算方便，求导方便，计算速度非常快，只需要判断输入是否大于0<br>3，收敛速度远远大于 Sigmoid函数和 tanh函数，可以加速网络训练</p><p>缺点：</p><ol><li>由于负数部分恒为零，会导致一些神经元无法激活</li><li>输出不是以0为中心</li></ol><p>缺点的致因：</p><ol><li>非常不幸的参数初始化，这种情况比较少见</li><li>learning rate 太高，导致在训练过程中参数更新太大，不幸使网络进入这种状态。</li></ol><p>另，<strong>ReLU 激活函数在零点不可导</strong>，求导按左导数来计算，是0。</p><h3 id="2-4-Sigmoid"><a href="#2-4-Sigmoid" class="headerlink" title="2.4 Sigmoid"></a>2.4 Sigmoid</h3><script type="math/tex; mode=display">Sig(x)=\frac{1}{1 + e^{-x}}</script><script type="math/tex; mode=display">Sig'(x)=Sig(x)(1-Sig(x))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc5.png" alt="activefunc5"></p><p>Sigmoid 因其在 logistic 回归中的重要地位而被人熟知，值域在 0 到 1 之间。Logistic Sigmoid（或者按通常的叫法，Sigmoid）激活函数给神经网络引进了概率的概念。它的导数是非零的，并且很容易计算（是其初始输出的函数）。然而，在分类任务中，sigmoid 正逐渐被 Tanh 函数取代作为标准的激活函数，因为后者为奇函数（关于原点对称）。</p><p>主要是其有一些缺点：</p><ul><li>容易出现梯度弥散或者梯度饱和；</li><li>Sigmoid函数的output不是0均值（zero-centered）；</li><li>对其解析式中含有幂函数，计算机求解时相对比较耗时。</li></ul><h3 id="2-5-Tanh"><a href="#2-5-Tanh" class="headerlink" title="2.5 Tanh"></a>2.5 Tanh</h3><script type="math/tex; mode=display">tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}</script><script type="math/tex; mode=display">tanh'(x)=1-tanh^2(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc6.png" alt="activefunc6"></p><p>在分类任务中，双曲正切函数（Tanh）逐渐取代 Sigmoid 函数作为标准的激活函数，其具有很多神经网络所钟爱的特征。它是完全可微分的，反对称，对称中心在原点。输出均值是0，使得其收敛速度要比Sigmoid快，减少迭代次数。为了解决学习缓慢和/或梯度消失问题，可以使用这个函数的更加平缓的变体（log-log、softsign、symmetrical sigmoid 等等）.</p><h3 id="2-6-Leaky-ReLU"><a href="#2-6-Leaky-ReLU" class="headerlink" title="2.6 Leaky ReLU"></a>2.6 Leaky ReLU</h3><script type="math/tex; mode=display">LeakyReLU(x)=\left\{\begin{matrix}   x \quad &for \ x \ge 0 \\    0.01 x \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">LeakyReLU'(x)=\left\{\begin{matrix}   1 \quad &for \ x \ge 0 \\    0.01 \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc7.png" alt="activefunc7"></p><p>经典（以及广泛使用的）ReLU 激活函数的变体，带泄露修正线性单元（Leaky ReLU）的输出对负值输入有很小的坡度。由于导数总是不为零，这能减少静默神经元的出现，允许基于梯度的学习（虽然会很慢）。</p><h3 id="2-7-PReLU"><a href="#2-7-PReLU" class="headerlink" title="2.7 PReLU"></a>2.7 PReLU</h3><script type="math/tex; mode=display">PReLU(x)=\left\{\begin{matrix}   x \quad for \ x \ge 0 \\    \alpha x \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">PReLU'(x)=\left\{\begin{matrix}   1 \quad for \ x \ge 0 \\    \alpha \quad for \ x < 0\end{matrix}\right.</script><p><strong>其中$\alpha$一般取根据数据来确定.</strong></p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc8.png" alt="activefunc8"></p><p>参数化修正线性单元（Parameteric Rectified Linear Unit，PReLU）属于 ReLU 修正类激活函数的一员。它和 RReLU 以及 Leaky ReLU 有一些共同点，即为负值输入添加了一个线性项。而最关键的区别是，这个线性项的斜率实际上是在模型训练中学习到的。如果$\alpha$是一个很小的固定值（如 ai=0.01），则PReLU 退化为 Leaky ReLU（LReLU）。有实验证明：与 ReLU 相比，LReLU 对最终结果几乎没有什么影响。</p><h3 id="2-8-RReLU"><a href="#2-8-RReLU" class="headerlink" title="2.8 RReLU"></a>2.8 RReLU</h3><script type="math/tex; mode=display">RReLU(x_{ji})=\left\{\begin{matrix}   x_{ji} \quad &for \ x_{ji} \ge 0 \\    \alpha_{ji} x_{ji} \quad &for \ x_{ji} < 0\end{matrix}\right.</script><p>where</p><script type="math/tex; mode=display">\alpha_{ji} \sim U(l,u),l<u \ and \ l,u \in [0,1)</script><script type="math/tex; mode=display">RReLU'(x)=\left\{\begin{matrix}   1 \quad for \ x \ge 0 \\    \alpha \quad for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc9.png" alt="activefunc9"></p><p>随机带泄露的修正线性单元（Randomized Leaky Rectified Linear Unit，RReLU 也是 Leaky ReLU的一个变体。在 PReLU中，负值的斜率在训练中是随机的，在之后的测试中就变成了固定的了。RReLU 的亮点在于，在训练环节中，aji 是从一个均匀的分布 U(I, u) 中随机抽取的数值。</p><p>这里我们要上一个经典的三者对比图：<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc10.png" alt="activefunc10"><br>其中 PReLU 中的 ai 是根据数据变换的；Leaky ReLU中的 ai 是固定的；RReLU中的 aji 是在一个给定的范围内随机抽取的值，这个值在测试环境就会固定下来。</p><h3 id="2-9-ELU"><a href="#2-9-ELU" class="headerlink" title="2.9 ELU"></a>2.9 ELU</h3><script type="math/tex; mode=display">ELU(x)=\left\{\begin{matrix}   x \quad &for \ x \ge 0 \\    \alpha (e^x-1) \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">ELU'(x)=\left\{\begin{matrix}   1 \quad &for \ x \ge 0 \\    \alpha e^x \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc11.png" alt="activefunc11"></p><p>指数线性单元（Exponential Linear Unit，ELU）也属于 ReLU 修正类激活函数的一员。和 PReLU 以及 RReLU 类似，为负值输入添加了一个非零输出。和其它修正类激活函数不同的是，它包括一个负指数项，从而防止静默神经元出现，导数收敛为零，从而提高学习效率。<br>根据一些研究，ELUs 分类精确度是高于 ReLUs的。ELU在正值区间的值为x本身，这样减轻了梯度弥散问题（x&gt;0区间导数处处为1），这点跟ReLU、Leaky ReLU相似。而在负值区间，ELU在输入取较小值类似于 Leaky ReLU ，理论上虽然好于 ReLU，但是实际使用中目前并没有好的证据 ELU 总是优于 ReLU。时具有软饱和的特性，提升了对噪声的鲁棒性。类似于 Leaky ReLU ，理论上虽然好于 ReLU，但是实际使用中目前并没有好的证据 ELU 总是优于 ReLU。</p><h3 id="2-10-SELU"><a href="#2-10-SELU" class="headerlink" title="2.10 SELU"></a>2.10 SELU</h3><script type="math/tex; mode=display">SELU(x)=\lambda\left\{\begin{matrix}   x \quad &for \ x \ge 0 \\    \alpha (e^x-1) \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">with \lambda=1.0507, \alpha=1.67326</script><script type="math/tex; mode=display">SELU'(x)=\left\{\begin{matrix}   \lambda \quad &for \ x \ge 0 \\    \lambda \alpha e^x \\ =\lambda(SELU(x)+\alpha) \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc12.png" alt="activefunc12"><br>扩展指数线性单元（Scaled Exponential Linear Unit，SELU）是激活函数指数线性单元（ELU）的一个变种。其中λ和α是固定数值（分别为 1.0507 和 1.6726）。这些值背后的推论（零均值/单位方差）构成了自归一化神经网络的基础（SNN）。值看似是乱讲的，实际上是作者推导出来的，详情也可以看<a href="https://github.com/bioinf-jku/SNNs">作者的github</a>。</p><h3 id="2-11-SReLU"><a href="#2-11-SReLU" class="headerlink" title="2.11 SReLU"></a>2.11 SReLU</h3><script type="math/tex; mode=display">SReLU(x)=\left\{\begin{matrix}   t_l + a_l(x-t_l) &for \ x \le t_l \\    x &for \ t_l < x < t_r \\ t_r + a_r(x - t_r) &for \ x \ge t_r\end{matrix}\right.</script><script type="math/tex; mode=display">SReLU'(x)=\left\{\begin{matrix}   a_l &for \ x \le t_l \\    1 &for \ t_l < x < t_r \\   a_r &for \ x \ge t_r\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc13.png" alt="activefunc13"><br>S 型整流线性激活单元（S-shaped Rectified Linear Activation Unit，SReLU）属于以 ReLU 为代表的整流激活函数族。它由三个分段线性函数组成。其中两种函数的斜度，以及函数相交的位置会在模型训练中被学习。</p><h3 id="2-12-Hard-Sigmoid"><a href="#2-12-Hard-Sigmoid" class="headerlink" title="2.12 Hard Sigmoid"></a>2.12 Hard Sigmoid</h3><script type="math/tex; mode=display">Hard Sigmoid(x)=max(0, min(1, \frac{x+1}{2}))</script><script type="math/tex; mode=display">Hard Sigmoid'(x)=\left\{\begin{matrix}   0 &for \ x \le t_l \\    0.5 &for \ t_l < x < t_r \\   0 &for \ x \ge t_r\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc14.png" alt="activefunc14"><br>Hard Sigmoid 是 Logistic Sigmoid 激活函数的分段线性近似。它更易计算，这使得学习计算的速度更快，尽管首次派生值为零可能导致静默神经元/过慢的学习速率（详见 ReLU）。</p><h3 id="2-13-Hard-Tanh"><a href="#2-13-Hard-Tanh" class="headerlink" title="2.13 Hard Tanh"></a>2.13 Hard Tanh</h3><script type="math/tex; mode=display">Hard Tanh(x)=\left\{\begin{matrix}   -1 &for \ x < -1 \\    x &for \ -1 \le x \le 1 \\   1 &for \ x > 1\end{matrix}\right.</script><script type="math/tex; mode=display">Hard Tanh'(x)=\left\{\begin{matrix}   0 &for \ x < -1 \\    1 &for \ -1 \le x \le 1 \\   0 &for \ x > 1\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc15.png" alt="activefunc15"></p><p>Hard Tanh 是 Tanh 激活函数的线性分段近似。相较而言，它更易计算，这使得学习计算的速度更快，尽管首次派生值为零可能导致静默神经元/过慢的学习速率（详见 ReLU）。</p><h3 id="2-14-LeCun-Tanh"><a href="#2-14-LeCun-Tanh" class="headerlink" title="2.14 LeCun Tanh"></a>2.14 LeCun Tanh</h3><script type="math/tex; mode=display">LeCun Tanh(x)=1.7519tanh(\frac{2}{3} x)</script><script type="math/tex; mode=display">LeCun Tanh'(x)=1.7519 * \frac{2}{3} (1 - tanh^2(\frac{2}{3} x))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc16.png" alt="activefunc16"></p><p>LeCun Tanh（也被称作 Scaled Tanh）是 Tanh 激活函数的扩展版本。它具有以下几个可以改善学习的属性：f(± 1) = ±1；二阶导数在 x=1 最大化；且有效增益接近 1。</p><h3 id="2-15-ArcTan"><a href="#2-15-ArcTan" class="headerlink" title="2.15 ArcTan"></a>2.15 ArcTan</h3><script type="math/tex; mode=display">ArcTan(x)=tan^{-1}(x)</script><script type="math/tex; mode=display">ArcTan'(x)=\frac{1}{x^2 + 1}</script><p><img src="深度模型中的激活函数们.resources/32DC77F2-3E16-464C-A477-BCCF6EE22BEE.png" alt="4750b64c7e1471b58e36b2774392f5f5"><br>视觉上类似于双曲正切（Tanh）函数，ArcTan 激活函数更加平坦，这让它比其他双曲线更加清晰。在默认情况下，其输出范围在-π/2 和π/2 之间。其导数趋向于零的速度也更慢，这意味着学习的效率更高。但这也意味着，导数的计算比 Tanh 更加昂贵。</p><h3 id="2-16-Softsign"><a href="#2-16-Softsign" class="headerlink" title="2.16 Softsign"></a>2.16 Softsign</h3><script type="math/tex; mode=display">Softsign(x)=\frac{x}{1 + |x|}</script><script type="math/tex; mode=display">Softsign'(x)=\frac{1}{(|x| + 1)^2}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc17.png" alt="activefunc17"></p><p>Softsign 是 Tanh 激活函数的另一个替代选择。就像 Tanh 一样，Softsign 是反对称、去中心、可微分，并返回-1 和 1 之间的值。其更平坦的曲线与更慢的下降导数表明它可以更高效地学习。另一方面，导数的计算比 Tanh 更麻烦。</p><h3 id="2-17-SoftPlus"><a href="#2-17-SoftPlus" class="headerlink" title="2.17 SoftPlus"></a>2.17 SoftPlus</h3><script type="math/tex; mode=display">SoftPlus(x)=ln(1 + e^x)</script><script type="math/tex; mode=display">SoftPlus'(x)=\frac{1}{1 + e ^{-x}}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc18.png" alt="activefunc18"></p><p>作为 ReLU 的一个不错的替代选择，SoftPlus 能够返回任何大于 0 的值。与 ReLU 不同，SoftPlus 的导数是连续的、非零的，无处不在，从而防止出现静默神经元。然而，SoftPlus 另一个不同于 ReLU 的地方在于其不对称性，不以零为中心，这兴许会妨碍学习。此外，由于导数常常小于 1，也可能出现梯度消失的问题。</p><h3 id="2-18-Signum"><a href="#2-18-Signum" class="headerlink" title="2.18 Signum"></a>2.18 Signum</h3><script type="math/tex; mode=display">Signum(x)=\left\{\begin{matrix}   1 &for \ x > 0 \\    -1 &for \ x < 0 \\   0 &for \ x = 0\end{matrix}\right.</script><script type="math/tex; mode=display">Signum'(x)=\left\{\begin{matrix}   0 &for \ x \ne 0 \\    ? &for \ x = 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc19.png" alt="activefunc19"></p><p>激活函数 Signum（或者简写为 Sign）是二值阶跃激活函数的扩展版本。它的值域为 [-1,1]，原点值是 0。尽管缺少阶跃函数的生物动机，Signum 依然是反对称的，这对激活函数来说是一个有利的特征。</p><h3 id="2-19-Bent-Identity"><a href="#2-19-Bent-Identity" class="headerlink" title="2.19 Bent Identity"></a>2.19 Bent Identity</h3><script type="math/tex; mode=display">Bent Identity(x)=\frac{\sqrt{x ^ 2 + 1} - 1}{2} + x</script><script type="math/tex; mode=display">Bent Identity'(x)=\frac{x}{2 \sqrt{x ^ 2 + 1}} + 1</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc20.png" alt="activefunc20"><br>激活函数 Bent Identity 是介于 Identity 与 ReLU 之间的一种折衷选择。它允许非线性行为，尽管其非零导数有效提升了学习并克服了与 ReLU 相关的静默神经元的问题。由于其导数可在 1 的任意一侧返回值，因此它可能容易受到梯度爆炸和消失的影响。</p><h3 id="2-20-Symmetrical-Sigmoid"><a href="#2-20-Symmetrical-Sigmoid" class="headerlink" title="2.20 Symmetrical Sigmoid"></a>2.20 Symmetrical Sigmoid</h3><script type="math/tex; mode=display">Symmetrical Sigmoid(x)=tanh(x/2)=\frac{1 - e^{-x}}{1 + e^{-x}}</script><script type="math/tex; mode=display">Symmetrical Sigmoid'(x)=0.5 (1 - tanh^2(x/2))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc21.png" alt="activefunc21"><br>Symmetrical Sigmoid 是另一个 Tanh 激活函数的变种（实际上，它相当于输入减半的 Tanh）。和 Tanh 一样，它是反对称的、零中心、可微分的，值域在 -1 到 1 之间。它更平坦的形状和更慢的下降派生表明它可以更有效地进行学习。</p><h3 id="2-21-Log-Log"><a href="#2-21-Log-Log" class="headerlink" title="2.21 Log Log"></a>2.21 Log Log</h3><script type="math/tex; mode=display">Log Log(x)=1 - e^{-e^x}</script><script type="math/tex; mode=display">Log Log'(x)=e^x(e^{-e^x})=e^{x-e^x}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc22.png" alt="activefunc22"><br>Log Log 激活函数（由上图 f(x) 可知该函数为以 e 为底的嵌套指数函数）的值域为 [0,1]，Complementary Log Log 激活函数有潜力替代经典的 Sigmoid 激活函数。该函数饱和地更快，且零点值要高于 0.5。</p><h3 id="2-22-Gaussian"><a href="#2-22-Gaussian" class="headerlink" title="2.22 Gaussian"></a>2.22 Gaussian</h3><script type="math/tex; mode=display">Gaussian(x)=e^{-x^2}</script><script type="math/tex; mode=display">Gaussian'(x)=-2xe^{-x^2}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc23.png" alt="activefunc23"><br>高斯激活函数（Gaussian）并不是径向基函数网络（RBFN）中常用的高斯核函数，高斯激活函数在多层感知机类的模型中并不是很流行。该函数处处可微且为偶函数，但一阶导会很快收敛到零。</p><h3 id="2-23-Absolute"><a href="#2-23-Absolute" class="headerlink" title="2.23 Absolute"></a>2.23 Absolute</h3><script type="math/tex; mode=display">Absolute(x)=|x|</script><script type="math/tex; mode=display">Absolute'(x)=\left\{\begin{matrix}   -1 &for \ x < 0 \\    ? &for \ x = 0 \\  1 &for x > 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc24.png" alt="activefunc24"><br>顾名思义，绝对值（Absolute）激活函数返回输入的绝对值。该函数的导数除了零点外处处有定义，且导数的量值处处为 1。这种激活函数一定不会出现梯度爆炸或消失的情况。</p><h3 id="2-24-Sinusoid"><a href="#2-24-Sinusoid" class="headerlink" title="2.24 Sinusoid"></a>2.24 Sinusoid</h3><script type="math/tex; mode=display">Sinusoid(x)=sin(x)</script><script type="math/tex; mode=display">Sinusoid'(x)=cos(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc25.png" alt="activefunc25"></p><p>如同余弦函数，Sinusoid（或简单正弦函数）激活函数为神经网络引入了周期性。该函数的值域为 [-1,1]，且导数处处连续。此外，Sinusoid 激活函数为零点对称的奇函数。</p><h3 id="2-25-Cos"><a href="#2-25-Cos" class="headerlink" title="2.25 Cos"></a>2.25 Cos</h3><script type="math/tex; mode=display">Cos(x)=cos(x)</script><script type="math/tex; mode=display">Cos'(x)=sin(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc26.png" alt="activefunc26"></p><p>如同正弦函数，余弦激活函数（Cos/Cosine）为神经网络引入了周期性。它的值域为 [-1,1]，且导数处处连续。和 Sinusoid 函数不同，余弦函数为不以零点对称的偶函数。</p><h3 id="2-26-Sinc"><a href="#2-26-Sinc" class="headerlink" title="2.26 Sinc"></a>2.26 Sinc</h3><script type="math/tex; mode=display">Sinc(x)=\left\{\begin{matrix}   1 &for \ x = 0 \\  \frac{sin(x)}{x} &for x \ne 0\end{matrix}\right.</script><script type="math/tex; mode=display">Sinc'(x)=\left\{\begin{matrix}   0 &for \ x = 0 \\  \frac{cos(x)}{x} - \frac{sin(x)}{x^2} &for x \ne 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc27.png" alt="activefunc27"><br>Sinc 函数（全称是 Cardinal Sine）在信号处理中尤为重要，因为它表征了矩形函数的傅立叶变换（Fourier transform）。作为一种激活函数，它的优势在于处处可微和对称的特性，不过它比较容易产生梯度消失的问题。</p><p><strong>参考文章</strong><br><a href="https://www.cnblogs.com/wj-1314/p/12015278.html">深度学习笔记——常用的激活（激励）函数</a><br><a href="https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/">Visualising Activation Functions in Neural Networks</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;本文参考多方资料总结了一下当前在深度模型中常遇到的几种激活函数。&lt;/p&gt;
&lt;p&gt;在神经网络中，激活函数主要有两个用途：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入非线性&lt;/li&gt;
&lt;li&gt;充分组合特征&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中&lt;strong&gt;非线性&lt;/strong&gt;激活函数允许网络复制复杂的非线性行为。正如绝大多数神经网络借助某种形式的梯度下降进行优化，激活函数需要是&lt;strong&gt;可微分&lt;/strong&gt;（或者至少是几乎完全可微分的）。此外，复杂的激活函数也许产生一些梯度消失或爆炸的问题。因此，神经网络倾向于部署若干个特定的激活函数（identity、sigmoid、ReLU 及其变体）。&lt;br&gt;因此，神经网络中激励函数的作用通俗上讲就是将多个线性输入转换为非线性的关系。如果不使用激励函数的话，神经网络的每层都只是做线性变换，即使是多层输入叠加后也还是线性变换。通过激励函数引入非线性因素后，使神经网络的表达能力更强了。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="深度学习" scheme="https://www.xiemingzhao.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="激活函数" scheme="https://www.xiemingzhao.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>布谷鸟过滤器(Cuckcoo Filter)</title>
    <link href="https://www.xiemingzhao.com/posts/cuckooFilter.html"/>
    <id>https://www.xiemingzhao.com/posts/cuckooFilter.html</id>
    <published>2020-05-28T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.656Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在了解了布隆过滤器的缺点之后，如果想要解决就可以来学习一下布谷鸟过滤器。其最早是在2001年的论文<a href="https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf">《Cuckoo Filter: Practically Better Than Bloom》</a>中提出的。论文中也很直接的抨击布隆过滤器的缺点，表明自己可以有效支持反向删除操作。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><p>先来介绍最简单的布谷鸟过滤器的工作原理。假设我们有：</p><ul><li>两个Hash表，T1和T2；</li><li>两个Hash函数，H1和H2。</li></ul><span id="more"></span><p>当一个不存在的元素需要进行插入的时候：</p><ol><li>先使用H1计算出其在T1的位置，如果空就插入；</li><li>如果不空，就再利用H2计算其在T2的位置，如果空就放入；</li><li>如果依然不空，那就<code>鸠占鹊巢</code>，把当前位置的元素踢出去，再把待插入的元素插入即可。这也是布谷鸟过滤器名称的来源。</li></ol><p>以上就是布谷鸟过滤器的主要原理，看到这里肯定各种疑问，被踢出的怎么办？会不会存在循环踢出？等等问题，研究人员也都进行了解决。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter1.png" alt="cuckooFilter1"></p><p>首先，不同于布谷鸟的是，布谷鸟哈希算法会帮这些受害者（被挤走的数据）寻找其它的位置。参考上面论文中的图(a)：</p><blockquote><p>当x想要插入的时候，发现在T1和T2中对应的位置都存在了元素，那就随机把 T1 表对应位置上的 y 踢出去吧，而 y 的另一个位置被 z 元素占领了。于是 y 毫不留情把 z 也踢了出去。z 发现自己的备用位置还空着（虽然这个备用位置也是元素 v 的备用位置），赶紧就位。</p></blockquote><p>经过上述的插入过程后，整个数据结构就从(a)图中的左变成了右。这种类似于套娃的解决方式看是可行，但是总是有<code>出现循环踢出</code>导致放不进 x 的问题。比如上图中的(b)。</p><p>当遇到这种情况时候，说明布谷鸟 hash 已经到了极限情况，应该进行扩容，或者 hash 函数的优化。所以，你再次去看伪代码的时候，你会明白里面的 <code>MaxLoop</code> 的含义是什么了。这个 <code>MaxLoop</code> 的含义就是<strong>为了避免相互踢出的这个过程执行次数太多，设置的一个阈值</strong>。</p><h2 id="3-优化"><a href="#3-优化" class="headerlink" title="3 优化"></a>3 优化</h2><h3 id="3-1-思路"><a href="#3-1-思路" class="headerlink" title="3.1 思路"></a>3.1 思路</h3><p>看过上述的原理，相信依然对其性能和效果存在质疑。这里首先抛出论文中提到的短处。</p><blockquote><p>虽然<code>MaxLoop</code>能够避免太多循环踢出，但是这使得在完美的情况下，也就是没有发生哈希冲突之前，它的空间利用率最高只有 50%。</p></blockquote><p>对于上述的问题，一般会有下面的优化方法：</p><ol><li>增加 hash 函数，这样可以大大降低碰撞的概率，将空间利用率提高到 95%左右。</li><li>在数组的每个位置上挂上多个座位，这样即使两个元素被 hash 在了同一个位置，也可以随意放一个。这种方案的空间利用率只有 85%左右，但是查询效率会很高。</li></ol><h3 id="3-2-特殊的-hash-函数"><a href="#3-2-特殊的-hash-函数" class="headerlink" title="3.2 特殊的 hash 函数"></a>3.2 特殊的 hash 函数</h3><p>论文在市级的优化中，一个很重要的就是构建了特殊的Hash函数。回忆一下布谷鸟 Hash，它存储的是插入元素的原始值，比如 x 会经过两个 hash 函数，如果我们记数组的长度为 L，那么就是这样的：</p><ul><li>p1 = H1(x) % L</li><li>p2 = H2(x) % L</li></ul><p>而布谷鸟过滤器计算位置时候实际上是：</p><ul><li>H1(x) = Hash(x)</li><li>H2(x) = H1(x) $\oplus$ Hash(x’s fingerprint)</li></ul><p>可以看到，虽然有两个Hash函数，但实际上内部只有一个Hash函数构成，在H2中使用了H1和待插入元素 x 的指纹Hash结果，然后再做异或运算。</p><blockquote><p><code>指纹</code>其实就是插入的元素进行一个 Hash 计算，而 Hash 计算的产物就是 几个 bit 位。布谷鸟过滤器里面存储的就是元素的“指纹”。删除数据的时候，也只是抹掉该位置上的“指纹”而已：</p></blockquote><p><strong>注意</strong>：异或运算确保了一个重要的性质：这两个位置具有对偶性。</p><blockquote><p>只要保证 Hash(x’s fingerprint) !=0，那么就可以确保 H2!=H1，也就可以确保，不会出现自己踢自己的死循环问题。</p></blockquote><p><em>为什么要对“指纹”进行一个 hash 计算之后再进行异或运算呢？</em></p><blockquote><p>如果不进行 hash 计算，假设“指纹”的长度是 8bit，那么其对偶位置算出来，距离当前位置最远也才 256。所以，对“指纹”进行哈希处理可确保被踢出去的元素，可以重新定位到哈希表中完全不同的存储桶中，从而减少哈希冲突并提高表利用率。</p></blockquote><p><em>它没有对数组的长度进行取模，那么它怎么保证计算出来的下标一定是落在数组中的呢？</em></p><blockquote><p>其强制数组的长度必须是 2 的指数倍。一定是这样的：10000000…（n个0）。这个限制带来的好处就是，进行异或运算时，可以保证计算出来的下标一定是落在数组中的。</p></blockquote><h3 id="3-3-空间利用率"><a href="#3-3-空间利用率" class="headerlink" title="3.3 空间利用率"></a>3.3 空间利用率</h3><p>由于是对元素进行 hash 计算，那么必然会出现“指纹”相同的情况，也就是会出现误判的情况。没有存储原数据，所以牺牲了数据的准确性，但是只保存了几个 bit，因此提升了空间效率。</p><p>在完美的情况下，也就是没有发生哈希冲突之前，它的空间利用率最高只有 50%。因为没有发生冲突，说明至少有一半的位置是空着的。这个比率还是很低的，前面提到了优化方案，论文中也是基于只有2个Hash的条件下来进行优化的，也即<strong>增加数组的维度</strong>。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter2.png" alt="cuckooFilter2"></p><p>参考上面论文中的图(c)，我们可以发现对数组进行展开，从一维变成了二维，这样每个位置可以放4个元素了。如此，论文中表述到，当 hash 函数固定为 2 个的时候，如果一个下标只能放一个元素，那么空间利用率是 50%。但是如果一个下标可以放 2，4，8 个元素的时候，空间利用率就会飙升到 84%，95%，98%。</p><h3 id="3-4-最后的弊端"><a href="#3-4-最后的弊端" class="headerlink" title="3.4 最后的弊端"></a>3.4 最后的弊端</h3><p>布谷鸟过滤器整个了解下来，看起来一切都是这么的完美。各项指标都比布隆过滤器好，主打的是支持删除的操作。但实际上其依然存在不小的弊端。</p><blockquote><p>对重复数据进行限制：如果需要布谷鸟过滤器支持删除，它必须知道一个数据插入过多少次。不能让同一个数据插入 kb+1 次。其中 k 是 Hash 函数的个数，b 是一个下标的位置能放几个元素。</p></blockquote><p>举例：比如 2 个 hash 函数，一个二维数组，它的每个下标最多可以插入 4 个元素。那么对于同一个元素，最多支持插入 8 次。<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter3.png" alt="cuckooFilter3"></p><p>why 已经插入了 8 次了，如果再次插入一个 why，则会出现循环踢出的问题，直到最大循环次数，然后返回一个 false。想要避免这个问题，就需要维护一个记录表，记录每个元素插入的次数就行了。但是这成本一下子就大了起来。</p><p>虽然布谷鸟过滤器也不算完美无暇，但是从技术上和实际应用上看，这无异又是人类的一次技术迭代。下面的图是各种过滤器的指标对比。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter4.png" alt="cuckooFilter4"></p><p>补充一个冷知识，虽然布谷鸟过滤器在2001年就被大佬 <code>Burton Howard Bloom</code> 提出来了，不少海内外博主一直想要看看这位大佬是和容颜。但是，海内外全网都没有，是一个彻彻底底的低调技术大佬。</p><p><strong>参考文章</strong><br><a href="https://segmentfault.com/a/1190000039156246">布隆，牛逼！布谷鸟，牛逼！</a><br><a href="https://www.163.com/dy/article/G55C599D05372639.html">聊聊Redis布隆过滤器与布谷鸟过滤器？一文避坑</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在了解了布隆过滤器的缺点之后，如果想要解决就可以来学习一下布谷鸟过滤器。其最早是在2001年的论文&lt;a href=&quot;https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf&quot;&gt;《Cuckoo Filter: Practically Better Than Bloom》&lt;/a&gt;中提出的。论文中也很直接的抨击布隆过滤器的缺点，表明自己可以有效支持反向删除操作。&lt;/p&gt;
&lt;h2 id=&quot;2-原理&quot;&gt;&lt;a href=&quot;#2-原理&quot; class=&quot;headerlink&quot; title=&quot;2 原理&quot;&gt;&lt;/a&gt;2 原理&lt;/h2&gt;&lt;p&gt;先来介绍最简单的布谷鸟过滤器的工作原理。假设我们有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个Hash表，T1和T2；&lt;/li&gt;
&lt;li&gt;两个Hash函数，H1和H2。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据结构" scheme="https://www.xiemingzhao.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器(Bloom Filter)</title>
    <link href="https://www.xiemingzhao.com/posts/bloomFilter.html"/>
    <id>https://www.xiemingzhao.com/posts/bloomFilter.html</id>
    <published>2020-05-23T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.656Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在实际工作中，我们经常涉及判断一个对象或者数据是否存在于内存或者数据库。往往大家会想到HashMap，但是这时候有一个问题,存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，可行性就差了。<br>另一方面，如果很多请求是在请求数据库根本不存在的数据,那么数据库就要频繁响应这种不必要的IO查询,如果再多一些,数据库大多数IO都在响应这种毫无意义的请求操作,为了解决这一个问题，过滤器由此诞生！</p><h2 id="2-布隆过滤器"><a href="#2-布隆过滤器" class="headerlink" title="2 布隆过滤器"></a>2 布隆过滤器</h2><blockquote><p>过滤原理：布隆过滤器(Bloom Filter)大概的思路就是,当你请求的信息来的时候,先检查一下你查询的数据我这有没有,有的话将请求压给数据库,没有的话直接返回。</p></blockquote><span id="more"></span><p>布隆过滤器是一个 bit 向量或者说 bit 数组。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter1.jpg" alt="bloomFilter1"></p><p>如图,一个bitmap用于记录,bitmap原始数值全都是0,当一个数据存进来的时候,用三个Hash函数分别计算三次Hash值,并且将bitmap对应的位置设置为1,上图中,bitmap 的1,3,6位置被标记为1,这时候如果一个数据请求过来,依然用之前的三个Hash函数计算Hash值,如果是同一个数据的话,势必依旧是映射到1,3,6位,那么就可以判断这个数据之前存储过,如果新的数据映射的三个位置,有一个匹配不上,加入映射到1,3,7位,由于7位是0,也就是这个数据之前并没有加入进数据库,所以直接返回。</p><h2 id="3-存在的问题"><a href="#3-存在的问题" class="headerlink" title="3 存在的问题"></a>3 存在的问题</h2><h3 id="3-1-误判"><a href="#3-1-误判" class="headerlink" title="3.1 误判"></a>3.1 误判</h3><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter2.jpg" alt="bloomFilter2"></p><p>如上图所示，假如有这么一个情景,放入数据包1时,将bitmap的1,3,6位设置为了1,放入数据包2时将bitmap的3,6,7位设置为了1,此时一个并没有存过的数据包请求3,做三次哈希之后,对应的bitmap位点分别是1,6,7,这个数据之前并没有存进去过,但是由于数据包1和2存入时将对应的点设置为了1,所以请求3也会压到数据库上,这种情况,会随着存入的数据增加而增加。</p><p>所以，布隆过滤器只能够得出<strong>两种结论</strong>：</p><ul><li>当hash对应的位置出现0的时候，就表明一定不存在；</li><li>当全是1的时候，由于误判的可能，只能表明可能存在。</li></ul><h3 id="3-2-无法删除"><a href="#3-2-无法删除" class="headerlink" title="3.2 无法删除"></a>3.2 无法删除</h3><blockquote><p>布隆过滤器无法删除的原因有二：</p><ol><li>由于有误判的可能,并不确定数据是否存在数据库里,例如数据包3。</li><li>当你删除某一个数据包对应位图上的标志后,可能影响其他的数据包。<br>（例如上面例子中,如果删除数据包1,也就意味着会将bitmap1,3,6位设置为0,此时数据包2来请求时,会显示不存在,因为3,6两位已经被设置为0。）</li></ol></blockquote><p>为此还出现了一个改进版的布隆过滤器，即 <code>Counting Bloom filter</code>，可以用来测试元素计数个数是否绝对小于某个阈值，如下图所示。这个过滤器的思路是将布隆过滤器的bitmap更换成数组,当数组某位置被映射一次时就+1,当删除时就-1,这样就避免了普通布隆过滤器删除数据后需要重新计算其余数据包Hash的问题,但实际上也无法解决删除的问题。原因是，由于一开始就存在误判的可能，如果在删除的时候，一个本来不存在的由于误判而进行了删除，就会使得其他原本正确的出现错误计数。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter3.jpg" alt="bloomFilter3"></p><p>这个问题造就了其软肋，布隆过滤器就好比是印迹，来过来就会有痕迹，就算走了也无法清理干净。比如你的系统里本来只留下 1kw 个元素，但是整体上来过了上亿的流水元素，布隆过滤器很无奈，它会将这些流失的元素的印迹也会永远存放在那里。随着时间的流失，这个过滤器会越来越拥挤，直到有一天你发现它的误判率太高了，不得不进行重建。</p><h3 id="3-3-其他问题"><a href="#3-3-其他问题" class="headerlink" title="3.3 其他问题"></a>3.3 其他问题</h3><p><strong>查询性能弱</strong><br>是因为布隆过滤器需要使用多个 hash 函数探测位图中多个不同的位点，这些位点在内存上跨度很大，会导致 CPU 缓存行命中率低。</p><p><strong>空间效率低</strong><br>是因为在相同的误判率下，布谷鸟过滤器的空间利用率要明显高于布隆，空间上大概能节省 40% 多。不过布隆过滤器并没有要求位图的长度必须是 2 的指数，而布谷鸟过滤器必须有这个要求。从这一点出发，似乎布隆过滤器的空间伸缩性更强一些。</p><h3 id="3-4-参数选择"><a href="#3-4-参数选择" class="headerlink" title="3.4 参数选择"></a>3.4 参数选择</h3><p>布隆过滤器在构建时，有两个重要的参数，一个是Hash函数的个数k，另一个是 bit 数组的大小m。</p><p>过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。<br>另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。</p><p>我们参考如下一个图：<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter4.png" alt="bloomFilter4"></p><p>其中：</p><blockquote><p>k是Hash函数的个数；<br>m是布隆过滤器数组的长度；<br>n是需要插入元素的个数；<br>p是误报率。</p></blockquote><h3 id="3-5-误报率"><a href="#3-5-误报率" class="headerlink" title="3.5 误报率"></a>3.5 误报率</h3><p>如果 m 是位数组中的比特数，则在插入元素期间某一特定比特位不被某个哈希函数设置为 1 的概率是：</p><script type="math/tex; mode=display">1 - \frac{1}{m}</script><p>如果哈希函数的数量是 k，则通过 k 个哈希函数都未将该位设置为 1 的概率是：</p><script type="math/tex; mode=display">(1 - \frac{1}{m})^k</script><p>那么，如果我们插入了 n 个元素，某个位为1的概率，我们利用反向概率就可以求得为：</p><script type="math/tex; mode=display">1 - (1 - \frac{1}{m})^{kn}</script><p>现在我们要判断一个元素是否在集合中，假设这个元素本不在集合中，理论上来讲，经过 k 个哈希函数计算后得到的位数组的 k 个位置的值都应该是 0，如果发生了误判，即这 k 个位置的值都为 1，这就对应着误判率如下：</p><script type="math/tex; mode=display">p=(1 - [1 - \frac{1}{m}]^{kn})^k \approx (1 - e^{-\frac{kn}{m}})^k</script><p>参考极限公式：</p><script type="math/tex; mode=display">\lim_{x \to \infty} (1 - \frac{1}{x})^{-x}=e</script><h3 id="3-6-最优的k"><a href="#3-6-最优的k" class="headerlink" title="3.6 最优的k"></a>3.6 最优的k</h3><p>这里存在两个互斥：</p><ul><li>如果哈希函数的个数多，那么在对一个不属于集合的元素进行查询时得到0的概率就大；</li><li>一方面，如果哈希函数的个数少，那么位数组中的0就多。</li></ul><p>为了得到最优的哈希函数个数，我们需要根据上一节中的错误率公式进行计算。<br>我们首先对误判率两边取对数：</p><script type="math/tex; mode=display">ln(p) = k ln(1-e^{-\frac{kn}{m}})</script><p>我们的目的是求最优的k，且最优就表明误判率p要是最小，所以两边对k求导：</p><script type="math/tex; mode=display">\frac{1}{p} \cdot p' = ln(1 - e^{-\frac{nk}{m}}) + \frac{k e^{-\frac{nk}{m}} \frac{n}{m}}{1 - e^{-\frac{nk}{m}}}</script><p>另$p’=0$就有：</p><script type="math/tex; mode=display">ln(1 - e^{-\frac{nk}{m}}) + \frac{k e^{-\frac{nk}{m}} \frac{n}{m}}{1 - e^{-\frac{nk}{m}}} = 0</script><script type="math/tex; mode=display">(1 - e^{-\frac{nk}{m}}) \cdot ln(1 - e^{-\frac{nk}{m}}) = -k e^{-\frac{nk}{m}} \frac{n}{m}</script><script type="math/tex; mode=display">(1 - e^{-\frac{nk}{m}}) \cdot ln(1 - e^{-\frac{nk}{m}}) = e^{-\frac{nk}{m}}(-\frac{nk}{m})</script><p>所以：</p><script type="math/tex; mode=display">1 - e^{-\frac{nk}{m}} = e^{-\frac{nk}{m}}</script><script type="math/tex; mode=display">e^{-\frac{nk}{m}} = 1/2</script><script type="math/tex; mode=display">\frac{kn}{m} = ln2</script><script type="math/tex; mode=display">k = \frac{m}{n}ln2</script><h3 id="3-7-最优的m"><a href="#3-7-最优的m" class="headerlink" title="3.7 最优的m"></a>3.7 最优的m</h3><p>根据上面求出的最优k，我们带入误判率p的公式就有：</p><script type="math/tex; mode=display">p=(1 - e^{-\frac{kn}{m}})^k=(1 - e^{-(\frac{m}{n}ln2)\frac{n}{m}})^k=\frac{1}{2}^k</script><p>将最优的k代入：</p><script type="math/tex; mode=display">p = 2^{-ln2 \cdot\frac{m}{n}}</script><p>两边同时取ln就有：</p><script type="math/tex; mode=display">lnp = ln2 \cdot (-ln2)\frac{m}{n}</script><script type="math/tex; mode=display">m = -\frac{n \cdot lnp}{(ln2)^2}</script><h3 id="3-8-估算-BF-的元素数量n"><a href="#3-8-估算-BF-的元素数量n" class="headerlink" title="3.8 估算 BF 的元素数量n"></a>3.8 估算 BF 的元素数量n</h3><script type="math/tex; mode=display">n = -\frac{m}{k}ln(1 - \frac{t}{m})</script><p>其中 n 是估计 BF 中的元素个数，t 是位数组中被置为 1 的位的个数。</p><h2 id="4-代码参考"><a href="#4-代码参考" class="headerlink" title="4 代码参考"></a>4 代码参考</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mmh3</span><br><span class="line"><span class="keyword">from</span> bitarray <span class="keyword">import</span> bitarray</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># zhihu_crawler.bloom_filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Implement a simple bloom filter with murmurhash algorithm.</span></span><br><span class="line"><span class="comment"># Bloom filter is used to check wether an element exists in a collection, and it has a good performance in big data situation.</span></span><br><span class="line"><span class="comment"># It may has positive rate depend on hash functions and elements count.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BIT_SIZE = <span class="number">5000000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BloomFilter</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Initialize bloom filter, set size and all bits to 0</span></span><br><span class="line">        bit_array = bitarray(BIT_SIZE)</span><br><span class="line">        bit_array.setall(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.bit_array = bit_array</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Add a url, and set points in bitarray to 1 (Points count is equal to hash funcs count.)</span></span><br><span class="line">        <span class="comment"># Here use 7 hash functions.</span></span><br><span class="line">        point_list = <span class="variable language_">self</span>.get_postions(url)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> point_list:</span><br><span class="line">            <span class="variable language_">self</span>.bit_array[b] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">contains</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Check if a url is in a collection</span></span><br><span class="line">        point_list = <span class="variable language_">self</span>.get_postions(url)</span><br><span class="line"></span><br><span class="line">        result = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> point_list:</span><br><span class="line">            result = result <span class="keyword">and</span> <span class="variable language_">self</span>.bit_array[b]</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_postions</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Get points positions in bit vector.</span></span><br><span class="line">        point1 = mmh3.<span class="built_in">hash</span>(url, <span class="number">41</span>) % BIT_SIZE</span><br><span class="line">        point2 = mmh3.<span class="built_in">hash</span>(url, <span class="number">42</span>) % BIT_SIZE</span><br><span class="line">        point3 = mmh3.<span class="built_in">hash</span>(url, <span class="number">43</span>) % BIT_SIZE</span><br><span class="line">        point4 = mmh3.<span class="built_in">hash</span>(url, <span class="number">44</span>) % BIT_SIZE</span><br><span class="line">        point5 = mmh3.<span class="built_in">hash</span>(url, <span class="number">45</span>) % BIT_SIZE</span><br><span class="line">        point6 = mmh3.<span class="built_in">hash</span>(url, <span class="number">46</span>) % BIT_SIZE</span><br><span class="line">        point7 = mmh3.<span class="built_in">hash</span>(url, <span class="number">47</span>) % BIT_SIZE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [point1, point2, point3, point4, point5, point6, point7]</span><br></pre></td></tr></table></figure><p><strong>参考文章：</strong><br><a href="https://www.cnblogs.com/cpselvis/p/6265825.html">布隆过滤器(Bloom Filter)的原理和实现</a><br><a href="https://www.163.com/dy/article/G55C599D05372639.html">聊聊Redis布隆过滤器与布谷鸟过滤器？一文避坑</a><br><a href="https://cloud.tencent.com/developer/article/1136056">Counting Bloom Filter 的原理和实现</a><br><a href="https://zhuanlan.zhihu.com/p/43263751">详解布隆过滤器的原理，使用场景和注意事项</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在实际工作中，我们经常涉及判断一个对象或者数据是否存在于内存或者数据库。往往大家会想到HashMap，但是这时候有一个问题,存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，可行性就差了。&lt;br&gt;另一方面，如果很多请求是在请求数据库根本不存在的数据,那么数据库就要频繁响应这种不必要的IO查询,如果再多一些,数据库大多数IO都在响应这种毫无意义的请求操作,为了解决这一个问题，过滤器由此诞生！&lt;/p&gt;
&lt;h2 id=&quot;2-布隆过滤器&quot;&gt;&lt;a href=&quot;#2-布隆过滤器&quot; class=&quot;headerlink&quot; title=&quot;2 布隆过滤器&quot;&gt;&lt;/a&gt;2 布隆过滤器&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;过滤原理：布隆过滤器(Bloom Filter)大概的思路就是,当你请求的信息来的时候,先检查一下你查询的数据我这有没有,有的话将请求压给数据库,没有的话直接返回。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据结构" scheme="https://www.xiemingzhao.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>一致性哈希算法(Consistent Hashing)</title>
    <link href="https://www.xiemingzhao.com/posts/consistentHash.html"/>
    <id>https://www.xiemingzhao.com/posts/consistentHash.html</id>
    <published>2020-04-07T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.656Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>一致性哈希算法(Consistent Hashing)在分布式系统的应用还是十分广泛的。例如随着业务的扩展，流量的剧增，单体项目逐渐划分为分布式系统。对于经常使用的数据，我们可以使用Redis作为缓存机制，减少数据层的压力。因此，重构后的系统架构如下图所示：</p><span id="more"></span><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash1.png" alt="consistentHash1"></p><p>这个时候一般有两种方案：</p><ol><li><p>每个机器缓存全量数据；</p><blockquote><p>如此虽然能保证请求打到任何一台机器都可以，但是冗余性巨高；</p></blockquote></li><li><p>每个机器只缓存一部分，分布式存储；</p><blockquote><p>如此需要保证对应的请求打到对应的机器上，否则查询结果为空，轮训查询的话效率极低不靠谱；</p></blockquote></li></ol><h2 id="2-原始Hash方案"><a href="#2-原始Hash方案" class="headerlink" title="2 原始Hash方案"></a>2 原始Hash方案</h2><p>这时候，自然而然想到一个方案，那就是使用hash算法 例如，有三台Redis，对于每次的访问都可以通过计算hash来求得hash值。 如公式 h=hash(key)%3，我们把Redis编号设置成0,1,2来保存对应hash计算出来的值，h的值等于Redis对应的编号。</p><p>但是，使用上述HASH算法进行缓存时，会出现一些缺陷。例如：</p><ul><li>缓存的3台缓存服务器由于故障使得机器数量减少；</li><li>缓存量的增加需要新增使得缓存机器增加。</li></ul><p>如此缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义，由于大量缓存在同一时间失效，造成了缓存的雪崩，此时前端缓存已经无法起到承担部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述HASH算法本身的缘故，使用取模法进行缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。</p><h2 id="3-一致性Hash算法"><a href="#3-一致性Hash算法" class="headerlink" title="3 一致性Hash算法"></a>3 一致性Hash算法</h2><p>根据上述我们知道一致性Hash算法需要解决：</p><ol><li>当缓存服务器数量发生变化时，会引起缓存的雪崩，可能会引起整体系统压力过大而崩溃（大量缓存同一时间失效）。</li><li>当缓存服务器数量发生变化时，几乎所有缓存的位置都会发生改变，尽量减少受影响的缓存。</li></ol><p>其实，一致性哈希算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性哈希算法是对2^32取模。</p><p>首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆，示意图如下：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash2.png" alt="consistentHash2"></p><p>我们把这个由2的32次方个点组成的圆环称为hash环。</p><p>假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产环境中，这三台服务器肯定有自己的IP地址。</p><p><strong>hash（服务器A的IP地址） %  2^32</strong></p><p>通过上述公式算出的结果一定是一个0到2^32-1之间的一个整数，我们就用算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环上必定有一个点与这个整数对应，而我们刚才已经说明，使用这个整数代表服务器A，那么，服务器A就可以映射到这个环上，用下图示意：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash3.png" alt="consistentHash3"></p><p>同理，服务器B与服务器C也可以通过相同的方法映射到上图中的hash环中</p><p><strong>hash（服务器B的IP地址） %  2^32</strong></p><p><strong>hash（服务器C的IP地址） %  2^32</strong></p><p>通过上述方法，可以将服务器B与服务器C映射到上图中的hash环上，示意图如下：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash4.png" alt="consistentHash4"></p><p>我们通过上述方法，把缓存服务器映射到了hash环上，那么使用同样的方法，我们也可以将需要缓存的对象映射到hash环上。</p><p>假设，我们需要使用缓存服务器缓存图片，而且我们仍然使用图片的名称作为找到图片的key，那么我们使用如下公式可以将图片映射到上图中的hash环上。</p><p><strong>hash（图片名称） %  2^32</strong></p><p>映射后的示意图如下，下图中的橘黄色圆形表示图片：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash5.png" alt="consistentHash5"></p><p>现在服务器与图片都被映射到了hash环上，上图中的图片将会被缓存到服务器A上，为什么呢？因为从图片的位置开始，沿顺时针方向遇到的第一个服务器就是A服务器，所以，上图中的图片将会被缓存到服务器A上，如下图所示：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash6.png" alt="consistentHash6"></p><p>一致性哈希算法就是通过这种方法，判断一个对象应该被缓存到哪台服务器上的，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一张图片必定会被缓存到固定的服务器上，那么，当下次想要访问这张图片时，只要再次使用相同的算法进行计算，即可算出这个图片被缓存在哪个服务器上，直接去对应的服务器查找对应的图片即可。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash7.png" alt="consistentHash7"></p><p>1号、2号图片将会被缓存到服务器A上，3号图片将会被缓存到服务器B上，4号图片将会被缓存到服务器C上。</p><h2 id="4-一致性哈希算法的优点"><a href="#4-一致性哈希算法的优点" class="headerlink" title="4 一致性哈希算法的优点"></a>4 一致性哈希算法的优点</h2><p>一致性哈希算法如何解决之前出现的问题呢？</p><p>假设，服务器B出现了故障，我们现在需要将服务器B移除，那么，我们将上图中的服务器B从hash环上移除即可，移除服务器B以后示意图如下：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash8.png" alt="consistentHash8"></p><p>在服务器B未移除时，图片3应该被缓存到服务器B中，可是当服务器B移除以后，按照之前描述的一致性哈希算法的规则，图片3应该被缓存到服务器C中，因为从图片3的位置出发，沿顺时针方向遇到的第一个缓存服务器节点就是服务器C，也就是说，如果服务器B出现故障被移除时，图片3的缓存位置会发生改变：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash9.png" alt="consistentHash9"></p><p>但是，图片4仍然会被缓存到服务器C中，图片1与图片2仍然会被缓存到服务器A中，这与服务器B移除之前并没有任何区别，这就是一致性哈希算法的优点，如果使用之前的hash算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分缓存会失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一时间集中到后端服务器上。</p><h2 id="5-hash环的偏斜"><a href="#5-hash环的偏斜" class="headerlink" title="5 hash环的偏斜"></a>5 hash环的偏斜</h2><p>在介绍一致性哈希的概念时，我们理想化的将3台服务器均匀的映射到了hash环上，如下图所示：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash4.png" alt="consistentHash10"></p><p>在实际的映射中，服务器可能会被映射成如下模样。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash11.png" alt="consistentHash11"></p><p>如果服务器被映射成上图中的模样，那么被缓存的对象很有可能大部分集中缓存在某一台服务器上，如下图所示。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash12.png" alt="consistentHash12"></p><p>上图中，1号、2号、3号、4号、6号图片均被缓存在了服务器A上，只有5号图片被缓存在了服务器B上，服务器C上甚至没有缓存任何图片，如果出现上图中的情况，A、B、C三台服务器并没有被合理的平均的充分利用，缓存分布的极度不均匀，而且，如果此时服务器A出现故障，那么失效缓存的数量也将达到最大值，在极端情况下，仍然有可能引起系统的崩溃，上图中的情况则被称之为hash环的偏斜。当然也有办法解决此问题的。</p><h2 id="6-虚拟节点"><a href="#6-虚拟节点" class="headerlink" title="6 虚拟节点"></a>6 虚拟节点</h2><p>话接上文，由于我们只有3台服务器，当我们把服务器映射到hash环上的时候，很有可能出现hash环偏斜的情况，当hash环偏斜以后，缓存往往会极度不均衡的分布在各服务器上，聪明如你一定已经想到了，如果想要均衡的将缓存分布到3台服务器上，最好能让这3台服务器尽量多的、均匀的出现在hash环上，但是，真实的服务器资源只有3台，我们怎样凭空的让它们多起来呢，没错，就是凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。加入虚拟节点以后的hash环如下。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/consistentHash13.png" alt="consistentHash13"></p><p>虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。</p><p>从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了，上图中，1号、3号图片被缓存在服务器A中，5号、4号图片被缓存在服务器B中，6号、2号图片被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点，以便减小hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。</p><p><strong>参考文章</strong><br><a href="https://www.zsythink.net/archives/1182">白话解析：一致性哈希算法 consistent hashing</a><br><a href="https://juejin.cn/post/6844903750860013576">5分钟理解一致性哈希算法</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;一致性哈希算法(Consistent Hashing)在分布式系统的应用还是十分广泛的。例如随着业务的扩展，流量的剧增，单体项目逐渐划分为分布式系统。对于经常使用的数据，我们可以使用Redis作为缓存机制，减少数据层的压力。因此，重构后的系统架构如下图所示：&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="Hash" scheme="https://www.xiemingzhao.com/tags/Hash/"/>
    
  </entry>
  
  <entry>
    <title>HNSW算法详解</title>
    <link href="https://www.xiemingzhao.com/posts/hnswAlgo.html"/>
    <id>https://www.xiemingzhao.com/posts/hnswAlgo.html</id>
    <published>2020-03-11T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.653Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在向量检索领域，HNSW算法算是有比较重要的一席之地，很多地方都会用到，那么本文主要是对其具体构建的细节逻辑和背后的思想进行一个阐述和介绍。</p><p><a href="https://arxiv.org/abs/1603.09320">Hierarchical Navigable Small World Graphs (HNSW)</a> 是Yury A. Malkov提出的一种基于图索引的方法，它是Yury A. Malkov在他本人之前工作<code>NSW</code>上一种改进。通过采用层状结构，将边按特征半径进行分层，使每个顶点在所有层中平均度数变为常数，从而将NSW的计算复杂度由多重对数(Polylogarithmic)复杂度降到了对数(logarithmic)复杂度。</p><h2 id="2-朴素思想"><a href="#2-朴素思想" class="headerlink" title="2 朴素思想"></a>2 朴素思想</h2><p>这里我们以一个小的场景为例来开始，假设我们现在有13个2维数据向量，我们把这些向量放在了一个平面直角坐标系内，隐去坐标系刻度，它们的位置关系如下图所示。</p><span id="more"></span><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw1.png" alt="hnsw1"></p><p><strong>朴素查找法</strong>：</p><ol><li>有一个很容易的的朴素想法，把某些点和点之间连上线，构成一个查找图，存下来备用；</li><li>当我想查找与粉色点最近的一点时，我从任意一个黑色点出发，计算它和粉色点的距离，与这个任意黑色点有连接关系的点我们称之为“友点”（直译）；</li><li>然后我要计算这个黑色点的所有“友点”与粉色点的距离，从所有“友点”中选出与粉色点最近的一个点，把这个点作为下一个进入点；</li><li>继续按照上面的步骤查找下去。如果当前黑色点对粉色点的距离比所有“友点”都近，终止查找，这个黑色点就是我们要找的离粉色点最近的点。</li></ol><p>整个思想就是找出当前点及其邻近点雨目标点之间的最近的那个，然后把它当作当前点，再次循环。举个例子。</p><blockquote><p>目标：我们要查找与粉色点最近的点。<br>步骤：</p><ol><li>从任意一个黑色点出发，这里我们随便选个C点吧，计算一下C点和粉色点的距离，存下来备用;</li><li>再计算C点的所有友点（A，I，B）与粉色点的距离（计算距离和度量的方式有多种，这里我们采用欧氏距离，就是二维物理空间上的“近和远”），我们计算得出B与粉色点的距离最近，而且B点距离粉色点的距离比C点距离粉色点的距离（前面算过）更近l;</li><li>所以我们下面用B点继续查找。B点距离粉色点的距离保存下来，B点的友点是E，A，C，I，H，分别计算它们与粉色点的距离，得到E点与粉色点距离最近，且E点比B点距离粉色点还要近，所以我们选择E点作为下一个查找点。</li><li>E点的友点是J，B，D，G，这时我们发现J点的与粉色点的距离最近，但是，but，however，J点的距离粉色点的距离比E点还要远，所以满足了终止查找的条件，因此我们返回E点。</li></ol></blockquote><p><strong>之所以叫朴素想法就是因为它的缺点非常多:</strong></p><ol><li>首先，我们发现图中的K点是无法被查询到的，因为K点没有友点</li><li>其次，如果我们要查找距离粉色点最近的两个点，而这两个近点之间如果没有连线，那么将大大影响效率（比如L和E点，如果L和E有连线，那么我们可以轻易用上述方法查出距离粉色点最近的两个点）;</li><li>最后D点真的需要这么多“友点”吗？谁是谁的友点应该怎么确定呢？</li></ol><p><strong>相关解决办法：</strong></p><ol><li>关于K点的问题，我们规定在构图时所有数据向量节点都必须有友点。</li><li>关于L和E的问题，我们规定在构图时所有距离相近（相似）到一定程度的向量必须互为友点。</li><li>关于D点问题，权衡构造这张图的时间复杂度，我们规定尽量减少每个节点的“友点”数量。</li></ol><h2 id="3-NSW算法"><a href="#3-NSW算法" class="headerlink" title="3 NSW算法"></a>3 NSW算法</h2><p>上述最后部分针对各个问题的解决办法促成了NSW算法的诞生。在图论中有一个很好的剖分法则专门解决上一节中提到的朴素想法的缺陷问题—-<strong>德劳内（Delaunay）三角剖分算法</strong>，这个算法可以达成如下要求：</p><ol><li>图中每个点都有“友点”。</li><li>相近的点都互为“友点”。</li><li>图中所有连接（线段）的数量最少。效果如下图。</li></ol><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw2.png" alt="hnsw2"></p><p>如上图所示就是一个经典的满足上述三个条件的德劳内三角网图。但NSW算法并没有采用德劳内三角剖分法来构成德劳内三角网图，原因是：</p><ul><li>德劳内三角剖分构图算法时间复杂度太高，换句话说，构图太耗时。</li><li>德劳内三角形的查找效率并不一定最高，如果初始点和查找点距离很远的话我们需要进行多次跳转才能查到其临近点，需要“<strong>高速公路</strong>”机制（Expressway mechanism, 这里指部分远点之间拥有线段连接，以便于快速查找）。</li></ul><p><strong>在理想状态下，我们的算法不仅要满足上面三条需求，还要算法复杂度低，同时配有高速公路机制的构图法。</strong></p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw3.png" alt="hnsw3"></p><p>如上图所示，这是NSW论文中给出的一张满足条件的网络图，可以发现黑色是近邻点的连线，红色线就是“高速公路机制”了。我们从enter point点进入查找，查找绿色点临近节点的时候，就可以用过红色连线“高速公路机制”快速查找到结果。</p><p><strong>NSW朴素构图算法</strong>：</p><ol><li>向图中逐个插入点，点的选取上随机的；</li><li>插入一个全新点时，通过朴素想法中的朴素查找法查找到与这个全新点最近的m个点（通过计算“友点”和待插入点的距离来判断下一个进入点是哪个点，m由用户设置）；</li><li>连接全新点到m个点的连线。</li></ol><p>仔细分析这个简单的构图方法，其中有一个精妙之处就是构图算法是逐点随机插入的，这就意味着<strong>在图构建的早期，很有可能构建出“高速公路”。</strong>一个点，越早插入就越容易形成与之相关的“高速公路”连接，越晚插入就越难形成与之相关的“高速公路”连接。这种方法<strong>不仅降低了构图算法时间复杂度的同时还带来了数量有限的“高速公路”，加速了查找。</strong></p><h3 id="NSW构图示例"><a href="#NSW构图示例" class="headerlink" title="NSW构图示例"></a>NSW构图示例</h3><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw4.png" alt="hnsw4"></p><p>如上图所示就是一个构建好的NSW网络图，我们说明一下过程：</p><ol><li>我们对7个二维点进行构图，用户设置m=3（每个点在插入时找3个紧邻友点）。</li><li>首先初始点是A点（随机出来的），A点插入图中只有它自己，所以无法挑选“友点”。</li><li>然后是B点，B点只有A点可选，所以连接BA，此为第1次构造。</li><li>然后插入F点，F只有A和B可以选，所以连接FA，FB，此为第2此构造。</li><li>然后插入了C点，同样地，C点只有A，B，F可选，连接CA，CB，CF，此为第3次构造。</li><li>重点来了，然后插入了E点，E点在A，B，F，C中只能选择3个点（m=3）作为“友点”，根据我们前面讲规则，要选最近的三个，怎么确定最近呢？朴素查找！从A，B，C，F任意一点出发，计算出发点与E的距离和出发点的所有“友点”和E的距离，选出最近的一点作为新的出发点，如果选出的点就是出发点本身，那么看我们的m等于几，如果不够数，就继续找第二近的点或者第三近的点，本着不找重复点的原则，直到找到3个近点为止。由此，我们找到了E的三个近点，连接EA，EC，EF，此为第四次构造。</li><li>第5次构造和第6次与E点的插入一模一样，都是在“现成”的图中查找到3个最近的节点作为“友点”，并做连接。</li></ol><p>当图构建完了，请关注E点和A点的连线，如果我再这个图的基础上再插入6个点，这6个点有3个和E很近，有3个和A很近，那么距离E最近的3个点中没有A，距离A最近的3个点中也没有E，但因为A和E是构图早期添加的点，A和E有了连线，我们管这种连线叫“高速公路”，在查找时可以提高查找效率</p><blockquote><p><strong>NSW算法的优化</strong></p><ul><li>在查找的过程中，为了<strong>提高效率</strong>，我们可以建立一个废弃列表，在一次查找任务中遍历过的点不再遍历。在一次查找中，已经计算过这个点的所有友点距离查找点的距离，并且已经知道正确的跳转方向了，这些结果是唯一的，没有必要再去做走这个路径，因为这个路径会带给我们同样的重复结果，没有意义。</li><li>在查找过程中，为了<strong>提高准确度</strong>，我们可以建立一个动态列表，把距离查找点最近的n个点存储在表中，并行地对这n个点进行同时计算“友点”和待查找点的距离，在这些“友点”中选择n个点与动态列中的n个点进行并集操作，在并集中选出n个最近的友点，更新动态列表。</li></ul></blockquote><p>由于插入过程之前会先进行查找，所以优化查找过程就是在优化插入过程。所以我们先来看<strong>NSW查找步骤</strong>。设待查找q点的m个近邻点：</p><ol><li>随机选一个点作为初始进入点，建立空废弃表g和动态列表c，g是变长的列表，c是定长为s的列表（s&gt;m）,将初始点放入动态列表c（附上初始点和待查找q的距离信息），制作动态列表的影子列表c’。</li><li>对动态列表c中的所有点并行找出其“友点”，查看这些“友点”是否存储在废弃表g中，如果存在，则丢弃，如不存在，将这些   剩余“友点”记录在废弃列表g中（以免后续重复查找，走冤枉路）。</li><li>并行计算这些剩余“友点”距离待查找点q的距离，将这些点及其各自的距离信息放入c。</li><li>对动态列表c去重，然后按距离排序（升序），储存前s个点及其距离信息。</li><li>查看动态列表c和c’是否一样，如果一样，结束本次查找，返回动态列表中前m个结果。如果不一样，将c’的内容更新为c的    内容，执行第2步。</li></ol><p>插入算法就是先用查找算法查找到m个（用户设置）与待插入点最近的点并连接。</p><h2 id="4-跳表结构"><a href="#4-跳表结构" class="headerlink" title="4 跳表结构"></a>4 跳表结构</h2><p>设有有序链表，名叫sorted_link，里面有n个节点，每个节点是一个整数。</p><ul><li>我们从表头开始查找，查找第t（0&lt;t&lt;n）个节点需要跳转几次？答：t-1次（没错，我是从1开始数的）。</li><li>把n个节点分成n次查找的需求，都查找一遍，需要跳转几次？答：（0+1+2+3+…..+（n-1））次。</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw5.png" alt="hnsw5"></p><p>但上图所示的已经不是一个有序链表了，这是三个有序链表+分层连接指针构成的跳表了。看这张示意图就能明白它的查找过程，先查第一层，然后查第二层，然后查第三层，然后找到结果。如果把上段所描述的名字叫sorted_link的链表建立成这样的跳表，那么把sorted_link中的所有元素都查一遍还需要花费（0+1+2+3+…..+（n-1））次吗？当然不需要。</p><blockquote><p><strong>跳表怎么构建呢？</strong><br>抛硬币随机生成。</p><ol><li>对于sorted_link链表中的每个节点进行抛硬币，如抛正，则该节点进入上一层有序链表，每个sorted_link中的节点有50%的概率进入上一层有序链表。</li><li>将上一层有序链表中和sorted_link链表中相同的元素做一一对应的指针链接。</li><li>再从sorted_link上一层链表中再抛硬币，sorted_link上一层链表中的节点有50%的可能进入最表层，相当于sorted_link中的每个节点有25%的概率进入最表层。以此类推。</li></ol></blockquote><p>这种四件简单来看就是每层保留一定比例的节点，越往上层越少，相邻两层对应点相连。就保证了表层是“高速通道”，底层是精细查找，这个思想被应用到了NSW算法中，变成了HNSW。</p><h2 id="5-HNSW算法"><a href="#5-HNSW算法" class="headerlink" title="5 HNSW算法"></a>5 HNSW算法</h2><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/hnsw6.png" alt="hnsw6"></p><p>直接上图，现在看到这张图应该不陌生了。其中第0层中，是数据集中的所有点，你需要设置一个常数ml，通过公式floor(-ln(uniform(0,1)) x ml)来计算这个点可以深入到第几层。公式中x是乘号，floor（）的含义是向下取整，uniform（0,1）的含义是在均匀分布中随机取出一个值，ln（）表示取对数。</p><blockquote><p><strong>梳理一下它的查找过程</strong>:</p><ol><li>从表层（上图中编号为Layer=2）任意点开始查找，选择进入点最邻近的一些友点，把它们存储在定长的动态列表中，别忘了把它们也同样在废弃表中存一份，以防后面走冤枉路。</li><li>一般地，在第x次查找时，先计算动态列表中所有点的友点距离待查找点（上图绿色点）的距离，在废弃列表中记录过的友点不要计算，计算完后更新废弃列表，不走冤枉路;</li><li>再把这些计算完的友点存入动态列表，去重排序，保留前k个点，看看这k个点和更新前的k个点是不是一样的，如果不是一样的，继续查找，如果是一样的，返回前m个结果。</li></ol><p><strong>插入构图的时候</strong>:<br>先计算这个点可以深入到第几层，在每层的NSW图中查找t个最紧邻点，分别连接它们，对每层图都进行如此操作。</p></blockquote><p><strong>算法参数</strong></p><ol><li>首先，插入时的动态列表c的大小，它的大小直接影响了插入效率，和构图的质量，size越大，图的质量越高，构图和查找效率就越低。</li><li>其次，一个节点至少有几个“友点”，“友点”越多，图的质量越高，查找效率越低。</li><li>作者在论文中还提到了“max友点连接数”这个参数，设置一个节点至多有多少友点，来提高查找效率，但是设的太小又会影响图的质量，权衡着来。</li><li>上一段中的ml也是你来控制的，设置的大了，层数就少，内存消耗少，但严重影响效率，太大了会严重消耗内存和构图时间。</li></ol><p>在论文中，作者将查找状态下的<strong>动态列表长度和插入状态下的动态列表长度</strong>做了区分，你可以通过调整他们来实现“<strong>精构粗找</strong>”或者“<strong>精找粗构</strong>”。</p><p><strong>参考文章</strong><br><a href="http://yongyuan.name/blog/vector-ann-search.html">图像检索：向量索引</a><br><a href="https://blog.csdn.net/u011233351/article/details/85116719">一文看懂HNSW算法理论的来龙去脉</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在向量检索领域，HNSW算法算是有比较重要的一席之地，很多地方都会用到，那么本文主要是对其具体构建的细节逻辑和背后的思想进行一个阐述和介绍。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.09320&quot;&gt;Hierarchical Navigable Small World Graphs (HNSW)&lt;/a&gt; 是Yury A. Malkov提出的一种基于图索引的方法，它是Yury A. Malkov在他本人之前工作&lt;code&gt;NSW&lt;/code&gt;上一种改进。通过采用层状结构，将边按特征半径进行分层，使每个顶点在所有层中平均度数变为常数，从而将NSW的计算复杂度由多重对数(Polylogarithmic)复杂度降到了对数(logarithmic)复杂度。&lt;/p&gt;
&lt;h2 id=&quot;2-朴素思想&quot;&gt;&lt;a href=&quot;#2-朴素思想&quot; class=&quot;headerlink&quot; title=&quot;2 朴素思想&quot;&gt;&lt;/a&gt;2 朴素思想&lt;/h2&gt;&lt;p&gt;这里我们以一个小的场景为例来开始，假设我们现在有13个2维数据向量，我们把这些向量放在了一个平面直角坐标系内，隐去坐标系刻度，它们的位置关系如下图所示。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="向量检索" scheme="https://www.xiemingzhao.com/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>向量检索算法</title>
    <link href="https://www.xiemingzhao.com/posts/vecRetrieval.html"/>
    <id>https://www.xiemingzhao.com/posts/vecRetrieval.html</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.657Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1 基础知识"></a>1 基础知识</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><p>在深度学习大兴的时代，embeding无处不在，不论是在搜索推荐领域还是cv领域亦或nlp领域。俗话说得好，万物皆可embeding，那么对于embeding化后的对象我们在做topk检索/召回的时候怎么提效呢？毕竟候选集往往都是在千万级或者亿级的时候，计算量是相当大的。这时候，向量检索算法就发挥了作用。在我理解的向量检索一般可以分为两个方向，一种是精确化检索，需要遍历每个样本，计算量往往很大，基本上被淘汰了。另一种就是近似检索，学术上对应的专有名词叫Approximate Nearest Neighbor Search (ANNS)，即近似最近邻搜索。为什么是近似，而不是我们想要的精确？这就是精度与时间、算力资源的折中，采用了牺牲精度换取时间和空间的方式，从海量的样本中实时获取跟查询最相似的样本。</p><span id="more"></span><h3 id="1-2-向量距离"><a href="#1-2-向量距离" class="headerlink" title="1.2 向量距离"></a>1.2 向量距离</h3><p>深度学习时代用的最多的就是embeding向量，而向量的基础形式往往就是一个数组，我们一般所需要的任务就是找出按照候选集中各个向量与目标向量的相似度倒排后的topK个。既然谈到向量之间的相似度，那么就要引入向量间的距离来进行刻画了。在实际中常用的向量距离主要有以下四种：</p><ol><li><p>欧式距离(Euclidean Distance)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d_&#123;12&#125; = \sqrt&#123;\sum_&#123;k=1&#125;^n(x_&#123;1k&#125;-x_&#123;2k&#125;)^2&#125;</span><br></pre></td></tr></table></figure><p>两点间的真实距离，值越小，说明距离越近；</p></li><li><p>夹角余弦(Cosine)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cos \theta = \frac&#123;x_1x_2 + y_1y_2&#125;&#123;\sqrt&#123;x_1^2 + y_1^2&#125; \sqrt&#123;x_2^2+y_2^2&#125;&#125;</span><br></pre></td></tr></table></figure><p>就是两个向量围成夹角的 cosine 值，cosine 值越大，越相似；</p></li><li><p>汉明距离(Hamming distance)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d(x,y)=\sum x_i \oplus y_i</span><br></pre></td></tr></table></figure><p>一般作用于二值化向量，二值化的意思是向量的每一列只有 0 或者 1 两种取值。汉明距离的值就两个向量每列数值的异或和，值越小说明越相似，一般用于图片识别；</p></li><li><p>杰卡德相似系数(Jaccard similarity coefficient)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">J(A,B)=\frac&#123;A \cap B&#125;&#123;A \cup B&#125;</span><br></pre></td></tr></table></figure><p>把向量作为一个集合，所以它可以不仅仅是数字代表，也可以是其他编码，比如词，该值越大说明越相似，一般用于相似语句识别；</p></li></ol><h3 id="1-3-Brute-Force"><a href="#1-3-Brute-Force" class="headerlink" title="1.3 Brute Force"></a>1.3 Brute Force</h3><p>提到向量检索，最简单，最准确但最低效的方法就是 Brute Force，顾名思义，就是暴力比对每一条向量的距离。一般可以作为其他检索方法的baseline，尤其是独一召回率的参考。<br>值得一提的是阿里使用 BinaryDocValues 实现了 ES 上的 BF 插件。更进一步，要加速计算，所以使用了 JAVA Vector API 。JAVA Vector API 是在 openJDK project Panama 项目中的，它使用了 SIMD 指令优化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jdk.panama.vector.*;</span><br><span class="line"><span class="keyword">import</span> jdk.panama.vector.Vector.Shape;</span><br><span class="line"></span><br><span class="line">Species = FloatVector.species(Shape.S_256_BIT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 求平方和</span></span><br><span class="line">vecSquare = Species.broadcast(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>; i+(Species.length()) &lt;+ size; i+= Species.length())&#123;</span><br><span class="line">    <span class="comment">// 可以直接从byte数组计算，减少一步byte[]转floast[]</span></span><br><span class="line">    vec = Species.fromByteArray(array, i&gt;&gt;<span class="number">2</span>);</span><br><span class="line">    vecSquare = vec.mul(vec).add(vecSquare);</span><br><span class="line">    &#125;</span><br><span class="line">    sum = vecSquare.addAll();</span><br></pre></td></tr></table></figure><p>使用 avx2 指令优化，100w 的 256 维向量，单分片比对，RT 在 260ms，是常规 BF 的 1/6。 ElasticSearch 官方在7.3版本也发布了向量检索功能，底层也是基于 Lucene 的 BinaryDocValues，并且它还集成入了 painless 语法中，使用起来更加灵活。</p><h2 id="2-向量检索模型"><a href="#2-向量检索模型" class="headerlink" title="2 向量检索模型"></a>2 向量检索模型</h2><p>一个高效的向量检索模型网网需要满足下面三个条件才能达到工业级可用：</p><ul><li>实时查询，支持海量（百亿、千亿级别）规模库量级的；</li><li>存储高效，要求构建的向量索引模型数据压缩比高，达到大幅缩减内存使占用的目的；</li><li>召回精度好，top@K有比较好的召回率，跟暴力搜索（brute-force search）的结果相比；</li></ul><p>前面提到向量检索按照思想可以分为精确检索和金丝检索，这里按照召回具体方法分为四大类：<strong>基于树的方法、哈希方法、矢量量化方法、图索引量化方法。</strong></p><h3 id="2-1-基于树的方法"><a href="#2-1-基于树的方法" class="headerlink" title="2.1 基于树的方法"></a>2.1 基于树的方法</h3><p>KNN 算法表示的是准确的召回 topK 的向量，这里主要有两种算法，一种是 KDTtree，一种是 Brute Force。我们首先分析了 KDTree 的算法，发现 KDTree 并不适合高维向量召回。</p><h4 id="2-1-1-KDTree-算法"><a href="#2-1-1-KDTree-算法" class="headerlink" title="2.1.1 KDTree 算法"></a>2.1.1 KDTree 算法</h4><p>简单来讲，就是把数据按照平面分割，并构造二叉树代表这种分割，在检索的时候，可以通过剪枝减少搜索次数。</p><h5 id="构建树KD"><a href="#构建树KD" class="headerlink" title="构建树KD"></a>构建树KD</h5><p>树选择从哪一维度进行开始划分的标准，采用的是求每一个维度的方差，然后选择<strong>方差最大的那个维度</strong>开始划分。</p><blockquote><p><em>为何要选择方差作为维度划分选取的标准？</em><br>我们知道，方差的大小可以反映数据的波动性。方差大表示数据波动性越大，选择方差最大作为划分空间标准的好处在于，可以使得所需的划分面数目最小，反映到树的数据结构上，可以使得我们构建的 KD 树的树深度尽可能小。</p></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval1.jpg" alt="vecRetrieval1"></p><p>如上图为例，假设不以方差最大的x轴为划分面(x_var = 16.25)，而是以y轴(y_var = 0.0)轴为划分面，如图中虚线所示，可以看到，该划分使得图中的四个点都落入在同一个子空间中，从而使得该划分成为一个无效的划分，体现在以树结构上，就是多了一层无用的树深度。而以x轴为初始划分则不同(图像实线所示)，以x轴为初始划分可以得到数据能够比较均匀的散布在左右两个子空间中，使得整体的查找时间能够最短。<strong>注意，在实际的kd树划分的时候，并不是图中虚线所示，而是选取中值最近的点。</strong></p><p>以二维平面点 (x,y) 的集合 (2,3),(5,4),(9,6),(4,7),(8,1),(7,2) 为例构建树：</p><ol><li>构建根节点时，x 维度上面的方差较大，如上点集合在 x 维从小到大排序为 (2,3)，(4,7)，(5,4)，(7,2)，(8,1)，(9,6)；</li><li>其中值为 (7,2)。(2,3)，(4,7)，(5,4) 挂在 (7,2) 节点的左子树，(8,1)，(9,6) 挂在 (7,2) 节点的右子树。</li><li>构建 (7,2) 节点的左子树时，点集合 (2,3)，(4,7)，(5,4) 此时的切分维度为 y，中值为 (5,4) 作为分割平面，(2,3) 挂在其左子树，(4,7) 挂在其右子树。</li><li>构建 (7,2) 节点的右子树时，点集合 (8,1)，(9,6) 此时的切分维度也为 y，中值为 (9,6) 作为分割平面，(8,1) 挂在其左子树。</li></ol><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval2.jpg" alt="vecRetrieval2"></p><p>上述的构建过程结合下图可以看出，构建一个 KDTree 即是将一个二维平面逐步划分的过程。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval3.jpg" alt="vecRetrieval3"></p><h5 id="搜索-3-5-的最近邻"><a href="#搜索-3-5-的最近邻" class="headerlink" title="搜索 (3,5) 的最近邻"></a>搜索 (3,5) 的最近邻</h5><ol><li>首先从根节点 (7,2) 出发，将当前最近邻设为 (7,2)，对该 KDTree 作深度优先遍历。</li><li>以 (3,5) 为圆心，其到 (7,2) 的距离为半径画圆（多维空间为超球面），可以看出 (8,1) 右侧的区域与该圆不相交，所以 (8,1) 的右子树全部忽略。</li><li>接着走到 (7,2) 左子树根节点 (5,4)，与原最近邻对比距离后，更新当前最近邻为 (5,4)。</li><li>以 (3,5) 为圆心，其到 (5,4) 的距离为半径画圆，发现 (7,2) 右侧的区域与该圆不相交，忽略改厕所有节点，这样 (7,2) 的整个右子树被标记为已忽略。</li><li>遍历完 (5,4) 的左右叶子节点，发现与当前最优距离相等，不更新最近邻。所以 (3,5) 的最近邻为 (5,4)。</li></ol><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval4.jpg" alt="vecRetrieval4"></p><p>KDTree 的查询复杂度为O(kn(k−1)/k)，k 表示维度，n 表示数据量。说明 k 越大，复杂度越接近线性，所以它并<strong>不适合高维向量召回。</strong></p><h4 id="2-1-2-Annoy"><a href="#2-1-2-Annoy" class="headerlink" title="2.1.2 Annoy"></a>2.1.2 Annoy</h4><p><strong>Annoy是Erik Bernhardsson写的一个以树为作为索引结构的近似最近邻搜索库</strong>，并用在Spotify的推荐系统中。</p><p>Annoy的核心是不断用选取的两个质心的法平面对空间进行分割，最终将每一个划分的子空间里面的样本数据限制在K以内。对于待插入的样本xi，从根节点依次使用法向量跟xi做内积运算，从而判断使用法平面的哪一边（左子树or右子树）。对于查询向量qi，采用同样的方式（在树结构上体现为从根节点向叶子节点递归遍历），即可定位到跟qi在同一个子空间或者邻近的子空间的样本，这些样本即为qi近邻。</p><p>为了提高查询召回率，Annoy采用建立<strong>多棵子树</strong>的方式，这种方式其实有点类似AdaBoost的意思，即用多个弱分类器构成强单元分类器，NV-tree也采用了这种方式，哈希方法也同样采用了这种方式（构建多表）的方式。</p><p>值得注意的是，Annoy如果不保存原始特征，则Annoy只能返回查询的k个近邻，至于这k个里面的排序顺序是怎么样的，它是不知道的，如果需要知道，需要对这k个返回的结果，获取原始特征，再计算各自的相似度，排序一下即可得到这k个结果的排序。</p><h3 id="2-2-基于Hash的方法"><a href="#2-2-基于Hash的方法" class="headerlink" title="2.2 基于Hash的方法"></a>2.2 基于Hash的方法</h3><p>哈希就是将连续的一系列值映射到较短的离散值，在这里一般是指映射到0、1值。根据学习的策略，可以将哈希方法分为无监督、有监督和半监督三种类型。</p><h4 id="2-2-1-LSH-Local-Sensitive-Hashing"><a href="#2-2-1-LSH-Local-Sensitive-Hashing" class="headerlink" title="2.2.1 LSH(Local Sensitive Hashing)"></a>2.2.1 LSH(Local Sensitive Hashing)</h4><p>LSH的中文名称是局部敏感哈希算法，而哈希函数满意局部敏感的定义是在哈希后的空间内，相近的样本点对比相远的样本点更容易发生碰撞。个人理解就是会有一些聚类的效果。</p><p><strong>LSH加速检索的原理</strong><br>如下图所示，我们选取多个局部敏感hash函数，把候选集向量通过平面分割做 hash。0表示点在平面的左侧，1表示点在平面的右侧。由于应用了多个局部敏感hash函数，可以发现hash值相同的点都比较相近，也即查询样本的最近邻将极有可能落在查询样本的cell中。所以我们在检索的时候只需要计算hash值相似的向量就能够召回较为精确度的topK。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval5.jpg" alt="vecRetrieval5"></p><blockquote><p><em>为什么要用多表哈希？</em><br>对于单表哈希，当哈希函数数目K（上图中是2）取得太大，查询样本与其对应的最近邻落入同一个桶中的可能性会变得很微弱，针对这个问题，我们可以重复这个过程L次，从而增加最近邻的召回率。这个重复L次的过程，可以转化为构建L（上图中是3）个哈希表，这样在给定查询样本时，我们可以找到L个哈希桶（每个表找到一个哈希桶），然后我们在这L个哈希表中进行遍历。这个过程相当于构建了K*L个哈希函数(注意是“相当”，不要做“等价”理解)。</p><p><em>多表哈希中哈希函数数目K和哈希表数目L如何选取？</em><br>哈希函数数目K如果设置得过小，会导致每一个哈希桶中容纳了太多的数据点，从而增加了查询响应的时间；<br>而当K设置得过大时，会使得落入每个哈希桶中的数据点变小，而为了增加召回率，我们需要增加L以便构建更多的哈希表，但是哈希表数目的增加会导致更多的内存消耗，并且也使得我们需要计算更多的哈希函数，同样会增加查询相应时间。<br>但是在K过大或过小之间仍然可以找到一个比较合理的折中位置。通过选取合理的K和L，我们可以获得比线性扫描极大的性能提升。</p></blockquote><h4 id="2-2-2-Multiprobe-LSH"><a href="#2-2-2-Multiprobe-LSH" class="headerlink" title="2.2.2 Multiprobe LSH"></a>2.2.2 Multiprobe LSH</h4><p>多probe LSH主要是为了提高<strong>查找准确率</strong>而引入的一种策略。<br><strong>原始的LSH</strong>: 是对于构建的L个哈希表，我们在每一个哈希表中找到查询样本落入的哈希桶，然后再在这个哈希桶中做遍历.<br><strong>而Multiprobe</strong>: 指的是我们不止在查询样本所在的哈希桶中遍历，还会找到其他的一些哈希桶，然后这些找到的T个哈希桶中进行遍历。<br>这些其他哈希桶的<strong>选取准则</strong>是：跟查询样本所在的哈希桶邻近的哈希桶，“邻近”指的是<strong>汉明距离</strong>度量下的邻近。</p><blockquote><p>如果不使用Multiprobe，我们需要的哈希表数目L在100到1000之间，在处理大数据集的时候，其空间的消耗会非常的高，幸运地是，因为有了上面的Multiprobe的策略，LSH在任意一个哈希表中查找到最近邻的概率变得更高，从而使得我们能到减少哈希表的构建数目。</p></blockquote><p><strong>对于LSH，涉及到的主要的参数有三个：</strong></p><ul><li>K，每一个哈希表的哈希函数（空间划分）数目</li><li>L，哈希表（每一个哈希表有K个哈希函数）的数目</li><li>T，近邻哈希桶的数目，即the number of probes</li></ul><blockquote><p>这三个设置参数可以按照如下顺序进行：</p><ol><li>首先，根据可使用的内存大小选取L，然后在K和T之间做出折中：哈希函数数目K越大，相应地，近邻哈希桶的数目的数目T也应该设置得比较大，反之K越小，L也可以相应的减小。</li><li>获取K和L最优值的方式可以按照如下方式进行：对于每个固定的K，如果在查询样本集上获得了我们想要的精度，则此时T的值即为合理的值。</li><li>在对T进行调参的时候，我们不需要重新构建哈希表，甚至我们还可以采用二分搜索的方式来加快T参数的选取过程。</li></ol></blockquote><h5 id="LSH开源实现"><a href="#LSH开源实现" class="headerlink" title="LSH开源实现"></a>LSH开源实现</h5><p>关于LSH开源工具库，有很多，这里推荐两个LSH开源工具包：LSHash和FALCONN, 分别对应于学习和应用场景。</p><p><strong>LSHash</strong><br>LSHash非常适合用来学习，里面实现的是最经典的LSH方法，并且还是单表哈希。<em>哈希函数的系数采用随机的方式生成</em>，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_generate_uniform_planes</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Generate uniformly distributed hyperplanes and return it as a 2D</span></span><br><span class="line"><span class="string">    numpy array.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.random.randn(<span class="variable language_">self</span>.hash_size, <span class="variable language_">self</span>.input_dim)</span><br></pre></td></tr></table></figure><p>hash_size为哈希函数的数目，即前面介绍的K。如果要在实用中使用LSH，可以使用FALCONN。</p><h4 id="2-2-3-FALCONN"><a href="#2-2-3-FALCONN" class="headerlink" title="2.2.3 FALCONN"></a>2.2.3 FALCONN</h4><p>FALCONN是经过极致优化的LSH，其对应的论文为NIPS 2015 Practical and Optimal LSH for Angular Distance，Piotr Indyk系作者之一，下面将其Python例子中初始化索引以及构建哈希表的部分提取出来，对其中的参数做一下简要的分析.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hyperplane hashing</span></span><br><span class="line">params_hp = falconn.LSHConstructionParameters()</span><br><span class="line">params_hp.dimension = d</span><br><span class="line">params_hp.lsh_family = <span class="string">&#x27;hyperplane&#x27;</span></span><br><span class="line">params_hp.distance_function = <span class="string">&#x27;negative_inner_product&#x27;</span></span><br><span class="line">params_hp.storage_hash_table = <span class="string">&#x27;flat_hash_table&#x27;</span></span><br><span class="line">params_hp.k = <span class="number">19</span></span><br><span class="line">params_hp.l = <span class="number">10</span></span><br><span class="line">params_hp.num_setup_threads = <span class="number">0</span></span><br><span class="line">params_hp.seed = seed ^ <span class="number">833840234</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hyperplane hash\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">start = timeit.default_timer()</span><br><span class="line">hp_table = falconn.LSHIndex(params_hp)</span><br><span class="line">hp_table.setup(data)</span><br><span class="line">hp_table.set_num_probes(<span class="number">2464</span>)</span><br></pre></td></tr></table></figure><p>有3个很重要的参数，分别是<strong>k、l和set_num_probes</strong>，对应的具体意义即前面所述。</p><p>性能方面FALCONN的索引构建过程非常快，百万量级数据，维度如果是128维，其构建索引时间大概2-3min的样子，实时搜索可以做到几毫秒响应时间。</p><p>对于小数据集和中型规模的数据集(几个million-几十个million)， FALCONN和NMSLIB是一个非常不错的选择，如果对于大型规模数据集(几百个million以上)，基于矢量量化的<code>Faiss</code>是一个明智的选择。</p><blockquote><p><em>遗留问题</em><br>FALCONN还不是很完善，比如对于数据的动态增删目前还不支持，NMSLIB目前也不支持。<br>一般而言，动态的增删在实际应用场合是一个基本的要求，但是我们应注意到，增删并不是毫无限制的，在增删频繁且持续了一段时间后，这时的<em>数据分布已经不是我们原来建索引的数据分布形式</em>了，我们应该重新构建索引。在这一点上，基于<strong>矢量量化的方法对数据的动态增删更友好</strong>。</p></blockquote><p>在召回率上一般哈希向量量化方法比矢量量化方法要差一些。<br>一个比较直观的理解是：哈希向量量化后在计算距离的时候，计算的是汉明距离，在向量量化比特位长度相同的条件下，<strong>汉明距离表示的距离集合是有限的，而矢量量化计算的距离是一个实数</strong>，意味着它构成的距离集合是无限的。</p><p>所以，实际工业采用的向量索引方法，主要还是<strong>矢量量化方法居多</strong>，主要原因有二：</p><ul><li>矢量量化方法能够较好的兼顾检索召回率以及量化压缩比；</li><li>增删友好的优点使得构建的服务更稳定；</li></ul><h3 id="2-3-矢量量化方法"><a href="#2-3-矢量量化方法" class="headerlink" title="2.3 矢量量化方法"></a>2.3 矢量量化方法</h3><p>矢量量化方法，Vector Quantization，定义为：<strong>将一个向量空间中的点用其中的一个有限子集来进行编码的过程</strong>。其关键是码本的建立和码字搜索算法。</p><h4 id="2-3-1-多阶段矢量量化（MSVQ）"><a href="#2-3-1-多阶段矢量量化（MSVQ）" class="headerlink" title="2.3.1 多阶段矢量量化（MSVQ）"></a>2.3.1 多阶段矢量量化（MSVQ）</h4><p>多阶段矢量量化（Multi-Stage Vector Quantization，MSVQ）也称为<strong>残差矢量量化</strong>（Residual Vector Quantization, RVQ）。它是一种思想，即将编码任务分解为一系列级联过程。级联过程可以用下图直观的展示出来：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval6.jpg" alt="vecRetrieval6"></p><p>如上图所示，途中quantizer为量化器，可以认为就是码本生成器。对于待量化的向量x：</p><ol><li>经过一级量化器quantizer1后，得到的量化残差为r1 = x - C1b1；</li><li>其中C1为一级量化器的码本，b1为x经过一级量化器quantizer1后的表示结果；</li><li>将一级量化误差r1作为二级量化器的输入，后面过程与此类似。</li></ol><p>通过这种级联量化的量化方式，当构建的量化器为无穷个时，<strong>x可以被这无穷个码本精确表示</strong>。上图右侧子图比较直观的描绘了x被多个码本逐步近似的过程。</p><blockquote><p><strong>码本的构建和查询</strong><br>图中的C1、C2、…、Ci、… 这些码本在构建的时候，可以采用KMeans等方式得到各个量化器的码本。以上面构建的4个级联的码本为例，当得到码本C1、C2、C3、C4后，x量化的结果即可用[b1, b2, b3, b4]表示。对于xq查询向量与x距离的计算，在计算xq与 C1、C2、…、Ci、… 之间的内积距离表后，可以通过查表的方式，获取到非对称距离。</p></blockquote><p>这种多阶段级联的矢量量化方式，相比单阶段一次性量化，极大的降低了码本在训练过程中消耗的计算资源。</p><p>举个例子，4个阶段的MSVQ，每阶段用KMeans只需构建构建256大小的码本，则对空间分割构建的cell数目为$256^4=4294967296$，效率是很高的，但是如果采用单阶段一次性量化构建4294967296大小的码本，这个码本根本没法用KMeans聚出来。<br>此外在计算距离的时候，采用4阶段的<code>MSVQ</code>方式，只需计算4x256次距离的计算构成距离表，然后采用查表方式计算距离，而单阶段一次性量化需要计算4294967296次的距离计算。MSVQ的进一步加速版本是倒排MSVQ，将一级码本视为倒排链，从而构建倒排结构，构建MSVQ倒排结构。我们可以将MSVQ类比成“<strong>深度加深</strong>”的过程</p><h4 id="2-3-2-乘积量化-PQ"><a href="#2-3-2-乘积量化-PQ" class="headerlink" title="2.3.2 乘积量化(PQ)"></a>2.3.2 乘积量化(PQ)</h4><p>乘积量化(Product Quantization，PQ)是Herve Jegou在2011年提出的一种非常经典实用的矢量量化索引方法，在工业界向量索引中已得到广泛的引用，并作为主要的向量索引方法，在<a href="https://github.com/facebookresearch/faiss">Fasis</a>有非常高效的实现。</p><p>乘积量化的核心思想:分段（划分子空间）和聚类，或者说具体应用到ANN近似最近邻搜索上，KMeans是PQ乘积量化子空间数目为1的特例。</p><p>PQ乘积量化生成码本和量化的过程可以用如下图示来说明：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval7.jpg" alt="vecRetrieval7"></p><blockquote><p>在训练阶段:</p><ol><li>针对N个训练样本，假设样本维度为128维，我们将其切分为4个子空间，则每一个子空间的维度为32维;</li><li>然后我们在每一个子空间中，对子向量采用K-Means对其进行聚类(图中示意聚成256类)，这样每一个子空间都能得到一个码本。</li><li>这样训练样本的每个子段，都可以用子空间的聚类中心来近似，对应的编码即为类中心的ID。</li><li>如图所示，通过这样一种编码方式，训练样本仅使用的很短的一个编码得以表示，从而达到量化的目的。</li><li>对于待编码的样本，将它进行相同的切分，然后在各个子空间里逐一找到距离它们最近的类中心，然后用类中心的id来表示它们，即完成了待编码样本的编码。</li></ol><p>在查询阶段:</p><ol><li>PQ同样在计算查询样本与dataset中各个样本的距离，只不过这种距离的计算转化为<strong>间接近似</strong>的方法而获得。</li><li>PQ乘积量化方法在计算距离的时候，有两种距离计算方式，<strong>一种是对称距离，另外一种是非对称距离</strong>。</li><li>非对称距离的损失小(<em>也就是更接近真实距离</em>)，实际中也经常采用这种距离计算方式。</li></ol></blockquote><p>下面过程示意的是查询样本来到时，以非对称距离的方式(红框标识出来的部分)计算到dataset样本间的计算示意：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval8.jpg" alt="vecRetrieval8"></p><blockquote><p>查询向量来到时:</p><ol><li>按训练样本生成码本的过程，将其同样分成相同的子段，然后在每个子空间中，计算子段到该子空间中所有聚类中心得距离。(如图中所示，可以得到4x256个距离，这里为便于后面的理解说明，可以把这些算好的距离称作距离表)。</li><li>在计算库中某个样本到查询向量的距离时，比如编码为(124, 56, 132, 222)这个样本到查询向量的距离时，我们分别到距离表中取各个子段对应的距离即可。(比如编码为124这个子段，在第1个算出的256个距离里面把编号为124的那个距离取出来就可)。</li><li>所有子段对应的距离取出来后，将这些子段的距离求和相加，即得到该样本到查询样本间的非对称距离。</li><li>所有距离算好后，排序后即得到我们最终想要的结果。</li></ol></blockquote><p><strong>PQ乘积量化能够加速索引的原理</strong>：<br>即将全样本的距离计算，转化为到子空间类中心的距离计算。</p><ul><li>比如上面所举的例子，原本brute-force search的方式计算距离的次数随样本数目N成线性增长，但是经过PQ编码后，对于耗时的距离计算，只要计算4x256次，几乎可以忽略此时间的消耗。</li><li>另外，从上图也可以看出，对特征进行编码后，可以用一个相对比较短的编码来表示样本，自然对于内存的消耗要大大小于brute-force search的方式。</li></ul><p>在某些特殊的场合，我们总是希望获得精确的距离，而不是近似的距离，并且我们总是喜欢获取向量间的余弦相似度（余弦相似度距离范围在[-1,1]之间，便于设置固定的阈值），针对这种场景，可以针对PQ乘积量化得到的前top@K做一个brute-force search的排序。</p><h4 id="2-3-3-倒排乘积量化（IVFPQ）"><a href="#2-3-3-倒排乘积量化（IVFPQ）" class="headerlink" title="2.3.3 倒排乘积量化（IVFPQ）"></a>2.3.3 倒排乘积量化（IVFPQ）</h4><p>倒排PQ乘积量化(IVFPQ)是PQ乘积量化的更进一步加速版。其加速的本质依然是<strong>加速原理：为了加快查找的速度，几乎所有的ANN方法都是通过对全空间分割，将其分割成很多小的子空间，在搜索的时候，通过某种方式，快速锁定在某一（几）子空间，然后在该（几个）子空间里做遍历</strong>。</p><blockquote><p><strong>仔细观察PQ乘积量化存在一定的优化空间</strong>：<br>其在计算距离的时候，虽然已经预先算好了，但是对于每个样本到查询样本的距离，还是得老老实实挨个去求和相加计算距离。<br>实际上我们感兴趣的是那些跟查询样本相近的样本（姑且称这样的区域为感兴趣区域），也就是说老老实实挨个相加其实做了很多的无用功。如果能够通过某种手段快速将全局遍历锁定为感兴趣区域，则可以舍去不必要的全局计算以及排序。<br>倒排PQ乘积量化的”倒排“，正是这样一种思想的体现，在具体实施手段上，采用的是通过聚类的方式实现感兴趣区域的快速定位，在倒排PQ乘积量化中，聚类可以说应用得淋漓尽致。</p></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval9.jpg" alt="vecRetrieval9"></p><p>如上图所示：<strong>在PQ乘积量化之前，增加了一个粗量化过程。</strong></p><blockquote><p>具体地:</p><ol><li>先对N个训练样本采用KMeans进行聚类，这里聚类的数目一般设置得不应过大，一般设置为1024差不多，这种可以以比较快的速度完成聚类过程。</li><li>得到了聚类中心后，针对每一个样本x_i，找到其距离最近的类中心c_i后，两者相减得到样本x_i的残差向量(x_i-c_i);</li><li>后面剩下的过程，就是针对(x_i-c_i)的PQ乘积量化过程。</li></ol></blockquote><p>在查询的时候，通过相同的粗量化，可以快速定位到查询向量属于哪个c_i（即在哪一个感兴趣区域），然后在该感兴趣区域按上面所述的PQ乘积量化距离计算方式计算距离。</p><h4 id="2-3-4-最优乘积量化（OPQ）"><a href="#2-3-4-最优乘积量化（OPQ）" class="headerlink" title="2.3.4 最优乘积量化（OPQ）"></a>2.3.4 最优乘积量化（OPQ）</h4><p>最优乘积量化（Optimal Product Quantization, OPQ）是PQ的一种改进版本。其改进体现在，<strong>致力于在子空间分割时，对各子空间的方差进行均衡</strong>。</p><p>Optimal的过程一般实现为一个组件。而用于检索的原始特征维度较高，所以实际在使用PQ等方法构建索引的时候，常会对高维的特征使用<strong>PCA等降维</strong>方法对特征先做降维处理。</p><p><strong>这样降维预处理，可以达到两个目的：</strong></p><ul><li>一是降低特征维度；</li><li>二是在对向量进行子段切分的时候要求特征各个维度是不相关的，做完PCA之后，可以一定程度缓解这个问题。</li></ul><p>但是这么做了后，在切分子段的时候，采用顺序切分子段仍然存在一定的问题，这个问题可以借用ITQ中的一个二维平面的例子加以说明：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval10.jpg" alt="vecRetrieval10"></p><blockquote><p><em>这个问题就是：</em><br>如上面a图所示，对于PCA降维后的二维空间，假设在做PQ的时候，将子段数目设置为2段，即切分成x和y两个子向量，然后分别在x和y上做聚类（假设聚类中心设置为2）。<br>对a图和c图聚类的结果进行比较，可以明显的发现，a图在y方向上聚类的效果明显差于c图，而PQ又是采用聚类中心来近似原始向量（这里指降维后的向量），也就是c图是我们需要的结果。</p></blockquote><p>这个问题可以转化为数据方差来描述：在做PQ编码时，对于切分的各个子空间，我们应尽可能使得各个子空间的方差比较接近，最理想的情况是各个子空间的方差都相等。</p><blockquote><p><em>解决办法：</em><br>为了在切分子段的时候，使得各个子空间的方差尽可能的一致，Herve Jegou在<a href="https://lear.inrialpes.fr/pubs/2010/JDSP10/jegou_compactimagerepresentation.pdf">Aggregating local descriptors into a compact image representation</a>中提出使用一个正交矩阵来对PCA降维后的数据再做一次变换，使得各个子空间的方差尽可能的一致。</p></blockquote><p>OPQ致力于解决的问题正是对各个子空间方差的均衡。思想主要是<strong>在聚类的时候对聚类中心寻找对应的最优旋转矩阵，使得所有子空间中各个数据点到对应子空间的类中心的L2损失的求和最小。</strong></p><p>OPQ在具体求解的时候，分为非参求解方法和带参求解方法，具体为：</p><ul><li>非参求解方法。跟ITQ的求解过程一样。</li><li>带参求解方法。带参求解方法假设数据服从高斯分布，在此条件下，最终可以将求解过程简化为数据经过PCA分解后，特征值如何分组的问题。在实际中，该解法更具备高实用性。</li></ul><h4 id="2-4-基于图索引量化方法"><a href="#2-4-基于图索引量化方法" class="headerlink" title="2.4 基于图索引量化方法"></a>2.4 基于图索引量化方法</h4><p>图索引量化是一种将图引入向量索引的方法，由于图索引的高召回特点，近几年基于图索引量化方法出现了不少这方面的工作，比如早期的KNNGraph和最近的将基于图索引量化方法推向成熟应用的HNSW方法。</p><p>首先从检索的<strong>召回率</strong>上来评估，基于图的索引方法要优于目前其他一些主流ANN搜索方法，比如乘积量化方法（PQ、OPQ）、哈希方法等。虽然乘积量化方法的召回率不如HNSW，<strong>但由于乘积量化方法具备内存耗用更小、数据动态增删更灵活等特性</strong>，使得在工业检索系统中，在对召回率要求不是特别高的场景下，乘积量化方法在工业界，仍然是使用得较多的一种索引方法。</p><p>下面是乘积量化和图索引方法特性做的一个对比，以HNSW和OPQ为典型代表：</p><div class="table-container"><table><thead><tr><th>特性</th><th>OPQ</th><th>HNSW</th></tr></thead><tbody><tr><td>内存占用</td><td>小</td><td>大</td></tr><tr><td>召回率</td><td>较高</td><td>高</td></tr><tr><td>数据动态增删</td><td>灵活</td><td>不易</td></tr></tbody></table></div><p>基于图索引的ANN方法由于数据在插入索引的时候，需要计算（部分）数据间的近邻关系，因而需要实时获取到到数据的原始特征，几乎所有基于图ANN的方法在处理该问题的时候，都是直接将原始特征加载在内存（索引）里，<strong>从而造成对内存使用过大，至于召回率图ANN方法要比基于量化的方法要高</strong>，这个理解起来比较直观。</p><h4 id="2-4-1-NSW"><a href="#2-4-1-NSW" class="headerlink" title="2.4.1 NSW"></a>2.4.1 NSW</h4><p>在介绍经典的HNSW之前我们先介绍它的前身NSW，该算法如下图，它是一个顺序构建图流程：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval11.jpg" alt="vecRetrieval11"></p><p>我们以图中第5次构造D点为例来介绍流程：</p><ol><li>构建的时候，我们约定每次加入节点只连 3 条边，防止图变大，在实际使用中，要通过自身的数据；</li><li>随机一个节点，比如 A，保存下与 A 的距离，然后沿着 A 的边遍历，E 点最近，连边。然后再重新寻找，不能与之前重复，直到添加完 3 条边；</li></ol><p>查找流程包含在了插入流程中，一样的方式，只是不需要构建边，直接返回结果。</p><h4 id="2-4-2-HNSW"><a href="#2-4-2-HNSW" class="headerlink" title="2.4.2 HNSW"></a>2.4.2 HNSW</h4><p><a href="https://arxiv.org/abs/1603.09320">Hierarchical Navigable Small World Graphs (HNSW)</a> 是Yury A. Malkov提出的一种基于图索引的方法，它是Yury A. Malkov在他本人之前工作<code>NSW</code>上一种改进。通过采用层状结构，将边按特征半径进行分层，使每个顶点在所有层中平均度数变为常数，从而将NSW的计算复杂度由多重对数(Polylogarithmic)复杂度降到了对数(logarithmic)复杂度。</p><p><strong>HNSW的主要贡献如下：</strong></p><ul><li>图输入节点明确的选择；</li><li>使用不同尺度划分链接；</li><li>使用启发式方式来选择最近邻；</li></ul><h5 id="近邻图技术"><a href="#近邻图技术" class="headerlink" title="近邻图技术"></a>近邻图技术</h5><p>对于给定的近邻图，在开始搜索的时候，从若干输入点（随机选取或分割算法）开始迭代遍历整个近邻图。</p><p>在每一次横向迭代的时候，算法会检查链接或当前base节点之间的距离，然后选择下一个base节点作为相邻节点，使得能最好的最小化连接间的距离。</p><p>近邻图主要的缺陷：</p><ol><li>在路由阶段，如果随机从一个或者固定的阶段开始，迭代的步数会随着库的大小增长呈现幂次增加；</li><li>当使用k-NN图的时候，一个全局连接可能的损失会导致很差的搜索结果。</li></ol><h5 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h5><p>网络图以连续插入的方式构建。对于每一个要插入的元素，采用指数衰变概率分布函数来随机选取整数最大层。HNSW 算法是 NSW 算法的分层优化，借鉴了 skiplist 算法的思想，提升查询性能，开始先从稀疏的图上查找，逐渐深入到底层的图。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval12.jpg" alt="vecRetrieval12"></p><ul><li>图构建元素<strong>插入过程</strong>（Algorithm 1）：从顶层开始贪心遍历graph，以便在某层A中找到最近邻。当在A层找到局部最小值之后，再将A层中找到的最近邻作为输入点（entry point），继续在下一层中寻找最近邻，重复该过程；</li><li><strong>层内最近邻查找</strong>（Algorithm 2）：贪心搜索的改进版本；</li><li><strong>搜索阶段</strong>，维护一个动态列表，用于保持ef个找到的最近邻元素</li></ul><blockquote><p>在搜索的初步阶段，ef参数设置为1。搜索过程包括zoom out和zoom in两个阶段，zoom out是远程路由，zoom in顾名思义就是在定位的区域做精细的搜索过程。<br>整个过程可以类比在地图上寻找某个位置的过程：</p><ol><li>我们可以地球当做最顶层，五大洲作为第二层，国家作为第三层，省份作为第四层……;</li><li>现在如果要找海淀五道口，我们可以通过顶层以逐步递减的特性半径对其进行路由（第一层地球-&gt;第二层亚洲—&gt;第三层中国-&gt;第四层北京-&gt;海淀区）;</li><li>到了第0层后，再在局部区域做更精细的搜索。</li></ol></blockquote><p><strong>参数详细意义</strong></p><ol><li>M：参数M定义了第0层以及其他层近邻数目，不过实际在处理的时候，第0层设置的近邻数目是2xM。如果要更改第0层以及其他层层近邻数目，在HNSW的源码中进行更改即可。另外需要注意的是，第0层包含了所有的数据点，其他层数据数目由参数mult定义，详细的细节可以参考HNSW论文。</li><li>delaunay_type：检索速度和索引速度可以通过该参数来均衡heuristic。HNSW默认delaunay_type为1，将delaunay_type设置为1可以提高更高的召回率(&gt; 80%)，但同时会使得索引时间变长。因此，对于召回率要求不高的场景，推荐将delaunay_type设置为0。</li><li>post：post定义了在构建图的时候，对数据所做预处理的数量（以及类型），默认参数设置为0，表示不对数据做预处理，该参数可以设置为1和2（2表示会做更多的后处理）。</li></ol><p>更详细的参数说明，可以参考<a href="https://github.com/nmslib/nmslib/blob/9ed3071d0a74156a9559f3347ee751922e4b06e7/python_bindings/parameters.md">parameters</a>说明。</p><h4 id="2-4-3-NSG算法"><a href="#2-4-3-NSG算法" class="headerlink" title="2.4.3 NSG算法"></a>2.4.3 NSG算法</h4><p>NSG 全写为 Navigating Spreading-out Graph。NSG 围绕四个方向来改进：</p><ul><li>图的连通性;</li><li>减少出度;</li><li>缩短搜索路径;</li><li>缩减图的大小。</li></ul><p>具体是通过建立<strong>导航点 (Navigation Point)</strong>，特殊的选边策略, 深度遍历收回<strong>离散节点（Deep Traversal）</strong>等方法。</p><p>首先是 Navigation Point，在建图时，首先需要一张预先建立的 K-nearest-neighbor-graph (KNNG) 作为构图基准。随机选择一个点作为 Navigation Point，后续所有新插入的节点在选边时都会将 Navigation Point 加入候选。在建图过程中，逐渐会将子图都和 Navigation point 相连接，这样其他的节点只需保持很少的边即可，从而减少了图的大小。每次搜索从 Navigation Point 出发能够指向具体的子图，从而减少无效搜索，获得更好搜索性能。</p><p>NSG 使用的择边策略与 HNSW 类似，<strong>但是不同于 HNSW 只选择最短边为有效边，NSG 使用的择边策略如下图。</strong></p><blockquote><ul><li>以点 r 为例，当 r 与 p 建立连接时，以 r 和 p 为圆心，r 和 p 的距离为半径，分别做圆，如果两个圆的交集内没有其他与 p 相连接的点，则 r 与 p 相连（见图 3-B）。</li><li>在连接点 s 时，由于以 s 和 p 距离为半径的交集圆内，已有点 r 与 p 相连，所以 s 和 p 不相连（见图 3-C）。下图中最终与点 p 相连的点只有 r, t 和 q（见图 3-A）。</li></ul></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/vecRetrieval13.jpg" alt="vecRetrieval13"></p><p>NSG 这样做的原因是<strong>考虑到由于边数一多，整个图就会变得稠密</strong>，最后在搜索时会浪费大量算力。但是减少边的数量，<strong>带来的坏处也比较明显，最后的图会是一张稀疏图</strong>，会使得有些节点难以被搜索到。不仅如此，NSG 的边还是单向边。在如此激进的策略下，图的连通性就会产生问题，这时 NSG 选择使用深度遍历来将离群的节点收回到图中。通过以上步骤，图的建立就完成了。</p><h5 id="HNSW-和-NSG-的比较"><a href="#HNSW-和-NSG-的比较" class="headerlink" title="HNSW 和 NSG 的比较"></a>HNSW 和 NSG 的比较</h5><p>HNSW 从结构入手，利用分层图提高图的导航性减少无效计算从而降低搜索时间，达到优化的目的。</p><p>而 NSG 选择将图的整体度数控制在尽可能小的情况下，提高导航性，缩短搜索路径来提高搜索效率。</p><p>下面我们从<strong>内存占用，搜索速度，精度</strong>等方面来比较 HNSW 和 NSG。</p><blockquote><ol><li>HNSW 由于多层图的结构以及连边策略，导致搜索时内存占用量会大于 NSG，在内存受限场景下选择 NSG 会更好。</li><li>但是 NSG 在建图过程中无论内存占用还是耗时都大于 HNSW。此外 HNSW 还拥有目前 NSG 不支持的特性，即增量索引，虽然耗时巨大。</li><li>对比其他的索引类型，无论 NSG 还是 HNSW 在搜索时间和精度两个方面，都有巨大优势。</li></ol></blockquote><p>目前在 Milvus 内部已经实现了 NSG 算法，并将 KNNG 计算放到了 GPU 上进行从而极大地加快了 NSG 图的构建。</p><h2 id="3-算法总结"><a href="#3-算法总结" class="headerlink" title="3 算法总结"></a>3 算法总结</h2><p><strong>KNN 适合场景：</strong></p><ul><li>数据量小(单分片100w以下)；</li><li>先过滤其他条件，只剩少量数据，再向量召回的场景；</li><li>召回率100%；</li></ul><p><strong>ANN 场景：</strong></p><ul><li>数据量大(千万级以上)；</li><li>先向量过滤再其他过滤；</li><li>召回率不需要100%；</li><li>LSH 算法： 召回率性能要求不高，少量增删；</li><li>IVFPQ 算法：召回率性能要求高，数据量大(千万级)，少量增删，需要提前构建；</li><li>HNSW 算法： 召回率性能要求搞，数据量适中(千万以下)，索引全存内存，内存够用；</li></ul><p><strong>参考文章</strong><br><a href="https://www.sofastack.tech/blog/antfin-zsearch-vector-search/">蚂蚁金服 ZSearch 在向量检索上的探索</a><br><a href="https://www.6aiq.com/article/1587522027341">大规模特征向量检索算法总结 (LSH PQ HNSW)</a><br><a href="http://yongyuan.name/blog/vector-ann-search.html">图像检索：向量索引</a><br><a href="https://milvus.io/cn/blogs/2020-01-16-hnsw-nsg-comparison.md">Milvus 揭秘系列（一）：向量索引算法 HNSW 和 NSG 的比较</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-基础知识&quot;&gt;&lt;a href=&quot;#1-基础知识&quot; class=&quot;headerlink&quot; title=&quot;1 基础知识&quot;&gt;&lt;/a&gt;1 基础知识&lt;/h2&gt;&lt;h3 id=&quot;1-1-背景&quot;&gt;&lt;a href=&quot;#1-1-背景&quot; class=&quot;headerlink&quot; title=&quot;1.1 背景&quot;&gt;&lt;/a&gt;1.1 背景&lt;/h3&gt;&lt;p&gt;在深度学习大兴的时代，embeding无处不在，不论是在搜索推荐领域还是cv领域亦或nlp领域。俗话说得好，万物皆可embeding，那么对于embeding化后的对象我们在做topk检索/召回的时候怎么提效呢？毕竟候选集往往都是在千万级或者亿级的时候，计算量是相当大的。这时候，向量检索算法就发挥了作用。在我理解的向量检索一般可以分为两个方向，一种是精确化检索，需要遍历每个样本，计算量往往很大，基本上被淘汰了。另一种就是近似检索，学术上对应的专有名词叫Approximate Nearest Neighbor Search (ANNS)，即近似最近邻搜索。为什么是近似，而不是我们想要的精确？这就是精度与时间、算力资源的折中，采用了牺牲精度换取时间和空间的方式，从海量的样本中实时获取跟查询最相似的样本。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="向量检索" scheme="https://www.xiemingzhao.com/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>位运算的巧用</title>
    <link href="https://www.xiemingzhao.com/posts/bitArithmetic.html"/>
    <id>https://www.xiemingzhao.com/posts/bitArithmetic.html</id>
    <published>2020-01-15T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.657Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-位运算简介"><a href="#1-位运算简介" class="headerlink" title="1 位运算简介"></a>1 位运算简介</h2><ul><li><p><code>&amp;</code> 与运算 两个位都是 1 时，结果才为 1，否则为 0，如：<br><code>10011&amp;11001=10001</code></p></li><li><p><code>|</code> 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 <code>10011 | 11001 = 11011</code></p></li><li><p><code>^</code> 异或运算，两个位相同则为 0，不同则为 1，如 <code>10011 ^ 11001 = 01010</code> </p></li><li><p><code>~</code> 取反运算，0 则变为 1，1 则变为 0，如<code>~ 10011 = 01100</code></p></li><li><p><code>&lt;&lt;</code> 左移运算，向左进行移位操作，高位丢弃，低位补 0，如</p></li></ul><span id="more"></span><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int a = 8;</span><br><span class="line">a &lt;&lt; 3;</span><br><span class="line">移位前：0000 0000 0000 0000 0000 0000 0000 1000</span><br><span class="line">移位后：0000 0000 0000 0000 0000 0000 0100 0000</span><br></pre></td></tr></table></figure><ul><li><code>&gt;&gt;</code> 右移运算，向右进行移位操作，对无符号数，高位补 0，对于有符号数，高位补符号位，如<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unsigned int a = 8;</span><br><span class="line">a &gt;&gt; 3;</span><br><span class="line">移位前：0000 0000 0000 0000 0000 0000 0000 1000</span><br><span class="line">移位后：0000 0000 0000 0000 0000 0000 0000 0001</span><br><span class="line"></span><br><span class="line">int a = -8;</span><br><span class="line">a &gt;&gt; 3;</span><br><span class="line">移位前：1111 1111 1111 1111 1111 1111 1111 1000</span><br><span class="line">移位前：1111 1111 1111 1111 1111 1111 1111 1111</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-位运算巧解问题"><a href="#2-位运算巧解问题" class="headerlink" title="2 位运算巧解问题"></a>2 位运算巧解问题</h2><h3 id="2-1-位操作实现乘除法数"><a href="#2-1-位操作实现乘除法数" class="headerlink" title="2.1 位操作实现乘除法数"></a>2.1 位操作实现乘除法数</h3><blockquote><p>a 向右移一位，相当于将 a 除以 2；数 a 向左移一位，相当于将 a 乘以 2<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int a = 2;</span><br><span class="line">a &gt;&gt; 1; ---&gt; 1</span><br><span class="line">a &lt;&lt; 1; ---&gt; 4</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="2-2-位操作交换两数"><a href="#2-2-位操作交换两数" class="headerlink" title="2.2 位操作交换两数"></a>2.2 位操作交换两数</h3><blockquote><p>位操作交换两数可以不需要第三个临时变量，虽然普通操作也可以做到，但是没有其效率高<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//普通操作</span><br><span class="line">void swap(int &amp;a, int &amp;b) &#123;</span><br><span class="line">  a = a + b;</span><br><span class="line">  b = a - b;</span><br><span class="line">  a = a - b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//位与操作</span><br><span class="line">void swap(int &amp;a, int &amp;b) &#123;</span><br><span class="line">  a ^= b;</span><br><span class="line">  b ^= a;</span><br><span class="line">  a ^= b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>位与操作解释：</p><ul><li>第一步：a ^= b —-&gt; a = (a^b); </li><li>第二步：b ^= a —-&gt; b = b^(a^b) —-&gt; b = (b^b)^a = a</li><li>第三步：a ^= b —-&gt; a = (a^b)^a = (a^a)^b = b</li></ul></blockquote><h3 id="2-3-位操作判断奇偶数"><a href="#2-3-位操作判断奇偶数" class="headerlink" title="2.3 位操作判断奇偶数"></a>2.3 位操作判断奇偶数</h3><blockquote><p>只要根据数的最后一位是 0 还是 1 来决定即可，为 0 就是偶数，为 1 就是奇数。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(0 == (a &amp; 1)) &#123;</span><br><span class="line"> //偶数</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="2-4-位操作交换符号"><a href="#2-4-位操作交换符号" class="headerlink" title="2.4 位操作交换符号"></a>2.4 位操作交换符号</h3><blockquote><p>交换符号将正数变成负数，负数变成正数<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int reversal(int a) &#123;</span><br><span class="line">  return ~a + 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>整数取反加1，正好变成其对应的负数(补码表示)；负数取反加一，则变为其原码，即正数</p></blockquote><h3 id="2-5-位操作求绝对值"><a href="#2-5-位操作求绝对值" class="headerlink" title="2.5 位操作求绝对值"></a>2.5 位操作求绝对值</h3><blockquote><p>整数的绝对值是其本身，负数的绝对值正好可以对其进行取反加一求得，即我们首先判断其符号位（整数右移 31 位得到 0，负数右移 31 位得到 -1,即 0xffffffff），然后根据符号进行相应的操作<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int abs(int a) &#123;</span><br><span class="line">  int i = a &gt;&gt; 31;</span><br><span class="line">  return i == 0 ? a : (~a + 1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>上面的操作可以进行优化，可以将 i == 0 的条件判断语句去掉。我们都知道符号位 i 只有两种情况，即 i = 0 为正，i = -1 为负。对于任何数与 0 异或都会保持不变，与 -1 即 0xffffffff 进行异或就相当于对此数进行取反,因此可以将上面三目元算符转换为((a^i)-i)，即整数时 a 与 0 异或得到本身，再减去 0，负数时与 0xffffffff 异或将 a 进行取反，然后在加上 1，即减去 i(i =-1)<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int abs2(int a) &#123;</span><br><span class="line">  int i = a &gt;&gt; 31;</span><br><span class="line">  return ((a^i) - i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="2-6-位操作进行高低位交换"><a href="#2-6-位操作进行高低位交换" class="headerlink" title="2.6 位操作进行高低位交换"></a>2.6 位操作进行高低位交换</h3><p>给定一个 16 位的无符号整数，将其高 8 位与低 8 位进行交换，求出交换后的值，如：</p><blockquote><p>34520的二进制表示：<br>10000110 11011000</p><p>将其高8位与低8位进行交换，得到一个新的二进制数：<br>11011000 10000110<br>其十进制为55430</p></blockquote><p>从上面移位操作我们可以知道，</p><ul><li>只要将无符号数 a&gt;&gt;8 即可得到其高 8 位移到低 8 位，高位补 0；</li><li>将 a&lt;&lt;8 即可将 低 8 位移到高 8 位，低 8 位补 0;</li><li>然后将 a&gt;&gt;8 和 a&lt;&lt;8 进行或操作既可求得交换后的结果。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unsigned short a = 34520;</span><br><span class="line">a = (a &gt;&gt; 8) | (a &lt;&lt; 8);</span><br></pre></td></tr></table></figure><h3 id="2-7-位操作进行二进制逆序"><a href="#2-7-位操作进行二进制逆序" class="headerlink" title="2.7 位操作进行二进制逆序"></a>2.7 位操作进行二进制逆序</h3><p>将无符号数的二进制表示进行逆序，求取逆序后的结果，如</p><blockquote><p>数34520的二进制表示：<br>10000110 11011000</p><p>逆序后则为：<br>00011011 01100001<br>它的十进制为7009</p></blockquote><p>在字符串逆序过程中，可以从字符串的首尾开始，依次交换两端的数据。在二进制中使用位的高低位交换会更方便进行处理，这里我们分组进行多步处理。</p><ul><li><p>第一步:以每 2 位为一组，组内进行高低位交换</p><blockquote><p>交换前： 10 00 01 10 11 01 10 00<br>交换后： 01 00 10 01 11 10 01 00</p></blockquote></li><li><p>第二步：在上面的基础上，以每 4 位为 1 组，组内高低位进行交换</p><blockquote><p>交换前： 0100 1001 1110 0100<br>交换后： 0001 0110 1011 0001</p></blockquote></li><li><p>第三步：以每 8 位为一组，组内高低位进行交换</p><blockquote><p>交换前： 00010110 10110001<br>交换后： 01100001 00011011</p></blockquote></li><li><p>第四步：以每16位为一组，组内高低位进行交换</p><blockquote><p>交换前： 0110000100011011<br>交换后： 0001101101100001</p></blockquote></li></ul><p>对于上面的第一步，依次以 2 位作为一组，再进行组内高低位交换，这样处理起来<strong>比较繁琐</strong>，下面介绍另外一种方法进行处理。</p><p>先分别取原数 10000110 11011000 的奇数位和偶数位，将空余位用 0 填充：</p><blockquote><p>原数：  10000110 11011000<br>奇数位： 10000010 10001000<br>偶数位： 00000100 01010000</p></blockquote><p>再将奇数位右移一位，偶数位左移一位，此时将两个数据相或即可以达到奇偶位上数据交换的效果：</p><blockquote><p>原数：  10000110 11011000<br>奇数位右移一位： 0 10000010 1000100<br>偶数位左移一位：0000100 01010000 0<br>两数相或得到： 01001001 11100100</p></blockquote><p>上面的方法用位操作可以表示为：</p><ul><li>取a的奇数位并用 0 进行填充可以表示为：a &amp; 0xAAAA</li><li>取a的偶数为并用 0 进行填充可以表示为：a &amp; 0x5555 </li><li>因此，上面的第一步可以表示为：a = ((a &amp; 0xAAAA) &gt;&gt; 1) | ((a &amp; 0x5555) &lt;&lt; 1)</li><li>同理，可以得到其第二、三和四步为：<blockquote><p>a = ((a &amp; 0xCCCC) &gt;&gt; 2) | ((a &amp; 0x3333) &lt;&lt; 2)<br>a = ((a &amp; 0xF0F0) &gt;&gt; 4) | ((a &amp; 0x0F0F) &lt;&lt; 4)<br>a = ((a &amp; 0xFF00) &gt;&gt; 8) | ((a &amp; 0x00FF) &lt;&lt; 8)</p></blockquote></li></ul><p>因此整个操作为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">unsigned short a = 34520;</span><br><span class="line"></span><br><span class="line">a = ((a &amp; 0xAAAA) &gt;&gt; 1) | ((a &amp; 0x5555) &lt;&lt; 1);</span><br><span class="line">a = ((a &amp; 0xCCCC) &gt;&gt; 2) | ((a &amp; 0x3333) &lt;&lt; 2);</span><br><span class="line">a = ((a &amp; 0xF0F0) &gt;&gt; 4) | ((a &amp; 0x0F0F) &lt;&lt; 4);</span><br><span class="line">a = ((a &amp; 0xFF00) &gt;&gt; 8) | ((a &amp; 0x00FF) &lt;&lt; 8);</span><br></pre></td></tr></table></figure></p><h3 id="2-8-位操作统计二进制中-1-的个数"><a href="#2-8-位操作统计二进制中-1-的个数" class="headerlink" title="2.8 位操作统计二进制中 1 的个数"></a>2.8 位操作统计二进制中 1 的个数</h3><p>统计二进制1的个数可以分别获取每个二进制位数，然后再统计其1的个数，此方法效率比较低。这里介绍另外一种高效的方法，同样以 34520 为例，我们计算其 <code>a &amp;= (a-1)</code>的结果：</p><ul><li>第一次：计算前：1000 0110 1101 1000 计算后：1000 0110 1101 0000</li><li>第二次：计算前：1000 0110 1101 0000 计算后：1000 0110 1100 0000</li><li>第三次：计算前：1000 0110 1100 0000 计算后：1000 0110 1000 0000 </li></ul><p>我们发现，每计算一次二进制中就少了一个 1，则我们可以通过下面方法去统计：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">count = 0  </span><br><span class="line">while(a)&#123;  </span><br><span class="line">  a = a &amp; (a - 1);  </span><br><span class="line">  count++;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>参考文章</strong><br><a href="https://www.zhihu.com/question/38206659">位运算有什么奇技淫巧？</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-位运算简介&quot;&gt;&lt;a href=&quot;#1-位运算简介&quot; class=&quot;headerlink&quot; title=&quot;1 位运算简介&quot;&gt;&lt;/a&gt;1 位运算简介&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;amp;&lt;/code&gt; 与运算 两个位都是 1 时，结果才为 1，否则为 0，如：&lt;br&gt;&lt;code&gt;10011&amp;amp;11001=10001&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;|&lt;/code&gt; 或运算 两个位都是 0 时，结果才为 0，否则为 1，如 &lt;code&gt;10011 | 11001 = 11011&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;^&lt;/code&gt; 异或运算，两个位相同则为 0，不同则为 1，如 &lt;code&gt;10011 ^ 11001 = 01010&lt;/code&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;~&lt;/code&gt; 取反运算，0 则变为 1，1 则变为 0，如&lt;code&gt;~ 10011 = 01100&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;&amp;lt;&amp;lt;&lt;/code&gt; 左移运算，向左进行移位操作，高位丢弃，低位补 0，如&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="位运算" scheme="https://www.xiemingzhao.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>稀疏矩阵(Sparse Matrix)</title>
    <link href="https://www.xiemingzhao.com/posts/sparseMatrix.html"/>
    <id>https://www.xiemingzhao.com/posts/sparseMatrix.html</id>
    <published>2020-01-07T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.655Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在企业的深度学习项目中，<code>Sparse稀疏矩阵</code>这个词想必大家都不陌生。在模型的矩阵计算中，往往会遇到矩阵较为庞大且非零元素较少。由其是现在深度学习中embedding大行其道，稀疏矩阵成为必不可少的基建。而这种情况下，如果依然使用dense的矩阵进行存储和计算将是极其低效且耗费资源的。Sparse稀疏矩阵就称为了救命稻草。在拜读多篇优秀博客后，这里做一些自己的汇总和填补。</p><h2 id="2-稀疏矩阵"><a href="#2-稀疏矩阵" class="headerlink" title="2 稀疏矩阵"></a>2 稀疏矩阵</h2><h3 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h3><span id="more"></span><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix1.png" alt="sparseMatrix1"></p><p>如上所示，一般当矩阵非零项较少的时候，就称为非零矩阵，也即其中只有少量的有用信息-非零项。</p><p>那么可以做一个更为书面的<strong>定义</strong>：<br><code>具有少量非零项的矩阵 - Number of Non-Zero (NNZ) &lt; 0.5</code></p><blockquote><p>在矩阵中，若数值0的元素数目远多于非0元素的数目，并且非0元素分布没有规律。</p></blockquote><p><strong>矩阵的稠密度</strong></p><blockquote><p>非零元素的总数比上矩阵所有元素的总数为矩阵的稠密度。</p></blockquote><h3 id="2-2-压缩存储"><a href="#2-2-压缩存储" class="headerlink" title="2.2 压缩存储"></a>2.2 压缩存储</h3><p>存储矩阵的一般方法是采用二维数组，其优点是可以随机地访问每一个元素，因而能够容易实现矩阵的各种运算，如转置运算、加法运算、乘法运算等。</p><p>对于稀疏矩阵，它通常具有很大的维度，有时甚大到整个矩阵（零元素）占用了绝大部分内存，采用二维数组的存储方法既浪费大量的存储单元来存放零元素，又要在运算中浪费大量的时间来进行零元素的无效运算。因此必须考虑对稀疏矩阵进行压缩存储（只存储非零元素）。</p><p>我们可以通过<code>python</code>的<code>scipy</code>包看到一些压缩方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"><span class="built_in">help</span>(sparse)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Sparse Matrix Storage Formats</span></span><br><span class="line"><span class="string">There are seven available sparse matrix types:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        1. csc_matrix: Compressed Sparse Column format</span></span><br><span class="line"><span class="string">        2. csr_matrix: Compressed Sparse Row format</span></span><br><span class="line"><span class="string">        3. bsr_matrix: Block Sparse Row format</span></span><br><span class="line"><span class="string">        4. lil_matrix: List of Lists format</span></span><br><span class="line"><span class="string">        5. dok_matrix: Dictionary of Keys format</span></span><br><span class="line"><span class="string">        6. coo_matrix: COOrdinate format (aka IJV, triplet format)</span></span><br><span class="line"><span class="string">        7. dia_matrix: DIAgonal format</span></span><br><span class="line"><span class="string">        8. spmatrix: Sparse matrix base clas</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><p>其中一般较为常用的是<code>csc_matrix</code>，<code>csr_matrix</code>和<code>coo_matrix</code>。</p><h3 id="2-3-一些属性和通用方法"><a href="#2-3-一些属性和通用方法" class="headerlink" title="2.3 一些属性和通用方法"></a>2.3 一些属性和通用方法</h3><p>我们还是以<code>python</code>的<code>scipy</code>包为例，来介绍一些稀疏矩阵的属性和通用方法。</p><p><strong>稀疏属性</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> csr_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment">### 共有属性</span></span><br><span class="line">mat.shape  <span class="comment"># 矩阵形状</span></span><br><span class="line">mat.dtype  <span class="comment"># 数据类型</span></span><br><span class="line">mat.ndim  <span class="comment"># 矩阵维度</span></span><br><span class="line">mat.nnz   <span class="comment"># 非零个数</span></span><br><span class="line">mat.data  <span class="comment"># 非零值, 一维数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### COO 特有的</span></span><br><span class="line">coo.row  <span class="comment"># 矩阵行索引</span></span><br><span class="line">coo.col  <span class="comment"># 矩阵列索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### CSR\CSC\BSR 特有的</span></span><br><span class="line">bsr.indices    <span class="comment"># 索引数组</span></span><br><span class="line">bsr.indptr     <span class="comment"># 指针数组</span></span><br><span class="line">bsr.has_sorted_indices  <span class="comment"># 索引是否排序</span></span><br><span class="line">bsr.blocksize  <span class="comment"># BSR矩阵块大小</span></span><br></pre></td></tr></table></figure></p><p><strong>通用方法</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="comment">### 转换矩阵格式</span></span><br><span class="line">tobsr()、tocsr()、to_csc()、to_dia()、to_dok()、to_lil()</span><br><span class="line">mat.toarray()  <span class="comment"># 转为array</span></span><br><span class="line">mat.todense()  <span class="comment"># 转为dense</span></span><br><span class="line"><span class="comment"># 返回给定格式的稀疏矩阵</span></span><br><span class="line">mat.asformat(<span class="built_in">format</span>)</span><br><span class="line"><span class="comment"># 返回给定元素格式的稀疏矩阵</span></span><br><span class="line">mat.astype(t)  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 检查矩阵格式</span></span><br><span class="line">issparse、isspmatrix_lil、isspmatrix_csc、isspmatrix_csr</span><br><span class="line">sp.issparse(mat)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 获取矩阵数据</span></span><br><span class="line">mat.getcol(j)  <span class="comment"># 返回矩阵列j的一个拷贝，作为一个(mx 1) 稀疏矩阵 (列向量)</span></span><br><span class="line">mat.getrow(i)  <span class="comment"># 返回矩阵行i的一个拷贝，作为一个(1 x n)  稀疏矩阵 (行向量)</span></span><br><span class="line">mat.nonzero()  <span class="comment"># 非0元索引</span></span><br><span class="line">mat.diagonal()   <span class="comment"># 返回矩阵主对角元素</span></span><br><span class="line">mat.<span class="built_in">max</span>([axis])  <span class="comment"># 给定轴的矩阵最大元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 矩阵运算</span></span><br><span class="line">mat += mat     <span class="comment"># 加</span></span><br><span class="line">mat = mat * <span class="number">5</span>  <span class="comment"># 乘</span></span><br><span class="line">mat.dot(other)  <span class="comment"># 坐标点积</span></span><br></pre></td></tr></table></figure></p><h2 id="3-常用压缩方法"><a href="#3-常用压缩方法" class="headerlink" title="3 常用压缩方法"></a>3 常用压缩方法</h2><h3 id="3-1-COO"><a href="#3-1-COO" class="headerlink" title="3.1 COO"></a>3.1 COO</h3><p>全称是<code>Coordinate Matrix</code>对角存储矩阵，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><blockquote><ul><li>采用三元组(row, col, data)(或称为ijv format)的形式来存储矩阵中非零元素的信息;</li><li>三个数组 row 、col 和 data 分别保存非零元素的行下标、列下标与值（一般长度相同;</li><li>故 coo[row[k]][col[k]] = data[k] ，即矩阵的第 row[k] 行、第 col[k] 列的值为 data[k];</li></ul></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix2.png" alt="sparseMatrix2"></p><p><strong>适用场景</strong></p><ul><li>主要用来创建矩阵，因为coo_matrix无法对矩阵的元素进行增删改等操作</li><li>一旦创建之后，除了将之转换成其它格式的矩阵，几乎无法对其做任何操作和矩阵运算</li></ul><p><strong>优点</strong></p><ul><li>转换成其它存储格式很快捷简便（tobsr()、tocsr()、to_csc()、to_dia()、to_dok()、to_lil()）</li><li>能与CSR / CSC格式的快速转换</li><li>允许重复的索引（例如在1行1列处存了值2.0，又在1行1列处存了值3.0，则转换成其它矩阵时就是2.0+3.0=5.0）</li></ul><p><strong>缺点</strong></p><ul><li>不支持切片和算术运算操作</li><li>如果稀疏矩阵仅包含非0元素的对角线，则对角存储格式(DIA)可以减少非0元素定位的信息量</li><li>这种存储格式对有限元素或者有限差分离散化的矩阵尤其有效</li></ul><p><strong>属性</strong></p><ul><li>data：稀疏矩阵存储的值，是一个一维数组</li><li>row：与data同等长度的一维数组，表征data中每个元素的行号</li><li>col：与data同等长度的一维数组，表征data中每个元素的列号</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据</span></span><br><span class="line">row = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">col = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成coo格式的矩阵</span></span><br><span class="line"><span class="comment"># &lt;class &#x27;scipy.sparse.coo.coo_matrix&#x27;&gt;</span></span><br><span class="line">coo_mat = sparse.coo_matrix((data, (row, col)), shape=(<span class="number">4</span>, <span class="number">4</span>),  dtype=np.<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coordinate-value format</span></span><br><span class="line"><span class="built_in">print</span>(coo)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(0, 0)        1</span></span><br><span class="line"><span class="string">(1, 1)        2</span></span><br><span class="line"><span class="string">(2, 2)        3</span></span><br><span class="line"><span class="string">(3, 3)        4</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">coo.data</span><br><span class="line">coo.row</span><br><span class="line">coo.col</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转化array</span></span><br><span class="line"><span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line">coo_mat.toarray()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[1, 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 2, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 3, 4],</span></span><br><span class="line"><span class="string">       [0, 0, 0, 0]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h3 id="3-2-CSR"><a href="#3-2-CSR" class="headerlink" title="3.2 CSR"></a>3.2 CSR</h3><p>全称是<code>Compressed Sparse Row Matrix</code>压缩稀疏行格式，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><ul><li>csr_matrix是按行对矩阵进行压缩的</li><li>通过 indices, indptr，data 来确定矩阵。<br>data 表示矩阵中的非零数据</li><li>对于第 i 行而言，该行中非零元素的列索引为 indices[indptr[i]:indptr[i+1]]</li><li>可以将 indptr 理解成利用其自身索引 i 来指向第 i 行元素的列索引</li><li>根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如<ol><li>若 index[i] = 3 且 index[i+1] = 3 ，则第 i 行的没有非零元素</li><li>若 index[j] = 6 且 index[j+1] = 7 ，则第 j 行的非零元素的列索引为 indices[6:7]</li></ol></li><li>得到了行索引、列索引，相应的数据存放在： data[indptr[i]:indptr[i+1]]</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix3.png" alt="sparseMatrix3"></p><p><strong>构造方法</strong></p><ul><li>对于矩阵第 0 行，我们需要先得到其非零元素列索引<ol><li>由 indptr[0] = 0 和 indptr[1] = 2 可知，第 0 行有两个非零元素。</li><li>它们的列索引为 indices[0:2] = [0, 2] ，且存放的数据为 data[0] = 8 ， data[1] = 2</li><li>因此矩阵第 0 行的非零元素 csr[0][0] = 8 和 csr[0][2] = 2</li></ol></li><li>对于矩阵第 4 行，同样我们需要先计算其非零元素列索引<ol><li>由 indptr[4] = 3 和 indptr[5] = 6 可知，第 4 行有3个非零元素。</li><li>它们的列索引为 indices[3:6] = [2, 3，4] ，且存放的数据为 data[3] = 7 ，data[4] = 1 ，data[5] = 2</li><li>因此矩阵第 4 行的非零元素 csr[4][2] = 7 ， csr[4][3] = 1 和 csr[4][4] = 2</li></ol></li></ul><p><strong>适用场景</strong><br>常用于读入数据后进行稀疏矩阵计算，运算高效。</p><p><strong>优点</strong></p><ul><li>高效的稀疏矩阵算术运算</li><li>高效的行切片</li><li>快速地矩阵矢量积运算</li></ul><p><strong>缺点</strong></p><ul><li>较慢地列切片操作（可以考虑CSC）</li><li>转换到稀疏结构代价较高（可以考虑LIL，DOK）</li></ul><p><strong>属性</strong></p><ul><li>data ：稀疏矩阵存储的值，一维数组</li><li>indices ：存储矩阵有有非零值的列索引</li><li>indptr ：类似指向列索引的指针数组</li><li>has_sorted_indices：索引 indices 是否排序</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">indptr = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line">indices = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">data = np.array([<span class="number">8</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">csr = sparse.csr_matrix((data, indices, indptr))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为array</span></span><br><span class="line">csr.toarray()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[8, 0, 2, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 5, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 7, 1, 2],</span></span><br><span class="line"><span class="string">       [0, 0, 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, 9, 0]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h3 id="3-3-CSC"><a href="#3-3-CSC" class="headerlink" title="3.3 CSC"></a>3.3 CSC</h3><p>全称是<code>Compressed Sparse Column Matrix</code>压缩稀疏列矩阵，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><ul><li>csc_matrix是按列对矩阵进行压缩的</li><li>通过 indices, indptr，data 来确定矩阵，可以对比CSR</li><li>data 表示矩阵中的非零数据</li><li>对于第 i 列而言，该行中非零元素的行索引为indices[indptr[i]:indptr[i+1]]</li><li>可以将 indptr 理解成利用其自身索引 i 来指向第 i 列元素的列索引</li><li>根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如<ol><li>若 index[i] = 1 且 index[i+1] = 1 ，则第 i 列的没有非零元素</li><li>若 index[j] = 4 且 index[j+1] = 6 ，则第 j列的非零元素的行索引为 indices[4:6]</li></ol></li><li>得到了列索引、行索引，相应的数据存放在： data[indptr[i]:indptr[i+1]]</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix4.png" alt="sparseMatrix4"></p><p><strong>构造方法</strong></p><ul><li>对于矩阵第 0 列，我们需要先得到其非零元素行索引<ol><li>由 indptr[0] = 0 和 indptr[1] = 1 可知，第 0列行有1个非零元素。</li><li>它们的行索引为 indices[0:1] = [0] ，且存放的数据为 data[0] = 8</li><li>因此矩阵第 0 行的非零元素 csc[0][0] = 8</li></ol></li><li>对于矩阵第 3 列，同样我们需要先计算其非零元素行索引<ol><li>由 indptr[3] = 4 和 indptr[4] = 6 可知，第 4 行有2个非零元素。</li><li>它们的行索引为 indices[4:6] = [4, 6] ，且存放的数据为 data[4] = 1 ，data[5] = 9</li><li>因此矩阵第 i 行的非零元素 csr[4][3] = 1 ， csr[6][3] = 9</li></ol></li></ul><p>应用场景和优缺点基本上与<code>CSR</code>互相对应。</p><p><strong>特殊属性</strong></p><ul><li>data ：稀疏矩阵存储的值，一维数组</li><li>indices ：存储矩阵有有非零值的行索引</li><li>indptr ：类似指向列索引的指针数组</li><li>has_sorted_indices ：索引是否排序</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">row = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">col = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">data = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">csc = sparse.csc_matrix((data, (row, col)), shape=(<span class="number">3</span>, <span class="number">3</span>)).toarray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为array</span></span><br><span class="line">csc.toarray()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[1, 0, 4],</span></span><br><span class="line"><span class="string">       [0, 0, 5],</span></span><br><span class="line"><span class="string">       [2, 3, 6]], dtype=int64)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按col列来压缩</span></span><br><span class="line"><span class="comment"># 对于第i列，非0数据行是indices[indptr[i]:indptr[i+1]] 数据是data[indptr[i]:indptr[i+1]]</span></span><br><span class="line"><span class="comment"># 在本例中</span></span><br><span class="line"><span class="comment"># 第0列，有非0的数据行是indices[indptr[0]:indptr[1]] = indices[0:2] = [0,2]</span></span><br><span class="line"><span class="comment"># 数据是data[indptr[0]:indptr[1]] = data[0:2] = [1,2],所以在第0列第0行是1，第2行是2</span></span><br><span class="line"><span class="comment"># 第1行，有非0的数据行是indices[indptr[1]:indptr[2]] = indices[2:3] = [2]</span></span><br><span class="line"><span class="comment"># 数据是data[indptr[1]:indptr[2] = data[2:3] = [3],所以在第1列第2行是3</span></span><br><span class="line"><span class="comment"># 第2行，有非0的数据行是indices[indptr[2]:indptr[3]] = indices[3:6] = [0,1,2]</span></span><br><span class="line"><span class="comment"># 数据是data[indptr[2]:indptr[3]] = data[3:6] = [4,5,6],所以在第2列第0行是4，第1行是5,第2行是6</span></span><br></pre></td></tr></table></figure></p><h3 id="3-4-BSR"><a href="#3-4-BSR" class="headerlink" title="3.4 BSR"></a>3.4 BSR</h3><p>全称是<code>Block Sparse Row Matrix</code>分块压缩稀疏行格式，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.bsr_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><ul><li>基于行的块压缩，与csr类似，都是通过data，indices，indptr来确定矩阵</li><li>与csr相比，只是data中的元数据由0维的数变为了一个矩阵（块），其余完全相同</li><li>块大小 blocksize<ol><li>块大小 (R, C) 必须均匀划分矩阵 (M, N) 的形状。</li><li>R和C必须满足关系：M % R = 0 和 N % C = 0</li><li>适用场景及优点参考csr</li></ol></li></ul><p><strong>特殊属性</strong></p><ul><li>data ：稀疏矩阵存储的值，一维数组</li><li>indices ：存储矩阵有有非零值的列索引</li><li>indptr ：类似指向列索引的指针数组</li><li>blocksize ：矩阵的块大小</li><li>has_sorted_indices：索引 indices 是否排序</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">indptr = np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>])</span><br><span class="line">indices = np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">data = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]).repeat(<span class="number">4</span>).reshape(<span class="number">6</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">bsr = bsr_matrix((data, indices, indptr), shape=(<span class="number">6</span>,<span class="number">6</span>)).todense()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为array</span></span><br><span class="line">bsr.todense()</span><br><span class="line">matrix([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure></p><h3 id="3-5-LIL"><a href="#3-5-LIL" class="headerlink" title="3.5 LIL"></a>3.5 LIL</h3><p>全称是<code>Linked List Matrix</code>链表矩阵格式，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><ul><li>使用两个列表存储非0元素data</li><li>rows保存非零元素所在的列</li><li>可以使用列表赋值来添加元素，如 lil[(0, 0)] = 8</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix5.png" alt="sparseMatrix5"></p><p><strong>构造方法</strong></p><ul><li>lil[(0, -1)] = 4 ：第0行的最后一列元素为4</li><li>lil[(4, 2)] = 5 ：第4行第2列的元素为5</li></ul><p><strong>适用场景</strong></p><ul><li>适用的场景是逐渐添加矩阵的元素（且能快速获取行相关的数据）</li><li>需要注意的是，该方法插入一个元素最坏情况下可能导致线性时间的代价，所以要确保对每个元素的索引进行预排序</li></ul><p><strong>优点</strong></p><ul><li>适合递增的构建成矩阵</li><li>转换成其它存储方式很高效</li><li>支持灵活的切片</li></ul><p><strong>缺点</strong></p><ul><li>当矩阵很大时，考虑用coo</li><li>算术操作，列切片，矩阵向量内积操作慢</li></ul><p><strong>属性</strong></p><ul><li>data：存储矩阵中的非零数据</li><li>rows：存储每个非零元素所在的列（行信息为列表中索引所表示）</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">lil = sparse.lil_matrix((<span class="number">6</span>, <span class="number">5</span>), dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数值</span></span><br><span class="line"><span class="comment"># set individual point</span></span><br><span class="line">lil[(<span class="number">0</span>, -<span class="number">1</span>)] = -<span class="number">1</span></span><br><span class="line"><span class="comment"># set two points</span></span><br><span class="line">lil[<span class="number">3</span>, (<span class="number">0</span>, <span class="number">4</span>)] = [-<span class="number">2</span>] * <span class="number">2</span></span><br><span class="line"><span class="comment"># set main diagonal</span></span><br><span class="line">lil.setdiag(<span class="number">8</span>, k=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set entire column</span></span><br><span class="line">lil[:, <span class="number">2</span>] = np.arange(lil.shape[<span class="number">0</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为array</span></span><br><span class="line">lil.toarray()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[ 8,  0,  1,  0, -1],</span></span><br><span class="line"><span class="string">       [ 0,  8,  2,  0,  0],</span></span><br><span class="line"><span class="string">       [ 0,  0,  3,  0,  0],</span></span><br><span class="line"><span class="string">       [-2,  0,  4,  8, -2],</span></span><br><span class="line"><span class="string">       [ 0,  0,  5,  0,  8],</span></span><br><span class="line"><span class="string">       [ 0,  0,  6,  0,  0]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">lil.data</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([list([0, 2, 4]), list([1, 2]), list([2]), list([0, 2, 3, 4]),</span></span><br><span class="line"><span class="string">       list([2, 4]), list([2])], dtype=object)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">lil.rows</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[list([8, 1, -1])],</span></span><br><span class="line"><span class="string">       [list([8, 2])],</span></span><br><span class="line"><span class="string">       [list([3])],</span></span><br><span class="line"><span class="string">       [list([-2, 4, 8, -2])],</span></span><br><span class="line"><span class="string">       [list([5, 8])],</span></span><br><span class="line"><span class="string">       [list([6])]], dtype=object)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p><h3 id="3-6-DIA"><a href="#3-6-DIA" class="headerlink" title="3.6 DIA"></a>3.6 DIA</h3><p>全称是<code>Diagonal Matrix</code>对角存储格式格式，这里是<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.dia_matrix.html">官方文档</a>。</p><p><strong>定义详解</strong></p><ul><li>最适合对角矩阵的存储方式</li><li>dia_matrix通过两个数组确定： data 和 offsets</li><li>data ：对角线元素的值</li><li>offsets ：第 i 个 offsets 是当前第 i 个对角线和主对角线的距离</li><li>data[k:] 存储了 offsets[k] 对应的对角线的全部元素</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/sparseMatrix6.png" alt="sparseMatrix6"></p><p><strong>构造方法</strong></p><ul><li>当 offsets[0] = 0 时，表示该对角线即是主对角线，相应的值为 [1, 2, 3, 4, 5]</li><li>当 offsets[2] = 2 时，表示该对角线为主对角线向上偏移2个单位，相应的值为 [11, 12, 13, 14, 15]</li><li>但该对角线上元素仅有三个 ，于是采用先出现的元素无效的原则</li><li>即前两个元素对构造矩阵无效，故该对角线上的元素为 [13, 14, 15]</li></ul><p><strong>属性</strong></p><ul><li>data：存储DIA对角值的数组</li><li>offsets：存储DIA对角偏移量的数组</li></ul><p><strong>code case</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">data = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">offsets = np.array([<span class="number">0</span>, -<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">dia = sparse.dia_matrix((data, offsets), shape=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">dia.data</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[[1 2 3 4]</span></span><br><span class="line"><span class="string">        [5 6 0 0]</span></span><br><span class="line"><span class="string">        [0 7 8 9]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为array</span></span><br><span class="line">dia.toarray()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">array([[1 7 0 0]</span></span><br><span class="line"><span class="string">       [0 2 8 0]</span></span><br><span class="line"><span class="string">       [5 0 3 9]</span></span><br><span class="line"><span class="string">       [0 6 0 4]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><br><strong>参考文献</strong><br><a href="https://cloud.tencent.com/developer/article/1544016">经典算法之稀疏矩阵    </a><br><a href="https://zhuanlan.zhihu.com/p/188700729">Sparse稀疏矩阵主要存储格式总结</a><br><a href="https://www.jianshu.com/p/dca6ed5f213f">20190624_稀疏矩阵存储及计算介绍</a><br><a href="https://www.jianshu.com/p/b335ad456990">sparse matrix 的分布式存储和计算</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在企业的深度学习项目中，&lt;code&gt;Sparse稀疏矩阵&lt;/code&gt;这个词想必大家都不陌生。在模型的矩阵计算中，往往会遇到矩阵较为庞大且非零元素较少。由其是现在深度学习中embedding大行其道，稀疏矩阵成为必不可少的基建。而这种情况下，如果依然使用dense的矩阵进行存储和计算将是极其低效且耗费资源的。Sparse稀疏矩阵就称为了救命稻草。在拜读多篇优秀博客后，这里做一些自己的汇总和填补。&lt;/p&gt;
&lt;h2 id=&quot;2-稀疏矩阵&quot;&gt;&lt;a href=&quot;#2-稀疏矩阵&quot; class=&quot;headerlink&quot; title=&quot;2 稀疏矩阵&quot;&gt;&lt;/a&gt;2 稀疏矩阵&lt;/h2&gt;&lt;h3 id=&quot;2-1-定义&quot;&gt;&lt;a href=&quot;#2-1-定义&quot; class=&quot;headerlink&quot; title=&quot;2.1 定义&quot;&gt;&lt;/a&gt;2.1 定义&lt;/h3&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="稀疏矩阵" scheme="https://www.xiemingzhao.com/tags/%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5/"/>
    
  </entry>
  
  <entry>
    <title>Deep and Cross Network for Ad Click Predictions (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/96501d7f.html"/>
    <id>https://www.xiemingzhao.com/posts/96501d7f.html</id>
    <published>2019-07-28T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.652Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1708.05123.pdf">原始论文：Deep &amp; Cross Network for Ad Click Predictions</a></p><h2 id="深度和交叉网络的广告点击预测"><a href="#深度和交叉网络的广告点击预测" class="headerlink" title="深度和交叉网络的广告点击预测"></a>深度和交叉网络的广告点击预测</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。</p><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。</p><span id="more"></span><p>识别出常用的预测特征且同时探索出那些看不见的或者稀少的交叉特征是做出好预测的关键。然而，网站级别的推荐系统的数据主要都是离散的和类别型的，这就导致了一个大的和稀疏的特征空间，而这对于特征探索来说是一个挑战。这就限制了大多数的大规模系统都是线性模型例如逻辑回归。</p><p>线性模型是简单的，可解释的并且容易扩展的；然而，它们受限于自己的表达能力。另一方面，交叉特征已经被证明能够有效地提高模型的表达力。不幸的是，它一般要求人工特征工程或者穷举来找到这些特征；再者，泛化出这些看不见的特征交叉项是很困难的。</p><p>在本文中，我们致力于通过引入一个新的神经网络结构来避免特征工程任务——一个<em>交叉网络</em>——它是以自动的方式显示地应用在特征交叉中。交叉网络由多层网络组成，其中特征的最高交叉维度完全由网络层的深度决定。每一层网络都以及已经存在的特征生成一个更高度的交叉项，同时又保留了前一层网络的交叉项。我们将交叉忘了和一个深度神经网络（DNN）进行联合训练。DNN能够捕获特征中的非常复杂的交叉项；然而，相比于我们的交叉忘了它需要同一数量级的参数，也无法形成显示的交叉特征，并且可能无法有效地学习某些特征交叉项。然而，交叉和深度部分的联合训练能够有效地捕获预测性的特征交叉项，并且在Criteo CTR数据集上提供了一个最先进的效果表现。</p><p><strong>1.1 相关工作</strong><br>由于数据集的规模和维度急剧性的增加，于是提出了很多的方法用来避免特定任务中的大规模特征工程，大部分都是基于嵌入技术和神经网络的。</p><p>因式分解机（FMs）将稀疏特征映射到低维的稠密向量上，并且从这些特征的内积中学习特征交叉项。场感知因式分解机（FFMs）让每个特征都可以学习到多个向量，其中每个响亮都是与一个场相关的。遗憾的是，FM和FFM浅显的结构限制了它们的模型表达力。有许多的工作都是为了将FM扩展到一个更高的级别，但是一个缺点就是产生了大量的参数从而大大增加了原本他们不期望产生的计算成本。深度神经网络（DNN）就可以学习到一些重要的高维的特征交叉项，这得益于它们的嵌入向量和非线性的激活函数。最近残差网络的成功使得训练一个非常深的网络有了可能。深度交叉扩展了残差网络，同时通过对所有输入类型的堆叠达到了自动特征学习的效果。</p><p>深度学习的非凡成功引出了它的表达力的理论分析。有研究表明，在给定足够多的的隐含单元或者隐含层的时候，DNN能够再某种平滑线的假设条件下取近似一个有任意准确性的函数。再者，实际上已经发现了DNN在有合适参数的时候就已经能够表现地很好了。一个关键的原因就是实际使用的大多数函数都不是任意选择的。</p><p>一个依然存在的问题就是DNN是否真的在那些实际中使用的表征函数中是最有效的一个。在Kaggle竞赛中，许多胜利者的解决方法中人工精心设计的特征都是低阶的、确切形式且有效地。另一方面，从DNN中学习到的特征都是隐含的且高度非线性的。这就表明了设计一个模型要能够学习到相比于普通的DNN更加有效且确切的有界阶特征交叉项。</p><p>wide-and-deep就是这种想法创建的模型。它将交叉特征作为线性模型的输入，然后将线性模型和DNN模型进行联合训练。然而，wide-and-deep是否成功很大程度上依赖于交叉特征的事前选择，一个指数级的问题就是是否存在还没发现的更有效的方法。</p><p><strong>1.2 主要贡献</strong><br>在本文中，我们提出了Deep &amp; Cross Network（DCN）模型，它能够在同时有稀疏输入和密集输入的时候进行网站规模的自动化特征学习。DCN能够有效地抓取有界阶的有用特征交叉项，学习高度非线性的交叉项，并且不要求人工特征工程或者穷举，同时又只有较低的计算成本。</p><p>本文主要的贡献包括：</p><ul><li>我们提出了一个将特征交叉应用在每一层的新交叉网络，它能够有效地学习到具有预测价值的有限阶交叉特征，并且不要求进行人工特征工程或者穷举。</li><li>交叉忘了是简单且有效的。通过设计，每一层多项式的最高阶都在增加并且由层数的深度决定。整个网络是由从低阶到高阶的交叉项以及所有不同的系数组成的。</li><li>交叉网络是能够有效记忆的，并且能够很简单地实现。</li><li>一个带有交叉网络的DNN，在参数个数少一个量级的情况下，它的对数损失依然比普通的DNN要低。</li></ul><h3 id="2-深度-amp-交叉网络（DCN）"><a href="#2-深度-amp-交叉网络（DCN）" class="headerlink" title="2 深度&amp;交叉网络（DCN）"></a><strong>2 深度&amp;交叉网络（DCN）</strong></h3><p>在这一部分，我们将会介绍深度&amp;交叉网络（DCN）模型的结构。DCN是开始于embedding和stacking层的，紧接着是一个交叉网络和一个深度网络并行。按顺序接着是一个最终的联合层用来合并两个网络的输出。完整的DCN模型如图1中所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/deep%26cross-1.JPG" alt="D&amp;C-1.jpg"></p><p><strong>2.1 嵌入和堆叠层</strong><br>我们考虑包含稀疏和密集特征的输入数据。在网站级规模的推荐系统如CTR预估中，输入数据大部分都是类别型特征，例如“country=usa”。这样的特征经常会被进行one-hot编码，例如“[0,1,0]”；然而，这就经常导致产生过高维的特征空间来适用大型词典。</p><p>为了降低维度，我们使用了一个embedding过程来将这些二值特征转换成密集的实值向量（通常称为嵌入向量）：</p><script type="math/tex; mode=display">x_{embed,i}=W_{embed,i}x_i</script><p>其中$x<em>{embed,i}$是嵌入向量，$x_i$是第i个类别的二值输入，$W</em>{embed,i} \ \in \mathbb R^{n_e \times n_v}$是对应的嵌入矩阵，它可以和网络中其他的参数一起进行优化，$n_e,n_v$分别是嵌入层大小和词典的大小。</p><p>最后，我们将嵌入向量和标准化后的密集特征进行堆叠，形成一个最终的向量：</p><script type="math/tex; mode=display">x_0 = [x_{embed,1}^T,...,x_{embed,k}^T,x_{dense}^T]</script><p>然后再将这个向量喂入到网络中去。</p><p><strong>2.2 交叉网络</strong><br>我们创新交叉网络的关键思想就是以一个有效地方式来显示地应用特征交叉。交叉网络由交叉层组成，每一层都有如下的公式：</p><script type="math/tex; mode=display">x_{l+1} = x_0 x_l^T w_l + b_l x_l = f(x_l , w_l, b_L) + x_l</script><p>其中$x<em>l,x</em>{l+1} \ \in \ \mathbb R^d$都是列向量，分别表示第l层和第l+1层交叉网络的输出$w<em>l, b_l \ \in \ \mathbb R^d$是第l层网络的权重和偏置项参数。每一交叉层在特征交叉f之后都反加上它的输入部分，并且映射函数$f:\mathbb R^d \rightarrow \mathbb R^d$拟合$x</em>{l+1}-x_l$的残差。一个交叉层的可视化展示如图2所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/deep%26cross-2.JPG" alt="D&amp;C-2.jpg"></p><p><strong>高阶特征交叉项</strong>。交叉网络特殊的结构造就了交叉特征的阶数随着网络层数增加而增加。第l层交叉网络的多项式最高阶数（相对于输入层来说）是l+1。事实上，交叉网络包含了所有的交叉项$x_1^{\alpha_1} x_2^{\alpha_2}…x_d^{\alpha_d}$，其中d取值从1到l+1。详细的分析在章节3。</p><p><strong>复杂度分析</strong>$L_c$表示交叉层的个数，d表示输入层的维度。然后，交叉网络中的参数个数就是：</p><script type="math/tex; mode=display">d \times L_c \times 2</script><p>交叉网络的时间和空间复杂度是关于输入层维度的线性增长。因此，交叉网络相比与其深度部分仅引入了一个微乎其微的复杂度部分，这使得DCN的整体复杂度与传统的DNN基本一致。这个有效性是得益于$x_0x_l^T$的秩为1的属性，这使得我们可以无需计算和存储整个矩阵的时候生成所有的交叉项。</p><p>交叉网络很少的参数限制了模型的能力。为了获得更高阶的非线性交叉项，我们并行引入了深度网络。</p><p><strong>2.3 深度网络</strong><br>深度网络部分是一个全连接的前向神经网络，其每一层的公式可以表示成如下：</p><script type="math/tex; mode=display">h_{l+1} = f(W_lh_l+b_l)</script><p>其中$h<em>l \in \mathbb R^{n_l},h</em>{l+1}\in \mathbb R^{n<em>{l+1}}$分别是第l和第l+1隐含层；$W_l \in \mathbb R^{n</em>{l+1} \times n<em>l}, b_l \in \mathbb R^{n</em>{l+1}}$是第l深度层的参数；$f(\cdot)$是ReLU激活函数。</p><p><strong>复杂度分析</strong>。为了简化，我们假设所有的深度网络层都是等维度的。$L_d$表示深度网络的层数，m表示深度网络层的大小。那么深度网络的参数个数就是：</p><script type="math/tex; mode=display">d \times m + m + (m^2 + m) \times (L_d -1)</script><p><strong>2.4 联合层</strong><br>联合层是合并了了两个网络的输出部分，然后将合并后的向量喂入到标准的逻辑层中。</p><p>下面就是二分类问题的公式：</p><script type="math/tex; mode=display">p = \sigma([x_{l_1}^L,h_{L_2}^T w_{logits})</script><p>其中$x<em>{L_1} \in \mathbb R^d, h</em>{L<em>2} \in \mathbb R^m$分别是交叉网络和深度网络的输出，$w</em>{logits} \in \mathbb R^{(d+m)}$是合并层的参数向量，并且$\sigma(x) = 1/(1+exp(-x))$。</p><p>损失函数是带有正则项的对数损失函数，</p><script type="math/tex; mode=display">loss = -\frac{1}{N} \sum_{i=1}^N y_i log(p_i) + (1-y_i) log(1-p_i) + \lambda \sum_l ||w_l||^2</script><p>其中$p_i$是根据前一个公式计算的概率值，$y_i$是真实的标签，N是输入层的总数，$\lambda$是L2正则项参数。</p><p>我们将两个网络联合一起进行训练，这使得每一个单独的网络在训练过程中可以感知到其他部分。</p><h3 id="3-交叉网络分析"><a href="#3-交叉网络分析" class="headerlink" title="3 交叉网络分析"></a><strong>3 交叉网络分析</strong></h3><p>在这一部分，我们分析DCN的交叉网络为了更好地理解它的有效性。我们我们提拱了三个角度：多项式近似，泛化成FM，和高效映射。为了简化，我们假设$b_i = 0$。</p><p><em>注意</em>。将$w<em>j$中的第i个元素表示成$w_j^{(i)}$。对于多索引$\alpha = [\alpha_1,…,\alpha_d] \in \mathbb N^d$和$x = [x_1,…,x_d] \in \mathbb R^d$，我们定义$|\alpha| = \sum</em>{i=1}^d \alpha_i$。</p><p><em>术语</em>。交叉项（单个的）的等级$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$定义为$|\alpha|$。多项式的阶数由交叉项的最高阶来确定。</p><p><strong>3.1 多项式近似</strong><br>根据魏尔斯特拉斯逼近定理，闭区间上的连续函数可以用多项式函数一致逼近。因此，我们将从多项式逼近的角度来分析交叉网络。特别地，交叉网络近似的同次多项式类，以一种有效地、更具表达力的并且泛化的方式拟合现实数据集。</p><p>我们仔细地研究了关于交叉网络的同次多项式类的近似。我们定义$P_n(x)$表示n次多项式：</p><script type="math/tex; mode=display">P_n(x) = \{\sum_{\alpha} w_{\alpha} x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq n, \alpha \in \mathbb N^d\}</script><p>这个类中的每个多项式都有$O(d^n)$个系数。我们证明了，仅仅需要$O(d)$个参数，交叉网络就可以包含同次多项式汇总的所有交叉项，并且每一项的系数都互不相同。</p><p><em>定理3.1</em> 考虑一个l层交叉网络，其第i+1层定义为$x_{i+1} = x_0x_i^Tw_i + x_i$。网络的输入设为$x_0 = [x_1,x_2,…,x_d]^T$，输出为$g_l(x_0) = x_l^Tw_l$，其中参数为$w_i,b_i \in \mathbb R^d$。然后，这个多项式$g_l(x_0)$将会衍生出下面的多项式类：</p><script type="math/tex; mode=display">\{\sum_{\alpha} c_{\alpha}(w_0,...,w_L) x_1^{\alpha_1} x_2^{\alpha_2}...x_d^{\alpha_d}|0 \leq |\alpha| \leq l+1, \alpha \in \mathbb N^d \}</script><p>其中$c<em>{\alpha} = M</em>{\alpha} \sum<em>{i \in B</em>{\alpha}} \sum<em>{j \in P</em>{\alpha}} \prod<em>{k = 1}^{|\alpha|} w</em>{i<em>k}^{(j_k)}$，$M</em>{\alpha}$是常数，且与$w<em>i$无关，$i = [i_1,…,i</em>{|\alpha|}] 和 j = [j<em>1,…,i</em>{|\alpha|}]$是对应的索引，$B<em>{\alpha} = {y \in {0,1,…,l}^{|\alpha|}||y_i &lt; y_j \cap y</em>{|\alpha|} = l}$，并且$P_{\alpha}$是索引所有排列组成的集合$(1,…,1 \cdots d,…,d)$。</p><p>定理3.1的证明在附录中。我们给定一个示例，考虑$x<em>1x_2x_3$的系数$c</em>{\alpha}$，其中$\alpha = (1,1,1,0,…,0)$。对于某些常数，当$l = 2, c<em>{\alpha} = \sum</em>{i,j,k \in P<em>{\alpha}} w_0^{(i)} w_1^{(j)} w_2^{(k)}$；当$l = 3, c</em>{\alpha} = \sum<em>{i,j,k \in P</em>{\alpha}} w_0^{(i)} w_1^{(j)} w_3^{(k)} +  w_0^{(i)} w_2^{(j)} w_3^{(k)} +  w_1^{(i)} w_2^{(j)} w_3^{(k)}$。</p><p><strong>3.2 FM的推广</strong><br>交叉网络这种参数分享的思想类似于FM模型，进一步将其扩展到一个深度结构。</p><p>在FM模型中，特征$x<em>i$是伴随着一个参数向量$v_i$，并且交叉项$x_ix_j$的权重是由$(v_i,v_i)$计算得到的。在DCN汇总，$x_i$是和标量集${w_k^{(i)} }_k^l$相关的，并且$x_i x_j$的权重是由集合${w_k^{(i)} }</em>{k=0}^l$ 和 ${w<em>k^{(j)} }</em>{k=0}^l$中的各参数相乘得到的。模型每个特征学习的一些参数是独立于其他特征的，交叉项的权重是对应参数的某种联合。参数贡献不仅能够是的模型更加有效，而且也能使得模型能够产生看不见的特征交叉项并且使其对于噪声更加稳健。例如，使用带有稀疏特征的数据集的时候。如果两个二值类特征$x_i$和$x_j$很少或者从来不会在训练集中出现，即$x_i \neq 0 \wedge x_j \neq 0$，所以学习到的$x_i,x_j$的权重就不会在预测中输出有异议的信息。</p><p>FM模型是一个比较浅显的结构，其职能表征出2次的交叉项。相反，DCN能够构建所有的交叉项$x_1^{\alpha_1}x_2^{\alpha_2}…x_d^{\alpha_d}$其中$|\alpha|$由一些决定于网络层深度的常数来界定，如定理3.1所声明。因此，交叉网络是将参数共享这种思想从单层扩展到了多层和高次交叉项。注意到，不同于高阶的FM模型，一个交叉网络中的参数的个数仅仅随着输入层维度而线性增的长。</p><p><strong>3.3 高效地投影</strong><br>每一个交叉网络层都会将$x_0和x_l$映射出它们之间所有的成对交叉项，并且以一种有效的方式产生输入层的维度。</p><p>考虑$\tilde x \in \mathbb R^d$作为一个交叉层的输入。交叉层会隐式地构建出$d^2$个成对交叉项$x_i \tilde x_j$，并且会以一个高效记忆的方式将它们映射到d维空间。然而，直接的方式将会带来三倍的成本。</p><p>我们的交叉层提供了有效地解决方案来将成本降低到关于d维的线性函数。对于$x_p = x_0 \tilde x^T w$。这实际上等于：</p><script type="math/tex; mode=display">x_p^T = [x_1\tilde x_1 ... x_1 \tilde x_d \ ... \ x_d \tilde x_1 ... x_d \tilde x_d] \left[\begin{array}{cccc}w&0&...&0 \\ 0&w&...&0 \\ ...&...&...&... \\ 0&0&...&w \end{array} \right]</script><p>其中行向量包含所有的$d^2$个成对的交叉向量$x_i\tilde x_j$，投影矩阵有一个固定的对角结构，其中$w\in \mathbb R^d$是一个列向量。</p><h3 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4 实验结果</strong></h3><p>在这一部分，我们字啊一些流行的预测数据及上评估DCN模型的表现。</p><p><strong>4.1 Criteo Display Ads 数据</strong><br>Criteo Display广告数据及是为了预测广告点击率的。它包含13个整数型特征和26个类别型特征，其中每个类别都有高基数集。对于这个数据集，<strong>在对数损失上有0.001的提升就可以被认为是实践显著的。</strong>当考虑一个大的用户基础的时候，预测准确率的一个小提升就潜在地带来公司收益的大增长。数据包含11GB的横跨7天的用户日志（大约4100万条记录）。我们使用前6天的数据进行预测，并且将第7天的数据随机地等量地分成测试集和验证集。</p><p><strong>4.2 实现细节</strong><br>DCN是在TensorFlow上实现的，我们简短地讨论一些DCN训练中的一些实现细节。</p><p><em>数据的处理和嵌入*</em>。实值特征是使用对数变化来进行标准化处理的。对于类别特征，我们将特征嵌入成具有维度$6 \times (category cardinality)^{1/4}$的密集向量。将所有的嵌入结果全部连接到一起形成一个1026维的向量。</p><p><em>优化</em>。我们使用Adam这种小批量随机优化的优化器。批量大小社会为512。批量标准化应用在了深度网络中，并且将梯度裁剪常数（gradient clip norm）设为100.</p><p><em>正则化</em>。我们使用early stopping机制，因为我们使用L2正在和dropout都不起作用。</p><p><em>超参数</em>。我们汇报了对隐含层个数，隐含层大小，初始学习率以及交叉层个数进行grid search的结果。隐含层的个数是从2到5，隐含层的大小是从32到1024.对于DCN，交叉层的个数是从1到6,。初始学习率从0.0001到0.001，每次增加0.0001。所有的实验都使用了early stopping，训练步数设为150000，过拟合发生的时候就会提前停止。</p><p><strong>4.3 模型比较</strong><br>我们将DCN和5种模型进行了比较：没有交叉网络的DCN模型（DNN），逻辑回归（LR），因式分解机（FMs），Wide&amp;Deep模型（W&amp;D）和深度交叉模型（DC）。</p><p><em>DNN</em>。嵌入层、输出层以及过程中的超参数都是用与DCN一致的。唯一和DCN不用的就是没有交叉层。</p><p><em>LR</em>。我们使用Siby1——一个大型的机器学习系统来区分逻辑回归。整数型特征会被离散到一个对数尺度。交叉特征将会由一个精致且复杂的特诊供选择工具来进行筛选。所有的单特征是都会被使用。</p><p><em>FM</em>。我们使用了带有特定细节的FM模型。</p><p><em>W&amp;D</em>。不同于DCN，它的宽部分作为输入原始稀疏特征，并且依赖于穷举和知识域来选取有预测价值的交叉特征。我们跳过了这一块的比较因为没有比较好的方法来选择交叉特征。</p><p><em>DC</em>。相比于DCN，DC没有显示地构造交叉特征。它主要依靠堆叠和残差项来隐式地创造交叉特征。我们使用和DCN相同的嵌入层，紧接着是另一个ReLu层来生成输入数据到残差单元系列中。残差单元的个数一半设为1到5之间，输入维度和交叉维度一般是从100到1026。</p><h3 id="4-4-模型表现"><a href="#4-4-模型表现" class="headerlink" title="4.4 模型表现"></a><strong>4.4 模型表现</strong></h3><p>在这一部分，我们首先会列出不同模型在对数损失下的最好的结果，然后我们会将DCN和DNN进行仔细对比，之后，我们再进一步分析引入交叉网络的效果。</p><p><strong>不同模型的表现</strong>。不同模型的对数损失的最好测试结果都列在了表1中。最优的超参数设置是DCN模型有2个深层且大小为1024和6个交叉层，DNN则有大小为1024的5层网络，DC模型有5个输入维度为424交叉维度为537的残差单元，LR模型有42个交叉特征。最终发现最深的交叉结构获得了最好的表现结果，这表明交叉网络中高次的特征交叉项是有用的。如我们所见，DCN要远好于所有其他的模型。特别地，它优于最先进的DNN模型，而且仅仅是相对于DNN用了40%的内存消费。</p><p><em>表1 不同模型的最优对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Model</th><th style="text-align:center">DCN</th><th style="text-align:center">DC</th><th style="text-align:center">DNN</th><th style="text-align:center">FM</th><th style="text-align:center">LR</th></tr></thead><tbody><tr><td style="text-align:center">Logloss</td><td style="text-align:center"><strong>0.4419</strong></td><td style="text-align:center">0.4425</td><td style="text-align:center">0.4428</td><td style="text-align:center">0.4464</td><td style="text-align:center">0.4474</td></tr></tbody></table></div><p>对于每个模型的最优超参数设置，我们也汇报了10次不同对数损失测试结果的均值和标准差：<br>$DCN:0.4422 \pm 9 \times 10^{-5}$<br>$DNN:0.4430 \pm 3.7 \times 10^{-4}$<br>$DC:0.4430 \pm 4.3 \times 10^{-4}$。<br>如我们如看到的，DCN一致的大幅优于其他模型。</p><p><strong>DCN和DNN之间的比较</strong>。考虑到交叉网络仅仅额外引入了O(d)个参数，我们就将DCN和它——一个传统的DNN进行比较，并且将实验结果展现出来尽管存在较大的内存预算和损失公差。</p><p>接下来，我们将会汇报一定数量参数的损失数据，它们都是在所有的学习率和模型结构上得到的最好的验证集的损失。嵌入层的参数个数被省略了，因为在我们所有模型的计算中这一部分保持不变。</p><p>表2展示了要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数。从表2中我们可以看出DCN的内存有效性要比单一的DNN模型高出近一个量级，这得益于交叉网络能够有效地学习到有限次的特征交叉项。</p><p><em>表2 要获得一个达到预期对数损失阈值的模型所需要的最少的参数个数</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Logloss</th><th style="text-align:center">0.4430</th><th style="text-align:center">0.4460</th><th style="text-align:center">0.4470</th><th style="text-align:center">0.4480</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">3.2E6</td><td style="text-align:center">1.5E5</td><td style="text-align:center">1.5E5</td><td style="text-align:center">7.8E4</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center">7.9E5</td><td style="text-align:center">7.3E4</td><td style="text-align:center">3.7E4</td><td style="text-align:center">3.7E4</td></tr></tbody></table></div><p>表2对比了固定内存预算的神经网络的表现。我们可以看到，DCN一致的比DNN要好。在一个小参数体制里，交叉网络参数的个数和深度网络相比相差无几，但是可以看到明显提升这就表明交叉网络在学习有用特征交叉项中更为有效。在大参数体制中，DNN缩小了一些差距了。然而，DCN仍然要比DNN好一大截，这表明它可以有效地学习到一些很有用的甚至一个大DNN都学不到的特征交叉项。</p><p><em>表3 不同的内存预算下获得的最好的对数损失</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">5E4</th><th style="text-align:center">1E5</th><th style="text-align:center">4E5</th><th style="text-align:center">1.1E6</th><th style="text-align:center">2.5E6</th></tr></thead><tbody><tr><td style="text-align:center">DNN</td><td style="text-align:center">0.4480</td><td style="text-align:center">0.4471</td><td style="text-align:center">0.4439</td><td style="text-align:center">0.4433</td><td style="text-align:center">0.4431</td></tr><tr><td style="text-align:center">DCN</td><td style="text-align:center"><strong>0.4465</strong></td><td style="text-align:center"><strong>0.4453</strong></td><td style="text-align:center"><strong>0.4432</strong></td><td style="text-align:center"><strong>0.4426</strong></td><td style="text-align:center"><strong>0.4423</strong></td></tr></tbody></table></div><p>我们从更精确的细节来分析对于给定的DNN模型，引入交叉网络的DCN模型的影响。我们首先对比了拥有同样层数和层大小的DNN和DCN模型的最好表现，然后我们展示了验证集的对数损失是如何随着交叉网络层数的增加而变化的。表4展示了DCN和DNN模型在对数损失上面的区别。在同一实验设定下，从最优的对数损失上看DCN模型一致的优于有相同结构的单一DNN模型。这种对于所有超参数的改进是一致的，降低了参数在初始化和随机优化中的随机性影响。</p><p><em>表4 DCN和DNN在验证集上的对数损失之间的区别</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Layers/Nodes</th><th style="text-align:center">32</th><th style="text-align:center">64</th><th style="text-align:center">128</th><th style="text-align:center">256</th><th style="text-align:center">512</th><th style="text-align:center">1024</th></tr></thead><tbody><tr><td style="text-align:center">2</td><td style="text-align:center">-0.28</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.16</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.05</td><td style="text-align:center">-0.08</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">-0.19</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.18</td><td style="text-align:center">-0.07</td><td style="text-align:center">-0.05</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">-0.12</td><td style="text-align:center">-0.10</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.09</td><td style="text-align:center">-0.21</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">-0.21</td><td style="text-align:center">-0.11</td><td style="text-align:center">-0.13</td><td style="text-align:center">-0.00</td><td style="text-align:center">-0.06</td><td style="text-align:center">-0.02</td></tr></tbody></table></div><p>图3展示了在随机选择的设置中我们增加交叉层数的改进效果。对于图3中的深度网络，当增加了一个交叉层的时候有一个明显的提升。随着更多的交叉层引入的时候，对于某些模型设置会使得对数损失继续下降，这表明引入交叉项对于预测是有效的；鉴于对于其他模型设置对数损失开始波动甚至出现微幅增加，这就表明高阶的特征交叉项的银如意是没有太大作用的</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/deep%26cross-3.JPG" alt="D&amp;C-3.jpg"></p><h3 id="4-5-非CTR数据集"><a href="#4-5-非CTR数据集" class="headerlink" title="4.5 非CTR数据集"></a><strong>4.5 非CTR数据集</strong></h3><p>我们证明了DCN模型在非CTR预测问题中也表现得很好。我们使用来自UCI提供的森林植被类型（forest covertype）（581012样本和54个特征）和 希格斯粒子（Higgs）（11M样本和28个特征）数据集。数据集随机得被分为训练集（90%）和测试集（10%）。对于超参数进行了梯度搜索。深度网络层数从1到10，大小从50到300.交叉网络层数从4到10。残差单元的个数从1到5，他们的出入维度和交叉维度从50到300。对于DCN，输入向量会被直接喂入交叉网络。</p><p>对于森林植被类型数据，DCN在最少的内存消费下获得了最好的测试集准确率0.9740。DNN和DC都是0.9737。DCN最优的超参数设置是8个交叉层且大小为54，6个深度网络层且大小为292，DNN则是有7层大小为292的深度网络层，DC则是有输入维度为271交叉维度为287的4个残差单元。</p><p>对于希格斯粒子数据集，DCN模型获得的最好对数损失测试结果是0.4494，而DNN是0.4506。DCN最优的超参数设定是4层大小为28的交叉网络和4层大小为209深度网络层，DNN则是10层大小为196的深度网络层。DCN在仅用了DNN一半的内存情况下依然表现得比其要好。</p><h3 id="5-结论和未来方向"><a href="#5-结论和未来方向" class="headerlink" title="5 结论和未来方向"></a><strong>5 结论和未来方向</strong></h3><p>区分有效的特征交叉项已经称为了许多预测模型成功的关键。遗憾的是，过程往往需要进行手工特征和穷举。DNN是比较受欢迎的自动特征学习模型；然而，学到的特征是隐式的并且高度非线性的，同时网络并不一定需要很大而且无法学习到某些特征。本文剔除的Deep &amp; Cross Network模型能够处理大的稀疏和密集特征集，并且可以联合传统的深度表示来显示地学习有限次的交叉特征。交叉特征的阶数在每一个交叉层都会增加一。我们的实验结果已经证明了它在系数数据集和密集数据集上都要优于其他最先进的算法，优势体现在模型的准确率和内存使用上。</p><p>我们会进一步地在其他模型中探索使用交叉层，使得深度交叉网络能够有效地训练，研究交叉网络在多项式近似中的有效性，并且在优化过程中可以更好地理解深度网络的交叉项。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.05123.pdf&quot;&gt;原始论文：Deep &amp;amp; Cross Network for Ad Click Predictions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;a href=&quot;#深度和交叉网络的广告点击预测&quot; class=&quot;headerlink&quot; title=&quot;深度和交叉网络的广告点击预测&quot;&gt;&lt;/a&gt;深度和交叉网络的广告点击预测&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;特征工程已经成为许多预测模型成功的关键。然而，这个过程是不平常的并且经常会要手动特征工程或者穷举搜索。DNNs能够自动地学习特征交叉项；然而，它们都是隐式地生成所有交叉项，并且学习所有类型的交叉特征不一定有效。在本文中，我们提出深度和交叉网络(DCN)，它保持了深度模型的优势，并且又超越了这，它是一种在学习某种边界程度特征交叉项中更为有效的新奇网络。此外，DCN显示地在每一层应用特征交叉，不要求做人工程特征工程，同时也只是给DNN模型增加了一些可以忽略不计的复杂度。我们的实验结果已经证明它在CTR预测数据集和密集的分类数据集上，相对于其他高级模型在模型准确性和记忆方法上都具有优越性。&lt;/p&gt;
&lt;h3 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 介绍&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 介绍&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;点击率（CTR）预测是一个大规模的问题，它对数十亿美元的在线广告业来说至关重要。在广告业中，广告商会想发布商付费以在发布商的网站上展示他们的广告。一个普遍的付费模式是平均点击成本（CPC）模型，即广告商仅在点击发生的时候才会付费。因此，出版商的收入很大程度上依赖于能够准确预测CTR。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
    <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="CTR预估" scheme="https://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
    <category term="神经网络" scheme="https://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="Deep &amp; Cross" scheme="https://www.xiemingzhao.com/tags/Deep-Cross/"/>
    
  </entry>
  
  <entry>
    <title>ABTest显著性计算</title>
    <link href="https://www.xiemingzhao.com/posts/ABTestsignificancecomputing.html"/>
    <id>https://www.xiemingzhao.com/posts/ABTestsignificancecomputing.html</id>
    <published>2019-07-15T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.650Z</updated>
    
    <content type="html"><![CDATA[<h2 id="显著性计算—uv-based"><a href="#显著性计算—uv-based" class="headerlink" title="显著性计算—uv based"></a>显著性计算—uv based</h2><p><strong>这里以实验目标为提升CR（Conversion Rate）为例说明</strong></p><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p><strong>显著性：</strong> 显著：新版和老版的CR有明显差异，不显著: 新版和老版没有明显差异。<br><strong>上升幅度：</strong>(新版CR-老版CR)/老版CR<br><strong>功效:</strong> 一般功效（即power值）达到0.8, 我们认为样本量即实验UV充足，可下结论。</p><span id="more"></span><blockquote><p>假设观察实验进行3天后，power=0.5&lt;0.8，并且结果不显著，这时需要累计更多样本。 如果当power已达到0.8时，仍未显著，一般我们认为新版和老版的CR的确无明显差异。</p></blockquote><p><strong>AA校验：</strong>验证主测频道分流是否随机；若两个Control版本之间的指标没有显著差异，则表明分流随机；反之，则需排查Control版本中是否存在异常数据；</p><blockquote><p>AA异常也可能由于两个control版本，其中之一包含一些异常用户（订单数极高），而另外一个版本没有异常用户。</p></blockquote><h4 id="如何结合显著性、power和样本量对实验结果下结论"><a href="#如何结合显著性、power和样本量对实验结果下结论" class="headerlink" title="如何结合显著性、power和样本量对实验结果下结论"></a>如何结合显著性、power和样本量对实验结果下结论</h4><p>power和样本量功能类似，达到样本量基本等同于power达到80%。power与样本量计算相比，power可以更多的利用实验本身的信息，而样本量主要使用频道的数据，计算时与实验设置分流等无关，仅实验剩余天数与实验相关。</p><p>所以这里我们结合power和显著性对实验的结果进行判断。这里以转化率CR为例。</p><blockquote><ol><li>如果power达到80%时，CR仍不显著， 说明此时实验新版与老版无显著差异，停止实验。</li><li>如果power未到达80%，CR不显著，说明此时样本量不充足，需继续实验，累计更多的用户。</li></ol></blockquote><p><strong>以上均基于AA检验正常为前提。</strong></p><p>如果AA异常，需查询原因，如果是AA中某一版本中有少数用户订单数极高，导致AA异常，剔除这种异常用户后重新计算AA  Test的结果， 如果不再显著，AA正常。</p><p>严谨一点，再检查AB 的检验中(一般B&lt;新版&gt; vs C+D<C、D都为老版>)是否存在同样问题，即某一版本出现一些异常用户(订单数极高的用户), 如果存在，剔除后重新计算显著性。</p><h3 id="算法说明"><a href="#算法说明" class="headerlink" title="算法说明"></a>算法说明</h3><h4 id="显著性计算"><a href="#显著性计算" class="headerlink" title="显著性计算"></a><strong>显著性计算</strong></h4><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/Abtest-2.png" alt="ABtestsample"></p><p>我们将指标提升的百分比定义为lift， <strong>%Lift=（Treatment/Control-1）*100%</strong></p><p>如上图的示例结果图所示，CR 的lift估计值为：-0.79%， 区间（-1.55%,-0%）.  CR lift 的真实值以95%的可能性落在区间（-1.55%,-0%）内。由于区间未包括0，所以CR显著, 并且从数值上看是显著下降。说明新版的CR明显低于老版的CR.</p><p>具体计算方案，以国内酒店频道的CR例,假设:</p><blockquote><ul><li>老版本每个用户的订单数X为：$x<em>1,x_2,…,x</em>{n_1}$，其中$n_1$为老版本的用户数，且有：$E[X] = u_1, Var(X) = \sigma_1^2$</li><li>新版本每个用户的订单数Y为：$y<em>1,y_2,…,y</em>{n_2}$，其中$n_2$为新版本的用户数，且有：$E[Y] = u_2, Var(Y) = \sigma_2^2$</li><li>尽管 X 和 Y 的分布不满足正态的假设，由大数定律得到，老版人均订单数$(CR_1)$和新版的人均订单数$(CR_2)$分别满足$CR_1 ~ N(u_1，\sigma_1^2 / n_1)$ 和 $CR_2 ~ N(u_2，\sigma_2^2 / n_2)$ 的正态分布。人均订单数即CR。</li></ul></blockquote><p>那么 lift 值的计算方案就如下：<br><strong>Step1： 估计$u_1, u_2, \sigma_1^2, \sigma_2^2$</strong><br>根据上述四个公式即可得到这四个统计量的估计值。</p><p><strong>Step2：抽样产生 lift 的n（一般取10000）个随机数，$lift^i, i = 1, …, n$</strong><br>由于$CR_1 ~ N(u_1，\sigma_1^2 / n_1), CR_2 ~ N(u_2，\sigma_2^2 / n_2)$，那么结合 Step1 中的参数估计，就可以，</p><blockquote><p>产生满足$N(\hat u_1, \hat \sigma_1^2 / n_1)$分布的n个随机数，$CR_1^i, i = 1,2,…,n$<br>产生满足$N(\hat u_2, \hat \sigma_2^2 / n_2)$分布的n个随机数，$CR_2^i, i = 1,2,…,n$</p></blockquote><p>然后我们就可以计算：$lift^i = (CR_2^i - CR_1^i) / CR_1^i, i = 1,2,…,n$</p><p><strong>Step3：计算 lift 的均值和区间（置信度90%）</strong><br>lift 均值： $\sum_{i=1}^n lift^i / n$；<br>区间上界： $lift^i$ 的95%分位数；<br>区间下界： $lift^i$ 的5%分位数。</p><h4 id="功效（power值）计算"><a href="#功效（power值）计算" class="headerlink" title="功效（power值）计算"></a><strong>功效（power值）计算</strong></h4><script type="math/tex; mode=display">Power = \Phi (-Z_{1 - \alpha / 2} + \frac {\Delta}{\sqrt {\sigma_1^2 / n_1 + \sigma_2^2 / n_2} })</script><p>其中：</p><blockquote><p>$\alpha$ 是 Type I Error， 一般为0.05 或者0.1<br>$\sigma_1^2$是老版订单数（或其他指标）的方差，$n_1$是老版的uv数<br>$\sigma_2^2$是新版订单数（或其他指标）的方差，$n_2$是新版的uv数<br>$\Delta = lift * u$中的 lift 是实际实验新版相对老板提升的百分比，一般取值为0.02或者0.04，这里设此目标值是为了固定，使用实际的会出现波动太乱的情况<br>u 是老版的 CR （或者其他检验指标）。</p></blockquote><p>示例：一下以某一次酒店排序实验为例，其 type I error = 0.05, lift = 0.02, 计算 CR 对应的 power。<br>$n_1$ = 老版用户数 = 22917； $n_2$ = 新版用户数 = 34389<br>$\hat u$ = 老版 CR 估计值 = 0.37474<br>$\hat \sigma_1^2$ = 老版订单数方差估计值 = 0.7188733<br>$\hat \sigma_2^2$ = 新版订单数方差估计值 = 0.721059</p><script type="math/tex; mode=display">Power = \Phi (-Z_{1 - \alpha / 2} + \frac {\Delta}{\sqrt {\sigma_1^2 / n_1 + \sigma_2^2 / n_2} }) \\ =  \Phi (-1.959964 + \frac {0.02 \times 0.37474}{\sqrt {0.7188733/22917 + 0.721059/34389} }) \\ = \Phi (-0.923327) = 17.79 \%</script><p>附属代码：<br><strong>AbSampleSize.hql</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size <span class="operator">=</span><span class="number">2048</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSampleSize <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  exp.experiment,</span><br><span class="line">        exp.channelid,</span><br><span class="line">        cumstart,</span><br><span class="line">        cumend,</span><br><span class="line">        abversion,</span><br><span class="line"></span><br><span class="line">        channel.SmallestSize<span class="operator">*</span>(splitPct<span class="operator">/</span><span class="number">100</span>) <span class="keyword">as</span> SmallestSize,</span><br><span class="line">        exp.uv <span class="keyword">as</span> cumulativeUv,</span><br><span class="line">        datediff(if(datediff(<span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,exp.cumend)<span class="operator">&lt;</span><span class="number">0</span>,<span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,exp.cumend),exp.cumstart)<span class="operator">+</span><span class="number">1</span> <span class="keyword">as</span> days,</span><br><span class="line">        <span class="comment">--(channel.SmallestSize/exp.uv*(splitPct/100)-1)*(days)</span></span><br><span class="line">        (channel.SmallestSize<span class="operator">/</span>exp.uv<span class="operator">*</span>(splitPct<span class="operator">/</span><span class="number">100</span>)<span class="number">-1</span>)<span class="operator">*</span>(datediff(if(datediff(<span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,exp.cumend)<span class="operator">&lt;</span><span class="number">0</span>,<span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,exp.cumend),exp.cumstart)<span class="operator">+</span><span class="number">1</span>) <span class="keyword">as</span> remainingDays</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> report_abtestdb.AbChannelDailyAbsolute channel</span><br><span class="line"><span class="keyword">JOIN</span> `report_abtestdb`.`AbUserCumulativeAbsolute` exp</span><br><span class="line"><span class="keyword">ON</span> channel.channelid<span class="operator">=</span>exp.channelid</span><br><span class="line"><span class="keyword">AND</span> channel.d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> channel.clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> exp.d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> exp.clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> experiment,</span><br><span class="line">                    version,</span><br><span class="line">                    splitPct</span><br><span class="line">    <span class="keyword">FROM</span> dim_abtestdb.DimAbtestConfig</span><br><span class="line">    <span class="keyword">WHERE</span> d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> defaultversion<span class="operator">=</span><span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> <span class="built_in">lower</span>(versionproperty)<span class="operator">=</span><span class="string">&#x27;treatment&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> splitPct<span class="operator">&gt;</span><span class="number">0</span></span><br><span class="line">) config</span><br><span class="line"><span class="keyword">ON</span> exp.experiment<span class="operator">=</span>config.experiment</span><br><span class="line"><span class="keyword">AND</span> exp.abversion<span class="operator">=</span>config.version;</span><br></pre></td></tr></table></figure></p><p><strong>AbSignificance.hql</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join.noconditionaltask.size <span class="operator">=</span><span class="number">2048</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">add</span> jar abtest_udf<span class="number">-1.0</span>.jar;</span><br><span class="line"><span class="keyword">add</span> jar commons<span class="operator">-</span>math3<span class="number">-3.5</span>.jar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> lift_quantile <span class="keyword">AS</span> <span class="string">&#x27;com.ctrip.basebiz.abtest3.hive.function.UDFLiftQuantile&#x27;</span>;</span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> pnorm <span class="keyword">AS</span> <span class="string">&#x27;com.ctrip.basebiz.abtest3.hive.function.statistics.UDFCumulativeProbabilityNormalDistribution&#x27;</span>;</span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> makeJson <span class="keyword">AS</span> <span class="string">&#x27;com.ctrip.basebiz.abtest3.hive.function.UDFMakeJSONObj&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> </span><br><span class="line"><span class="comment">-- For Confidence Interval</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span>  treatment.experiment,</span><br><span class="line">            treatment.channelid,</span><br><span class="line">            treatment.abversion,</span><br><span class="line">            treatment.cumstart,</span><br><span class="line">            treatment.cumend,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_pv<span class="operator">-</span>control.mean_pv)<span class="operator">/</span>control.mean_pv <span class="keyword">as</span> lift_pv,</span><br><span class="line">            lift_quantile(treatment.mean_pv,treatment.std_pv,control.mean_pv,control.std_pv,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_pv,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.mean_pv<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.stddev_pv,<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.stddev_pv,<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_pv,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_orders<span class="operator">-</span>control.mean_orders)<span class="operator">/</span>control.mean_orders <span class="keyword">as</span> lift_orders,</span><br><span class="line">            lift_quantile(treatment.mean_orders,treatment.std_orders,control.mean_orders,control.std_orders,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_orders,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.mean_orders<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.stddev_orders,<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.stddev_orders,<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_orders,</span><br><span class="line"></span><br><span class="line">            (treatment.mean_quantity<span class="operator">-</span>control.mean_quantity)<span class="operator">/</span>control.mean_quantity <span class="keyword">as</span> lift_quantity,</span><br><span class="line">            lift_quantile(treatment.mean_orders,treatment.std_orders,control.mean_orders,control.std_orders,<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_quantity,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.mean_quantity<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.stddev_quantity,<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.stddev_quantity,<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_quantity,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>]<span class="operator">-</span>control.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>])<span class="operator">/</span>control.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>] <span class="keyword">as</span> lift_amount,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>],treatment.dynamicMap[<span class="string">&#x27;std_amount&#x27;</span>],control.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>],control.dynamicMap[<span class="string">&#x27;std_amount&#x27;</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_amount,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>]<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.dynamicMap[<span class="string">&#x27;stddev_amount&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.dynamicMap[<span class="string">&#x27;stddev_amount&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_amount,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>]<span class="operator">-</span>control.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>])<span class="operator">/</span>control.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>] <span class="keyword">as</span> lift_cost,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>],treatment.dynamicMap[<span class="string">&#x27;std_cost&#x27;</span>],control.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>],control.dynamicMap[<span class="string">&#x27;std_cost&#x27;</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_cost,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>]<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.dynamicMap[<span class="string">&#x27;stddev_cost&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.dynamicMap[<span class="string">&#x27;stddev_cost&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_cost,</span><br><span class="line"></span><br><span class="line">            (treatment.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>]<span class="operator">-</span>control.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>])<span class="operator">/</span>control.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>] <span class="keyword">as</span> lift_gross_profit,</span><br><span class="line">            lift_quantile(treatment.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>],treatment.dynamicMap[<span class="string">&#x27;std_gross_profit&#x27;</span>],control.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>],control.dynamicMap[<span class="string">&#x27;std_gross_profit&#x27;</span>],<span class="number">0.9</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_gross_profit,</span><br><span class="line">            pnorm(<span class="number">-1.644854</span><span class="operator">+</span><span class="number">0.02</span><span class="operator">*</span>control.dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>]<span class="operator">/</span><span class="built_in">sqrt</span>(<span class="built_in">power</span>(treatment.dynamicMap[<span class="string">&#x27;stddev_gross_profit&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>treatment.uv<span class="operator">+</span><span class="built_in">power</span>(control.dynamicMap[<span class="string">&#x27;stddev_gross_profit&#x27;</span>],<span class="number">2</span>)<span class="operator">/</span>control.uv)) <span class="keyword">as</span> power_gross_profit</span><br><span class="line"></span><br><span class="line">    <span class="keyword">FROM</span> `report_abtestdb`.`AbUserCumulativeAbsolute` treatment</span><br><span class="line">    <span class="keyword">JOIN</span> `report_abtestdb`.`AbUserCumulativeAbsolute` control</span><br><span class="line">     <span class="keyword">ON</span> treatment.experiment<span class="operator">=</span>control.experiment</span><br><span class="line">    <span class="keyword">AND</span> treatment.channelid<span class="operator">=</span>control.channelid</span><br><span class="line">    <span class="keyword">AND</span> <span class="built_in">lower</span>(treatment.versionproperty)<span class="operator">=</span><span class="string">&#x27;treatment&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> control.abversion<span class="operator">=</span><span class="string">&#x27;control&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> treatment.DefaultVersion<span class="operator">=</span><span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> control.DefaultVersion<span class="operator">=</span><span class="literal">FALSE</span> </span><br><span class="line">    <span class="keyword">AND</span> treatment.clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> control.clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span></span><br><span class="line">    <span class="keyword">WHERE</span> treatment.d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line">    <span class="keyword">AND</span> control.d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line">) ciResult</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> </span><br><span class="line"><span class="comment">-- For AA Test</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span>  experiment,</span><br><span class="line">            channelid,</span><br><span class="line">            (mean_pv1<span class="operator">-</span>mean_pv2)<span class="operator">/</span>mean_pv2 <span class="keyword">as</span> lift_pv,</span><br><span class="line">            lift_quantile(mean_pv1,std_pv1,mean_pv2,std_pv2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_pv,</span><br><span class="line"></span><br><span class="line">            (mean_orders1<span class="operator">-</span>mean_orders2)<span class="operator">/</span>mean_orders2 <span class="keyword">as</span> lift_orders,</span><br><span class="line">            lift_quantile(mean_orders1,std_orders1,mean_orders2,std_orders2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_orders,</span><br><span class="line"></span><br><span class="line">            (mean_quantity1<span class="operator">-</span>mean_quantity2)<span class="operator">/</span>mean_quantity2 <span class="keyword">as</span> lift_quantity,</span><br><span class="line">            lift_quantile(mean_quantity1,std_quantity1,mean_quantity2,std_quantity2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_quantity,</span><br><span class="line"></span><br><span class="line">            (mean_amount1<span class="operator">-</span>mean_amount2)<span class="operator">/</span>mean_amount2 <span class="keyword">as</span> lift_amount,</span><br><span class="line">            lift_quantile(mean_amount1,std_amount1,mean_amount2,std_amount2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_amount,</span><br><span class="line"></span><br><span class="line">            (mean_cost1<span class="operator">-</span>mean_cost2)<span class="operator">/</span>mean_cost2 <span class="keyword">as</span> lift_cost,</span><br><span class="line">            lift_quantile(mean_cost1,std_cost1,mean_cost2,std_cost2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_cost,</span><br><span class="line"></span><br><span class="line">            (mean_gross_profit1<span class="operator">-</span>mean_gross_profit2)<span class="operator">/</span>mean_gross_profit2 <span class="keyword">as</span> lift_gross_profit,</span><br><span class="line">            lift_quantile(mean_gross_profit1,std_gross_profit1,mean_gross_profit2,std_gross_profit2,<span class="number">0.95</span>,<span class="number">100000</span>) <span class="keyword">as</span> lift_quantile_gross_profit</span><br><span class="line">    <span class="keyword">FROM</span> (</span><br><span class="line">        <span class="keyword">SELECT</span>  experiment,</span><br><span class="line">                channelid,</span><br><span class="line">                abversion <span class="keyword">as</span> i_version,</span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(abversion)      <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> abversion1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(abversion)       <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> abversion2,</span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(mean_pv)        <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_pv1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(mean_pv)         <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_pv2,</span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(std_pv)         <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_pv1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(std_pv)          <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_pv2, </span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(mean_orders)    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_orders1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(mean_orders)     <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_orders2, </span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(std_orders)     <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_orders1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(std_orders)      <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_orders2, </span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(mean_quantity)  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_quantity1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(mean_quantity)   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_quantity2, </span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(std_quantity)   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_quantity1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(std_quantity)    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_quantity2,</span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_amount1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_amount&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_amount2, </span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_amount&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_amount1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_amount&#x27;</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_amount2,</span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_cost1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_cost&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_cost2, </span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_cost&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_cost1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_cost&#x27;</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_cost2,</span><br><span class="line"></span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>])  <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_gross_profit1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;mean_gross_profit&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> mean_gross_profit2, </span><br><span class="line">                <span class="built_in">FIRST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_gross_profit&#x27;</span>])   <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_gross_profit1,</span><br><span class="line">                <span class="built_in">LAST_VALUE</span>(dynamicMap[<span class="string">&#x27;std_gross_profit&#x27;</span>])    <span class="keyword">over</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> experiment,channelid) <span class="keyword">as</span> std_gross_profit2</span><br><span class="line">        <span class="keyword">FROM</span> `report_abtestdb`.`AbUserCumulativeAbsolute`</span><br><span class="line">        <span class="keyword">WHERE</span> d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span></span><br><span class="line">        <span class="keyword">AND</span> clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span></span><br><span class="line">        <span class="keyword">AND</span> <span class="built_in">lower</span>(versionproperty)<span class="operator">=</span><span class="string">&#x27;control&#x27;</span></span><br><span class="line">        <span class="keyword">AND</span> abversion<span class="operator">&lt;&gt;</span><span class="string">&#x27;control&#x27;</span></span><br><span class="line">        <span class="keyword">AND</span> DefaultVersion<span class="operator">=</span><span class="literal">FALSE</span></span><br><span class="line">    ) control</span><br><span class="line">    <span class="keyword">WHERE</span> i_version<span class="operator">=</span>abversion1</span><br><span class="line">    <span class="keyword">AND</span> abversion1<span class="operator">&lt;&gt;</span>abversion2</span><br><span class="line">) aaResult</span><br><span class="line"><span class="keyword">ON</span>  ciResult.experiment<span class="operator">=</span>aaResult.experiment</span><br><span class="line"><span class="keyword">AND</span> ciResult.channelid<span class="operator">=</span>aaResult.channelid</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_pv&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_pv.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_pv.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_pv <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_pv.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_pv.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_pv.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_pv.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_pv.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_pv.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_pv <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_orders&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_orders.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_orders.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_orders <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_orders.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_orders.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_orders.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_orders.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_orders.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_orders.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_orders <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_quantity&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_quantity.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_quantity.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_quantity <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_quantity.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_quantity.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_quantity.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_quantity.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_quantity.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_quantity.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_quantity <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_amount&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_amount.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_amount.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_amount <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_amount.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_amount.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_amount.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_amount.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_amount.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_amount.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_amount <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_cost&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_cost.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_cost.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_cost <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_cost.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_cost.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_cost.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_cost.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_cost.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_cost.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_cost <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> report_abtestdb.AbSignificance <span class="keyword">PARTITION</span>(d<span class="operator">=</span><span class="string">&#x27;$&#123;operate_date&#125;&#x27;</span>,clienttype<span class="operator">=</span><span class="string">&#x27;$&#123;client_type&#125;&#x27;</span>,index<span class="operator">=</span><span class="string">&#x27;cr_gross_profit&#x27;</span>)</span><br><span class="line"><span class="keyword">SELECT</span>  ciResult.experiment,</span><br><span class="line">        ciResult.channelid,</span><br><span class="line">        ciResult.cumstart,</span><br><span class="line">        ciResult.cumend,</span><br><span class="line">        ciResult.abversion,</span><br><span class="line">        (ciResult.lift_quantile_gross_profit.lci<span class="operator">&gt;</span><span class="number">0</span> <span class="keyword">or</span> ciResult.lift_quantile_gross_profit.uci<span class="operator">&lt;</span><span class="number">0</span>) <span class="keyword">as</span> isSignificant,</span><br><span class="line">        ciResult.lift_gross_profit <span class="keyword">as</span> lift,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_gross_profit.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(ciResult.lift_quantile_gross_profit.lci <span class="keyword">AS</span> STRING))</span><br><span class="line">        ) <span class="keyword">as</span> ciExt,</span><br><span class="line">        (aaResult.lift_quantile_gross_profit.lci<span class="operator">&lt;=</span><span class="number">0</span> <span class="keyword">AND</span> aaResult.lift_quantile_gross_profit.uci<span class="operator">&gt;=</span><span class="number">0</span>) <span class="keyword">as</span> isAANormal,</span><br><span class="line">        makeJson(map(</span><br><span class="line">            <span class="string">&#x27;uci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_gross_profit.uci <span class="keyword">AS</span> STRING),</span><br><span class="line">            <span class="string">&#x27;lci&#x27;</span>,<span class="built_in">CAST</span>(aaResult.lift_quantile_gross_profit.lci <span class="keyword">AS</span> STRING))) <span class="keyword">as</span> aaExt,</span><br><span class="line">        ciResult.power_gross_profit <span class="keyword">as</span> `power`,</span><br><span class="line">        makeJson(map()) <span class="keyword">as</span> powerExt</span><br><span class="line">;</span><br></pre></td></tr></table></figure></p><p><strong>UDFCumulativeProbabilityNormalDistribution.java</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ctrip.basebiz.abtest3.hive.function.statistics;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.math3.distribution.NormalDistribution;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.Description;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Description(name = &quot;pnorm&quot;,</span></span><br><span class="line"><span class="meta">        value = &quot;_FUNC_(quantile,mean,sd) - Density, distribution function, quantile &quot; +</span></span><br><span class="line"><span class="meta">                &quot;function and random generation for the normal distribution with mean&quot; +</span></span><br><span class="line"><span class="meta">                &quot; equal to mean and standard deviation equal to sd&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UDFCumulativeProbabilityNormalDistribution</span> <span class="keyword">extends</span> <span class="title class_">UDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">evaluate</span><span class="params">(Double quantile)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> evaluate(quantile, <span class="number">0.0D</span>, <span class="number">1.0D</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">evaluate</span><span class="params">(Double quantile, Double mean, Double sd)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (quantile == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">NormalDistribution</span> <span class="variable">normalDistribution</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NormalDistribution</span>(mean, sd);</span><br><span class="line">        <span class="keyword">return</span> normalDistribution.cumulativeProbability(quantile);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span>  <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        UDFCumulativeProbabilityNormalDistribution d=<span class="keyword">new</span> <span class="title class_">UDFCumulativeProbabilityNormalDistribution</span>();</span><br><span class="line">        System.out.println(d.evaluate(<span class="number">0.9</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>UDFLiftQuantile.java</strong><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">package com.ctrip.basebiz.abtest3.hive.function;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.exec.Description;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line">import org.apache.hadoop.hive.serde2.io.DoubleWritable;</span><br><span class="line"></span><br><span class="line">import java.math.BigDecimal;</span><br><span class="line">import java.math.RoundingMode;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.PriorityQueue;</span><br><span class="line">import java.util.Random;</span><br><span class="line"></span><br><span class="line">@Description(name = &quot;lift_quantile&quot;,</span><br><span class="line">        value = &quot;_FUNC_(meanTreatment,stdTreatment,meanControl,stdControl,confidenceLevel,samplingNum).&quot;,</span><br><span class="line">        extended = &quot;Construct sets of random number obey Gaussian distribution whose mean and standard deviation &quot; +</span><br><span class="line">                &quot;is the same as treatment version and control version. &quot; +</span><br><span class="line">                &quot;Return lift&#x27;s upper and lower quantile whose Confidence Level is confidenceLevel.\n&quot; +</span><br><span class="line">                &quot; Lift = (Treatment - Control) / Control &quot;)</span><br><span class="line">public class UDFLiftQuantile extends UDF &#123;</span><br><span class="line">    public static class UDFLiftQuantileResult &#123;</span><br><span class="line">        public DoubleWritable mean;</span><br><span class="line">        public DoubleWritable lci;</span><br><span class="line">        public DoubleWritable uci;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public UDFLiftQuantileResult evaluate(Double mTreatment, Double stdTreatment,</span><br><span class="line">                                          Double mControl, Double stdControl,</span><br><span class="line">                                          Double confidenceLevel, Integer samplingNum) &#123;</span><br><span class="line">        boolean isArgInvalid = (mTreatment == .0 &amp;&amp; stdTreatment == .0) || (mControl == .0 &amp;&amp; stdControl == .0);</span><br><span class="line">        if (isArgInvalid) &#123;</span><br><span class="line">            UDFLiftQuantileResult result = new UDFLiftQuantileResult();</span><br><span class="line">            result.mean = new DoubleWritable(0);</span><br><span class="line">            result.lci = new DoubleWritable(0);</span><br><span class="line">            result.uci = new DoubleWritable(0);</span><br><span class="line">            return result;</span><br><span class="line">        &#125;</span><br><span class="line">        Random randomTreatment = new Random();</span><br><span class="line">        Random randomControl = new Random();</span><br><span class="line">        int queueMaxSize = (int) (Math.floor((1.0 - confidenceLevel) / 2 * samplingNum) + 1);</span><br><span class="line">        PriorityQueue&lt;Double&gt; lciQueue = new PriorityQueue&lt;Double&gt;(queueMaxSize, Collections.reverseOrder());</span><br><span class="line">        PriorityQueue&lt;Double&gt; uciQueue = new PriorityQueue&lt;Double&gt;(queueMaxSize);</span><br><span class="line">        BigDecimal sum = BigDecimal.ZERO;</span><br><span class="line">        for (int i = 0; i &lt; samplingNum; i++) &#123;</span><br><span class="line">            double vTreatment = mTreatment + randomTreatment.nextGaussian() * stdTreatment;</span><br><span class="line">            double vControl = mControl + randomControl.nextGaussian() * stdControl;</span><br><span class="line">            if (vControl == 0.0) &#123;</span><br><span class="line">                i--;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            double lift = (vTreatment - vControl) / vControl;</span><br><span class="line">            sum = sum.add(BigDecimal.valueOf(lift));</span><br><span class="line">            if (lciQueue.size() &lt; queueMaxSize || lciQueue.peek() &gt;= lift) &#123;</span><br><span class="line">                lciQueue.add(lift);</span><br><span class="line">                if (lciQueue.size() &gt; queueMaxSize) &#123;</span><br><span class="line">                    lciQueue.poll();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (uciQueue.size() &lt; queueMaxSize || uciQueue.peek() &lt;= lift) &#123;</span><br><span class="line">                uciQueue.add(lift);</span><br><span class="line">                if (uciQueue.size() &gt; queueMaxSize) &#123;</span><br><span class="line">                    uciQueue.poll();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        UDFLiftQuantileResult result = new UDFLiftQuantileResult();</span><br><span class="line">        result.lci = new DoubleWritable(lciQueue.poll());</span><br><span class="line">        result.uci = new DoubleWritable(uciQueue.poll());</span><br><span class="line">        result.mean = new DoubleWritable(sum.divide(BigDecimal.valueOf(samplingNum), RoundingMode.HALF_EVEN).doubleValue());</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            System.out.println(&quot;Nyan~&quot;);</span><br><span class="line">            run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void run() &#123;</span><br><span class="line">        UDFLiftQuantile o = new UDFLiftQuantile();</span><br><span class="line">        UDFLiftQuantileResult result = o.evaluate(0.666141754, 0.257336891, 0.373081111, 0.079436106, 0.8, 100000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(.0, .0, .0, .0, 0.8, 1000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(.0, .0, 1.0, 2.0, 0.8, 1000);</span><br><span class="line">        //UDFLiftQuantileResult result = o.evaluate(2.0, 54.0, .0, .0, 0.8, 1000);</span><br><span class="line">        System.out.println(result.mean);</span><br><span class="line">        System.out.println(result.lci);</span><br><span class="line">        System.out.println(result.uci);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="显著性计算—date-based"><a href="#显著性计算—date-based" class="headerlink" title="显著性计算—date based"></a>显著性计算—date based</h2><h3 id="方法简述"><a href="#方法简述" class="headerlink" title="方法简述"></a>方法简述</h3><p>当总体呈现正态分布且总体标准差未知，而且容量小于30，那么这时一切可能的样本平均数与总体平均数的离差统计量呈T分布。</p><p>该方法采用统计中的two sample t test， 检验两组数据的均值是否相等。例如100个男生身高数据和100个女生身高数据，通过该方法可以检验男生的平均身高是否显著不等于女生的平均身高。</p><p>在报表中我们输入的两组数据，一组是一个版本每日的指标数据，另外一组是选择的另外一个版本对应的每日的指标数据。指标可以是任意数值型指标，比如UV数，点击率，订单数等等。</p><p>该方法我们只做两两间的比较。</p><h3 id="实验举例"><a href="#实验举例" class="headerlink" title="实验举例"></a>实验举例</h3><p>我们以一个首页改版为例，如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/Abtest-1.png" alt="AB home page"></p><p>首页改版，通过上面图片发现海外酒店位置发生变化，所以我们想知道位置的改变是否会影响海外酒店的点击数量，分流比：新版：老版=50%：50%</p><p>我们拿到了每天新老版本的点击UV数，通过统计检验，判断是否新版的点击UV数明显低于老版。<br>数据如下：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/Abtest-5.png" alt="home AB outcome"></p><h3 id="检验方法"><a href="#检验方法" class="headerlink" title="检验方法"></a>检验方法</h3><p>假设x：新版每日UV数，y：老板每日UV数。计算如下统计量：</p><script type="math/tex; mode=display">t = \frac {\bar x - \bar y}{s \sqrt{1 / n_1 + 1 / n_2} }</script><p>这里，</p><blockquote><p>$\bar x$ 是新版均值，$\bar x = \sum<em>{i=1}^{n_1} x_i / n_1, n_1 是天数$<br>$\bar y$ 是老板均值，$\bar y = \sum</em>{i=1}^{n<em>1} y_i / n_2, n_2 是天数$<br>$s = \sqrt{[(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2] / (n_1 + n_2 -2)}$，其中<br>$s_1^2 = \sum</em>{i=1}^{n<em>1} (x_i - \bar x)^2 / (n_1 - 1), s_2^2 = \sum</em>{i=1}^{n_2} (y_i - \bar y) / (n_2 - 1)$</p></blockquote><p>若 $| t | &gt; t<em>{n_1 + n_2 - 2, 1 - \alpha / 2}$，则显著，否则不显著。$t</em>{n_1 + n_2 - 2, 1 - \alpha / 2}$数值可通过查表或者计算器获取。</p><h3 id="示例剖析"><a href="#示例剖析" class="headerlink" title="示例剖析"></a>示例剖析</h3><p>基于上述方案，我们对前面的例子进行计算有：<br>$\bar x = 7555.111, \bar y = 14935$<br>共有9天数据，所以$n_1 = n_2 = 9$</p><p>$s_1^2 = 1556811, s_2^2 = 335096.8, s = 972.6015$<br>t = (7555.111-14935) / 3890.406/$\sqrt{2/9}$ = -16.09612</p><p>查表或者计算机可得：$t<em>{n_1 + n_2 - 2, 1 - \alpha / 2} = t</em>{16,1 - \alpha / 2} = 1.745884（自由度=9+9-2=16）$<br>由于$| t | &gt; t_{16,1 - \alpha / 2}$，所以新版还外加酒店宫格点击用户数相对老版是显著下降的。</p><p>最小样本量：<br>在方法简述中提到：当总体呈现正态分布且总体标准差未知，而且容量小于30，那么这时一切可能的样本平均数与总体平均数的离差统计量呈T分布。</p><p>在ABtest中实验天数小于30天即可用T检验来进行判定。那么是不是实验天数越小越好呢？答案显然是否定的，实验天数越多得到的结论可靠性越好，</p><p>但是业务人员希望实验天数越少越好，两者之间形成了悖论。在此，一般建议实验最少进行两周（14天）：一周数据（7天）太少，且旅游数据大部分都是以一周为一个周期上下浮动，选择两周可以有效地平滑掉周期对结果的影响。</p><h3 id="实验最小-uv-量"><a href="#实验最小-uv-量" class="headerlink" title="实验最小 uv 量"></a>实验最小 uv 量</h3><p>假设实验组分流比例 (B) = 对照组分流比例 (C+D), 指标(CR等)满足正态分布(Central Limit Theorem)且方差相等。</p><p>选择参与实验的主指标数量为m (选项有CR, Quantity, GP-C)。对于每个选中的主指标, 计算该指标需要的最小样本量$S_i$:</p><script type="math/tex; mode=display">n = \frac {((k+1) + (k+1)/k) \sigma^2 (z_{a - \alpha / 2m} + z_{1 - \beta})^2}{\Delta^2}= treatment_uv + control_uv</script><blockquote><ul><li>$\Delta = lift * u_x$，大流量 lift 可取值0.02，小流量可取0.03<br>  （$u_x$可取该指标在试验频道前2周的均值；$lift = (u_y - u_x)/u_x$，其中$(u_y - u_x)$是实验组和对照组的均值差）</li><li>Type I Error 一般取$\alpha = 10 \%$；Type II Error 一般取$\beta = 0.2(Power = 10 \%)$</li><li>$z_x$是正态分布累计概率为 x 时对应的分位数</li><li>$\sigma^2$是该指标子啊试验频道前2周的方差。k = 实验组UV/对照组UV</li></ul></blockquote><p><strong>最后选取实验的所需最小样本量的最大值$max{S_i: i = 1, …, m}$</strong></p><h4 id="知识小科普："><a href="#知识小科普：" class="headerlink" title="知识小科普："></a>知识小科普：</h4><p>T检验和成对T检验的区别：<br>通常T检验或成对T检验是用来判断两组数据的平均值是否在统计上有差别,换一个理解,对两组数据而言,每组数据本身内部有一个波动范围(组内变异),而两组数据之间平均值的波动相称为组间变异,如果组间变异相对于组内变异小的话,就可以认为两组数据之间的平均值是没有差异的,这是T检验的做法. 而对于成对T检验,在一组中的数据与另一组的数据有对应关系,也就是两组数据是以成队的形式出现的,这个时候,运用这两个成队数据之间的差值,可以得到一个数据列,如果这个数据列的平均值在统计上是非零的,即可认为两组数据均值是有差异的,在这个地方,没有单独的去考虑两组数据之内的差异,而是通过将两组数据中对应的数据相减,得到一组数据,通过类似偏倚的算法,来看它在统计是是否非零.换一句话说,是当组内差异比较大(或者说是噪音较大),但是可以通过其它一个因子作区隔时,可以用成对T检验。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;显著性计算—uv-based&quot;&gt;&lt;a href=&quot;#显著性计算—uv-based&quot; class=&quot;headerlink&quot; title=&quot;显著性计算—uv based&quot;&gt;&lt;/a&gt;显著性计算—uv based&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;这里以实验目标为提升CR（Conversion Rate）为例说明&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;名词解释&quot;&gt;&lt;a href=&quot;#名词解释&quot; class=&quot;headerlink&quot; title=&quot;名词解释&quot;&gt;&lt;/a&gt;名词解释&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;显著性：&lt;/strong&gt; 显著：新版和老版的CR有明显差异，不显著: 新版和老版没有明显差异。&lt;br&gt;&lt;strong&gt;上升幅度：&lt;/strong&gt;(新版CR-老版CR)/老版CR&lt;br&gt;&lt;strong&gt;功效:&lt;/strong&gt; 一般功效（即power值）达到0.8, 我们认为样本量即实验UV充足，可下结论。&lt;/p&gt;</summary>
    
    
    
    <category term="ABTest" scheme="https://www.xiemingzhao.com/categories/ABTest/"/>
    
    
    <category term="ABTest" scheme="https://www.xiemingzhao.com/tags/ABTest/"/>
    
  </entry>
  
  <entry>
    <title>如何构建一个ABTest</title>
    <link href="https://www.xiemingzhao.com/posts/ABTestbuilding.html"/>
    <id>https://www.xiemingzhao.com/posts/ABTestbuilding.html</id>
    <published>2019-07-11T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.657Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何构建一个ABTest"><a href="#如何构建一个ABTest" class="headerlink" title="如何构建一个ABTest"></a>如何构建一个ABTest</h2><h3 id="谁会参与"><a href="#谁会参与" class="headerlink" title="谁会参与"></a>谁会参与</h3><ol><li>业务部门。 定义一个Ab Testing.</li><li>Ab Testing管理后台。 录入一个Ab Tesing.</li><li>业务开发者。 负责具体的方案开发实现。</li><li>用户。我们所关心的用户。</li><li>数据收集系统。收集我们关心的数据。</li><li>数据分析系统。根据收集到的数据，分析出我们所关心的指标。</li></ol><span id="more"></span><h3 id="构建一个Ab-Testing的流程"><a href="#构建一个Ab-Testing的流程" class="headerlink" title="构建一个Ab Testing的流程"></a>构建一个Ab Testing的流程</h3><blockquote><p><strong>简要步骤</strong><br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/Abtest-4.jpg" alt="ab-testing-lifecycle-summary"></p></blockquote><ol><li>业务部门负责定义一个ab testing</li><li>管理后台负责录入管理ab testing</li><li>业务开发负责具体的业务实现</li><li>日志系统负责收集数据</li><li>数据分析系统负责生成指定报表</li></ol><p>Ab Testing Framework 在其中的作用：</p><ol><li>无数据管理，提供restful api接口</li><li>提供client library 供业务开发使用，实现分流。</li></ol><h3 id="流程细化"><a href="#流程细化" class="headerlink" title="流程细化"></a>流程细化</h3><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/ABtest-3.png" alt="ab-testing-lifecycle"></p><h3 id="Ab-Testing-Framework"><a href="#Ab-Testing-Framework" class="headerlink" title="Ab Testing Framework"></a>Ab Testing Framework</h3><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/Abtest/Abtest-6.png" alt="where-is-ab-testing-framework"></p><h3 id="AB-Test-基础方面"><a href="#AB-Test-基础方面" class="headerlink" title="AB Test 基础方面"></a>AB Test 基础方面</h3><p><strong>1. ab配置系统环境</strong><br>由于生产环境的防火墙限制，实验不能往生产环境同步。建议实验先配置生产环境，然后往fws环境和uat环境进行同步。</p><p><strong>2. 实验状态</strong></p><blockquote><p>a.目前一个实验有配置中、待审核、审核通过（进行中）、实验结束等状态。<br>b.审核通过之后到了实验开始时间即为进行中。其中，实验开始时间以计算开始时间为准。<br>c.同步过去的实验状态为配置中。同步实验不能同步实验的分流规则，没有分流规则的实验一定是配置中状态。<br>d.实验的版本数有改动会清空规则，实验重新进入配置中状态。</p></blockquote><p><strong>3. 实验类型</strong><br>借助于浏览器的是web实验，web实验里面分为online实验和h5实验，区分在于是否采用h5技术；借助于app的是app实验，app实验里面分为app native、app hybrid和app服务端实验。采用手机原生态接口的，或者建立在原生态接口之上的是app native实验；其中，再混入h5或其他技术，是hybrid实验。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:left">online实验</th><th style="text-align:left">h5实验</th><th style="text-align:left">app native实验</th><th style="text-align:left">app hybrid实验</th><th style="text-align:left">app 服务端实验</th></tr></thead><tbody><tr><td style="text-align:center">实验位置</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">客户端</td><td style="text-align:left">服务端</td></tr><tr><td style="text-align:center">采用技术</td><td style="text-align:left">html、css、js等web技术</td><td style="text-align:left">主要为h5技术，web app</td><td style="text-align:left">native app</td><td style="text-align:left">hybrid app</td><td style="text-align:left">服务端技术</td></tr></tbody></table></div><p>最容易混淆的是h5实验和app hybrid实验，需要注意，这两个的区别在于h5实验直接借助浏览器呈现实验页面，而app hybrid实验借助于携程app，直接或间接的采用系统的原生态接口。也可参考H5 &amp; Native &amp; Hybrid。</p><p><strong>4. ab实验版本</strong></p><ul><li>版本号。abtest测试至少需要4个版本号，3个版本号放置老版，1个版本号放置新版。如果有多个新版，可在这基础上新增版本号代表新版。老版为control，新版为treatment。、</li><li>版本开多少流量。在4个版本ABCD中，B为新版，ACD为老版。其中，建议A老版，默认版，盛放流量余量；B新版，新版流量；CD老版，AA实验流量。流量关系需要满足1.sum(A+B+C+D)=100%；2.C=D；3.C+D=B。</li><li>不建议实验上线之后还修改版本。如果修改了版本，请重新分配流量。</li></ul><p><strong>5. 分流</strong></p><ol><li>分流比是否正常<br>可通过dashboard监控来看分流比，其中metricname为abtest.client.reqeust.count,expcode选择实验号，并按expversion分组。在请求数达到一定量的前提，如果存在分流比和配置的分流比出入较大，即分流异常。</li><li>分流比异常原因<br>A. 分流总体较少；B. 实验相互干扰；C.实验存在嵌套（目前不支持）；D.配置或ab代码有误</li><li>app实验分流请求总数很大<br>该请求数表示直接调用abtest.client.dll的接口数，不反映app实验的用户分流请求数。基于app渠道的特殊性，只要用户启动app，将在app加载所有app实验的的ab分流结果。</li></ol><h3 id="异常数据剔除"><a href="#异常数据剔除" class="headerlink" title="异常数据剔除"></a>异常数据剔除</h3><p>异常用户判断逻辑：<br>1.取出所有μ+3Sigma以外的，放入集合A;<br>2.对集合A中的用户做LOF（Local Outlier Factor），取出离群点放入集合B；<br>3.取集合B中用户，其数值大于μ+4Sigma的，视为异常用户。</p><p><strong>这里可根据多个维度进行判断，例如pv量，order量以及amount量</strong></p><p>异常数据剔除逻辑：<br>1.取出异常用户，将该用户在实验有效期内参与的数据均做剔除；</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;如何构建一个ABTest&quot;&gt;&lt;a href=&quot;#如何构建一个ABTest&quot; class=&quot;headerlink&quot; title=&quot;如何构建一个ABTest&quot;&gt;&lt;/a&gt;如何构建一个ABTest&lt;/h2&gt;&lt;h3 id=&quot;谁会参与&quot;&gt;&lt;a href=&quot;#谁会参与&quot; class=&quot;headerlink&quot; title=&quot;谁会参与&quot;&gt;&lt;/a&gt;谁会参与&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;业务部门。 定义一个Ab Testing.&lt;/li&gt;
&lt;li&gt;Ab Testing管理后台。 录入一个Ab Tesing.&lt;/li&gt;
&lt;li&gt;业务开发者。 负责具体的方案开发实现。&lt;/li&gt;
&lt;li&gt;用户。我们所关心的用户。&lt;/li&gt;
&lt;li&gt;数据收集系统。收集我们关心的数据。&lt;/li&gt;
&lt;li&gt;数据分析系统。根据收集到的数据，分析出我们所关心的指标。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="ABTest" scheme="https://www.xiemingzhao.com/categories/ABTest/"/>
    
    
    <category term="ABTest" scheme="https://www.xiemingzhao.com/tags/ABTest/"/>
    
  </entry>
  
  <entry>
    <title>RF,GBDT,XGBOOST, LightGBM之间的爱恨情仇</title>
    <link href="https://www.xiemingzhao.com/posts/diffofRFGBDTXGBLGB.html"/>
    <id>https://www.xiemingzhao.com/posts/diffofRFGBDTXGBLGB.html</id>
    <published>2019-07-04T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.655Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>RF,GBDT,XGBoost,lightGBM都属于<strong>集成学习（Ensemble Learning）</strong>，集成学习的目的是通过结合多个基学习器的预测结果来改善基本学习器的泛化能力和鲁棒性。 </p><p>根据基本学习器的生成方式，目前的集成学习方法大致分为两大类：即基本学习器之间存在强依赖关系、必须串行生成的<strong>序列化方法</strong>；以及基本学习器间不存在强依赖关系、可同时生成的<strong>并行化方法</strong>。前者的代表就是Boosting，后者的代表是Bagging和“随机森林”（Random Forest）。 </p><p>本文主要从下面四个广泛讨论和使用的方法进行了对比分析总结：<br><strong>RF（随机森林）,GBDT（梯度提升决策树）,XGBoost,lightGBM</strong></p><span id="more"></span><h2 id="2-RF（随机森林）"><a href="#2-RF（随机森林）" class="headerlink" title="2. RF（随机森林）"></a>2. RF（随机森林）</h2><h3 id="2-1-算法原理"><a href="#2-1-算法原理" class="headerlink" title="2.1 算法原理"></a>2.1 算法原理</h3><p>介绍RF之前需要先了解一下<strong>Bagging</strong>，其可以简单的理解为：放回抽样，多数表决（分类）或简单平均（回归）,同时Bagging的基学习器之间属于并列生成，不存在强依赖关系。</p><p>回到RF身上，他其实是Bagging的一个扩展变体，主要可以概括为如下四步：</p><blockquote><p>1、随机选择样本（放回抽样）；<br>2、随机选择特征（相比普通通bagging多了特征采样）；<br>3、构建决策树；<br>4、随机森林投票（平均）。</p></blockquote><h3 id="2-2-特性"><a href="#2-2-特性" class="headerlink" title="2.2 特性"></a>2.2 特性</h3><p>在构建决策树的时候，RF的每棵决策树都最大可能的进行生长而不进行剪枝；在对预测输出进行结合时，<strong>RF通常对分类问题使用简单投票法，回归任务使用简单平均法</strong>。</p><p>RF的重要特性是不用对其进行交叉验证或者使用一个独立的测试集获得无偏估计，它可以在内部进行评估，也就是说在生成的过程中可以对误差进行无偏估计，由于每个基学习器只使用了训练集中约63.2%的样本，剩下约36.8%的样本可用做验证集来对其泛化性能进行<strong>“包外估计”</strong>。 </p><h3 id="2-3-RF和Bagging对比："><a href="#2-3-RF和Bagging对比：" class="headerlink" title="2.3 RF和Bagging对比："></a>2.3 RF和Bagging对比：</h3><p>随机选择样本和Bagging相同，随机选择特征是指在树的构建中，会从样本集的特征集合中<strong>随机选择部分特征</strong>，然后再从这个子集中选择最优的属性用于划分，这种随机性导致随机森林的偏差会有稍微的增加（相比于单棵不随机树），但是由于随机森林的‘平均’特性，会使得它的<strong>方差减小</strong>，而且方差的减小<strong>补偿了偏差的增大</strong>，因此总体而言是更好的模型。 </p><p>RF的起始性能较差，特别当只有一个基学习器时，但随着学习器数目增多，随机森林通常会收敛到更低的泛化误差。随机森林的训练效率也会高于Bagging，因为在单个决策树的构建中，Bagging使用的是‘确定性’决策树，在选择特征划分结点时，要对所有的特征进行考虑，而随机森林使用的是‘随机性’特征数，只需考虑特征的子集。</p><h3 id="2-4-优缺点"><a href="#2-4-优缺点" class="headerlink" title="2.4 优缺点"></a>2.4 优缺点</h3><p>优点：</p><ol><li>训练可以高度并行化，对于大数据时代的大样本训练速度有优势，算是主要优势；</li><li>能够处理很高维的数据，并且不用特征选择，而且在训练完后，给出特征的重要性；</li><li>相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。<br>　　<br>缺点：在噪声较大的分类或者回归问题上容易过拟合。</li></ol><h2 id="3-GBDT（梯度提升决策树）"><a href="#3-GBDT（梯度提升决策树）" class="headerlink" title="3. GBDT（梯度提升决策树）"></a>3. GBDT（梯度提升决策树）</h2><h3 id="3-1-算法原理"><a href="#3-1-算法原理" class="headerlink" title="3.1 算法原理"></a>3.1 算法原理</h3><p>首先是基于Boosting的，提升树是加法模型，学习算法为前向分布算法时的算法。但GBDT与传统的Boosting区别较大，是对提升树的改进，不过它限定基本学习器为决策树。它的每一次计算都是为了减少上一次的残差，而为了消除残差，我们可以在<strong>残差减小的梯度方向上建立模型</strong>,所以说，在GradientBoost中，每个新的模型的建立是为了使得之前的模型的残差往梯度下降的方法，与传统的Boosting中关注正确错误的样本加权有着很大的区别。</p><p>具体的算法求解过程可以参考<a href="https://www.jianshu.com/p/405f233ed04b">这篇博客</a>或者<a href="https://www.jstor.org/stable/2699986">原始论文</a>。</p><h3 id="3-2-特性"><a href="#3-2-特性" class="headerlink" title="3.2 特性"></a>3.2 特性</h3><p>对于二分类问题，损失函数为指数函数，就是把AdaBoost算法中的基本学习器限定为二叉决策树就可以了；对于回归问题，损失函数为平方误差，此时，拟合的是当前模型的残差。<strong>提升树算法只适合误差函数为指数函数和平方误差，对于一般的损失函数，梯度提升树算法利用损失函数的负梯度在当前模型的值，作为残差的近似值。</strong></p><p>在GradientBoosting算法中，关键就是利用损失函数的负梯度方向在当前模型的值作为残差的近似值，进而拟合一棵CART回归树。<strong>GBDT的会累加所有树的结果，而这种累加是无法通过分类完成的，因此GBDT的树都是CART回归树，而不是分类树</strong>（尽管GBDT调整后也可以用于分类但不代表GBDT的树为分类树）。</p><h3 id="3-3-优缺点："><a href="#3-3-优缺点：" class="headerlink" title="3.3 优缺点："></a>3.3 优缺点：</h3><p>优点：</p><ol><li>它能灵活的处理各种类型的数据；</li><li>在相对较少的调参时间下，预测的准确度较高，这个是相对SVM来说的。 </li></ol><p>缺点：基学习器之前存在串行关系，难以并行训练数据。</p><h2 id="4-XGBoost"><a href="#4-XGBoost" class="headerlink" title="4 XGBoost"></a>4 XGBoost</h2><h3 id="4-1-算法原理"><a href="#4-1-算法原理" class="headerlink" title="4.1 算法原理"></a>4.1 算法原理</h3><p>XGBoost的性能在GBDT上又有一步提升，而其性能也能通过各种比赛管窥一二。坊间对XGBoost最大的认知在于其能够自动地运用CPU的多线程进行并行计算，同时在算法精度上也进行了精度的提高。由于GBDT在合理的参数设置下，往往要生成一定数量的树才能达到令人满意的准确率，在数据集较复杂时，模型可能需要几千次迭代运算。但是XGBoost利用并行的CPU更好的解决了这个问题。</p><p>针对XGBoost细节可以参考本人对<a href="https://www.xiemingzhao.com/posts/15b10533.html">原始论文的译文</a>以及本人的另一篇专门针对<a href="https://www.xiemingzhao.com/posts/XGBoostDetailAnalysis.html">XGBoost原理的详解</a>的博客。</p><h3 id="4-2-特性"><a href="#4-2-特性" class="headerlink" title="4.2 特性"></a>4.2 特性</h3><p>这里的特性也一般是XGBoost本身加的很多tricks，也是算法的优势所在。</p><p><strong>4.2.1 基分类器</strong><br>传统GBDT以CART树作为基分类器，<strong>xgboost还支持线性分类器</strong>，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。—可以通过booster[default=gbtree]设置参数:gbtree: tree-based models/gblinear: linear models。</p><p><strong>4.2.2 目标函数</strong><br>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了<strong>二阶泰勒展开</strong>，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。</p><p>对损失函数做了改进（泰勒展开），我们知道目标函数定义如下：</p><script type="math/tex; mode=display">\mathcal L^{(t)} = \sum_{t=1}^n l(y_i,\hat y_i^{(t-1)} + f_t(x_i)) + \Omega(f_t) + constant</script><p>其中： <script type="math/tex">\Omega(f) = \gamma T + \frac{1}{2} \lambda ||w||^2</script></p><p>上述目标函数的第二项是正则项，包含了L1和L2正则。且最后一项constant是常数项，优化中可以先忽略，后面我们不再提。然后我们对目标函数进行二阶的泰勒展开来近似，所以有：</p><script type="math/tex; mode=display">\mathcal L^{(t)} \simeq \sum_{t=1}^n [l(y_i,\hat y^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)</script><p>其中，$g<em>i = \partial</em>{\hat y^{(t-1)}} l(y<em>i,\hat y^{(t-1)})$和$h_i = \partial</em>{\hat y^{(t-1)}}^2 l(y_i,\hat y^{(t-1)})$，</p><p>我们可以很清晰地看到，<strong>最终的目标函数只依赖于每个数据点的在误差函数上的一阶导数和二阶导数</strong>。</p><p><strong>4.2.3 正则项</strong><br>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了<strong>树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和</strong>。从 Bias-variance tradeoff 角度来讲，正则项降低了模型 variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。正则化包括了两个部分，都是为了防止过拟合，剪枝是都有的，叶子结点输出L2平滑是新增的。</p><p><strong>4.2.4 shrinkage</strong><br>还是为了防止过拟合，shrinkage缩减类似于学习速率，在每一步 tree boosting 之后增加了一个参数$\eta$（权重），即有$F^{t} =F^{t-1} + \eta f^t$。 通过这种方式来减小每棵树的影响力，给后面的树提供空间去优化模型。权重一般在0-1之间，经验上&lt;=0.1的时候比较好。（补充：传统GBDT的实现也有学习速率）</p><p><strong>4.2.5 column subsampling</strong> 列(特征)抽样，说是从随机森林那边学习来的，防止过拟合的效果比传统的行抽样还好（xgb同样也包含行抽样功能），并且有利于后面提到的并行化处理算法。</p><p><strong>4.2.6 split finding algorithms(划分点查找算法)</strong>：</p><blockquote><p><strong>exact greedy algorithm</strong>—贪心算法获取最优切分点;<br><strong>approximate algorithm</strong>—近似算法，提出了候选分割点概念，先通过直方图算法获得候选分割点的分布情况，然后根据候选分割点将连续的特征信息映射到不同的buckets中，并统计汇总信息。详细见论文3.3节<br><strong>Weighted Quantile Sketch</strong>—分布式加权直方图算法，论文3.4节</p></blockquote><p>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，对特征排序后仅选择常数个候选分裂位置作为候选分裂点，用于高效地生成候选的分割点。<strong>这里的加权就是指当进行某一个特征划分点查找的时候，利用样本的二阶导即$h_i$值作为样本的权重，而并不是按照样本原始个数取找分位数。</strong></p><p><strong>4.2.7 对缺失值的处理。</strong><br>对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。<strong>稀疏感知算法</strong>，论文3.4节，Algorithm 3: Sparsity-aware Split Finding。具体处理方式可以概述如下：</p><blockquote><ol><li>在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。</li><li>在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。</li></ol></blockquote><p><em>一棵树中每个结点在分裂时，寻找的是某个特征的最佳分裂点（特征值），完全可以不考虑存在特征值缺失的样本，也就是说，如果某些样本缺失的特征值缺失，对寻找最佳分割点的影响不是很大。</em></p><p><strong>4.2.8 Built-in Cross-Validation（内置交叉验证)</strong>。<br>XGBoost允许在每一轮boosting迭代中使用交叉验证。因此，可以方便地获得最优boosting迭代次数。而GBM使用网格搜索，只能检测有限个值。</p><p><strong>4.2.9 continue on Existing Model（接着已有模型学习）</strong>。<br>XGBoost可以在上一轮的结果上继续训练。这个特性在某些特定的应用上是一个巨大的优势。</p><p><strong>4.2.10 High Flexibility（高灵活性）</strong>。<br>XGBoost 允许用户定义自定义优化目标和评价标准，它对模型增加了一个全新的维度，所以我们的处理不会受到任何限制。</p><p><strong>4.2.11 并行化处理—系统设计模块,块结构设计等</strong></p><ul><li><p>XGBoost的并行，<strong>并不是说每棵树可以并行训练</strong>，XGB本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。</p></li><li><p>XGBoost的并行，指的是<strong>特征维度的并行</strong>：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。</p></li></ul><p><strong>4.2.12 剪枝</strong></p><blockquote><ol><li>在目标函数中增加了正则项：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度。</li><li>在结点分裂时，定义了一个阈值，如果分裂后目标函数的增益Gain小于该阈值(最小划分损失min_split_loss)，则不分裂。</li><li>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和min_child_weight），也会放弃此次分裂。</li><li>XGBoost 先从顶到底建立树直到最大深度，再从底到顶反向检查是否有不满足分裂条件的结点，进行剪枝。</li><li>当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。</li></ol></blockquote><p>对于最后一点，XGBoost会一直分裂到指定的最大深度(max_depth)，然后回过头来剪枝，即后剪枝。如果某个节点之后不再有正值，它会去除这个分裂。这种做法的优点，当一个负损失（如-2）后面有个正损失（如+10）的时候，就显现出来了。预剪枝会在-2处停下来，因为它遇到了一个负值。但是XGBoost会继续分裂，然后发现这两个分裂综合起来会得到+8，因此会保留这两个分裂。</p><p><strong>4.2.13 高速缓存压缩感知算法</strong><br>xgboost还设计了高速缓存压缩感知算法，这是系统设计模块的效率提升。当梯度统计不适合于处理器高速缓存和高速缓存丢失时，会大大减慢切分点查找算法的速度。</p><p>针对 exact greedy algorithm采用缓存感知预取算法<br>针对 approximate algorithms选择合适的块大小</p><p><strong>4.2.14 处理不平衡数据</strong><br>对于不平衡的数据集，例如用户的购买行为，肯定是极其不平衡的，这对XGBoost的训练有很大的影响，XGBoost有两种自带的方法来解决：</p><ul><li><p>第一种，如果你在意AUC，采用AUC来评估模型的性能，那你可以通过设置<strong>scale_pos_weight</strong>来平衡正样本和负样本的权重。例如，当正负样本比例为1:10时，scale_pos_weight可以取10；</p></li><li><p>第二种，如果你在意概率(预测得分的合理性)，你不能重新平衡数据集(会破坏数据的真实分布)，应该设置<strong>max_delta_step</strong>为一个有限数字来帮助收敛（基模型为LR时有效）。</p></li></ul><p>原理是增大了少数样本的权重。除此之外，还可以通过<strong>上采样、下采样、SMOTE算法或者自定义代价函数</strong>的方式解决正负样本不平衡的问题。</p><h3 id="4-3-XGBoost不足之处："><a href="#4-3-XGBoost不足之处：" class="headerlink" title="4.3 XGBoost不足之处："></a>4.3 XGBoost不足之处：</h3><blockquote><ol><li>每轮迭代时，都需要遍历整个训练数据多次。如果把整个训练数据装进内存则会限制训练数据的大小；如果不装进内存，反复地读写训练数据又会消耗非常大的时间。</li><li>预排序方法（pre-sorted）：首先，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如排序后的索引，为了后续快速的计算分割点），这里需要消耗训练数据两倍的内存。其次时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。</li><li>对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。</li></ol></blockquote><h3 id="4-4-常用问题解答"><a href="#4-4-常用问题解答" class="headerlink" title="4.4 常用问题解答"></a>4.4 常用问题解答</h3><p><strong>4.4.1 RF和GBDT的区别</strong></p><p>他们都是由多棵树组成，最终的结果都是由多棵树一起决定。而不同点主要有：</p><blockquote><ul><li>集成学习：RF属于bagging思想，而GBDT是boosting思想；</li><li>偏差-方差权衡：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差；</li><li>训练样本：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本；</li><li>并行性：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成)；</li><li>最终结果：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合；</li><li>数据敏感性：RF对异常值不敏感，而GBDT对异常值比较敏感；</li><li>泛化能力：RF不易过拟合，而GBDT容易过拟合。</li></ul></blockquote><p><strong>4.4.2 XGBoost与GBDT有什么不同</strong></p><blockquote><ul><li>基分类器：XGBoost的基分类器不仅支持CART决策树，还支持线性分类器，此时XGBoost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li><li>导数信息：XGBoost对损失函数做了二阶泰勒展开，GBDT只用了一阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶、二阶可导。</li><li>正则项：XGBoost的目标函数加了正则项， 相当于预剪枝，使得学习出来的模型更加不容易过拟合。</li><li>列抽样和缩减：XGBoost支持列采样，与随机森林类似，同时对每棵树输出使用shrinkage，都是用于防止过拟合。</li><li>缺失值处理：对树中的每个非叶子结点，XGBoost可以自动学习出它的默认分裂方向。如果某个样本该特征值缺失，会将其划入默认分支。</li><li>并行化：注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。</li><li>可并行的近似直方图算法：树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</li></ul></blockquote><p><strong>4.4.3 XGBoost为什么使用泰勒二阶展开</strong></p><ul><li><strong>精准性</strong>：相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，阶信息本身就能让梯度收敛更快更准确。这一点在优化算法里的牛顿法里已经证实了。可以简单认为一阶导指引梯度方向，二阶导指引梯度方向如何变化。</li><li><strong>可扩展性</strong>：Xgboost官网上有说，当目标函数是MSE时，展开是一阶项（残差）+二阶项的形式（官网说这是一个nice form），而其他目标函数，如logloss的展开式就没有这样的形式。为了能有个统一的形式，所以采用泰勒展开来得到二阶项，这样就能把MSE推导的那套直接复用到其他自定义损失函数上。简短来说，就是为了统一损失函数求导的形式以支持自定义损失函数。</li></ul><p><strong>4.4.4 XGBoost为什么快</strong></p><blockquote><ul><li><strong>分块并行</strong>：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点</li><li><strong>候选分位点</strong>：每个特征采用常数个分位点作为候选分割点</li><li><strong>CPU cache 命中优化</strong>： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。</li><li><strong>Block 处理优化</strong>：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐</li></ul></blockquote><p><strong>4.4.5 XGBoost防止过拟合的方法</strong></p><blockquote><ul><li><strong>目标函数添加正则项</strong>：叶子节点个数+叶子节点权重的L2正则化</li><li><strong>列抽样</strong>：训练的时候只用一部分特征（不考虑剩余的block块即可）</li><li><strong>子采样</strong>：每轮计算可以不使用全部样本，使算法更加保守</li><li><strong>shrinkage</strong>: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间</li><li><strong>剪枝</strong>：多种方式限制树的复杂度，参考4.2.12。</li></ul></blockquote><p><strong>4.4.6 XGBoost中叶子结点的权重如何计算出来</strong></p><p>$\mathcal F = {f(x) = w_{q(x)}}(q: \mathbb R^m \rightarrow T, w \in \mathbb R^T)$是回归树（也叫做CART）的空间。</p><p>$q$表示将样本映射到叶节点的树的结构。$T$是每棵树叶子的数量。每个$F_k$对应了独立的树结构$q$和叶权值$w$。与决策树不同，每棵回归树的每个叶子上包含连续的连续值打分，<strong>我们用$w_i$表示第$i$个叶子的打分。</strong></p><p><strong>即这里每个样本最终在$q$结构的树上最终只会落在某一个叶子节点上，那么对应的$w$这个权重即为输出值。所以我们需要确定最优的$w$，而这个就需要根据最优的损失目标来确定。有$T$个叶子节点所以有$T$个$w$</strong></p><p>定义$I_j = {i|q(x_i)=j}$为叶子结点j里面的样本，我们可以通过扩展$\Omega$来重写公式（3）：</p><script type="math/tex; mode=display">\tilde{\mathcal L}^{(t)} = \sum_{t=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2 \\=\sum_{j=1}^T[(\sum_{i \in I_j} g_i) w_j + \frac{1}{2}(\sum_{i \in I_j} h_i + \lambda) w_j^2] + \gamma T</script><p>对于一个固定的结构$q(x)$，我们可以根据二次函数求最值的方法计算叶子结点$j$的最优权重$w_j^{*}$，即在$w_j^{*}$取如下值的时候目标函数能够取最小值：</p><script type="math/tex; mode=display">w_j^* = -\frac{\sum_{i \in I_j} g_i} {\sum_{i \in I_j} h_i + \lambda}</script><p>并通过下式计算相应的目标函数最优值：</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{(t)}(q)=-\frac{1}{2} \sum_{j=1}^{T} \frac{\left(\sum_{i \in I_{j}} g_{i}\right)^{2}}{\sum_{i \in I_{j}} h_{i}+\lambda}+\gamma T</script><p>我们需要检测这次分裂是否会给损失函数带来增益，增益的定义如下：</p><script type="math/tex; mode=display">\mathcal{L}_{\text {split}}=\frac{1}{2}\left[\frac{\left(\sum_{i \in I_{L}} g_{i}\right)^{2}}{\sum_{i \in I_{L}} h_{i}+\lambda}+\frac{\left(\sum_{i \in I_{R}} g_{i}\right)^{2}}{\sum_{i \in I_{R}} h_{i}+\lambda}-\frac{\left(\sum_{i \in I} g_{i}\right)^{2}}{\sum_{i \in I} h_{i}+\lambda}\right]-\gamma</script><p><strong>4.4.7 XGBoost如何评价特征的重要性</strong><br>官方文档主要介绍了三种方法来评判XGBoost模型中特征的重要程度：</p><blockquote><p>weight ：该特征在所有树中被用作分割样本的特征的总次数。<br>gain ：该特征在其出现过的所有树中产生的平均增益。<br>cover ：该特征在其出现过的所有树中的平均覆盖范围。</p></blockquote><p><em>注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</em></p><blockquote><p>除了这一部分，本人在实际项目中为了做模型的可解释性，发现了另一种方法。得益于XGBoost本身依然是树结构的模型，所以我们能够得到样本在打分过程中在每一棵树上所到达的每一个节点的权重值，通过这样的路径和权重值我们能够通过叶子结点沿着路径反向计算权重的差值即可得到每一个特征在各个节点处的贡献值。</p></blockquote><p><strong>4.4.8 XGBoost如何选择最佳分裂点</strong></p><p>在分裂一个结点时，我们会有很多个候选分割点，寻找最佳分割点的大致步骤如下：</p><blockquote><ol><li>遍历每个结点的每个特征；</li><li>对每个特征，按特征值大小将特征值排序；</li><li>线性扫描，找出每个特征的最佳分裂特征值；</li><li>在所有特征中找出最好的分裂点（分裂后增益最大的特征及特征值）。</li></ol></blockquote><p><em>上面是一种贪心的方法，每次进行分裂尝试都要遍历一遍全部候选分割点，也叫做全局扫描法。</em></p><p>但当数据量过大导致内存无法一次载入或者在分布式情况下，贪心算法的效率就会变得很低，全局扫描法不再适用。基于此，XGBoost提出了一系列加快寻找最佳分裂点的方案，也即4.2.6中提到的<strong>近似分位数（直方图）算法</strong>：</p><blockquote><ul><li><strong>特征预排序+缓存</strong>：XGBoost在训练之前，预先对每个特征按照特征值大小进行排序，然后保存为block结构，后面的迭代中会重复地使用这个结构，使计算量大大减小。</li><li><strong>分位点近似法</strong>：对每个特征按照特征值排序后，采用类似分位点选取的方式，仅仅选出常数个特征值作为该特征的候选分割点，在寻找该特征的最佳分割点时，从候选分割点中选出最优的一个。</li><li><strong>并行查找</strong>：由于各个特性已预先存储为block结构，XGBoost支持利用多个线程并行地计算每个特征的最佳分割点，这不仅大大提升了结点的分裂速度，也极利于大规模训练集的适应性扩展。</li></ul></blockquote><h2 id="5-LightGBM"><a href="#5-LightGBM" class="headerlink" title="5 LightGBM"></a>5 LightGBM</h2><h3 id="5-1-算法原理"><a href="#5-1-算法原理" class="headerlink" title="5.1 算法原理"></a>5.1 算法原理</h3><p>它是微软出的新的boosting框架，基本原理与XGBoost一样，只是在框架上做了一优化（重点在模型的训练速度的优化）。对于其细节算法可以参考本人对<a href="https://www.xiemingzhao.com/posts/c7ab2b84.html">原始论文的译文博客</a>。</p><h3 id="5-2-LightGBM和XGBoost的区别"><a href="#5-2-LightGBM和XGBoost的区别" class="headerlink" title="5.2 LightGBM和XGBoost的区别"></a>5.2 LightGBM和XGBoost的区别</h3><h4 id="5-2-1-树生长策略"><a href="#5-2-1-树生长策略" class="headerlink" title="5.2.1 树生长策略"></a>5.2.1 树生长策略</h4><p>XGB采用level-wise的分裂策略，LGB采用leaf-wise的分裂策略。XGB对每一层所有节点做无差别分裂，但是可能有些节点增益非常小，对结果影响不大，带来不必要的开销。Leaf-wise是在所有叶子节点中选取分裂收益最大的节点进行的，但是很容易出现过拟合问题，所以需要对最大深度做限制 。</p><p><strong>Level-wise</strong>：此为XGBoost主要是用的方法，过一次数据可以<strong>同时分裂同一层的叶子</strong>，容易进行多线程优化，也好控制模型复杂度，不容易过拟合。但实际上Level-wise是一种<strong>低效算法</strong>，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p><p><strong>Leaf-wise</strong>：LightGBM使用的方法，是一种更为高效的策略，每次从当前所有叶子中，找到<strong>分裂增益最大</strong>的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。但是可能会长出比较深的决策树，<strong>产生过拟合</strong>。因此LightGBM在Leaf-wise之上增加了一个<strong>最大深度限制</strong>，在保证高效率的同时防止过拟合。</p><p><em>注意：目前XGBoost现在两种方式都是支持的</em></p><h4 id="5-2-2-分割点查找算法"><a href="#5-2-2-分割点查找算法" class="headerlink" title="5.2.2 分割点查找算法"></a>5.2.2 分割点查找算法</h4><p>lightgbm使用了基于histogram的切分点算法，这一点不同与xgboost中的预排序的 exact greedy 算法，histogram算法在内存和计算代价上都有不小优势。<strong>XGBoost里现在也提供了这一选项</strong>，不过默认的方法是对特征预排序。</p><p>直方图算法的基本思想：先把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图。遍历数据时，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。<strong>直方图算法是一种牺牲了一定的切分准确性而换取训练速度以及节省内存空间消耗的算法。</strong></p><p>下面我们就看一下直方图算法的优势：</p><blockquote><ul><li><strong>内存上优势</strong>。很明显，直方图算法的内存消耗为(# data <em> # features </em> 1Bytes)(因为对特征分桶后只需保存特征离散化之后的值)，而预排序的 exact greedy 算法内存消耗为：(2 <em> # data </em> # features* 4Bytes)，因为后者既要保存原始feature的值，也要保存这个值的顺序索引，这些值需要32位的浮点数来保存。直方图算法则不需要从而减少了并行训练的通信代价。</li><li><strong>计算上的优势</strong>。预排序算法在选择好分裂特征计算分裂收益时需要遍历所有样本的特征值，时间为O(# feature <em> # data),而直方图算法只需要遍历桶就行了，时间为O(#feature </em> # bins)。�𝑒×#𝑏�</li><li><strong>直方图做差加速</strong>。一个子节点的直方图可以通过父节点的直方图减去兄弟节点的直方图得到，从而加速计算。</li></ul></blockquote><p>但实际上xgboost的近似直方图算法也类似于lightgbm这里的直方图算法，为什么xgboost的近似算法比lightgbm还是慢很多呢？</p><blockquote><p>xgboost在每一层都动态构建直方图，因为xgboost的直方图算法不是针对某个特定的feature，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而lightgbm中对每个特征都有一个直方图，所以构建一次直方图就够了。</p></blockquote><h4 id="5-2-3-支持离散变量"><a href="#5-2-3-支持离散变量" class="headerlink" title="5.2.3 支持离散变量"></a>5.2.3 支持离散变量</h4><p>XGBoost无法直接输入类别型变量，因此需要事先对类别型变量进行编码（例如独热编码），而LightGBM可以<strong>直接输入 categorical 的 feature</strong>。在对离散特征分裂时，每个取值都当作一个桶，分裂时的增益算的是”是否属于某个category“的gain，类似于one-hot编码。</p><h4 id="5-2-4-缓存命中率"><a href="#5-2-4-缓存命中率" class="headerlink" title="5.2.4 缓存命中率"></a>5.2.4 缓存命中率</h4><p>使用<strong>collective communication</strong>算法替代了<strong>point-to-point communication</strong>算法提升了效率</p><ul><li>XGB使用Block结构的一个缺点是取梯度的时候，是通过索引来获取的，而这些梯度的获取顺序是按照特征的大小顺序的，这将导致非连续的内存访问，可能使得CPU cache缓存命中率低，从而影响算法效率。</li><li>而LGB是基于直方图分裂特征的，梯度信息都存储在一个个bin中，所以访问梯度是连续的，缓存命中率高。</li></ul><h4 id="5-2-5-并行策略"><a href="#5-2-5-并行策略" class="headerlink" title="5.2.5 并行策略"></a>5.2.5 并行策略</h4><p><strong>(1) 特征并行</strong></p><blockquote><ul><li>LGB特征并行：</li></ul><ol><li>是每个worker留有一份完整的数据集（不经过采样的），这样就不必在切分后传输切分结果数据，因为每个机器已经持有完整的数据集；</li><li>各个机器上的worker根据所分配的特征子集寻找到局部的最优切分点(特征、阈值)；</li><li>worker之间需要相互通信，通过比对损失来确定的最佳切分点；</li><li>然后将这个最佳切分点的位置进行全局广播，每个worker进行切分即可。</li></ol><ul><li>XGB的特征并行：</li></ul><ol><li>对数据列采样，即不同的机器上保留不同的特征子集；</li><li>各个机器上的worker根据所分配的特征子集寻找到局部的最优切分点(特征、阈值)；</li><li>互相通信来从局部最佳切分点里得到最佳切分点；</li><li>拥有最佳切分点的worker执行切分操作，然后将切分结果传送给其他的worker；</li><li>其他的worker根据接收到的数据来切分数据。</li></ol></blockquote><p>二者的区别就导致了LGB中worker间通信成本明显降低，只需通信一个特征分裂点即可。而XGB中要广播样本索引，计算量太大，并没有提升切分的效率，时间复杂度为O(#data)(因为每个worker持有所有行，需要处理全部的记录)，当数据量较大时特征并行并不能提升速度切分结果的通信代价，大约为O(#data/8)(若一个数据样本为1bit)</p><p><strong>Notes:LGB是典型的空间换时间，差别就是减少了传输切分结果的步骤，节省了这里的通信消耗</strong></p><p><strong>(2) 数据并行</strong> ：<br>当数据量很大，特征相对较少时，需要考虑数据并行策略。</p><blockquote><ul><li><strong>XGB中的数据并行是传统做法</strong></li></ul><ol><li>行采样，对数据进行横向切分；</li><li>worker使用分配到的局部数据构建局部的直方图；</li><li>合并局部直方图得到全局的直方图；</li><li>对全局直方图寻找最优切分点，然后进行切分。</li></ol><ul><li><strong>LightGBM的做法(依然是降低通信代价)</strong></li></ul><ol><li>不同于合并所有的局部直方图获得全局的直方图，LightGBM通过Reduce Scatter方法来合并不同worker的无交叉的不同特征的直方图，这样找到该直方图的局部最优切分点，最后同步到全局最优切分点；</li><li>基于直方图做差的方法，先计算样本量少的节点的样本索引，在通信的过程中可以只传输某一叶节点的直方图，而对于其邻居可通过直接相减得到子节点的样本索引，这个直方图算法使得worker间的通信成本降低一倍，因为只用通信以此样本量少的节点。通信的时间复杂度为O(0.5<em>#feature</em>#bin)</li></ol></blockquote><p><strong>Notes: 传统做法的通信代价过高，若使用point-to-point的通信算法，每个机器的通信代价时间复杂度为O(# machine <em> # feature </em> # bin)，若使用collective通信算法则通信代价为O(2 <em> # feature </em> \ # bin)</strong></p><p><strong>(3) 投票并行（LGB）</strong>：</p><blockquote><p>当数据量和维度都很大时，选用投票并行，该方法是数据并行的一个改进。数据并行中的合并直方图的代价相对较大，尤其是当特征维度很大时。大致思想是：<strong>每个worker首先会找到本地的一些优秀的特征，然后进行全局投票，根据投票结果，选择top的特征进行直方图的合并，再寻求全局的最优分割点。</strong></p></blockquote><h4 id="5-2-6-Early-Stopping"><a href="#5-2-6-Early-Stopping" class="headerlink" title="5.2.6 Early Stopping"></a>5.2.6 Early Stopping</h4><p>XGBoost,LightGBM都支持早停止，不过在细节上略有不同。XGBoost和LightGBM里的early_stopping则都是用来控制基学习器的数目的</p><blockquote><ul><li>两者都可以使用多组评价指标，但是不同之处在于XGBoost会根据指标列表中的最后一项指标控制模型的早停止，而LightGBM则会受到所有的评估指标的影响；</li><li>在使用early stopping控制迭代次数后，模型直接返回的是最后一轮迭代的学习器不一定是最佳学习器，而在做出预测时可以设置参数选择某一轮的学习器作出预测。<blockquote><ul><li>XGBoost里保存了三种状态的学习器，分别是bst.best_score, bst.best_iteration, bst.best_ntree_limit,官方的建议是在做预测时设置为bst.best_ntree_limit，实际使用时感觉bst.best_iteration和 bst.best_ntree_limit的表现上区别不大</li></ul></blockquote></li><li>LightGBM则仅提供了bst.best_iteration这一种方式。</li></ul></blockquote><p><strong>参考博文：</strong><br><a href="https://blog.csdn.net/u014248127/article/details/79015803">yealxxy: RF,GBDT,XGBoost,lightGBM的对比</a><br><a href="https://blog.csdn.net/data_scientist/article/details/79022025">data_scientist:F、GBDT、XGBoost、lightGBM原理与区别</a><br><a href="https://baijiahao.baidu.com/s?id=1645723756242129387&amp;wfr=spider&amp;for=pc">启迪云:XGBoost超详细推导，终于有人讲明白了</a><br><a href="https://www.cnblogs.com/cassielcode/p/12469053.html">AlwaysBeta:XGBoost20题</a><br><a href="https://blog.csdn.net/yimingsilence/article/details/82193890">默一鸣:RF,GBDT,XGBOOST, LightGBM的对比和分析</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1. 前言&quot;&gt;&lt;/a&gt;1. 前言&lt;/h2&gt;&lt;p&gt;RF,GBDT,XGBoost,lightGBM都属于&lt;strong&gt;集成学习（Ensemble Learning）&lt;/strong&gt;，集成学习的目的是通过结合多个基学习器的预测结果来改善基本学习器的泛化能力和鲁棒性。 &lt;/p&gt;
&lt;p&gt;根据基本学习器的生成方式，目前的集成学习方法大致分为两大类：即基本学习器之间存在强依赖关系、必须串行生成的&lt;strong&gt;序列化方法&lt;/strong&gt;；以及基本学习器间不存在强依赖关系、可同时生成的&lt;strong&gt;并行化方法&lt;/strong&gt;。前者的代表就是Boosting，后者的代表是Bagging和“随机森林”（Random Forest）。 &lt;/p&gt;
&lt;p&gt;本文主要从下面四个广泛讨论和使用的方法进行了对比分析总结：&lt;br&gt;&lt;strong&gt;RF（随机森林）,GBDT（梯度提升决策树）,XGBoost,lightGBM&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="LightGBM" scheme="https://www.xiemingzhao.com/tags/LightGBM/"/>
    
    <category term="XGBoost" scheme="https://www.xiemingzhao.com/tags/XGBoost/"/>
    
    <category term="GBDT" scheme="https://www.xiemingzhao.com/tags/GBDT/"/>
    
    <category term="RF" scheme="https://www.xiemingzhao.com/tags/RF/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost原理细节详解</title>
    <link href="https://www.xiemingzhao.com/posts/XGBoostDetailAnalysis.html"/>
    <id>https://www.xiemingzhao.com/posts/XGBoostDetailAnalysis.html</id>
    <published>2019-06-30T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.656Z</updated>
    
    <content type="html"><![CDATA[<p>原文来自大神级的论文<a href="https://netman.aiops.org/~peidan/ANM2018/3.MachineLearningBasics/LectureCoverage/18.xgboost.pdf">XGBoost: A Scalable Tree Boosting System</a>，论文很全面，框架介绍很完整，但是在某些tricks上面并没有对细节做详细解说，而需要读者亲自去进行一定的推导，这使得阅读起来稍显吃力，当然基础很雄厚的大牛级别的应该不以为然，但我相信还有很多与我一样入行不久的，那么这篇博客就是你的所需。</p><p><strong>这里特别感谢作者<code>meihao5</code>的博文，其分享的内容就是我一直想要整理但迟迟未进行的，它的原文可见最后面的参考文章链接里。</strong></p><h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1 基础知识"></a>1 基础知识</h2><p>XGBoost的成功可以总结为回归（树回归+线性回归）+提升（boosting）+优化（5个方面）牛顿法、预排序、加权分位数、稀疏矩阵识别以及缓存识别等技术来大大提高了算法的性能。下面开始介绍一些入门必须的基础知识：</p><span id="more"></span><h3 id="1-2-低维到高维的转变"><a href="#1-2-低维到高维的转变" class="headerlink" title="1.2 低维到高维的转变"></a>1.2 低维到高维的转变</h3><h4 id="梯度和Hessian矩阵"><a href="#梯度和Hessian矩阵" class="headerlink" title="梯度和Hessian矩阵"></a>梯度和Hessian矩阵</h4><ul><li>一阶导数和梯度(gradient vector)</li></ul><script type="math/tex; mode=display">f'(x); g(x) = \nabla f(x) = \frac{\partial f(x)}{\partial x} = \left[\begin{array} {c} \frac{\partial f(x)}{\partial x_1}\\ \vdots \\ \frac{\partial f(x)}{\partial x_n} \end{array} \right]</script><ul><li>二阶导数和Hessian矩阵</li></ul><script type="math/tex; mode=display">f''(x); H(x) = \nabla f(x) = \left[\begin{array} {c c c c} \frac{\partial^2 f(x)}{\partial x_1^2} \frac{\partial^2 f(x)}{\partial x_1 \partial x_2} \cdots \frac{\partial^2 f(x)}{\partial x_1 \partial x_n} \\ \frac{\partial^2 f(x)}{\partial x_2 \partial x_1} \frac{\partial^2 f(x)}{\partial x_2^2} \cdots \frac{\partial^2 f(x)}{\partial x_2 \partial x_n} \\ \vdots \\ \frac{\partial^2 f(x)}{\partial x_n \partial x_1} \frac{\partial^2 f(x)}{\partial x_n \partial x_2} \cdots \frac{\partial^2 f(x)}{\partial x_n^2} \end{array} \right]</script><h3 id="1-3-泰勒级数和极值"><a href="#1-3-泰勒级数和极值" class="headerlink" title="1.3 泰勒级数和极值"></a>1.3 泰勒级数和极值</h3><p><strong>泰勒级数展开（标量和向量）</strong></p><ul><li>输入为标量的泰勒级数展开</li></ul><script type="math/tex; mode=display">f(x_k + \delta) \approx f(x_k) + f'(x_k) \delta + \frac{1}{2} f''(x_k) \delta^2 + \cdots + \frac{1}{k!}f^k (x_k) \delta^k + \cdots</script><ul><li>输入为向量的泰勒级数展开</li></ul><script type="math/tex; mode=display">f(x_k + \delta) \approx = f(x_k) + g^T (x_k) \delta + \frac{1}{2} \delta^T H(x_k) \delta</script><h3 id="1-4-极值点"><a href="#1-4-极值点" class="headerlink" title="1.4 极值点"></a>1.4 极值点</h3><p><strong>标量情况</strong></p><ul><li>输入为标量的泰勒展开</li></ul><script type="math/tex; mode=display">f(x_k + \delta) \approx f(x_k) + f'(x_k) \delta + \frac{1}{2} f''(x_k) \delta^2</script><ul><li><p>严格局部极小点指：$f(x_k + \delta) &gt; f(x_k)$</p></li><li><p>称满足$f’(x_k) = 0$的点为平稳点（候选点）。</p></li><li>函数在$x_k$有严格局部极小值条件为$f’(x_k) = 0$且$f’’(x_k) &gt; 0$。</li></ul><p><strong>向量情况</strong></p><ul><li>输入为向量的泰勒级数展开</li></ul><script type="math/tex; mode=display">f(x_k + \delta) \approx f(x_k) +  g^T (x_k) \delta + \frac{1}{2} \delta^T H(x_k) \delta</script><ul><li>称满足$g(x_k) = 0$的点为平稳点（候选点），此时如果有<blockquote><p>$H(x_k) \succ 0$， $x_k$为一个严格局部极小点（反之，局部严格最大点）<br>如果$H(x)$不定矩阵，是一个鞍点(saddle point)。（如下图所示）</p></blockquote></li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis1.png" alt="XGBoostDetailAnalysis1"></p><h3 id="1-5-怎么求一个函数的极值"><a href="#1-5-怎么求一个函数的极值" class="headerlink" title="1.5 怎么求一个函数的极值"></a>1.5 怎么求一个函数的极值</h3><p>答案自然是迭代法。迭代法的基本结构可以表示成如下所示（最小化$f(x)$）：</p><blockquote><p>选择一个初始点，设置一个 convergence tolerance $\epsilon$，技术k=0<br>决定抖索方向$d<em>k$， 是的函数下降（核心）<br>决定步长$\alpha_k$是的$f(x_k + \alpha_k d_k)$对于$\alpha_k \geq 0$最小化，构建$x</em>{k+1} = x<em>k + \alpha_k d_k$<br>如果$||d_k|| &lt; \epsilon$，则停止输出解$x</em>{k+1}$，否则继续迭代。（如下图所示）</p></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis2.png" alt="XGBoostDetailAnalysis2"></p><p>各种各样的优化算法不同点在于：选取的步长不一样，选取的方向不一样。</p><p>Xgboost也是GBDT的一中，只不过进行了大量的优化！，其中一点就是优化方法选取了牛顿法（选取的方向不一样，一个梯度的方向，一个二阶导数的方向）</p><h2 id="2-GBDT-梯度提升树）"><a href="#2-GBDT-梯度提升树）" class="headerlink" title="2 GBDT(梯度提升树）"></a>2 GBDT(梯度提升树）</h2><p>如何构建得带的回归提升树（CRAT树），简单来说就是重复构建很多树，每一棵树都是基于前面的一棵树，使得当前这棵树拟合样本数据平方损失最小。</p><blockquote><p>当损失函数是平方损失函数或者指数函数时，每一步优化很简单，但是对一般损失函数，优化就不算那么容易了。于是，就有了梯度提升树算法。</p></blockquote><p>**梯度提升算法的本质：拟合一个回归树是的损失函数最小。<br>这个思想在优化算法经常用，但是没有解析解，一般就是拟合一个近似值（例如注明的著名的拟牛顿法）。</p><h3 id="2-1-参数空间与函数空间"><a href="#2-1-参数空间与函数空间" class="headerlink" title="2.1 参数空间与函数空间"></a>2.1 参数空间与函数空间</h3><p>因为梯度提升树就是在函数空间做优化，如下图所示：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis3.png" alt="XGBoostDetailAnalysis3"></p><h3 id="2-2-Boosting思想"><a href="#2-2-Boosting思想" class="headerlink" title="2.2 Boosting思想"></a>2.2 Boosting思想</h3><p>提升树使用了Boosting思想，即：</p><blockquote><p>先从初始训练集中训练出一个基学习器，再根据学习器的表现对训练样本分布进行调整，使得先前基学习器做错的样本在后续受到更多的关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直到基学习器数目达到事先指定的T，最终将T个基学习器进行加权结合。</p></blockquote><p><strong> Gradient Boosting Tree 算法原理 </strong></p><ul><li><p>Friedman在论文<a href="https://www.jstor.org/stable/2699986">greedy function approximation: a gradient boosting machine</a>中提出GBDT。</p></li><li><p>其模型F定义为加法模型：</p><script type="math/tex; mode=display">F(x;w) = \sum_{t=0}^T \alpha_t h_t(x;w_t) = \sum_{t=0}^T f_t (x;w_t)</script><p>其中，x 为输入样本， h 为分类回归树，w 是分类回归树的参数，$\alpha$ 是每个树的权重。</p></li><li><p>通过最小化损失函数求解最优模型：</p><script type="math/tex; mode=display">F^* = \mathop{\arg\min}\limits_{F} \sum_{i=0}^N L(y_i, F(x_i; w))</script><p>NP难问题 -&gt; 通过贪心算法，迭代求局部最优解。</p></li></ul><p><strong>计算流程表示如下：</strong></p><blockquote><p>输入：$(x_i, y_i), T, L$</p><ol><li>初始化$f_0$</li><li>for t=1 to T do<br> 2.1 计算响应：<br>$\tilde y<em>i = -[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}]</em>{F(x) = F<em>{t-1}(x)}, i = 1,2,\cdots,N$<br> 2.2 学习第t棵树：<br>$w^* = \mathop{\arg\min}\limits</em>{w} \sum<em>{i=1}^N(\tilde y_i - h_t(x_i;w))^2$<br> 2.3 line search 找步长（前向分步算法）：<br>$\rho^* = \mathop{\arg\min}\limits</em>{\rho} \sum<em>{i=1}^N L(y_i,F</em>{t-1}(x<em>i) + \rho h_t(x_i;w^<em>))$<br> 2.4  令$f_t = \rho^</em> h_t(x;w^*)$，更新模型：<br>$F_t = F</em>{t-1} + f_t$</li><li>输出$F_T$</li></ol></blockquote><p>根据上述流程，类比梯度下降，自然有一些梯度提升的感觉，一个是优化参数空间，一个是优化函数空间。</p><blockquote><p>2.1 计算残差（计算值域真实值之间的误差）<br>2.2 拟合是的残差最小（当前学习的这棵树）<br>2.3 $\rho$步长：基于学习器的权重， H树：表示方向<br>2.4 得到当前这一步的树</p></blockquote><p>一句话总结：新树模型的引入是为了减少上个树的残差，即前面模型未能拟合的剩余信息。我们可以在残差减少的梯度方向上建立这么一个新模型。对比提升树来说，提升树没有基学习器参数权重$\rho$。</p><p>以前面的均方损失为例，也是可以用这个方法来解释的。为了求导方便，我们在均方损失函数前乘上一个1/2：</p><script type="math/tex; mode=display">L(y_i, F(x_i)) = \frac{1}{2} (y_i - F(x_i))^2</script><p>注意到$F(x_i)$其实只是一些数字而已，我们可以将其像变量一样进行求导：</p><script type="math/tex; mode=display">\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)} = F(x_i) - y_i</script><p>而前面所说的残差就是上式相反数，即<strong>负梯度</strong>：</p><script type="math/tex; mode=display">r_{ti} = y_i - F_{t-1}(x) = -[\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}]_{F(x) = F_{t-1}(x)}</script><p>随着T的增大我们的模型的训练误差会越来越小，如果无限迭代下去，理想情况下训练误差就会收敛到一个极小值，相应的会收敛到一个极小值点* P 。这是不是有种似曾相似的感觉，想一想在凸优化里面梯度下降法（参数空间的优化），是不是很像？我们就把F(x)看成是在 N 维空间中的一个一个的点，而损失函数就是这个N 维空间中的一个函数（函数空间的优化），我们要用某种逐步逼近的算法来求解损失函数的极小值（最小值）。</p><h3 id="2-3-如果要将GBDT用于分类问题，怎么做呢？"><a href="#2-3-如果要将GBDT用于分类问题，怎么做呢？" class="headerlink" title="2.3 如果要将GBDT用于分类问题，怎么做呢？"></a>2.3 如果要将GBDT用于分类问题，怎么做呢？</h3><p>首先要明确的是，GBDT用于回归使用的仍然是CART回归树。回想我们做回归问题的时候，每次对残差（负梯度）进行拟合。而分类问题要怎么每次对残差拟合？要知道类别相减是没有意义的。因此，可以用Softmax进行概率的映射，然后拟合概率的残差！</p><p>具体的做法如下：<br>针对每个类别都先训练一个回归树，如三个类别，训练三棵树。就是比如对于样本xi为第二类，则输入三棵树分别为：$(x<em>i,0),(x_i,1);(x_i,0)$这其实是典型的OneVsRest的多分类训练方式。 而每棵树的训练过程就是CART的训练过程。这样，对于样本$x_i$就得出了三棵树的预测值$F1(x_i),F2(x_i),F3(x_i)$，模仿多分类的逻辑回归，用Softmax来产生概率，以类别1为例：<br>$p1(x_i)=\frac{exp(F1(x_i))}{\sum</em>{i=1}^3 (F1(xi))}$</p><p>对每个类别分别计算残差，如<br>类别1：y~i1=0–p1(xi),<br>类别2：y~i2=1–p2(xi),<br>类别3：y~i3=0–p3(xi)</p><p>开始第二轮的训练，针对第一类 输入为(xi,y~i1), 针对第二类输入为(xi,y~i2)针对第三类输入为(xi,y~i3)，继续训练出三颗树。</p><p>重复3直到迭代M轮，就得到了最后的模型。预测的时候只要找出概率最高的即为对应的类别。和上面的回归问题是大同小异的。</p><h2 id="3-XGBoost"><a href="#3-XGBoost" class="headerlink" title="3 XGBoost"></a>3 XGBoost</h2><p>所有的机器学习的过程都是一个搜索假设空间的过程，我们的模型就是在空间中搜索一组参数（这组参数组成一个模型），使得和目标最接近（损失函数或目标函数最小），通过不断迭代的方式，不断的接近学习到真实的空间分布。</p><p>得到这样一个分布或者映射关系后，对空间里的未知样本或者新样本就可以做出预测/推理。这也解释了为什么一般样本越多模型效果越好，（大数定律）</p><p><strong>有多少人工就有多少智能！</strong></p><p>真实的样本空间是有噪声的，所以学习准确率不可能百分之百。（贝叶斯上限）</p><h3 id="3-1-模型函数形式"><a href="#3-1-模型函数形式" class="headerlink" title="3.1 模型函数形式"></a>3.1 模型函数形式</h3><p>给定数据集$\mathcal D = { (x_i, y_i) }$，XGBoost进行 additive training，学习 K 颗树，采用以下函数对样本进行预测：</p><script type="math/tex; mode=display">\hat y_i = \phi (x_i) = \sum_{k=1}^K f_k (x_i), f_k \in \mathcal F</script><p>这里 $\mathcal F$ 是假设空间， $f(x)$ 是回归树（CART）：</p><script type="math/tex; mode=display">\mathcal F = \{ f(x) = w_{q(x)} \} (q:\mathbb R^m \rightarrow T, w \rightarrow \mathbb R^T)</script><p>$q(x)$ 表示将样本 x 分到了某个叶子结点上， w 是叶子结点的分数(leaf score)， 所以 $w_{q(x)}$ 表示回归树对样本的预测值。</p><h3 id="3-2-目标函数"><a href="#3-2-目标函数" class="headerlink" title="3.2 目标函数"></a>3.2 目标函数</h3><p>参数空间中的目标函数：</p><script type="math/tex; mode=display">Obj(\Theta) = L(\Theta) + \Omega (\Theta)</script><ul><li>$L(\Theta)$是误差函数，衡量模型拟合数据的程度；</li><li>$\Omega (\Theta)$ 是正则化项，用来惩罚复杂模型的。</li></ul><p>误差函数可以是 square loss， log loss 等，正则项可以是 L1 正则项，L2 正则等。</p><ul><li>Ridge Regression （岭回归）： $\sum_{i=1}^n (y_i - \theta^T x_i)^2 + \lambda ||\theta||^2$</li><li>LASSO：$\sum_{i=1}^n (y_i - \theta^T x_i)^2 + \lambda ||\theta||_1$</li></ul><h3 id="3-3-正则项"><a href="#3-3-正则项" class="headerlink" title="3.3 正则项"></a>3.3 正则项</h3><p>正则项的作用，可以从几个角度去解释：</p><ul><li>通过偏差方差分解去解释</li><li>PAC-learning 泛化界解释</li><li>Bayes 先验解释，把正则当成先验</li></ul><p>从 Bayes 角度来看，正则相当于对模型参数引入先验分布：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis4.PNG" alt="XGBoostDetailAnalysis4"></p><ul><li>L2 正则中，模型参数服从搞死分布 $\theta ~ N(0,\sigma^2)$， 对参数加了分布约束，大部分绝对值很小；</li><li>L1 正则中， 模型参数服从拉普拉斯分布， 对参数加了分布约束，大部分取值为0。</li></ul><h3 id="3-4-XGBoost-的目标函数"><a href="#3-4-XGBoost-的目标函数" class="headerlink" title="3.4 XGBoost 的目标函数"></a>3.4 XGBoost 的目标函数</h3><h4 id="正则项"><a href="#正则项" class="headerlink" title="正则项"></a>正则项</h4><p>XGBoost的目标函数（函数空间）：</p><script type="math/tex; mode=display">\mathcal L(\phi) = \sum_i l(\hat y_i, y_i) + \sum_k \Omega (f_k)</script><p>其中正则项对每棵树的复杂度进行了惩罚。</p><p>相比原始的 GBDT， XGBoost 的目标函数多了正则项， 是的学习出来的模型更加不容易过拟合。</p><p>有哪些指标可以衡量树的复杂度？<br><strong>树的深度，内部节点个数，叶子节点个数（T）， 叶子节点分数（w）…</strong></p><p>XGBoost采用的是：</p><script type="math/tex; mode=display">\Omega (f) = \gamma T + \frac{1}{2} \lambda ||w||^2</script><p>对叶子节点个数进行了惩罚， 相当于在训练过程中做了剪枝。</p><p><strong>怎么求最小目标函数？</strong><br>GBDT 是通过求一阶导数，迭代法的方式在函数空间拟合一个最小值。 XGBoost 通过泰勒展开实现了更精确的拟合。</p><h3 id="3-5-误差函数的二阶泰勒展开"><a href="#3-5-误差函数的二阶泰勒展开" class="headerlink" title="3.5 误差函数的二阶泰勒展开"></a>3.5 误差函数的二阶泰勒展开</h3><ul><li><p>第 t 次迭代后， 模型的预测等于前 t-1 次的模型预测加上第 t 颗树的预测：</p><script type="math/tex; mode=display">\hat y_i^{(t)} = \hat y_i^{(t-1)} + f_t (x_i)</script></li><li><p>此时目标函数可写作：</p><script type="math/tex; mode=display">\mathcal L ^{(t)} = \sum_{i=1}^n l(y_i, \hat y_i^{(t-1)} + f_t(x_i)) + \Omega (f_t)</script><p>公式中 $y_i, \tilde y_i^{(t-1)}$都已知， 模型要学习的只有第 t 颗树$f_t$</p></li><li><p>将误差函数在 $\tilde y_i^{(t-1)}$ 处二阶泰勒展开：</p><script type="math/tex; mode=display">\mathcal L^{(t)} \simeq \sum_{i=1}^n [l(y_i, \hat y^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2 (x_i)] + \Omega (f_t)</script></li></ul><p>公式中，$g<em>i = \partial</em>{\hat y^{(t-1)} } l(y<em>i, \hat y^{(t-1)}), h_i = \partial</em>{\hat y^{(t-1)} }^2 l(y_i, \hat y^{(t-1)})$</p><ul><li><p>将公式中的常数项去掉，得到：</p><script type="math/tex; mode=display">\mathcal{\tilde L^{(t)} } = \sum_{i=1}^n [ g_i f_t(x_i) + \frac{1}{2} h_i f_t^2 (x_i)] + \Omega (f_t)</script></li><li><p>把 $f_t, \Omega(f_t)$ 写成树结构的形式， 即把下式带入目标函数中：</p><script type="math/tex; mode=display">f(x) = w_{q(x)}, \Omega (f) = \gamma T + \frac{1}{2} \lambda ||w||^2</script></li></ul><p>得到：</p><script type="math/tex; mode=display">\mathcal{\tilde L^{(t)} } = \sum_{i=1}^n [ g_i f_t(x_i) + \frac{1}{2} h_i f_t^2 (x_i)] + \Omega (f_t) \\= \sum_{i=1}^n [g_i w_{q(x_i)} + \frac{1}{2} h_i w_{q(x_i)}^2] + \gamma T + \lambda \frac{1}{2} \sum_{j=1}^T w_j^2</script><ul><li><p>$\sum<em>{i=1}^n [g_i w</em>{q(x<em>i)} + \frac{1}{2} h_i w</em>{q(x<em>i)}^2]%=$ 是对样本的累加， $\frac{1}{2} \sum</em>{j=1}^T w_j^2$ 是对叶节点的累加。</p></li><li><p>如何统一呢？定义每个叶节点 j 上的样本集合为 $I_j = { i | q(x_i) = j }$，则目标函数可以写成按叶节点累加的形式：</p><script type="math/tex; mode=display">\mathcal{\tilde L^{(t)} } = \sum_{j=1}^T[(\sum_{i \in I_j} g_i) w_j + \frac{1}{2} (\sum_{i \in I_j} h_i + \lambda ) w_j^2] + \gamma T \\= \sum_{j=1}^T[G_j w_j + \frac{1}{2}（H_j + \lambda ) w_j^2] + \gamma T</script></li><li><p>如果确定了树的结构（即 $q(x)$ 确定了）， 为了使目标函数最小，可以令其导数为0， 解得每个叶节点的最优预测分数为：</p><script type="math/tex; mode=display">w_j^* = - \frac{G_j}{H_j + \lambda}</script></li></ul><p>带入目标函数，得到最小损失为：</p><script type="math/tex; mode=display">\mathcal{\tilde L^*} = -\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j + \lambda} + \gamma T</script><h3 id="3-6-回归树的学习策略"><a href="#3-6-回归树的学习策略" class="headerlink" title="3.6 回归树的学习策略"></a>3.6 回归树的学习策略</h3><p>当回归树的结构确定时，我们前面已经退到出其最优的叶节点分数以及对应的最小损失值，问题是怎么确定树的结构？</p><ul><li>暴力枚举所有可能的树结构，选择损失值最小的 - NP 难问题</li><li>贪心法， 每次尝试分裂一个叶节点，计算分裂前后的增益，选择增益最大的。</li></ul><p><strong>分裂前后的增益怎么计算呢？</strong></p><ul><li>ID3 算法采用信息增益</li><li>C4.5 算法采用信息增益比</li><li>CART 采用 Gini 系数</li><li>XGB 不一致</li></ul><h3 id="3-7-XGBoost-的打分函数"><a href="#3-7-XGBoost-的打分函数" class="headerlink" title="3.7 XGBoost 的打分函数"></a>3.7 XGBoost 的打分函数</h3><script type="math/tex; mode=display">\mathcal{\tilde L^*} = - \frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j + \lambda} + \gamma T</script><p>标红部分衡量了每个叶子节点对总体损失的贡献， 我们希望损失越小越好， 则标红部分的值越大越好。</p><p>因此， 对一个叶子结点进行分裂，分裂前后的增益定义为：</p><script type="math/tex; mode=display">Gain = \frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R+ \lambda} - \gamma</script><p>Gain 值越大，分裂后 L 减小越多。所以当对一个叶节点分割时，计算所有候选（feature, value）对应的 gain， 选取 gain 最大的进行分割。</p><p>这个公式跟我们之前遇到的信息增益或基尼值增量的公式是一个道理。XGBoost 就是利用这个公式计算出的值作为分裂条件。<br><strong>分裂后左边增益+右边增益-分类前增益</strong><br>也就是“最大损失减小值”的原则来选择。</p><h3 id="3-8-树节点分裂算法"><a href="#3-8-树节点分裂算法" class="headerlink" title="3.8 树节点分裂算法"></a>3.8 树节点分裂算法</h3><ul><li>近似算法距离：三分位数</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis5.PNG" alt="XGBoostDetailAnalysis5"></p><p>如上图所示，</p><script type="math/tex; mode=display">Gain = max\{ Gain, \frac{G_1^2}{H_1 + \lambda} + \frac{G_{23}^2}{H_{23} + \lambda} - \frac{G_{123}^2}{H_{123} + \lambda} - \gamma, \\\frac{G_{12}^2}{H_{12} + \lambda} + \frac{G_3^2}{H_3 + \lambda} - \frac{G_{123}^2}{H_{123} + \lambda} - \gamma\}</script><ul><li>实际上 XGBoost 不是简单按照样本个数进行分位， 而是以二阶导数值作为权重（Weighted Quantile Sketch）， 比如：</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis6.PNG" alt="XGBoost-Detail-Analysis6.png"></p><ul><li>为什么用 $h_i$ 加权，就是把目标函数整理成以下形式，可以看出 $h_i$ 有对 loss 加权的作用。</li></ul><script type="math/tex; mode=display">\sum_{i=1}^n \frac{1}{2} h_i (f_t(x_i)) - g_i/h_i)^2 + \Omega (f_t) + constant</script><h3 id="3-9-稀疏值处理"><a href="#3-9-稀疏值处理" class="headerlink" title="3.9 稀疏值处理"></a>3.9 稀疏值处理</h3><ul><li>稀疏值：缺失导致，诸如类别类 one-hot 编码会导致大量 0 值出现。</li><li>当特征出现缺失值的时候 XGBoost 可以学习出默认的节点分裂方向，如下图算法所示：</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis7.png" alt="XGBoostDetailAnalysis7"></p><p><strong>不会对该特征为missing的样本进行遍历统计，只对该列特征值为 non-missing 的样本上对应的特征值进行遍历</strong></p><h4 id="最后一步："><a href="#最后一步：" class="headerlink" title="最后一步："></a>最后一步：</h4><p>通过上述算法经过T此迭代我们得到T+1个弱学习器，${ F(x)_0,F(x)_1,F(x)_2, \cdots }$<br>那么通什么样的形式将他们迭代起来呢？答案是直接将 T+1个 模型相加，只不过为了防止过拟合，XGBoost 也采用了 shrinkage 方法来降低过拟合的风险，其模型集成形式如下：</p><script type="math/tex; mode=display">F_m(X) = F_{m-1}(X) + \eta f_m(X), 0< \eta \leq 1</script><p>Shrinkage论文提到：关于 n 和迭代次数 T 的取值，可以通过交叉验证得到合适的值，通常针对不同问题，其具体值是不同的。一般来说，当条条件允许时（如对模型训练时间没有要求等）可以设置一个较大的迭代次数 T ，然后针对该 T 值利用交叉验证来确定一个合适的 n 值。但 n 的取值也不能太小，否则模型达不到较好的效果.</p><h2 id="4-更多特性"><a href="#4-更多特性" class="headerlink" title="4 更多特性"></a>4 更多特性</h2><h3 id="4-1-XGBoost-的其他特性"><a href="#4-1-XGBoost-的其他特性" class="headerlink" title="4.1 XGBoost 的其他特性"></a>4.1 XGBoost 的其他特性</h3><ul><li>行抽样（row sample）</li><li>列抽样（column sample），借鉴随机森林</li><li>Shrinkage（缩减）， 即学习速率<br>将学习速率调小，迭代次数增多，有正则化作用</li><li>支持自定义损失函数（需二阶可导）</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis8.png" alt="XGBoostDetailAnalysis8"></p><h3 id="4-2-XGBoost-的系统设计"><a href="#4-2-XGBoost-的系统设计" class="headerlink" title="4.2 XGBoost 的系统设计"></a>4.2 XGBoost 的系统设计</h3><ul><li>Column Block</li></ul><ol><li>特征预排序，以 column block 的结构存于内存中</li><li>存储样本索引（instance indices）</li><li>block 中的数据以稀疏格式（CSC）存储</li></ol><p>这个结构加速了 split finding 的过程， 只需要在建树前排序一次，后面节点分裂时直接根据索引得到梯度信息</p><ul><li>Cache Aware Access</li></ul><ol><li>column block 按特征大小顺序存储， 相应的样本的梯度信息是分散的，造成内存的不连续访问，降低 CPU cache 命中率</li><li>缓存优化方法<ul><li>预取数据到buffer 中（非连续-&gt;连续）， 在统计梯度信息</li><li>调节块的大小</li></ul></li></ol><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis9.png" alt="XGBoostDetailAnalysis9"></p><h3 id="4-3-更高效的工具包-LightGBM"><a href="#4-3-更高效的工具包-LightGBM" class="headerlink" title="4.3 更高效的工具包 LightGBM"></a>4.3 更高效的工具包 LightGBM</h3><ul><li><p>速度更快<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis10.png" alt="XGBoostDetailAnalysis10"></p></li><li><p>内存占用更低<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/XGBoostDetailAnalysis11.png" alt="XGBoostDetailAnalysis11"></p></li><li><p>准确率更高（优势不明显， 与 XGBoost 相当）<br><em>在微软的论文中说是改动很大，实际应用中没有那么明显，可能与数据集有关系</em></p></li></ul><p><strong>主要改进：直方图优化，进一步并行优化。</strong></p><h3 id="4-4-XGBoost-的参数意义与调优："><a href="#4-4-XGBoost-的参数意义与调优：" class="headerlink" title="4.4 XGBoost 的参数意义与调优："></a>4.4 XGBoost 的参数意义与调优：</h3><p>1）Booster: 分类器类型<br>2）lambda: 正则化<br>3）min_child_weight:子节点权重<br>4）树的深度<br>4）学习率n<br>……</p><h2 id="XGBoost总结："><a href="#XGBoost总结：" class="headerlink" title="XGBoost总结："></a>XGBoost总结：</h2><ol><li>损失函数是用泰勒展式二项逼近，而不是像GBDT里的就是一阶导数；</li><li>对树的结构进行了正则化约束，防止模型过度复杂，降低了过拟合的可能性；</li><li>实现了并行化（树节点分裂的时候）</li><li>开头提到的优化</li><li>回归模型可选</li></ol><p><strong>参考文章</strong></p><ol><li><a href="https://blog.csdn.net/meihao5/article/details/83788525">xgboost原理详解-meihao5</a></li><li><a href="http://delivery.acm.org/10.1145/2940000/2939785/p785-chen.pdf?ip=61.152.150.141&amp;id=2939785&amp;acc=CHORUS&amp;key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&amp;__acm__=1576504271_55fd2b06af4e72ca559df3a74156a91f">XGBoost- A Scalable Tree Boosting System</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;原文来自大神级的论文&lt;a href=&quot;https://netman.aiops.org/~peidan/ANM2018/3.MachineLearningBasics/LectureCoverage/18.xgboost.pdf&quot;&gt;XGBoost: A Scalable Tree Boosting System&lt;/a&gt;，论文很全面，框架介绍很完整，但是在某些tricks上面并没有对细节做详细解说，而需要读者亲自去进行一定的推导，这使得阅读起来稍显吃力，当然基础很雄厚的大牛级别的应该不以为然，但我相信还有很多与我一样入行不久的，那么这篇博客就是你的所需。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里特别感谢作者&lt;code&gt;meihao5&lt;/code&gt;的博文，其分享的内容就是我一直想要整理但迟迟未进行的，它的原文可见最后面的参考文章链接里。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-基础知识&quot;&gt;&lt;a href=&quot;#1-基础知识&quot; class=&quot;headerlink&quot; title=&quot;1 基础知识&quot;&gt;&lt;/a&gt;1 基础知识&lt;/h2&gt;&lt;p&gt;XGBoost的成功可以总结为回归（树回归+线性回归）+提升（boosting）+优化（5个方面）牛顿法、预排序、加权分位数、稀疏矩阵识别以及缓存识别等技术来大大提高了算法的性能。下面开始介绍一些入门必须的基础知识：&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="XGBoost" scheme="https://www.xiemingzhao.com/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>DeepFM A Factorization-Machine based Neural Network for CTR Prediction (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/4bbfbe93.html"/>
    <id>https://www.xiemingzhao.com/posts/4bbfbe93.html</id>
    <published>2019-06-28T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.653Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1703.04247.pdf">原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction</a></p><h2 id="DeepFM-基于神经网络的因式分解机做点击率预估"><a href="#DeepFM-基于神经网络的因式分解机做点击率预估" class="headerlink" title="DeepFM:基于神经网络的因式分解机做点击率预估"></a>DeepFM:基于神经网络的因式分解机做点击率预估</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。</p><span id="more"></span><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a><strong>1 介绍</strong></h3><p>点击率(CTR)预测对于推荐系统是至关重要的，它是估计用户对某个商业项目进行点击的概率。大部分的推荐系统的目标是最大化点击次数，所以返回给用户的项目可以按照估计出的CTR进行排序；然而对于其他的高级应用例如在线广告，提升CTR可以增加企业的收入，所以总体上来说，排序的策略可以调整为CTR*bid，这里的bid是指用户每次点击给系统产生的收益。但是不管怎样，不断提升CTR可以创造更多的收益。不论什么情况，可以明确地是准确地预测CTR是最关键的。</p><p>通过用户的点击行为序列学习到背后潜在的特征交叉项对于CTR预测是特别重要的。根据我们在主流的app商店的研究，发现用户常常在用餐时间下载外卖类app，这就是一种二阶的交互信息：app应用类别和时间，这类的二阶交互信息可以用以CTR预估。再比如，男性青少年偏爱射击类和角色扮演游戏，这表明了这个三阶的交叉项：包含了性别，年龄和app的应用类别，也是有助于CTR。总的来说，这些用户行为背后的特征交互是非常复杂的，这里的低阶和高阶的特征交叉项都有着特别重要的作用。2016年谷歌的Wide &amp; Deep model系统基于低阶和高阶特征的交互信息在整体上都带来了额外的性能提升。</p><p>建模的核心挑战在于特征之间的交互信息。一些容易理解的特征交叉项可以有专业的人设计出来（例如上述举例的）。然而，大多数的特征交互项是隐藏于数据背后且难以利用先验知识发现的（例如啤酒与尿布的案例，是通过通过数据的而不是专家发现的），这种是仅可以通过机器学习字段捕获的。基于对于一些易理解的交互项来说，它们看上去也不像转接能够构造出来的，特别是在特征数量特别庞大的时候。</p><p>尽管普通的线性模型特别的简单，例如FTRL，但是在实际应用中却展示了相当好的效果。然而，线性模型缺少学习特征交叉项的能力，所以一般是在后期手动方式添加特征之间的交互项。这样的方法不仅难以泛化到高阶特征，也难以应付训练集中较少或者尚未出现的特征。2010年提出的因子分解机(FM)可以解决这个问题，FM是通过隐向量的内积表现特征之间的交叉项。尽管原则上FM可以构建高阶的特征交叉项，但是在实际中考虑到构建特征之间更高阶的关系会更加复杂，所以一般只采用2阶。</p><p>深度学习在特征表示上是一个很强大的算法，所以在学习复杂的特征交叉项上也具有很大潜力。所以就扩展出了一些想法，例如用CNN和RNN来做CTR预估。但是基于CNN的模型只能处理相邻特征，而基于RNN的模型由于天然的序列依赖特性更适于CTR领域。2016年有学者提出了Factorization-machine supported Neural Network (FNN)，该模型用FM进行预训练，再输入到DNN，因此这也使得模型受限于FM。Qu等人于2016年提出Product-based Neural Network (PNN)在嵌入层和全连接层之间引入一个product 层来表示特征之间的相互作用。其实FNN和PNN都仅仅能够表达低阶的特征间相互作用，且程度有限。为了能够同时表达低阶和高阶的特征信息，cheng等人于2016年提出一个混合网络结构：Wide &amp; Deep模型，该模型融合了一个线性模型（wide）和深度学习模型。在这个模型中，两个部分wide part和deep part分别需要两个不同的输入，其中wide part需要依赖专家的特征工程。</p><p>可以看出现有模型偏向于低或高阶特征交互，或依赖于特征工程。在本文，我们证明了可以构建一个学习模型，它是可以通过端到端的方式学习到所有阶数的特征交叉项，而除了原始的特征不需要任何额外的特征工程我们的主要贡献总结如下：</p><ul><li>我们提出了一个新的神经网络模型DeepFM，它是结合了FM和深度神经网络（DNN）的结构。它既可以像FM一样构建低阶的特征交叉项也可以像DNN一样拟合高阶的特特征交叉项。而不像Wide &amp; Deep模型，DeepFM可以在无需任何特征工程的条件下进行端到端的训练。</li><li>我们对DeepFM在基础数据集和商业数据集上都进行了评估，结果表明了它相对于目前已存在的CTR预估模型有一致性的提升效果。</li></ul><h3 id="2-我们的方法"><a href="#2-我们的方法" class="headerlink" title="2 我们的方法"></a><strong>2 我们的方法</strong></h3><p>假设数据的训练集包含n个样本$(\mathcal{X},y)$，其中$\mathcal{X}$是一个包含m个特征域的数据集，一版记录了相关的用户和物品对，并且$y \in (0,1)$对应的标签标示用户的点击行为（1表示用户点击了物品，否则为0）。$\mathcal{X}$可能会包含类别型特征（例如性别，位置）和连续型特征（例如年龄）。每个类别型特征都会被表示成一个one-hot编码的向量，每个连续型特征都会用它自己的值表示，或者在进行离散后也表示成一个one-hot编码的向量。然后，每个样本都会被转换成$(x,y)$，其中$x = [x<em>{field_1},x</em>{field<em>2},\cdots, x</em>{field<em>j},\cdots,x</em>{field<em>m}]$是一个d维的向量，$x</em>{field_1}$是$\mathcal{X}$中第j个特征的向量表示。一般的，x是一个高维且极度稀疏的向量。CTR预估的任务就是构建一个预测模型$\hat y = CTR_model(x)$来预估在给定上下文的条件下一个用户点击某个app的概率。</p><h4 id="2-1-DeepFM"><a href="#2-1-DeepFM" class="headerlink" title="2.1 DeepFM"></a><strong>2.1 DeepFM</strong></h4><p>我们的目标是学习高阶和低阶的特征交叉项。为了做到这个，我们提出了基于神经网络的因式分解机（DeepFM）。如图1所示，DeepFM由两部分组成，<em>FM部分和deep部分</em>，二者共享同一输入层。对于特征i，一个标量$w_i$作为权重来表示其一阶的重要性，一个潜在的向量$V_i$用来衡量它与其他特征的交叉项的重要性。$V_i$被喂入FM部分取构建2阶的特征交叉项，同时也被喂入深度部分取构建高阶的特征交叉项。所有的参数，包括$w_i，V_i$和网络参数$(W^{(l)},b^{(l)})$都在合并的模型中进行联合训练的：</p><script type="math/tex; mode=display">\hat y = sigmoid(y_{FM}+y_{DNN})</script><p>其中，$\hat y \in (0,1)$是预测的CTR，$y<em>{FM}$是FM部分的输出结果，$y</em>{DNN}$是深度部分的输出结果。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-1.JPG" alt="DeepFM-1.jpg"></p><p><strong>FM部分</strong><br>FM部分是一个因式分解机，它是在[Rendle,2010]中提出来用在推荐中学习特征交叉项的。除了线性的（一阶）特征交叉项，FM还利用特征间的隐向量的内积构建了成对的（二阶）特征交叉项。相比于以前的方法，特别是在数据集很稀疏的时候它可以更有效地捕获到二阶特征交叉项。在以前的算法中，特征i和j组成的交叉项的参数只能在某一数据记录同时出现特征i和j的时候才能得到训练。而在FM模型中，它们会通过它们的隐含向量$V_i和V_j$的内积计算得到。得益于这种灵活的设计，无论i（或j）何时出现在数据记录中FM模型都能够训练隐含向量$V_i(V_j)$。因此，那些从不或者很少出现在训练数据中的特征交叉项可以有FM模型很好的学习到。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-2.JPG" alt="DeepFM-2.jpg"></p><p>如图2所示，FM的输出是由一个累加单元加上一系列内几单元组成的：</p><script type="math/tex; mode=display">y_{FM} = <w,x> + \sum_{j_1 = 1}^d \sum_{j_2 = j_1 + 1}^d <V_i,V_j> x_{j_1} \cdot x_{j_2}</script><p>其中$w \in R^d 和 V_i \in R^k$（k是给定的）。累加单元$(<w,x>)$反映了一阶特征的重要性，内积单元代表了二阶特征交叉项的影响。</p><p><strong>Deep部分</strong><br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-3.JPG" alt="DeepFM-3.jpg"></p><p>深度部分是一个前馈神经网络，通常是来学习高阶特征交叉项的。如图3所示，一条数据记录（一个向量）被喂入神经网络。相比于输入数据是图片或者音频的神经网络，即输入数据是连续且密集的，CTR预估模型的输入数据则大不相同，它要求一个新设计的网络结构。特别地，CTR预估的原始特征输入向量一般都是高度稀疏的、超高维度的、类别型和连续型混合的并且聚合到特征域的（例如性别，位置，年龄）。这表明嵌入层是在将数据输入到第一层隐含层之前将输入向量压缩到了一个低维且密集的实值向量，否则网路将无法进行训练。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-4.JPG" alt="DeepFM-4.jpg"></p><p>图4提取了输入层到嵌入层的子网络结构。我们能够之处这个网络结构中的两个有趣的特点：1）尽管不同输入特征域向量的长度不同，但是它们 的嵌入向量确实相同大小(k)的；2）FM中的隐含特征向量（V）是作为网络的权重，它们是学习到的用来将输入特征向量压缩成嵌入向量的。在论文[Zhang tw al., 2016]，V是由FM提前训练好的值来作为初始化的。在这里，不是使用FM的隐含特征向量来初始化网络，而是除了DNN模型外，我们是将FM模型作为我们整体学习框架中的一部分。如此，我们就不需要通过FM来提前训练了，相反我们是将整体的网络结构以端到端的方式来进行联合训练。将嵌入层的输出表示成：</p><script type="math/tex; mode=display">a^{(0)} = [e_1,e_2,...,e_m]</script><p>其中$e_i$是第i个特征的嵌入，m是特征的个数。然后，$a^{(0)}$是喂入到深度神经网络的，并且前向的过程是：</p><script type="math/tex; mode=display">a^{(l+1)} = \sigma(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是网络的层数，$\sigma$是激活函数。$W^{(l)},a^{(l)}, b^{(l)}$分别是输出，模型权重和第l层的偏置项。之后，一个密集的实值特征向量就产生了，这最终会输入到CTR预估模型的sigmiod激活函数中去：$y_{DNN} = \sigma(W^{|H|+1} \cdot a^H + b^{|H|+1})$，其中$|H|$是隐含层的数量。</p><p>值得指出的是FM部分和deep部分共享同一特征嵌入层，这就带来了两个好处：1）可以从原始特征中同时学习了低阶和高阶的特征交叉项；2）不需要像Wide &amp; Deep一样在输入层上做专门的特征工程。</p><h4 id="2-2-与其他神经网络之间的关系"><a href="#2-2-与其他神经网络之间的关系" class="headerlink" title="2.2 与其他神经网络之间的关系"></a><strong>2.2 与其他神经网络之间的关系</strong></h4><p>受到深度学习在多种应用中取得巨大成功的影响，最近很多用来做CTR预估的深度模型被开发出来。这一部分将我们提出的DeepFM与其他现存的CTR预估深度模型进行比较。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-5.JPG" alt="DeepFM-5.jpg"></p><p><strong>FNN</strong>：如图5左侧所示，FNN是一个FM初始化的前馈神经网络模型[Zhang et al., 2016]。FM预训练的方法导致了两个限制：1）嵌入层的参数会由FM完全决定；2）引入的预训练步骤会使得模型的有效性降低。此外，FNN仅能捕获高阶的特征交叉项。相反，DeepFM不需预训练并且能够学习到高阶和低阶的特征交叉项。</p><p><strong>PNN</strong>：为了抓取高阶的特征交叉项，PNN在嵌入层和第一层隐含层之间强加了一个乘积层[Qu et al., 2016]。根据乘积运算的不同类型，又有三种不同的模型：IPNN,OPNN和PNN<em>，其中IPNN是基于向量内积的，OPNN是基于外积的，PNN</em>是基于内积和外积一起的。</p><p>为了使得计算更加有效，作者提出了一个内积和外积的近似计算：1）内积可以通过消除某些神经元来近似计算；2）外积可以通过将m个k维的特征向量压缩成一个k维的向量来近似计算。然而，我们发现外积相对于内积不太可靠，这是因为外积的这种近似计算会丢失很多信息使得结果不稳定。尽管内积相对比较可靠，它仍然需要很高的计算复杂度，因为乘积层的输出是与第一层隐含层所有的神经单元相连的。不同于PNN，DeepFM中的乘积层的输出仅与最终的输出层（一个神经元）相连。例如FNN，所有的PNN都忽略低阶特征交叉项。</p><p><strong>Wide &amp; Deep</strong>：Wide &amp; Deep（图5右侧所示）是由谷歌提出的来同时构建低阶和高阶特征交叉项的。如论文[Cheng te al., 2016]所示，它在“宽”部分部分的输入时需要专业的特征工程（例如，在app推荐中的用户安装的app和展示的app间的交叉特征）。相反，DeepFM不需要太多大额专业知识来处理输入层就可以直接地从原始特征中学习。</p><p>一个简单地扩展就是用FM替换这个模型中的LR部分（本文的第三部分我们也评估了这一扩展）。这个扩展类似于DeepFM，但是DeepFM在FM和deep部分之间共享了嵌入层。这种特征嵌入层共享的方法通过低阶和高阶特征交叉项影响了（以回传的方式）特征的表达，这就使得其可以更精确的构建特征表达。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-t1.JPG" alt="Deep-FM-t1.jpg"></p><p><strong>总结</strong>：综上所述，DeepFM和其他深度模型之间关系主要是表1中提到的4个方面。如我们所见，DeepFM是一个不需要预训练和特征工程的模型，并且能够抓取低阶和高阶的特征交叉项。</p><h3 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a><strong>3 实验</strong></h3><p><strong>数据集</strong><br>我们基于以下两个数据集来评估我们提出的DeepFM模型的效果和效率：</p><p><strong>1) Criteo Dataset</strong>：Criteo Dataset包含4500万的用户点击记录，有13个连续型特征和26个类别型特征。我们将数据集随机得分为两部分：90%用来作为训练集，剩下的10%作为测试集。</p><p><strong>2)Company Dataset</strong>：为了验证DeepFM模型在真实的工业CTR预估中的表现，我们在Company Dataset数据集上进行了实验。我们从Company App Store的游戏中心收集了连续7天的的用户点击记录数据作为训练集，下一天的数据作为测试集。全部收集的数据集大概有10亿条记录。在这个数据集中，有应用的特征（例如名称和类型等等），用户特征（例如用户下载的应用等等），上下文特征（例如操作时间等等）。</p><p><strong>评估指标</strong><br>在我们的实验中主要使用两个评价指标：<strong>AUC</strong>和<strong>Logloss</strong>。</p><p><strong>模型比较</strong><br>我们在实验中比较了9个模型：<strong>LR, FM, FNN, PNN (三种变体), Wide &amp; Deep, 和 DeepFM.</strong>在Wide &amp; Deep模型中，为了消除特征工程的工作量，我们将原始的 Wide &amp; Deep 模型中宽部分的LR用FM来代替。为了区别 Wide &amp; Deep 的这两种变体模型，我们分别把它们命名为 LR &amp; DNN 和 FM &amp; DNN。</p><p><strong>参数设定</strong><br>为了在Criteo dataset数据集上评估模型，我们追随[Qu et al., 2016]中的FNN和PNN的参数设定：(1)dropout:0.5;(2)网络结构：400-400-400；（3）优化器：Adam；（4）激活函数：IPNN用tanh，其他的深度模型用relu。为了公平，我们的DeepFM模型使用同样的设定。LR和FM的优化器分别是FTRL和Adam，并且FM隐含的维度是10.</p><p>为了在公司的数据集上获得每个模型最好的效果，我们仔细地进行参数学习，会在3.3部分详细讨论。</p><h4 id="3-2-效果评估"><a href="#3-2-效果评估" class="headerlink" title="3.2 效果评估"></a><strong>3.2 效果评估</strong></h4><p>在这一部分，我们会评估3.1部分列出的模型，并且在两个数据集上对比它们的效果和效率。</p><p><strong>效率对比</strong><br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-6.JPG" alt="DeepFM-6.jpg"></p><p>深度学习模型的销量在现实世界中是非常重要的。我们通过以下公式对比了各个模型在Criteo数据集上的效率表现：$\frac{|training time of deep CTR model|}{|training time of LR|}$。结果如图6所示，包含了在CPU（左侧）和GPU（右侧）上的测试结果，我们观察到了以下结果：1）FNN的预训练使其变得不是很有效率；2）尽管IPNN 和 PNN*在GPU上的表现要好于其他模型，但由于内积计算的操作使得他们仍然具有很高的计算成本；3）DeepFM几乎在所有的测试中表现地最有效率。</p><p><strong>效果对比</strong><br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-t2.JPG" alt="Deep-FM-t2.jpg"></p><p>不同CTR预估模型在Criteo和Company*的数据集上的表现如表2所示，我们可以得到如下观察结果：</p><ul><li>学习特征交叉项能够提升CTR预估模型的效果。这一发现实际上是来自于LR（它是唯一一个没有考虑特征交叉的模型）的表现要差于其他模型。对于Company* 和 Criteo数据集来说，DeepFM作为最好的模型其表现在AUC上要比LR分别高出0.86%和4.18%。</li><li>同时学习高阶和低阶的特征交叉项能够提高CTR预估模型的表现。DeepFM 模型的表现要好于那些仅仅学习低阶特征交叉项（例如FM）或者高阶特征交叉项（例如FNN, IPNN, OPNN, PNN*）的模型。相比于第二好的模型，DeepFM 在两个数据集上的AUC分别提升了0.37%和0.25%（Logloss 分别提升了0.42% 和0.29%）。</li><li>同时学习高阶和低阶的特征交叉项的时候，还共享特征的嵌入能够提高CTR预估模型的表现。DeepFM 的表现要好于那些在学习高阶和低阶特征交叉项的时候使用不同的特征嵌入的模型（例如LR &amp; DNN 和 FM &amp; DNN）。相比于这两个模型，在 Company* 和 Criteo 数据集上，DeepFM在AUC上要分别提升0.48%和0.33%（在Logloss上分别提升0.61%和0.66%）。</li></ul><p>总的来说，我们提出的 DeepFM 模型打败了其他的竞争者，在Company* 数据集上的AUC 和 Logloss分别提升了0.37%和0.42%。实际上，离线AUC评估指标的小改进很肯带来在线CTR的显著提升。如[Cheng et al., 2016]中所述，相比于LR，Wide &amp; Deep 将AUC提高了0.275%（离线），在线的CTR提高了3.9%。公司应用商店的每日流量价值百万美元，因此即使是几个百分点的CTR提升也能够带来每年百万美元的额外收入</p><h4 id="3-3-超参数研究"><a href="#3-3-超参数研究" class="headerlink" title="3.3 超参数研究"></a><strong>3.3 超参数研究</strong></h4><p>我们研究了在公司数据集上不同模型的不同超参数的影响力。顺序是：1）激活函数；2）dropout率；3）每层神经元个数；4）隐含层的层数；5）网络形状。</p><p><strong>激活函数</strong><br>根据[Qu et al., 2016]所述，在深度模型中<em>relu</em>和<em>tanh</em>是比<em>sigmoid</em>更适合的。再本文中，我们对比了深度模型在使用relu和tanh的效果。如图7所示，除了IPNN外，在所有的深度模型中relu都比tanh更加合适。可能的原因是relu降低了稀疏性。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-7.JPG" alt="DeepFM-7.jpg"></p><p><strong>Dropout</strong><br>Dropout[Srivastava et al., 2014]是网络中一个神经元保留下来的概率。Dropout 是一种用来折中神经网络的准确度和复杂度的正则技术。我们分别尝试了dropout在1.0,0.9,0.8,0.7,0.6,0.5下的效果。如图8所示，所有的模型当它们的dropout提前设定好的时候（0.6到0.9）都取得了它们最好的表现。结果表明往模型中加入一些合理的随机性能够增强模型的稳健性。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-8.JPG" alt="DeepFM-8.jpg"></p><p><strong>每层的神经网络个数</strong><br>当其他因素保持一致的时候，增加每一层的神经元个数会引入更高的复杂度。正如我们从图9可以观察到的，增加每一层的神经元个数并不总是能够带来收益。例如，当每一层神经元的个数从400增加到800的时候，DeepFM 的表现趋于稳定；更糟的是，当我们把神经元车上从400增加到800的时候OPNN表现反尔变差了。这是因为过度复杂的模型容易造成过拟合。在我们的数据集中，每一层设定200-400神经元是一个不错的选择。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-9.JPG" alt="DeepFM-9.jpg"></p><p><strong>隐含层的个数</strong><br>如图10所呈现的，增加隐含层的个数在一开始能够提高模型的表现，然而，如果层数一直增加他们的表现则会逐渐变差。这种现象一版也是由于过拟合造成的。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-10.JPG" alt="Deep-FM-10.jpg"></p><p><strong>网络形状</strong><br>我们测试了4种网络形状：不变、增长、减小和菱形。当我们改变网络的结构，我们会固定隐含层的个数以及总神经元的个数。例如，当隐含层数量是3且总神经元个数是600的时候，四中网络形状是：不变（200-200-200），增长（100-200-300），减小（300-200-100）和菱形（150-300-150）。正如从图11中可以看到，“不变”的网络形状一般要好于其他三种形状，这也与之前的研究保持了一致性[Larochelle et al., 2009]。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/DeepFM-11.JPG" alt="Deep-FM-11.jpg"></p><h3 id="4-相关工作"><a href="#4-相关工作" class="headerlink" title="4 相关工作"></a><strong>4 相关工作</strong></h3><p>在这篇文章，我们提出了一个新的深度学习网络结构用来做CTR预估。最相关的领域就是推荐系统中的CTR预估和深度学习。在这一部分，我们讨论一下这两个领域的相关工作。</p><p>CTR预估在推荐系统是特别地重要。除了一般的线性模型和FM，还有一些其他的模型会被用来做CTR预估，例如基于树，基于张量的模型，支持向量机，以及贝叶斯模型。</p><p>其他相关的领域就是推荐系统中的深度学习了。在第1部分和第2.2部分，我们已经提到了几个用来做CTR预估的深度学习模型，因此在这里我们不再讨论它们。一些深度模型一般会被用于推荐任务而不是CTR预估。[Salakhutdinov et al., 2007; Sedhain et al., 2015; Wang et al., 2015]提出通过深度学习来改进协同过滤。[Wang andWang, 2014; van den Oord et al., 2013]的作者通过深度学习来提取一些满意的特征用于改进音乐推荐。[Chen et al., 2016]设计了一个深度学习网路用来构建广告展示中的图片特征和基础特征。[Covington et al., 2016]开发了一个两部神经网络框架用来做YouTube的视频推荐。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>在本文中，我们提出了DeepFM模型，是一个基于神经网络的因式分解机用来做CTR预估，克服了当前最先进模型的缺点并获得了一个更好的表现。DeepFM 是联合训练了一个深度部分和FM部分。它是通过以下几个优势获得了更好地表现：1）它不需要任何预训练；2）它能够同时学习高阶和低阶的特征交叉项；3）它引入了一个特征嵌入层共享的策略来避免特征工程。我们在两个实际数据集上进行了大量的实验来比较DeepFM和最先进模型之间的效果和效率。我们的实验结果表名了：1）DeepFM在两个数据集上的AUC和Logloss的表现都要好于最先进的模型；2）DeepFM相比于当下最先进有效的深度模型而言要更有效率。</p><p>在未来的研究中有两个有趣的方向。一个是探索一些策略（例如引入pooling层）来增强学习更有用的高阶特征交叉项。另一个就是在GPU集群上训练DeepFM来解决大规模数据的问题。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.04247.pdf&quot;&gt;原始论文：DeepFM:A Factorization-Machine based Neural Network for CTR Prediction&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;DeepFM-基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;a href=&quot;#DeepFM-基于神经网络的因式分解机做点击率预估&quot; class=&quot;headerlink&quot; title=&quot;DeepFM:基于神经网络的因式分解机做点击率预估&quot;&gt;&lt;/a&gt;DeepFM:基于神经网络的因式分解机做点击率预估&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;对于推荐系统中的最大化CTR来说，学习那些用户行为背后的复杂而精确的特征交叉项是至关重要的。尽管有很大的提升，但是方法似乎在低阶或者高阶的交差项上带有很强的偏置项，又或者会要求专业性的特征工程。在这篇文章，我们会展示可以构造出一个端到端的学习模型，特别是对于低阶和高阶的交叉项的学习。DeepFM，提出的这个模型联合了因式分解机的推荐能力和一个新的神经网络结构在特征方面的深度学习能力。相比于Google提出的最新的Wide &amp;amp; Deep模型，DeepFM的“wide”和“deep”部分有一个共享输入层，并且除了最原始的特征不需要额外的特征工程。综合性的实验结果证明了DeepFM相比于其他的CTR模型在基础数据及和商业数据集上都有着更好的效果和效率。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90/"/>
    
    <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="CTR预估" scheme="https://www.xiemingzhao.com/tags/CTR%E9%A2%84%E4%BC%B0/"/>
    
    <category term="神经网络" scheme="https://www.xiemingzhao.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="DeepFM" scheme="https://www.xiemingzhao.com/tags/DeepFM/"/>
    
  </entry>
  
  <entry>
    <title>LTR(Learning to Rank)概述</title>
    <link href="https://www.xiemingzhao.com/posts/IntroductionofLTR.html"/>
    <id>https://www.xiemingzhao.com/posts/IntroductionofLTR.html</id>
    <published>2019-06-28T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.654Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Learning-to-Rank-简介"><a href="#1-Learning-to-Rank-简介" class="headerlink" title="1 Learning to Rank 简介"></a>1 Learning to Rank 简介</h2><p>Learning to Rank是采用机器学习算法，通过训练模型来解决排序问题，在Information Retrieval，Natural Language Processing，Data Mining等领域有着很多应用。</p><h2 id="1-1-排序问题"><a href="#1-1-排序问题" class="headerlink" title="1.1 排序问题"></a>1.1 排序问题</h2><p>如图 Fig.1 所示，在信息检索中，给定一个query，搜索引擎会召回一系列相关的Documents（通过term匹配，keyword匹配，或者semantic匹配的方法），然后便需要对这些召回的Documents进行排序，最后将Top N的Documents输出,一版可以认为是召回后的精排。而排序问题就是使用一个模型 f(q,d)来对该query下的documents进行排序，这个模型可以是人工设定一些参数的模型，也可以是用机器学习算法自动训练出来的模型。现在第二种方法越来越流行，尤其在Web Search领域，因为在Web Search 中，有很多信息可以用来确定query-doc pair的相关性，而另一方面，由于大量的搜索日志的存在，可以将用户的点击行为日志作为training data，使得通过机器学习自动得到排序模型成为可能。</p><p><strong>需要注意的是，排序问题最关注的是各个Documents之间的相对顺序关系，而不是各个Documents的预测分最准确。</strong></p><span id="more"></span><p>Learning to Rank是监督学习方法，所以会分为training阶段和testing阶段，如图 Fig.2  所示。</p><center class="half">    <img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-1.png" width="400"/><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-2.png" width="400"/></center><h3 id="1-1-1-Training-data的生成"><a href="#1-1-1-Training-data的生成" class="headerlink" title="1.1.1 Training data的生成"></a>1.1.1 Training data的生成</h3><p>对于Learning to Rank，training data是必须的，而feature vector通常都是可以得到的，关键就在于label的获取，而这个label实际上反映了query-doc pair的真实相关程度。通常我们有两种方式可以进行label的获取：</p><ul><li><p>第一种方式是<strong>人工标注</strong>，这种方法被各大搜索引擎公司广为应用。人工标注即对抽样出来作为training data的query-doc pair人为地进行相关程度的判断和标注。一般标注的相关程度分为5档：perfect，excellent，good，fair，bad。例如，query=“Microsoft”，这时候，Microsoft的官网是perfect；介绍Microsoft的wikipedia则是excellent；一篇将Microsoft作为其主要话题的网页则是good；一篇只是提到了Microsoft这个词的网页则是fair，而一篇跟Microsoft毫不相关的网页则是bad。人工标注的方法可以通过多人同时进行，最后以类似投票表决的方式决定一个query-doc pair的相关程度，这样可以相对减少各个人的观点不同带来的误差。</p></li><li><p>第二种方式是<strong>通过搜索日志获取</strong>。搜索日志记录了人们在实际生活中的搜索行为和相应的点击行为，点击行为实际上隐含了query-doc pair的相关性，所以可以被用来作为query-doc pair的相关程度的判断。一种最简单的方法就是利用同一个query下，不同doc的点击数的多少来作为它们相关程度的大小。实际中一般使用行为/曝光来制作target，但是最终还是要将连续型的值进行分桶，否则泛化能力不够。</p></li></ul><p>不过需要注意的是，这里存在着一个很大的陷阱，就是用户的点击行为实际上是存在<strong>“position bias”</strong>的，即用户偏向于点击位置靠前的doc，即便这个doc并不相关或者相关性不高。有很多 tricky的和 general 的方法可以用来去除这个“position bias”，例如，</p><blockquote><ol><li>当位置靠后的doc的点击数都比位置靠前的doc的点击数要高了，那么靠后的doc的相关性肯定要比靠前的doc的相关性大。</li><li>Joachims等人则提出了一系列去除bias的方法，例如 Click &gt; Skip Above, Last Click &gt; Skip Above, Click &gt; Earlier Click, Click &gt; Skip Previous, Click &gt; No Click Next等。</li><li>有个很tricky但是效果很不错的方法，之前我们说一个doc的点击数比另一个doc的点击数多，并不一定说明前者比后者更相关。但如果两者的差距大到一定程度了，即使前者比后者位置靠前，但是两者的点击数相差5-10倍，这时候我们还是愿意相信前者更加相关。当然这个差距的大小需要根据每个场景具体的调整。</li><li>position bias 存在的原因是，永远无法保证在一次搜索行为中，用户能够看到所有的结果，往往只看到前几位的结果。这时候就到了 Click Model大显身手的时候了，一系列的 Click Model 根据用户的点击信息对用户真正看到的doc进行“筛选”，进而能更准确地看出用户到底看到了哪些doc，没有看到哪些doc，一旦这些信息知道了，那么我们就可以根据相对更准确的 点击数/展示数（即展现CTR）来确定各个doc的相关性大小。</li></ol></blockquote><p>上述讲到的两种label获取方法各有利弊。人工标注受限于标注的人的观点，不同的人有不同的看法，而且毕竟标注的人不是真实搜索该query的用户，无法得知其搜索时候的真实意图；另一方面人工标注的方法代价较高且非常耗时。而从搜索日志中获取的方法则受限于用户点击行为的噪声，这在长尾query中更是如此，且有用户点击的query毕竟只是总体query的一个子集，无法获取全部的query下doc的label。</p><h3 id="1-1-2-Feature的生成"><a href="#1-1-2-Feature的生成" class="headerlink" title="1.1.2 Feature的生成"></a>1.1.2 Feature的生成</h3><p>这里只是简单介绍下，后续博客会有更纤细的讲解。</p><p>一般Learning to Rank的模型的feature分为两大类：<strong>relevance 和 importance（hotness）</strong>，即query-doc pair 的相关性feature，和doc本身的热门程度的feature。两者中具有代表性的分别是 BM25 和 PageRank。</p><h3 id="1-1-3-Evaluation"><a href="#1-1-3-Evaluation" class="headerlink" title="1.1.3 Evaluation"></a>1.1.3 Evaluation</h3><p>怎么判断一个排序模型的好坏呢？我们需要有验证的方法和指标。方法简单来说就是，比较模型的输出结果，和真实结果（ground truth）之间的差异大小。<em>用于Information Retrieval的排序衡量指标通常有：NDCG，MAP等。</em></p><p><strong>NDCG（Normalized Discounted Cumulative Gain）：</strong><br>NDCG表示了从第1位doc到第k位doc的“归一化累积折扣信息增益值”。其基本思想是：</p><blockquote><p>1） 每条结果的相关性分等级来衡量<br>2） 考虑结果所在的位置，位置越靠前的则重要程度越高<br>3） 等级高（即好结果）的结果位置越靠前则值应该越高，否则给予惩罚</p></blockquote><script type="math/tex; mode=display">NDCG(k)=G_{max,i}^{-1}(k)\sum_{j:\pi_i(j) \leq k}G(j)D(\pi_i(j))</script><p>其中G表示了这个doc得信息增益大小，一般与该doc的相关程度正相关：</p><script type="math/tex; mode=display">G(j)=2^{y_{i,j}}-1</script><p>D则表示了该doc所在排序位置的折扣大小，一般与位置负相关：</p><script type="math/tex; mode=display">D(\pi_i(j))=\frac{1}{log_2(1+\pi_i(j))}</script><p>而$G_{max}$则表示了归一化系数，是最理想情况下排序的“累积折扣信息增益值”。<br>最后，将每个query下的NDCG值平均后，便可以得到排序模型的总体NDCG大小。</p><p><strong>MAP（Mean Average Precision）</strong>：</p><p>其定义是求每个相关文档检索出后的准确率的平均值（即Average Precision）的算术平均值（Mean）。这里对准确率求了两次平均，因此称为Mean Average Precision。</p><p>在MAP中，对query-doc pair的相关性判断只有两档：1和0。<br>对于一个query，其AP值为：</p><script type="math/tex; mode=display">AP=\frac{\sum_{j=1}^{n_i} P(j) \cdot y_{i,j} }{\sum_{j=1}^{n_i}y_{i,j} }</script><p>$y_{ij}$即每个doc的label（1和0），而每个query-doc pair的P值代表了到dij这个doc所在的位置为止的precision：</p><script type="math/tex; mode=display">P(j)=\frac{\sum_{k:\pi_i(k)\leq \pi_i(j)}y_{i,k} }{\pi_i(j)}</script><p>其中，$\pi<em>i(j)$是$d</em>{ij}$在排序中的位置。</p><h2 id="1-2-Formulation"><a href="#1-2-Formulation" class="headerlink" title="1.2 Formulation"></a>1.2 Formulation</h2><p>用通用的公式来表示Learning to Rank算法，loss function为$L(F(x),y)$，从而risk function（loss function在X，Y联合分布下的期望值）为：</p><script type="math/tex; mode=display">R(F)=\int_{ {\cal X} ,{\cal Y} }L(F(x),y) {\cal d}P(x,y)</script><p>有了training data后，进一步得到empirical risk function：</p><script type="math/tex; mode=display">\hat R(F)=\frac{1}{m} \sum_{i=1}^m L'(F(x_i),y_i)</script><p>于是，学习问题变成了如何最小化这个empirical risk function。而这个优化问题很难解决，因为loss function不连续。于是可以使用一个方便求解的surrogate function来替换原始loss function，转而优化这个替换函数：</p><script type="math/tex; mode=display">\hat {R'}(F)=\frac{1}{m} \sum_{i=1}^m L'(F(x_i),y_i)</script><p>替换函数的选择有很多种，根据Learning to Rank的类型不同而有不同的选择：</p><p>1）pointwise loss：例如squared loss等。</p><script type="math/tex; mode=display">L'(F(x),y)=\sum_{i=1}^n (f(x_i),y_i)^2</script><p>2）pairwise loss：例如hinge loss，exponential loss，logistic loss等。</p><script type="math/tex; mode=display">L'(F(x),y)=\sum_{i=1}^{n-1} \sum_{j=i+1}^n \phi(sign(y_i-y_j),f(x_i)-f(x_j))</script><p>3）listwise loss：</p><script type="math/tex; mode=display">L'(F(x),y)=exp(-NDCG)</script><h2 id="1-3-Learning-to-Rank-Methods"><a href="#1-3-Learning-to-Rank-Methods" class="headerlink" title="1.3 Learning to Rank Methods"></a>1.3 Learning to Rank Methods</h2><p>Learning to Rank 方法可以分为三种类型：pointwise，pairwise，和listwise。</p><p>pointwise和pairwise方法将排序问题转化为classification，regression，ordinal classification等问题，优点是可以直接利用已有的classificatin和regression算法，缺点是group structure其实是被忽略的，即不会考虑每个query下所有doc之间的序关系。导致其学习目标和真实的衡量排序的目标并不一定是一致的（很多排序衡量指标，例如NDCG都是衡量每个query下的整体list的序关系的）。而listwise方法则将一个ranking list作为一个instance来进行训练，其实会考虑每个query下所有doc之间的序关系的。</p><p>这三种类型的Learning to Rank方法的具体算法一般有：</p><blockquote><p>1) Pointwise: Subset Ranking, McRank, Prank, OC SVM<br>2) Pairwise: Ranking SVM, RankBoost, RankNet, GBRank, IR SVM, Lambda Rank, LambdaMart<br>3) Listwise: ListNet, ListMLE, AdaRank, SVM MAP, Soft Rank</p></blockquote><p>针对各个具体的算法介绍，后续的博客会进一步给出，这里就不再多加详述了。</p><hr><h2 id="2-RankNet，LambdaRank，LambdaMart简介"><a href="#2-RankNet，LambdaRank，LambdaMart简介" class="headerlink" title="2 RankNet，LambdaRank，LambdaMart简介"></a>2 RankNet，LambdaRank，LambdaMart简介</h2><h2 id="2-1-RankNet"><a href="#2-1-RankNet" class="headerlink" title="2.1 RankNet"></a>2.1 RankNet</h2><p>RankNet是2005年微软提出的一种pairwise的Learning to Rank算法，它从概率的角度来解决排序问题。RankNet的核心是提出了一种概率损失函数来学习Ranking Function，并应用Ranking Function对文档进行排序。这里的Ranking Function可以是任意对参数可微的模型，也就是说，该概率损失函数并不依赖于特定的机器学习模型，在论文中，RankNet是基于神经网络实现的。除此之外，GDBT等模型也可以应用于该框架。</p><h3 id="2-1-1-相关性概率"><a href="#2-1-1-相关性概率" class="headerlink" title="2.1.1 相关性概率"></a>2.1.1 相关性概率</h3><p>我们先定义两个概率：预测相关性概率、真实相关性概率。</p><p><strong>（1）预测相关性概率</strong><br>对于任意一个doc对$(U_i,U_j)$，模型输出的score分别为$s_i$和$s_j$，那么根据模型的预测，$U_i$比$U_j$与Query更相关的概率为：</p><script type="math/tex; mode=display">P_{ij}=P(U_i>U_j)=\frac{1}{1+e^{-\sigma (s_i-s_j)}}</script><p>由于RankNet使用的模型一般为神经网络，根据经验sigmoid函数能提供一个比较好的概率评估。参数σ决定sigmoid函数的形状，对最终结果影响不大。</p><blockquote><p>RankNet证明了如果知道一个待排序文档的排列中相邻两个文档之间的排序概率，则通过推导可以算出每两个文档之间的排序概率。因此对于一个待排序文档序列，只需计算相邻文档之间的排序概率，不需要计算所有pair，减少计算量。</p></blockquote><p><strong>（2）真实相关性概率</strong><br>对于训练数据中的$U_i$和$U_j$，它们都包含有一个与Query相关性的真实label，比如$U_i$与Query的相关性label为good，$U_j$与Query的相关性label为bad，那么显然$U_j$比$U_j$更相关。我们定义$U_j$比$U_j$更相关的真实概率为：</p><script type="math/tex; mode=display">\bar P_{ij}=\frac{1}{2}(1+S_{ij})</script><p>如果$U<em>i$比$U_j$更相关，那么$S</em>{ij}$=1；如果$U<em>i$不如$U_j$相关，那么$S</em>{ij}$=−1；如果$U<em>i$、$U_j$与Query的相关程度相同，那么$S</em>{ij}$=0。通常，两个doc的relative relevance judgment可由人工标注或者从搜索日志中获取得到。</p><h3 id="2-1-2-损失函数"><a href="#2-1-2-损失函数" class="headerlink" title="2.1.2 损失函数"></a>2.1.2 损失函数</h3><p>对于一个排序，RankNet从各个doc的相对关系来评价排序结果的好坏，排序的效果越好，那么有错误相对关系的pair就越少。所谓错误的相对关系即如果根据模型输出$U<em>i$排在$U_j$前面，但真实label为$U_i$的相关性小于$U_j$，那么就记一个错误pair，RankNet本质上就是以错误的pair最少为优化目标。而在抽象成cost function时，<strong>RankNet实际上是引入了概率的思想：不是直接判断$U_i$排在$U_j$前面，而是说$U_i$以一定的概率P排在$U_j$前面，即是以预测概率与真实概率的差距最小作为优化目标</strong>。最后，RankNet使用Cross Entropy作为cost function，来衡量$P</em>{ij}$对$\bar P_{ij}$的拟合程度：</p><script type="math/tex; mode=display">C=-\bar P_{ij}logP_{ij}-(1-\bar P_{ij})log(1-P_{ij})</script><p>带入相应等式整理得：</p><script type="math/tex; mode=display">\begin{align*}C_{ij} &= -\frac{1}{2}(1+S_{ij})log \frac{1}{1+e^{-\sigma(s_i-s_j)}} -\frac{1}{2}(1-S_{ij}) log \frac{e^{-\sigma (s_i-s_j)}}{1+e^{-\sigma (s_i-s_j)}} \\&=-\frac{1}{2}(1+S_{ij})log \frac{1}{1+e^{-\sigma(s_i-s_j)}}-\frac{1}{2}(1-S_{ij})[-\sigma(s_i-s_j)+log \frac{1}{1+e^{-\sigma(s_i-s_j)}}] \\&=\frac{1}{2}(1-S_{ij})\sigma(s_i-s_j)+log(1+e^{-\sigma(s_i-s_j)})\end{align*}</script><p>其中：</p><script type="math/tex; mode=display">\begin{align*}C=\left\{\begin{array}{lr}log(1+e^{-\sigma(s_i-s_j)}), & S_{ij}=1  \\log(1+e^{-\sigma(s_j-s_i)}), & S_{ij}=-1 \\\end{array}\right.\end{align*}</script><p>下面展示了当$S_{ij}$分别取1，0，-1的时候cost function以$s_i-s_j$为变量的示意图：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-3.png" alt="cost function.jpg"></p><p>可以看到当$S<em>{ij}$=1时，模型预测的$s_i$比$s_j$越大，其代价越小；$S</em>{ij}$=−1时，$s<em>i$比$s_j$j越小，代价越小；$S</em>{ij}$=0时，代价的最小值在$s_i$与$s_j$相等处取得。</p><p>该损失函数有以下几个特点：</p><blockquote><p>1) 当两个相关性不同的文档算出来的模型分数相同时，损失函数的值大于0，仍会对这对pair做惩罚，使他们的排序位置区分开。<br>2) 损失函数是一个类线性函数，可以有效减少异常样本数据对模型的影响，因此具有鲁棒性。</p></blockquote><p>所以一个query的总代价为：</p><script type="math/tex; mode=display">C=\sum_{(i,j)\in I}C_{ij}</script><p>其中，I表示所有在同一query下，且具有不同relevance judgment的doc pair，每个pair有且仅有一次。</p><h3 id="2-1-3-合并概率"><a href="#2-1-3-合并概率" class="headerlink" title="2.1.3 合并概率"></a>2.1.3 合并概率</h3><p>上述的模型$P_{ij}$需要保持一致性，即如果Ui的相关性高于$U_j$，$U_j$的相关性高于$U_k$，则Ui的相关性也一定要高于$U_k$。否则，如果不能保持一致性，那么上面的理论就不好使了。</p><p>我们使用$U_i$ vs $U_j$的真实概率 和 $U_j$ vs $U_k$ 的真实概率，计算$U_j$ vs $U_k$的真实概率：</p><script type="math/tex; mode=display">\bar P_{ik}=\frac{\bar P_{ij}\bar P_{jk}}{1+2\bar P_{ij}\bar P_{jk}-\bar P_{ij}-\bar P_{jk}}</script><p>若$\bar P<em>{ij}=\bar P</em>{jk}=P$,则有如下图所示：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-4.png" alt="$P_{ik}$变化图.jpg"></p><blockquote><ol><li>$P=0$时，有$\bar P_{i,k}=P=0$表示：$D_i$排$D_j$后面,$D_j$排$D_k$的后面，则$D_i$一定排$D_k$的后面；</li><li>$0&lt;P&lt;0.5$时，\bar P_{i,k} &lt; P$；</li><li>$P=0.5$时，有\bar P_{i,k} = P = 0.5$表示：$D_i$有一半概率排在$D_j$前面，$D_j$也有一半概率排在$D_k$的前面，则$D_i$同样也是一半的概率排在$D_k$的前面；</li><li>$0.5 &lt; P <1$时，$\bar P_{i,k}>P$；</li><li>$P=1$时，有$\bar P_{i,k}=P=1$表示：$D_i$排在$D_j$前面，$D_j$排在$D_k$的前面，则$D_i$也一定排在$D_k$的前面；</li></ol></blockquote><h3 id="2-1-4-Gradient-Descent"><a href="#2-1-4-Gradient-Descent" class="headerlink" title="2.1.4 Gradient Descent"></a>2.1.4 Gradient Descent</h3><p>我们获得了一个可微的代价函数，下面我们就可以用随机梯度下降法来迭代更新模型参数$w_k$了，即</p><script type="math/tex; mode=display">w_k \rightarrow w_k - \eta \frac{\partial C}{\partial w_k}</script><p>$\eta$为步长，代价C沿负梯度方向变化。</p><script type="math/tex; mode=display">\Delta =\sum_k \frac{\partial C}{\partial w_k} \delta w_k = \sum_k\frac{\partial C}{\partial w_k}(\eta \frac{\partial C}{\partial w_k})=-\eta \sum_k (\frac{\partial C}{\partial w_k})^2<0</script><p>这表明沿负梯度方向更新参数确实可以降低总代价。而使用了随机梯度下降法时，有：</p><script type="math/tex; mode=display">\begin{align*}\frac{\partial C}{\partial w_k} &= \frac{\partial C}{\partial s_i} \frac{\partial s_i}{\partial w_k} + \frac{\partial C}{\partial s_j} \frac{\partial s_j}{\partial w_k} \\&= \sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1 + e^{\sigma (s_i - s_j)}})(\frac{\partial s_i}{\partial w_k}-\frac{\partial s_j}{\partial w_k}) \\&=\lambda_{ij}(\frac{\partial s_i}{\partial w_k}-\frac{\partial s_j}{\partial w_k}) \\\end{align*}</script><p>其中：</p><script type="math/tex; mode=display">\lambda_{ij}=\frac{\partial C(s_i-s_j)}{\partial s_i} = \sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-s_j)}})</script><h3 id="2-1-5-加速RankNet训练过程"><a href="#2-1-5-加速RankNet训练过程" class="headerlink" title="2.1.5 加速RankNet训练过程"></a>2.1.5 加速RankNet训练过程</h3><p>上面的是对于每一对pair都会进行一次权重的更新，其实是可以对<strong>同一个query下的所有文档pair</strong>全部带入神经网络进行前向预测，然后计算总差分并进行误差后向反馈，这样将大大减少误差反向传播的次数。</p><p>即，我们可以转而利用<strong>批处理的梯度下降法</strong>：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial w_k}=\sum_{(i ,j) \in I}(\frac{\partial C_{ij}}{\partial s_i} \frac{\partial s_i}{\partial w_k} + \frac{\partial C_{ij}}{\partial s_j} \frac{\partial s_j}{\partial w_k})</script><p>其中：</p><script type="math/tex; mode=display">\frac{\partial C_{ij}}{\partial s_i}=\sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-s_j)}})=-\frac{\partial C_{ij}}{\partial s_j}</script><p>令：</p><script type="math/tex; mode=display">\lambda_{ij}=\frac{\partial C_{ij}}{\partial s_i} = \sigma(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-s_j)}})</script><p>于是有：</p><script type="math/tex; mode=display">\begin{align*}\frac{\partial C}{\partial w_k} &= \sum_{(i,j) \in I}\sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-s_j)}})(\frac{\partial s_i}{\partial w_k}-\frac{\partial s_j}{\partial w_k}) \\&=\sum_{(i,j) \in I} \lambda_{ij}(\frac{\partial s_i}{\partial w_k}-\frac{\partial s_j}{\partial w_k})\\&=\sum_i \lambda_i \frac{\partial s_i}{\partial w_k} \\\end{align*} \\</script><p>下面我们来看看这个$\lambda<em>i$是什么。前面讲过集合I中只包含label不同的doc的集合，且每个pair仅包含一次，即$(U_i,U_j)$与$(U_j,U_i)$等价。为方便起见，我们假设I中只包含$(U_i,U_j)$)表示$U_i$相关性大于$U_j$的pair，即I中的pair均满足$S</em>{ij}=1$，那么</p><script type="math/tex; mode=display">\lambda_i=\sum_{j:(i,j)\in I}\lambda_{ij}-\sum_{j:(j,i)\in I}\lambda_{ij}</script><p>这个写法是Burges的paper上的写法。下面我们用一个实际的例子来看：有三个doc，其真实相关性满足$U_1&gt;U_2&gt;U_3$，那么集合I中就包含{(1,2), (1,3), (2,3)}共三个pair，那么:</p><script type="math/tex; mode=display">\frac{\partial C}{\partial w_k}=(\lambda_{12} \frac{\partial s_1}{\partial w_k}-\lambda_{12}\frac{\partial s_2}{\partial w_k})+(\lambda_{13}\frac{\partial s_1}{\partial w_k}-\lambda_{13}\frac{\partial s_3}{\partial w_k})+(\lambda_{23}\frac{\partial s_2}{\partial w_k}-\lambda_{23}\frac{\partial s_3}{\partial w_k})</script><p>显然$\lambda<em>1=\lambda</em>{12}+\lambda<em>{13},\lambda_2=\lambda</em>{23}-\lambda<em>{12},\lambda_3=-\lambda</em>{13}-\lambda_{23}$,因此$\lambda_i$其实可以写为：</p><script type="math/tex; mode=display">\lambda_i=\sum_{j:(i,j)\in I}\lambda_{ij}-\sum_{k:(k,i)\in I}\lambda_{ki}</script><blockquote><p><strong>$\lambda_i$决定着第i个doc在迭代中的移动方向和幅度，真实的排在$U_i$前面的doc越少，排在$U_i$后面的doc越多，那么文档$U_i$向前移动的幅度就越大(实际$\lambda_i$负的越多越向前移动)。这表明每个f下次调序的方向和强度取决于同一Query下可以与其组成relative relevance judgment的“pair对”的其他不同label的文档。</strong><br>同时，这样的改造相当于是mini-batch learning。可以加速RankNet的学习过程。<br>原先使用神经网络模型，通过Stochastic gradient descent计算的时候，是对每一个pair对都会进行一次权重的更新。而通过因式分解重新改造后，现在的mini-batch learning的方式，是对同一个query下的所有doc进行一次权重的更新。时间消耗从O(n2)降到了O(n)。这对训练过程的影响是很大的，因为使用的是神经网络模型，每次权重的更新迭代都需要先进行前向预测，再进行误差的后向反馈。</p></blockquote><h2 id="2-2-Information-Retrieval的评价指标"><a href="#2-2-Information-Retrieval的评价指标" class="headerlink" title="2.2 Information Retrieval的评价指标"></a>2.2 Information Retrieval的评价指标</h2><p>Information Retrieval的评价指标包括：MRR，MAP，ERR，NDCG等。NDCG和ERR指标的优势在于，它们对doc的相关性划分多个（&gt;2）等级，而MRR和MAP只会对doc的相关性划分2个等级（相关和不相关）。并且，这些指标都包含了doc位置信息（给予靠前位置的doc以较高的权重），这很适合于web search。然而，这些指标的缺点是不平滑、不连续，无法求梯度，如果将这些指标直接作为模型评分的函数的话，是无法直接用梯度下降法进行求解的。</p><p>这里简单介绍下ERR（Expected Reciprocal Rank）。ERR是受到cascade model的启发，即一个用户从上到下依次浏览doc，直至他找到一个满意的结果，ERR可以定义为：</p><script type="math/tex; mode=display">\sum_{r=1}^n \frac{1}{r}R_r \prod_{i=1}^{r-1}(1-R_i)</script><p>其中，$R_i$表示第i位的doc的相关性概率：</p><script type="math/tex; mode=display">R_i=\frac{2^{l_i}-1}{2^{l_m}}</script><p>其中，$l_m$表示相关性评分最高的一档。</p><h2 id="2-3-LambdaRank"><a href="#2-3-LambdaRank" class="headerlink" title="2.3 LambdaRank"></a>2.3 LambdaRank</h2><p>上面我们介绍了以错误pair最少为优化目标的RankNet算法，然而许多时候仅以错误pair数来评价排序的好坏是不够的，像NDCG或者ERR等评价指标就只关注top k个结果的排序，当我们采用RankNet算法时，往往无法以这些指标为优化目标进行迭代，所以RankNet的优化目标和IR评价指标之间还是存在gap的。以下图为例：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-5.png" alt="lambdarank.ipg"></p><p>如上图所示，每个线条表示文档，蓝色表示相关文档，灰色表示不相关文档，RankNet以pairwise error的方式计算cost，左图的cost为13，右图通过把第一个相关文档下调3个位置，第二个文档上条5个位置，将cost降为11，但是像NDCG或者ERR等评价指标只关注top k个结果的排序，在优化过程中下调前面相关文档的位置不是我们想要得到的结果。图 1右图左边黑色的箭头表示RankNet下一轮的调序方向和强度，但我们真正需要的是右边红色箭头代表的方向和强度，即更关注靠前位置的相关文档的排序位置的提升。LambdaRank正是基于这个思想演化而来，其中<strong>Lambda指的就是红色箭头，代表下一次迭代优化的方向和强度，也就是梯度。</strong></p><p><strong>LambdaRank是一个经验算法，它不是通过显示定义损失函数再求梯度的方式对排序问题进行求解，而是分析排序问题需要的梯度的物理意义，直接定义梯度，即Lambda梯度。</strong></p><p>LambdaRank在RankNet的加速算法形式($\lambda<em>{ij}=\frac{\partial C</em>{ij}}{\partial s<em>i} = \sigma(\frac{1}{2}(1-S</em>{ij})-\frac{1}{1+e^{\sigma (s<em>i-s_j)}}),S</em>{ij}=1$)的基础上引入评价指标Z（如NDCG、ERR等），把交换两个文档的位置引起的评价指标的变化$|\Delta_{NDCG}|$作为其中一个因子，实验表明对模型效果有显著的提升：</p><script type="math/tex; mode=display">\lambda_{ij}=\frac{\partial C(s_i-s_j)}{\partial s_i}=\frac{-\sigma}{1+e^{\sigma (s_i-s_j)}}|\Delta_{NDCG}|</script><p>损失函数的梯度代表了文档下一次迭代优化的方向和强度，由于引入了IR评价指标，Lambda梯度更关注位置靠前的优质文档的排序位置的提升。有效的避免了下调位置靠前优质文档的位置这种情况的发生。LambdaRank相比RankNet的优势在于分解因式后训练速度变快，同时考虑了评价指标，直接对问题求解，效果更明显。</p><h2 id="2-4-LambdaMart"><a href="#2-4-LambdaMart" class="headerlink" title="2.4 LambdaMart"></a>2.4 LambdaMart</h2><blockquote><p>1）Mart定义了一个框架，缺少一个梯度。<br>2）LambdaRank重新定义了梯度，赋予了梯度新的物理意义。</p></blockquote><p>因此，所有可以使用梯度下降法求解的模型都可以使用这个梯度，MART就是其中一种，将梯度Lambda和MART结合就是大名鼎鼎的LambdaMART。</p><p>MART的原理是直接在函数空间对函数进行求解，模型结果由许多棵树组成，每棵树的拟合目标是损失函数的梯度，在LambdaMART中就是Lambda。LambdaMART的具体算法过程如下：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/ltr-6.png" alt="lambdamart.jpg"></p><p><strong>可以看出LambdaMART的框架其实就是MART，主要的创新在于中间计算的梯度使用的是Lambda，是pairwise的。MART需要设置的参数包括：树的数量M、叶子节点数L和学习率v，这3个参数可以通过验证集调节获取最优参数。</strong></p><p>MART支持“热启动”，即可以在已经训练好的模型基础上继续训练，在刚开始的时候通过初始化加载进来即可。</p><p><strong>下面简单介绍LambdaMART每一步的工作：</strong><br>1)  每棵树的训练会先遍历所有的训练数据（label不同的文档pair），计算每个pair互换位置导致的指标变化$|\Delta Z<em>{ij}|$以及Lambda，即$\lambda</em>{ij}=-\frac{1}{1+e^{s<em>i-s_j}}|\Delta Z</em>{ij}|$ ，然后计算每个文档的Lambda： $\lambda<em>i=\sum</em>{j:(i,j)\in I}\lambda<em>{ij}-\sum</em>{k:(k,i)\in I}\lambda_{ki}$，再计算每个$\lambda_i$ 的导数$w_i$，用于后面的Newton step求解叶子节点的数值。</p><p>2)  创建回归树拟合第一步生成的$\lambda_i$，划分树节点的标准是Mean Square Error，生成一颗叶子节点数为L的回归树。</p><p>3)  对第二步生成的回归树，计算每个叶子节点的数值，采用Newton step求解，即对落入该叶子节点的文档集，用公式$\frac{\sum<em>{x_i \in R</em>{lm}}y<em>i}{\sum</em>{x<em>i \in R</em>{lm}}w_i}$计算该叶子节点的输出值。</p><p>4)  更新模型，将当前学习到的回归树加入到已有的模型中，用学习率v（也叫shrinkage系数）做regularization。</p><p><strong>LambdaMART具有很多优势：</strong><br>1)  适用于排序场景：不是传统的通过分类或者回归的方法求解排序问题，而是直接求解</p><p>2)  损失函数可导：通过损失函数的转换，将类似于NDCG这种无法求导的IR评价指标转换成可以求导的函数，并且赋予了梯度的实际物理意义，数学解释非常漂亮</p><p>3)  增量学习：由于每次训练可以在已有的模型上继续训练，因此适合于增量学习</p><p>4)  组合特征：因为采用树模型，因此可以学到不同特征组合情况</p><p>5)  特征选择：因为是基于MART模型，因此也具有MART的优势，可以学到每个特征的重要性，可以做特征选择</p><p>6)  适用于正负样本比例失衡的数据：因为模型的训练对象具有不同label的文档pair，而不是预测每个文档的label，因此对正负样本比例失衡不敏感</p><p><a href="https://www.cnblogs.com/bentuwuying/p/6681943.html">参考博文：Learning to Rank简介</a><br><a href="https://www.cnblogs.com/bentuwuying/p/6690836.html">参考博文：Learning to Rank算法介绍：RankNet，LambdaRank，LambdaMart</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-Learning-to-Rank-简介&quot;&gt;&lt;a href=&quot;#1-Learning-to-Rank-简介&quot; class=&quot;headerlink&quot; title=&quot;1 Learning to Rank 简介&quot;&gt;&lt;/a&gt;1 Learning to Rank 简介&lt;/h2&gt;&lt;p&gt;Learning to Rank是采用机器学习算法，通过训练模型来解决排序问题，在Information Retrieval，Natural Language Processing，Data Mining等领域有着很多应用。&lt;/p&gt;
&lt;h2 id=&quot;1-1-排序问题&quot;&gt;&lt;a href=&quot;#1-1-排序问题&quot; class=&quot;headerlink&quot; title=&quot;1.1 排序问题&quot;&gt;&lt;/a&gt;1.1 排序问题&lt;/h2&gt;&lt;p&gt;如图 Fig.1 所示，在信息检索中，给定一个query，搜索引擎会召回一系列相关的Documents（通过term匹配，keyword匹配，或者semantic匹配的方法），然后便需要对这些召回的Documents进行排序，最后将Top N的Documents输出,一版可以认为是召回后的精排。而排序问题就是使用一个模型 f(q,d)来对该query下的documents进行排序，这个模型可以是人工设定一些参数的模型，也可以是用机器学习算法自动训练出来的模型。现在第二种方法越来越流行，尤其在Web Search领域，因为在Web Search 中，有很多信息可以用来确定query-doc pair的相关性，而另一方面，由于大量的搜索日志的存在，可以将用户的点击行为日志作为training data，使得通过机器学习自动得到排序模型成为可能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需要注意的是，排序问题最关注的是各个Documents之间的相对顺序关系，而不是各个Documents的预测分最准确。&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="LTR" scheme="https://www.xiemingzhao.com/tags/LTR/"/>
    
  </entry>
  
  <entry>
    <title>LTR信息检索评价指标</title>
    <link href="https://www.xiemingzhao.com/posts/5fb7303d.html"/>
    <id>https://www.xiemingzhao.com/posts/5fb7303d.html</id>
    <published>2019-06-26T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.654Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-RP"><a href="#1-RP" class="headerlink" title="1 RP"></a>1 RP</h2><p>R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：</p><div class="table-container"><table><thead><tr><th style="text-align:center">—-</th><th style="text-align:center">Predict P</th><th style="text-align:center">Predict N</th></tr></thead><tbody><tr><td style="text-align:center">Target P</td><td style="text-align:center">TP</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Target N</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><span id="more"></span><p>正确率、召回率（查全率）、精准度、$F_{\beta}$ score、假阳率以及真阳率：</p><script type="math/tex; mode=display">Accuracy = \frac{TP+FN}{TP+TN+FP+FN}</script><script type="math/tex; mode=display">Recall=\frac{TP}{TP+FN}</script><script type="math/tex; mode=display">Precision=\frac{TP}{TP+FP}</script><script type="math/tex; mode=display">F_{\beta}=(1+\beta^2) \cdot \frac{Precision \cdot Recall}{\beta^2 \cdot Precision + Recall}</script><p>其中，F-Score/F-measure 作为综合指标，平衡 recall 和 precision 的影响，较为全面的评价一个模型。F1-Score 表示准确率和召回率一样重要；F2-Score 表示召回率比准确率重要一倍；F0.5-Score 表示准确率比召回率重要一倍。</p><script type="math/tex; mode=display">FPR=\frac{FP}{FP+TN}</script><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}</script><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/LTRindex-AUC.png" alt="LTRindex-AUC"></p><p>其中：<br>假阳率FPR=ROC曲线的X轴指标<br>真阳率TPR=ROC曲线的Y轴指标=召回率<br>AUC值就是曲线右下部分面积。</p><h2 id="2-MAP"><a href="#2-MAP" class="headerlink" title="2 MAP"></a>2 MAP</h2><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/LTRindex-PR.jpg" alt="LTRindex-PR"></p><p>如上图的PR曲线，对其进行积分求曲线下方的面积，就是AP(Average Precision)，即</p><script type="math/tex; mode=display">AP=\int_0^1 p(r) dr</script><p>其中，p 表示 precision，r 表示 recall，p 是一个以 r 为参数的函数，AP 的计算是对排序位置敏感的，相关文档排序的位置越靠前，检索出相关的文档越多，AP 值越大。</p><p>近似计算约等于 AAP（Aproximate Average Precision）：</p><script type="math/tex; mode=display">AAP=\sum_{k=1}^Np(k)\Delta r(k)=\frac{\sum_{k=1}^Np(k) \cdot rel(k)}{number Of Relevant Documents}</script><p>其中，N 代表所有相关文档的总数，p(k) 表示能检索出 k 个相关文档时的 precision 值，而 △r(k) 则表示检索相关文档个数从 k-1 变化到 k 时（通过调整阈值）recall 值的变化情况。<br>rel(k) 表示第 k 个文档是否相关，若相关则为1，否则为0，则可以简化公式为：</p><script type="math/tex; mode=display">AP=\frac{1}{N} \cdot \sum_{i=1}^N\frac{i}{position(i)}</script><p>其中，N 表示相关文档总数，position(i) 表示第 i 个相关文档在检索结果列表中的位置。</p><p>MAP（Mean Average Precision）即多个查询的平均正确率（AP）的均值，从整体上反映模型的检索性能。</p><p>下面举一个例子来说明上述公式的计算：<br>查询 query1 对应总共有4个相关文档，查询 query2 对应总共有5个相关文档。当通过模型执行查询1、2时，分别检索出4个相关文档（Rank=1、2、4、7）和3个相关文档（Rank=1、3、5）。<br>则 query1AP=(1/1+2/2+3/4+4/7)/4=0.83，query2AP=(1/1+2/3+3/5+0+0)/5=0.45，最后 MAP=(0.83+0.45)/2=0.64。</p><h2 id="3-NDCG"><a href="#3-NDCG" class="headerlink" title="3 NDCG"></a>3 NDCG</h2><h3 id="3-1-CG-Cumulative-Gain-累计效益"><a href="#3-1-CG-Cumulative-Gain-累计效益" class="headerlink" title="3.1 CG(Cumulative Gain)累计效益"></a>3.1 CG(Cumulative Gain)累计效益</h3><script type="math/tex; mode=display">CG@k=\sum_{i=1}^k rel_i</script><p>其中 k 表示 k 个文档组成的集合，rel 表示第 i 个文档的相关度，例如相关度分为以下几个等级：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Relevance Rating</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">Perfect</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">Excellent</td><td style="text-align:center">4</td></tr><tr><td style="text-align:center">Good</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">Fair</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">Simple</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">Bad</td><td style="text-align:center">0</td></tr></tbody></table></div><h3 id="3-2-DCG-Discounted-Cumulative-Gain"><a href="#3-2-DCG-Discounted-Cumulative-Gain" class="headerlink" title="3.2 DCG(Discounted Cumulative Gain)"></a>3.2 DCG(Discounted Cumulative Gain)</h3><p>在 CG 的计算中没有考虑到位置信息，例如检索到三个文档的相关度依次为（3，-1，1）和（-1，1，3），根据 CG 的计算公式得出的排名是相同的，但是显然前者的排序好一些。</p><p>所以需要在 CG 计算的基础上加入位置信息的计算，现假设根据位置的递增，对应的价值递减，为 1/log2(i+1)，其中 log2(i+1) 为折扣因子；</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{rel_i}{log_2 (i+1)}</script><p>另一种增加相关度影响比重的 DCG 计算公式：</p><script type="math/tex; mode=display">DCG@k=\sum_{i=1}^k \frac{2^{rel_i}-1}{log_2 (i+1)}</script><h3 id="3-3-IDCG-idea-DCG"><a href="#3-3-IDCG-idea-DCG" class="headerlink" title="3.3 IDCG(idea DCG)"></a>3.3 IDCG(idea DCG)</h3><p>理想情况下，按照相关度从大到小排序，然后计算 DCG 可以取得最大值情况。</p><script type="math/tex; mode=display">IDCG@k=\sum_{i=1}^{|REL|} \frac{2^{rel_i}-1}{log_2 (i+1)}</script><p>其中 |REL| 表示文档按照相关度从大到小排序，取前 k 个文档组成的集合。就是按理想排序情景的前k个。</p><h3 id="3-4-NDCG-Normalized-DCG"><a href="#3-4-NDCG-Normalized-DCG" class="headerlink" title="3.4 NDCG(Normalized DCG)"></a>3.4 NDCG(Normalized DCG)</h3><p>由于每个查询所能检索到的结果文档集合长度不一致，k 值的不同会影响 DCG 的计算结果。所以不能简单的对不同查询的 DCG 结果进行平均，需要先归一化处理。</p><p>NDCG 就是利用 IDCG 进行归一化处理，表示当前的 DCG 与理想情况下的 IDCG 相差多大：</p><script type="math/tex; mode=display">NDCG@k=\frac{DCG@k}{IDCG@K}</script><p>这样每个查询的 NDCG 均在 0-1 范围内，不同查询之间就可以进行比较，求取多个查询的平均 NDCG。</p><h2 id="4-ERR"><a href="#4-ERR" class="headerlink" title="4 ERR"></a>4 ERR</h2><h3 id="4-1-PR-reciprocal-rank"><a href="#4-1-PR-reciprocal-rank" class="headerlink" title="4.1 PR(reciprocal rank)"></a>4.1 PR(reciprocal rank)</h3><p>倒数排名，指检索结果中第一个相关文档的排名的倒数。</p><script type="math/tex; mode=display">RR=\frac{1}{rank_i}</script><h3 id="4-2-MRR-mean-reciprocal-rank"><a href="#4-2-MRR-mean-reciprocal-rank" class="headerlink" title="4.2 MRR(mean reciprocal rank)"></a>4.2 MRR(mean reciprocal rank)</h3><p>多个查询的倒数排名的均值，公式如下：</p><script type="math/tex; mode=display">MRR=\frac{1}{|N|} \sum_{i=1}^{|N|} \frac{1}{rank_i}</script><p>ranki 表示第 i 个查询的第一个相关文档的排名。</p><h3 id="4-3-Cascade-Model-瀑布模型"><a href="#4-3-Cascade-Model-瀑布模型" class="headerlink" title="4.3 Cascade Model(瀑布模型)"></a>4.3 Cascade Model(瀑布模型)</h3><p>点击模型中的瀑布模型，考虑到在同一个检索结果列表中各文档之间的位置依赖关系，假设用户从上至下查看，如果遇到某一检索结果项满意并进行点击，则操作结束；否则跳过该项继续往后查看。第 i 个位置的文档项被点击的概率为：</p><script type="math/tex; mode=display">P(C_i)=r_i \prod_{j=1}^{i-1} (1-r_j)</script><p>其中 ri 表示第 i 个文档被点击的概率，前 i-1 个文档则没有被点击，概率均为 1-rj；</p><h3 id="4-4-ERR-Expected-reciprocal-rank"><a href="#4-4-ERR-Expected-reciprocal-rank" class="headerlink" title="4.4 ERR(Expected reciprocal rank)"></a>4.4 ERR(Expected reciprocal rank)</h3><p>预期的倒数排名，表示用户的需求被满足时停止的位置的倒数的期望，与 RR 计算第一个相关文档的位置倒数不同。<br>首先用户在位置 r 处停止的概率 PPr 计算公式如下：</p><script type="math/tex; mode=display">PP_r=\prod_{i=1}^{r-1}(1-R_i) R_r</script><p>其中 Ri 是关于文档相关度等级的函数，现假设该函数为：</p><script type="math/tex; mode=display">R_i=R(g_i)=\frac{2^g-1}{2^{g_max}}</script><p>当文档是不相关的（g=0），则用户检索到相关文档的概率为0；而当文档极其相关（g=4，如果相关度划分5个等级）时，用户检索到相关文档的概率接近于1。上面公式中的 g 表示文档的相关度，参考 NDCG 中的 rel。</p><p>更通用一点来讲，ERR 不一定是计算用户需求满足时停止的位置的倒数的期望，它可以是基于位置的函数</p><script type="math/tex; mode=display">ERR=\sum_{r=1}^n \varphi(r)P Pr=\sum_{r=1}^n \frac{1}{r} P Pr=\sum_{r=1}^n \frac{1}{r} \prod_{i=1}^{r-1}(1-R_i)R_r</script><p>可以看出，当 φ(r)=1/r 时就是 ERR，当 φ(r)=1/log2(r+1) 就是DCG。</p><p><a href="https://www.cnblogs.com/memento/p/8673309.html">参考文章:https://www.cnblogs.com/memento/p/8673309.html</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-RP&quot;&gt;&lt;a href=&quot;#1-RP&quot; class=&quot;headerlink&quot; title=&quot;1 RP&quot;&gt;&lt;/a&gt;1 RP&lt;/h2&gt;&lt;p&gt;R（recall）表示召回率、查全率，指查询返回结果中相关文档占所有相关文档的比例；P（precision）表示准确率、精度，指查询返回结果中相关文档占所有查询结果文档的比例。假设有如下的混淆矩阵：&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;—-&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict P&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Predict N&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target P&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Target N&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;FP&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;TN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="排序" scheme="https://www.xiemingzhao.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="LTR" scheme="https://www.xiemingzhao.com/tags/LTR/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM A Highly Efficient Gradient Boosting Decision Tree （论文解析）</title>
    <link href="https://www.xiemingzhao.com/posts/c7ab2b84.html"/>
    <id>https://www.xiemingzhao.com/posts/c7ab2b84.html</id>
    <published>2019-06-22T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.654Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf">原始论文：LightGBM-A Highly Efficient Gradient Boosting Decision Tree</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Gradient Boosting Decision Tree (GBDT)是一个非常流行的机器学习算法，却只有像XGBoost和pGBRT的一些实现。尽管许多工程上的优化方案已经在这些实现中应用了，但是当特征维度较高和数据量巨大的时候，仍然存在效率和可扩展性的问题。一个主要原因就是对于每一个特征的每一个分裂点，都需要遍历全部数据计算信息增益，这一过程非常耗时。针对这一问题，本文提出两种新方法：Gradient-based One-Side Sampling (GOSS) 和Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）。在GOSS中，我们排除了一部分重要的具有小梯度实例数据的比例，只用剩下的来估计信息增益。我们证明，这些梯度大的实例在计算信息增益中扮演重要角色，GOSS可以用更小的数据量对信息增益进行相当准确的估计。对于EFB，我们捆绑互斥的特征（例如，特征间很少同时非零的特征），来降低特征的个数。我们完美地证明了捆绑互斥特征是NP难的，但贪心算法能够实现相当好的逼近率，因此我们能够在不损害分割点准确率许多的情况下，有效减少特征的数量。（牺牲一点分割准确率降低特征数量），这一算法命名为LightGBM。我们在多个公共数据集实验证明，LightGBM加速了传统GBDT训练过程20倍以上，同时达到了几乎相同的精度。</p><span id="more"></span><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>GBDT是一个广泛应用地机器学习算法，这得益于其本身的有效性、准确性、可解释性。GBDT在许多机器学习任务上均取得了最好的效果，例如多分类，点击预测，排序。但最近几年随着大数据的爆发（特征量和数据量），GBDT正在面临新的挑战，特别是在平衡准确率和效率的调整方面。常见的GBDT的实现，对于每个特征,都需要遍历全部数据来计算所有可能分裂点的信息增益。因此，其计算复杂度将受到特征数量和数据量双重影响，造成处理大数据时十分耗时。</p><p>为了解决这一问题，一个直接的方法就是减少特征量和数据量而且不影响精确度。然而，这将是非常重要的。例如，我们不清楚如何针对提升GBDT来进行数据抽样。而有部分工作根据数据权重采样来加速boosting的过程，它们不能直接地应用于GBDT，因为gbdt没有样本权重。在本文中，我们提出两种新方法实现此目标。</p><p>Gradient-based One-Side Sampling (GOSS)。尽管GBDT虽然没有数据实例权重，但每个数据实例有不同的梯度，从而在信息增益的计算中扮演不同的角色。特别地，根据计算信息增益的定义，梯度大的实例对信息增益有更大的影响。因此，在数据实例下采样时，为了保持信息增益预估的准确性，我们应该尽量保留梯度大的样本（预先设定阈值，或者最高百分位间），并且随机去掉梯度小的样本。我们证明此措施在相同的采样率下比随机采样获得更准确的结果，尤其是在信息增益范围较大时。</p><p>Exclusive Feature Bundling (EFB)。通常在真实应用中，虽然特征量比较多，但是由于特征空间十分稀疏，那我们是否可以设计一种无损的方法来减少有效特征呢？特别在，稀疏特征空间上，许多特征几乎都是互斥的（例如像文本挖掘中的one-hot特征）。我们就可以捆绑这些互斥的特征。最后，我们设计了一个有效的算法，将捆绑问题简化成图着色问题（方法是将特征作为节点，在每两个不完全互斥的特征之间添加边），并且通过贪心算法可以求得近似解。</p><p>我们将这种结合了 GOSS 和 EFB 的新 GBDT 算法称为<em>LightGBM</em>。我们在多个公开数据集上的实验结果证明了 LightGBM 在得到几乎相同准确率的情况下能够提升20倍的训练速度。</p><p>这篇文章剩下的部分将按如下安排。首先，我们在第二部分回顾了 GBDT 算法和相关工作。然后，我们分别在第三和第四部分介绍了 GOSS 和 EFB 的详细内容。在第五部分，展示了我们在公共数据集上所做的关于 LightGBM 的实验结果。最后，我们在第六部分进行了总结。</p><h2 id="2-预研"><a href="#2-预研" class="headerlink" title="2 预研"></a>2 预研</h2><h3 id="2-1-GBDT-和它的复杂度分析"><a href="#2-1-GBDT-和它的复杂度分析" class="headerlink" title="2.1 GBDT 和它的复杂度分析"></a>2.1 GBDT 和它的复杂度分析</h3><p>GBDT是一种集成模型的决策树，顺序训练决策树。每次迭代中，GBDT通过拟合负梯度（也被称为残差）来学到决策树。</p><p>学习决策树是GBDT主要的时间花销，而学习决策树中找到最优切分点最消耗时间。有一种最常用的预排序算法来找到最优切分点，这种方法会列举预排序中所有可能的切分点。这种算法虽然能够找到最优的切分点，但在训练速度和内存消耗上的效率都很低。另一种流行算法是直方图算法（histogram-based algorithm），如 Alg.1 所示。直方图算法并不通过特征排序找到最优的切分点，而是将连续的特征值抽象成离散的分箱，并使用这些分箱在训练过程中构建特征直方图。这种算法更加训练速度和内存消耗上都更加高效，lightGBM使用此种算法。</p><p>histogram-based算法通过直方图寻找最优切分点，其建直方图消耗O(#data <em> #feature)，寻找最优切分点消耗O(#bin </em> # feature)，而#bin的数量远小于#data，所以建直方图为主要时间消耗。如果能够减少数据量或特征量，那么还能够够加速GBDT的训练。（寻找最优切分点已经进行了优化，那么我们现在应该对建直方图的时间进行优化）</p><h2 id="2-2-相关工作"><a href="#2-2-相关工作" class="headerlink" title="2.2 相关工作"></a>2.2 相关工作</h2><p>GBDT有许多实现，如XGBoost，PGBRT，Scikit-learn，gbm in R。Scikit-learn和gbm in R实现都用了预排序，pGBRT使用了直方图算法。XGBoost支持预排序和直方图算法，由于XGBoost胜过其他算法，我们用它作为实验的baseline。</p><p>为了减小训练数据集，通常做法是下采样。例如过滤掉权重小于阈值的数据。SGB每次迭代中用随机子集训练弱学习器。或者采样率基于训练过程动态调整。然而，这些都是使用基于AdaBoost的SGB，其不能直接应用于GBDT是因为GBDT中没有原始的权重。虽然SGB也能间接应用于GBDT，但往往会影响精度。</p><p>同样，可以考虑过滤掉弱特征（什么是弱特征）来减少特征量。通常用主成分分析或者投影法。当然，这些方法依赖于一个假设-特征有高冗余性，但实际中往往不是。（设计特征来自于其独特的贡献，移除任何一维度都可以某种程度上影响精度）。</p><p>实际中大规模的数据集通常都是非常稀疏的，使用预排序算法的GBDT能够通过无视为0的特征来降低训练时间消耗。然而直方图算法没有优化稀疏的方案。因为直方图算法无论特征值是否为0，都需要为每个数据检索特征区间值。如果基于直方图的GBDT能够有效解决稀疏特征中的0值，并且这样将会有很好的性能。</p><p>为了解决前面工作的局限性，我们提出了两个全新的技术分别是 Gradient-based One-Side Sampling (GOSS) 和 Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）。跟多的细节会再下一部分介绍。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/lgbm1.JPG" alt="Alg.1 &amp; Alg.2"></p><h2 id="3-基于梯度的one-side采样"><a href="#3-基于梯度的one-side采样" class="headerlink" title="3 基于梯度的one-side采样"></a>3 基于梯度的one-side采样</h2><p>在这一部分，我们为 GBDT 提出了一个新的抽样方法， 这能够在减少数据实例个数和保持学习到的决策树的准确度之间达到一个平衡。</p><h3 id="3-1-算法描述"><a href="#3-1-算法描述" class="headerlink" title="3.1 算法描述"></a>3.1 算法描述</h3><p>在AdaBoost中，样本权重是数据实例重要性的指标。然而在GBDT中没有原始样本权重，不能应用权重采样。幸运的事，我们观察到GBDT中每个数据都有不同的梯度值，对采样十分有用，即实例的梯度小，实例训练误差也就较小，已经被学习得很好了，直接想法就是丢掉这部分梯度小的数据。然而这样做会改变数据的分布，将会影响训练的模型的精确度，为了避免此问题，我们提出了GOSS。</p><p>GOSS保留所有的梯度较大的实例，在梯度小的实例上使用随机采样。为了抵消对数据分布的影响，计算信息增益的时候，GOSS对小梯度的数据引入常量乘数。GOSS首先根据数据的梯度绝对值排序，选取top a x 100%个实例。然后在剩余的数据中随机采样bx100%个实例。接着计算信息增益时为采样出的小梯度数据乘以(1-a)/b（即，小梯度样本总数/随机采样出的小梯度样本数量），这样算法就会更关注训练不足的实例，而不会过多改变原数据集的分布。</p><h3 id="3-2-理论分析"><a href="#3-2-理论分析" class="headerlink" title="3.2 理论分析"></a>3.2 理论分析</h3><p>GBDT使用决策树，来学习获得一个将输入空间$\mathcal \chi^s$映射到梯度空间$\mathcal G$的函数。假设训练集有n个实例 ${x_1,…,x_n}$，每个$x_i$都是一个维度为s的特征向量。每次迭代时，模型数据变量的损失函数的负梯度方向表示为$g_1,…,g_n$，决策树通过最优切分点（最大信息增益点）将数据分到各个节点。对于GBDT，一般通过分割后的方差衡量信息增益，具体由下定义。</p><p><strong>定义3.1</strong>：$O$表示某个固定叶子节点的训练集，分割特征j的分割点d对应的方差增益定义为：</p><script type="math/tex; mode=display">V_{j|O} (d) = \frac{1}{n_O} ( \frac{(\sum_{ \{x_i \in O:x_{ij} \leq d\} } g_i)^2} {n_{l|O}^j (d)} + \frac{(\sum_{ \{x_i \in O:x_{ij} > d\} } g_i)^2} {n_{r|O}^j (d)} )</script><p>其中$n<em>O = \sum I[x_i \in O]$(<em>某个固定叶子节点的训练集样本的个数</em>)，$n</em>{l|O}^j (d) = \sum I[x<em>i \in O:x</em>{ij} \leq d]$（<em>在第j个特征上值小于等于d的样本个数</em>），和 $n<em>{r|O}^j (d) = \sum I[x_i \in O:x</em>{ij} &gt; d]$（<em>在第j个特征上值大于d的样本个数</em>）。</p><p>对于特征 j，决策树算法选择$d_j^<em> = argmax_d V_j(d)$并且计算最大信息增益$V_j(d_j^</em>)$。然后，数据集会根据特征$j^<em>$在点$d_j^</em>$分到左右子节点中去。</p><p>在我们所提出的GOSS方法中，首先，我们训练实例按照它们梯度的绝对值进行降序排列；第二，我们保留梯度最大的top-a x 100%个实例作为样本子集A；再者，对于剩下的包含(1-a) x 100%个更小梯度实例的子集$A^c$，我们进一步随机抽样一个大小为$b x |A^c|$的子集B；最后，我们我们将样本实例按照下列公式在子集$A \cup B$上的方法增益估计值进行分割：</p><script type="math/tex; mode=display">\tilde V_j(d) = \frac{1}{n} (\frac{(\sum_{x_i \in A_l} g_i + \frac{1-a}{b} \sum_{x_i \in B_l} g_i)^2}{n_l^j (d)} + \frac{(\sum_{x_i \in A_r} g_i + \frac{1-a}{b} \sum_{x_i \in B_r} g_i)^2}{n_r^j (d)}),     (1)</script><p>其中，$A<em>l = {x_i \in A:x</em>{ij} \leq A}, A<em>r = {x_i \in A:x</em>{ij} &gt; d}, B<em>l = {x_i \in b:x</em>{ij} \leq d}, B<em>r = {x_i \in B:x</em>{ij} &gt; d}$，并且系数(1-a)/b是用来将B上的梯度和归一化到$A^c$的大小上去。</p><p>因此，在GOSS中，我们使用更小实例子集上的估计值$\tilde V_j (d)$而不是使用所有的实例来计算精确的$V_j (d)$来得到分裂点，并且这种计算成本也可以得到大大地降低。更重要的是，下列定理表名了GOSS不会损失更多的训练精度并且会优于随机抽样。由于空间限制，我们将定理的证明放在了补充材料中。</p><p><strong>定理3.2</strong> 我们将GOSS的近似误差定义为$\varepsilon (d) = |\tilde V<em>j (d) - V_j (d)| \ and\ \bar g_l^j (d) = \frac{\sum</em>{x<em>i \in (A \cup A^c)_l |g_i|} }{n_l^j (d)}, \bar g_r^j (d)  = \frac{\sum</em>{x_i \in (A \cup A^c)_r |g_i|} }{n_r^j (d)}$。概率至少是$1- \delta$，我们有：</p><script type="math/tex; mode=display">\varepsilon (d) \leq C_{a,b}^2 ln 1/\delta \cdot max\{ \frac{1}{n_l^j(d)}, \frac{1}{n_r^j(d)} \} + 2DC_{a,b} \sqrt{\frac{ln 1/\delta}{n} },   (2)</script><p>其中$C<em>{a,b} = \frac{1-a}{\sqrt{b}} max</em>{x_i \in A^c} |g_i|$， 和 $D = max(\bar g_l^j (d), \bar g_r^j (d) )$。</p><p>根据定理，我们可以得到以下结论：(1)GOSS的渐进近似比率是$\mathcal O(\frac{1}{n<em>l^j (d)} + \frac{1}{n_r^j (d)} + \frac{1}{\sqrt{n}} )$。如果分割的不是特别不平衡(即$n_l^h \geq \mathcal O (\sqrt n)$ 且 $n_r^h \geq \mathcal O (\sqrt n)$)，近似误差可以由公式(2)中的第二项来表示，其中当$n \rightarrow \infty$时$\mathcal O (\sqrt n)$将趋向于0。这意味着当数据集个数很大的时候，近似值将是很准确的。(2)随机抽样是一个$a = 0$时GOSS的特例。在许多案例中，GOSS都会表现地比随机抽样要好，在$C</em>{0,\beta} &gt; C<em>{a,\beta - a}$条件下，这等价于$\frac{\alpha_a}{\sqrt \beta} &gt; \frac{1-a}{\sqrt{\beta - a} }$且有$\alpha_a = max</em>{x<em>i \in A\cup A^c} |g_i|/max</em>{x_i \in A^c |g_i|}$。</p><p>下一步，我们分析了GOSS的泛化表现。我们考虑了GOSS的泛化误差$\varepsilon<em>{gen}^{GOSS} (d) = |\tilde V_j (d) - V</em><em> (d)|$，这个值是由GOSS中抽样训练得到的方差增益和潜在分布的真实方差增益之间的差值。我们有$\varepsilon<em>{gen}^{GOSS} (d) \leq |\tilde V_j (d) - V_j (d)| + |V_j (d) - V</em></em> (d)| \triangleq \varepsilon<em>{GOSS} (d) + \varepsilon</em>{gen} (d)$。因此，如果GOSS近似是准确的，那么带GOSS的泛化误差是接近于使用全量数据集计算得结果。另一方面，抽样会增加基础学习器之间的多样性，这潜在地帮助提升了泛化的表现。</p><h2 id="4-互斥特征捆绑"><a href="#4-互斥特征捆绑" class="headerlink" title="4 互斥特征捆绑"></a>4 互斥特征捆绑</h2><p>这一章，我们提出了一个全新的方法来有效地减少特征数量。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/lgbm2.JPG" alt="Alg.3 &amp; Alg.4"></p><p>高维的数据通常是非常稀疏的。这种稀疏性启发我们可以设计一种无损地方法来减少特征的维度。特别地，在稀疏特征空间中，许多特征是完全互斥的，即它们从不同时为非零值。我们可以绑定互斥的特征为单一特征（这就是我们所说的互斥特征捆绑）。通过仔细设计特征扫描算法，我们从特征捆绑中构建了与单个特征相同的特征直方图。这种方式的构建直方图时间复杂度从O(#data <em> #feature)降到O(#data </em> #bundle)，由于#bundle &lt;&lt; # feature，我们能够极大地加速GBDT的训练过程而且不损失精度。(构造直方图的时候，遍历一个“捆绑的大特征”可以得到一组exclusive feature的直方图。这样只需要遍历这些“大特征”就可以获取到所有特征的直方图，降低了需要遍历的特征量。)在下面，我们将会展示如何实现这些方法的细节。</p><p>有两个问题需要被解决。第一个就是需要确定哪些特征后应该绑定在一起。第二个就是如何构造捆绑。</p><p><strong>定理4.1</strong> <em>将特征分割为较小量的互斥特征群是NP难的。</em></p><p><em>证明：</em>将图着色问题归约为此问题。而图着色是NP难的，所以我们可以得到我们的结论。</p><p>给定图着色的一个实例G=(V, E)。可以构建一个我们问题的一个实例如下所示。以G的关联矩阵的每一行为特征，得到我们问题的一个实例有|V|个特征。 很容易看到，在我们的问题中，一个独特的特征捆绑与一组具有相同颜色的顶点相对应，反之亦然。</p><p>对于第1个问题，我们在定理4.1说明寻找一个最优的捆绑策略是NP难的，这就表明不可能找到一个能够在多项式时间内解决的办法。为了寻找好的近似算法，我们将最优捆绑问题归结为图着色问题，如果两个特征之间不是相互排斥，那么我们用一个边将他们连接，然后用合理的贪婪算法（具有恒定的近似比）用于图着色来做特征捆绑。 此外，我们注意到通常有很多特征，尽管不是100％相互排斥的，也很少同时取非零值。 如果我们的算法可以允许一小部分的冲突，我们可以得到更少的特征包，进一步提高计算效率。经过简单的计算，随机污染小部分特征值将影响精度最多为$\mathcal O([(1-\gamma) n]^{-2/3})$(参考文献【2】)，$\gamma$是每个绑定中的最大冲突比率。所以，如果我们能选择一个相对较小的$\gamma$时，能够完成精度和效率之间的平衡。</p><p>基于上述的讨论，我们针对互斥特征捆绑设计了一个算法如Alg.3所示。首先，我们建立一个图，每个点代表特征，每个边有权重，其权重和特征之间总体冲突相关。第二，我们按照降序排列图中点的度来排序特征。最后，我们检查排序之后的每个特征，对它进行特征绑定或者建立新的绑定使得操作之后的总体冲突最小（由$\gamma$控制）。算法3的时间复杂度是$\mathcal O (# feature ^2)$，并且只在训练之前处理一次。其时间复杂度在特征不是特别多的情况下是可以接受的，但难以应对百万维的特征。为了继续提高效率，我们提出了一个更加高效的不用构建图的排序策略：将特征按照非零值个数排序，这和使用图节点的度排序相似，因为更多的非零值通常会导致冲突。新算法在算法3基础上只是改变了排序策略来避免重复。</p><p>对于第2个问题，我们需要一个好的办法合并同一个bundle的特征来降低训练时间复杂度。关键在于原始特征值可以从bundle中区分出来。鉴于直方图算法存储离散值而不是连续特征值，我们通过将互斥特征放在不同的箱中来构建bundle。这可以通过将偏移量添加到特征原始值中实现，例如，假设bundle中有两个特征，原始特征A取值[0, 10]，B取值[0, 20]。我们添加偏移量10到B中，因此B取值[10, 30]。通过这种做法，就可以安全地将A、B特征合并，使用一个取值[0, 30]的特征取代A和B。算法见Alg.4。</p><p>EFB算法能够将许多互斥的特征变为低维稠密的特征，就能够有效的避免不必要0值特征的计算。实际，对每一个特征，建立一个记录数据中的非零值的表，通过用这个表，来忽略零值特征，达到优化基础的直方图算法的目的。通过扫描表中的数据，建直方图的时间复杂度将从O(#data)降到O(#non_zero_data)。当然，这种方法在构建树过程中需要而额外的内存和计算开销来维持这种表。我们在lightGBM中将此优化作为基本函数.因为当bundles是稀疏的时候，这个优化与EFB不冲突（可以用于EFB）.</p><h2 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h2><p>在这一部分，我们汇报了我们提出的LightGBM算法的实验结果。我们使用五个不同的公开数据集。这些数据集的细节列在了表1中。在它们中，微软的排序数据集包含30K网站搜索请求数据。这个数据集中的特征大多是稠密数值特征。Allstate<br>Insurance Claim和Flight Delay数据集都包含许多one-hot编码特征。并且最后两个数据集来自KDD CUP 2010 and KDD CUP 2012。我们直接地使用这些由获胜者NTU提供的特征，其中包含稠密特征和稀疏特征，并且这两个数据集非常大。这些数据集都是很大的，同时包含稀疏特征和稠密特征，并且涵盖了许多真实的任务。因此，我们直接地可以使用它们来测试我们的算法。</p><p>我们的实验环境是一个Linux服务器，包含两个E5-2670 v3 CPUs（总共24核）和256GB的内存。所有试验都是多线程运行并且线程的个数固定在16。</p><h3 id="5-1-全部对比"><a href="#5-1-全部对比" class="headerlink" title="5.1 全部对比"></a>5.1 全部对比</h3><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/lgbm3.JPG" alt="table of experiment"></p><p>我们在这一部分展示了所有的实验对比。XGBoost和不包含GOSS以及EFB（称为lgb_baseline）的LightGBM用作基准线。对于XGBoost，我们使用两个版本，xgb_exa(预排序算法)和xgb_his(基于直方图的算法)。对于xgb_his，lgb_baseline，和LightGBM，我们使用leaf-wise树增长方法。对于xgb_exa，因为它仅仅支持layer-wise增长策略，我们将xgb_exa的参数设成使其和其他方法增长相似的树。我们也可以通过调整参数使其在所有的数据集上能在速度和准确率上面达到平衡。我们在Allstate, KDD10 和 KDD12上设定a=0.05,b=0.05，并且在Flight Delay 和 LETOR上设定a = 0.1; b = 0.1。我们对于EFB设定$\gamma = 0$。所有的算法都运行固定的线程数，并且我们从迭代过程中获取最好的分数的准确率结果。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/lgbm4.JPG" alt="training curves"></p><p>训练时间和测试准确率分别汇总在表2和表3中。从这些结果中，我们能够看到在于基准线保持几乎相同准确率的时候是最快速的。xgb_exa是基于预排序的算法，这相对于基于直方图的算法是非常慢的。相对于lgb_baseline，LightGBM在Allstate, Flight Delay, LETOR, KDD10 和 KDD12数据集上分别加速了21，6，1.6，14和13倍。因xgb_his非常消耗内存，导致其在KDD10 和 KDD12数据集上内存溢出而不能成功运行。在剩下的数据集上，LightGBM都是最快的，最高是在Allstate数据集上加速了9倍。由于所有的算法都在差不多的迭代次数后收敛了，所以加速是基于平均每次迭代时间计算得到的。为了展示整个训练过程，我们基于Flight Delay 和 LETOR的经过的时间也分别展示了训练曲线在图1和图2中。为了节省空间，我们将其他数据集的训练曲线放在了补充材料中。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/lgbm5.JPG" alt="Accuracy comparison"></p><p>在所有的数据集上，LightGBM都能够得到几乎和基准线一致的测试准确率。这表明GOSS和EFB都不会降低准确率并且能够带来显著地加速。这也与我们前面的理论分析保持一致。</p><p>LightGBM在不同的数据集上得到了不同的加速率。整体的加速结果是来自GOSS和EFB二者的联合，我们将下一部分分开讨论二者的贡献。</p><h3 id="5-2-GOSS的分析"><a href="#5-2-GOSS的分析" class="headerlink" title="5.2 GOSS的分析"></a>5.2 GOSS的分析</h3><p>首先，我们研究了GOSS的加速性能。从表2中LightGBM和EFB_only的对比来看，我们能够发现GOSS能够通过其自己在使用10%-20%的数据时候带来近2倍的加速。GOSS能够紧紧使用抽样数据进行学习树。然而，它依然保留了一些在全部数据集上的一些计算，例如预测和计算梯度。因此，我们能够发现整体的加速相对于抽样数据的百分比并不是线性的。然而，GOSS带来的加速又是非常显著地，并且这一技术可以普遍的应用在不同的数据集上。</p><p>第二，我们通过和SGB（随机梯度提升）对比评估了GOSS的准确率。为了没有泛化性的损失，我们使用LETOR数据集来进行测试。我们通过选择GOSS中不同的a和b值来设定抽样率，并且在SGB上使用同样的整体抽样率。我们使用这些设定运行并且使用early stopping直到其收敛。结果如表4所示。我们能够看到但我们使用相同的抽样率的时候GOSS的准确率总是比SGB要好。这一结果和我们3.2部分的讨论保持一致。所有的实验结果都表明了GOSS相比于随机抽样是一个更有效的抽样方法。</p><h3 id="5-3-EFB的分析"><a href="#5-3-EFB的分析" class="headerlink" title="5.3 EFB的分析"></a>5.3 EFB的分析</h3><p>我们通过对比lgb_baseline和EFB_only来检测了EFB在加速方面的贡献。结果如表2所示。这里我们没有允许捆绑发现流程中冲突的存在（即$\gamma = 0$）。我们发现EFB能够有助于在大规模数据集上获得显著性的加速。</p><p>请注意lgb_baseline已经在系数特征上进行了优化，且EFB依然能够在训练过程中进行加速。这是因为EFB将许多稀疏特征（one-hot编码的特征和一些潜在的互斥特征）合并成了很少的特征。基础的稀疏特征优化包含在了捆绑程序中。然而，EFB在树训练过程中为每个特征维持非零数据表上没有额外的成本。而且，由于许多预先独立出的特征捆绑到了一起，它能够增加本地空间并且能够显著地改善缓存冲击率。因此，在效率上的整体改进是显著地。基于上述分析，EFB是一个非常有效能够在基于直方图的算法中充分利用稀疏性的算法，并且它能够再GBDT训练过程中带来显著性加速。</p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>在这篇文章中，我们提出了全新的GBDT算法叫做LightGBM，它包含了连个新颖的技术：Gradient-based One-Side Sampling (GOSS) 和Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）分别来处理大数据量和高维特征的场景。我们在理论分析和实验研究表明，得益于GOSS和EFB，LightGBM在计算速度和内存消耗上明显优于XGBoost和SGB。未来工作中，我们将研究在GOSS中选择a，b值的优化方案，并且继续提高EFB在高维特征上的性能，无论其是否是稀疏的。</p><p><strong>参考文章</strong><br><a href="https://blog.csdn.net/anshuai_aw1/article/details/83048709">Lightgbm源论文解析-anshuai_aw1</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf&quot;&gt;原始论文：LightGBM-A Highly Efficient Gradient Boosting Decision Tree&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;Gradient Boosting Decision Tree (GBDT)是一个非常流行的机器学习算法，却只有像XGBoost和pGBRT的一些实现。尽管许多工程上的优化方案已经在这些实现中应用了，但是当特征维度较高和数据量巨大的时候，仍然存在效率和可扩展性的问题。一个主要原因就是对于每一个特征的每一个分裂点，都需要遍历全部数据计算信息增益，这一过程非常耗时。针对这一问题，本文提出两种新方法：Gradient-based One-Side Sampling (GOSS) 和Exclusive Feature Bundling (EFB)（基于梯度的one-side采样和互斥的特征捆绑）。在GOSS中，我们排除了一部分重要的具有小梯度实例数据的比例，只用剩下的来估计信息增益。我们证明，这些梯度大的实例在计算信息增益中扮演重要角色，GOSS可以用更小的数据量对信息增益进行相当准确的估计。对于EFB，我们捆绑互斥的特征（例如，特征间很少同时非零的特征），来降低特征的个数。我们完美地证明了捆绑互斥特征是NP难的，但贪心算法能够实现相当好的逼近率，因此我们能够在不损害分割点准确率许多的情况下，有效减少特征的数量。（牺牲一点分割准确率降低特征数量），这一算法命名为LightGBM。我们在多个公共数据集实验证明，LightGBM加速了传统GBDT训练过程20倍以上，同时达到了几乎相同的精度。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="LightGBM" scheme="https://www.xiemingzhao.com/tags/LightGBM/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客提交链接到搜索引擎来收录</title>
    <link href="https://www.xiemingzhao.com/posts/HexoblogSE.html"/>
    <id>https://www.xiemingzhao.com/posts/HexoblogSE.html</id>
    <published>2019-06-14T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.653Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>博客的搭建和个性化可以参考我的其他文章<a href="https://www.xiemingzhao.com/tags/Hexo/">Hexo搭建博客汇总</a>。当你博客搭建完毕后，如果不能被人搜索得到，心里难免会有些失落。所以，接下来我们介绍 Google 和百度收录博客网站的方法。整体来说，Google 实在是太效率了，收录操作不仅简单且迅速，基本一个小时内就可以检索了。相比之下，百度搜索则鸡肋的很，不仅操作繁杂，而且及时操作成功了收录成功与否还去取决于网站质量以及其其他原因。</p><p><strong>首先如何检测自己的博客能否被检索呢？</strong><br>在百度或者Google的搜索框内输入以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">site:www.xiemingzhao.com</span><br></pre></td></tr></table></figure><p>将<code>site:</code>后面的网址改为你自己的博客地址就行了，如果在搜索结果中能够展示自己博客的页面，那么就说已经被收录且可被搜索到。反之，则没有被收录。</p><span id="more"></span><h2 id="Google-收录"><a href="#Google-收录" class="headerlink" title="Google 收录"></a>Google 收录</h2><p>搜索网站的收录，其实就是将网站里各个网页对应的连接收录。所以，有一个东西就叫做站点地图，顾名思义，就是将自己网站下所有的页面集中到一起。</p><h3 id="安装站点地图"><a href="#安装站点地图" class="headerlink" title="安装站点地图"></a>安装站点地图</h3><p>我们需要安装以下插件来生成站点地图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save  </span><br></pre></td></tr></table></figure><p>可以看得出来，上面包含两个工具包，因为后面也是进行百度收录，而百度的站点地图格式与Google是有差异的，所以一次性将这两个全都安装了。</p><p>然后我们打开站点配置文件，找到或者添加如下的配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#hexo sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br><span class="line">baidusitemap:</span><br><span class="line">  path: baidusitemap.xml</span><br></pre></td></tr></table></figure><p><em>实际上，在操作中发现只要保留上面的<code>sitemap</code>配置，省略下面的也能生成两个</em></p><p>到此，后面再部署博客的时候，你会发现<code>public</code>目录下面多了 <code>sitemap.xml</code> 和 <code>baidusitemap.xml</code> 两个文件，同样的在线上也可添加这个页面，例如我的就是<a href="https://www.xiemingzhao.com/sitemap.xml">我的站点地图</a>。</p><blockquote><p>注意：</p><ol><li>插件生成的 sitemap 的文章链接，都是以站点配置文件中的 url 为基础的，如果将博客绑定了域名，那最好将 url 字段填写为绑定的域名。</li><li>不想生成 sitemap 的页面，可在页面最上方以 —- 分割的区域内，即 Front-matter 中，添加代码 sitemap: false。</li></ol></blockquote><h3 id="添加-robots-txt"><a href="#添加-robots-txt" class="headerlink" title="添加 robots.txt"></a>添加 robots.txt</h3><blockquote><p>robots.txt（统一小写）是一种存放于网站根目录下的 ASCII 编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。</p></blockquote><p>在 <code>source</code> 目录下增加 <code>robots.txt</code> 文件， 我的文件具体内容如下可供参考，注意将域名改为自己的网站：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: /</span><br><span class="line">Allow: /archives/</span><br><span class="line">Allow: /tags/</span><br><span class="line">Allow: /categories/</span><br><span class="line">Allow: /about/</span><br><span class="line">Allow: /guestbook/</span><br><span class="line">Allow: /others/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disallow: /js/</span><br><span class="line">Disallow: /css/</span><br><span class="line">Disallow: /lib/</span><br><span class="line"></span><br><span class="line">Sitemap: https://www.xiemingzhao.com/sitemap.xml</span><br><span class="line">Sitemap: https://www.xiemingzhao.com/baidusitemap.xml</span><br></pre></td></tr></table></figure><p>这样在下次部署博客时，<code>robots.txt</code> 就会被上传至网站了。稍后我们在提交 <code>sitemap</code> 时，可以顺便测试它是否被搜索引擎正确解析了。</p><h3 id="提交站点到-Google"><a href="#提交站点到-Google" class="headerlink" title="提交站点到 Google"></a>提交站点到 Google</h3><p>我们打开<a href="https://www.google.com/webmasters/tools/home?hl=zh-CN">Google 的站点平台</a>。你会看到如下页面，紧接着就是注册和登录，你有账号的话直接登录都可以。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/hexoBlog/HexoblogSE1.jpg" alt="se1"></p><p>紧接着，点击左上角的<code>添加资源</code>，开始验证自己的博客网站，你会看到如下页面，这里建议选择第二个，直接诸如博客站点的主链接就行了，例如我的就是<code>https://www.xiemingzhao.com</code>。点击继续后，需要你做一个很简单的验证方式，那就是将验证<code>html</code>文件下周下来之后放到自己博客站点的根目录上，然后可以部署一下。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/hexoBlog/HexoblogSE2.jpg" alt="se2"></p><p>之后回到验证的页面，点击验证即可，验证程刚后，就可以对你的博客站点进行站点地图的提交了。我们点击左侧的<code>站点地图</code>选项，你会看到如下的页面，在这里输入前面构建好的<code>sitemap</code>的地址再提交就可以了。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/hexoBlog/HexoblogSE3.jpg" alt="se3"></p><p>到这里就完成了 Google 的检索收录，是不是超级简单。稍等一段时间，就可以去Google上面进行测试自己的博客站点，我的在一个小时内就已经能够检索到了。</p><h2 id="百度的收录"><a href="#百度的收录" class="headerlink" title="百度的收录"></a>百度的收录</h2><p>百度的收录相比对Google要复杂的多，首先需要注册<a href="https://ziyuan.baidu.com">百度站长平台</a>。目前，账号需要绑定熊掌号才可以，因为熊掌号是百度的资源实名认证和管理的方法，不过对于我们来说确实麻烦了好多。这一些都很简单，就是费一些时间，当你实名认证并且绑定好账号之后，让我们开始下面的提交收录。</p><p>这里附上<a href="https://ziyuan.baidu.com/college/courseinfo?id=267&amp;page=2">百度站长工具平台使用帮助手册</a>，如果你有兴趣深入研究，可以仔细研究一下这个手册，里面基本上包含了各种坑的解决方法，缺点就是繁琐。</p><h3 id="验证网站"><a href="#验证网站" class="headerlink" title="验证网站"></a>验证网站</h3><p>首先需要的就是验证网站，我们进入<a href="https://ziyuan.baidu.com/site/siteadd">站点管理</a>，添加自己的博客站点地址，然后一步一步往下点，会有一些让你选择与你博客有关系的问题，客观的选择就可以了。</p><p>直到最后一步，网站的验证，如下所示，百度的验证有很多种方案，但我们跟上述Google一样，选择文件验证，方便又高效，下载对应的<code>html</code>文件，放入博客的根目录，部署后，访问一下试试，可以的话，回到验证页面，点击验证即可完成，基本上没什么难度。</p><blockquote><p>百度站长平台提供三种验证方式（百度统计的导入方式已下线）：文件验证、html标签验证、CNAME验证。<br>1.文件验证：您需要下载验证文件，将文件上传至您的服务器，放置于域名根目录下。<br>2.html标签验证：将html标签添加至网站首页html代码的<head>标签与</head>标签之间。<br>3.CNAME验证：您需要登录域名提供商或托管服务提供商的网站，添加新的DNS记录。</p></blockquote><h3 id="链接提交"><a href="#链接提交" class="headerlink" title="链接提交"></a>链接提交</h3><p>接下来最终要就是这一步，但也是最复杂方法最多的，不着急我们慢慢来。首先，进入站长平台，然后进入<code>网页抓取</code>目录下的<code>链接提交</code>页面，我们可以看到如下图，数据提交方式下面紧邻的是提交连接数量，目前你可得是没有的。再往下，你会发现有两个模块，分别是<code>自动提交</code>和<code>手动提交</code>。</p><p>其中收到提交点击去可以发现是需要你将你需要被检索的网站一个一个的列出来才行，这种笨方法当然不是我们要选择的。让我们回来看自动提交下面，分为三种方法，其中主动推送(实时)又分为四中示例，整个结构如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">链接提交：</span><br><span class="line">    手动提交</span><br><span class="line">    自动提交：</span><br><span class="line">        主动推送（实时）：</span><br><span class="line">            curl推送</span><br><span class="line">            post推送</span><br><span class="line">            php推送</span><br><span class="line">            ruby推送</span><br><span class="line">        自动推送</span><br><span class="line">        sitemap</span><br></pre></td></tr></table></figure><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/hexoBlog/HexoblogSE4.jpg" alt="se4"></p><h3 id="sitemap-提交"><a href="#sitemap-提交" class="headerlink" title="sitemap 提交"></a>sitemap 提交</h3><p>在上面，我们已经构建了<code>baidusitemap</code>了，在这里当然要使用了。我们选择自动提交中的<code>sitemap</code>，输入自己的<code>baidusitemap.xml</code>链接即可，一般都是自己的域名加上这个，例如我的就是<a href="https://www.xiemingzhao.com/baidusitemap.xml">https://www.xiemingzhao.com/baidusitemap.xml</a>。提交完成后可查看是否成功。</p><blockquote><p>注意：和谷歌不同，百度翻译速度很慢，而且百度提交了链接也不一定收录，要不断提升文章质量和数量才行。</p></blockquote><h3 id="百度相关的搜索配置"><a href="#百度相关的搜索配置" class="headerlink" title="百度相关的搜索配置"></a>百度相关的搜索配置</h3><p>由于 GitHub 屏蔽了百度的爬虫，即使提交成功，百度知道这里有可供抓取的链接，也不一定能抓取成功。首先我们先检测一下百度爬虫是否可以抓取网页。在百度站长平台<code>网页抓取</code>-&gt;<code>抓取诊断</code> 中，选择<code>PC UA</code>点击抓取，查看抓取状态，如果显示<code>抓取失败</code>，则需要进一步的配置。</p><p>可以测试一下<code>移动 UA</code>，因为一般这个一定是会成功的。</p><h3 id="主动推送和自动推送"><a href="#主动推送和自动推送" class="headerlink" title="主动推送和自动推送"></a>主动推送和自动推送</h3><p>我们讲过，百度<code>sitemap</code>的提交不一定能够成功，而且即使成功效率也低。百度本身也不提倡，所以还有另两种方案。</p><p>在前面提到的百度站长手册中，有讲解这一切，包括如何选择链接提交方式</p><blockquote><p>1、主动推送：最为快速的提交方式，推荐您将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。<br>2、自动推送：最为便捷的提交方式，请将自动推送的 JS 代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。<br>3、sitemap：您可以定期将网站链接放到 sitemap 中，然后将 sitemap 提交给百度。百度会周期性的抓取检查您提交的 sitemap，对其中的链接进行处理，但收录速度慢于主动推送。<br>4、手动提交：一次性提交链接给百度，可以使用此种方式</p></blockquote><h4 id="自动推送"><a href="#自动推送" class="headerlink" title="自动推送"></a>自动推送</h4><p>next 主题已经部署了自动推送的代码，我们只需在主题配置文件 中找到 <code>baidu_push</code> 字段 , 设置其为 true 即可。</p><h4 id="主动推送（实时）"><a href="#主动推送（实时）" class="headerlink" title="主动推送（实时）"></a>主动推送（实时）</h4><p>这个方案好处在于成功率大，且具有实时性。可以参考这篇文章<a href="https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/"> Hexo 插件之百度主动提交链接</a>。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/hexoBlog/HexoblogSE5.jpg" alt="se5"></p><p>首先我们在如上图中找到自己的秘钥，保存留用。紧接着，我们需要安装以下插件：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-baidu-url-submit --save</span><br></pre></td></tr></table></figure></p><p>然后，同样在根目录下，把以下内容配置到_config.yml文件中:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">baidu_url_submit:</span><br><span class="line">  count: 1 ## 提交最新的一个链接</span><br><span class="line">  host: www.hui-wang.info ## 在百度站长平台中注册的域名</span><br><span class="line">  token: your_token ## 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里!</span><br><span class="line">  path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里</span><br></pre></td></tr></table></figure><p>其次，记得查看_config.ym文件中url的值，必须包含是百度站长平台注册的域名（一般有www）， 比如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># URL</span><br><span class="line">url: http://www.hui-wang.info</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br></pre></td></tr></table></figure><p>最后，加入新的deployer:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">- type: s3 ## 这是我原来的deployer</span><br><span class="line">  bucket: hui-wang.info</span><br><span class="line">- type: baidu_url_submitter ## 这是新加的</span><br></pre></td></tr></table></figure><p>执行hexo deploy的时候，新的连接就会被推送了。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>推送功能的实现，分为两部分：</p><ul><li>新链接的产生， hexo generate 会产生一个文本文件，里面包含最新的链接</li><li>新链接的提交， hexo deploy 会从上述文件中读取链接，提交至百度搜索引擎</li></ul><blockquote><p>注意：</p><ol><li>百度每天主动提交的链接数量是有限制的。<br>（主动推送可提交的链接数量上限是根据您提交的新产生有价值链接数量而决定的，百度会根据您提交数量的情况不定期对上限额进行调整，提交的新产生有价值链接数量越多，可提交链接的上限越高。）</li><li>主动推送是否成功会在执行 hexo deploy 时显示, success后的数字为主动推送成功的链接数。</li></ol></blockquote><p><strong>附录</strong><br>其实，这些提交方法可以混合使用，最痛苦的是，及时提交成功了，要等好久也不知道自己的博客能否被收录。所以百度收录真的很鸡肋，比较注重网站的质量。</p><p>于是催生了另一种方案，那就是在 <code>Coding.net</code> 上进行镜像部署。这是利用 Coding.net 提供的 Coding Pages 功能另外部署一个镜像，让百度爬虫访问此镜像，普通用户还是访问位于 Github Pages 的页面。具体的这里就不在介绍，可以参考夏明额参考文章或者其他博主的文章。</p><p><strong>参考文章</strong><br><a href="http://www.yuan-ji.me/Hexo-%E4%BC%98%E5%8C%96%EF%BC%9A%E6%8F%90%E4%BA%A4sitemap%E5%8F%8A%E8%A7%A3%E5%86%B3%E7%99%BE%E5%BA%A6%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96-GitHub-Pages-%E9%97%AE%E9%A2%98/">Hexo 优化：提交 sitemap 及解决百度爬虫无法抓取 GitHub Pages 链接问题</a><br><a href="https://www.jianshu.com/p/1ff2fcbdd155">Hexo博客第三方主题next进阶教程</a><br><a href="https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/">Hexo插件之百度主动提交链接</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;博客的搭建和个性化可以参考我的其他文章&lt;a href=&quot;https://www.xiemingzhao.com/tags/Hexo/&quot;&gt;Hexo搭建博客汇总&lt;/a&gt;。当你博客搭建完毕后，如果不能被人搜索得到，心里难免会有些失落。所以，接下来我们介绍 Google 和百度收录博客网站的方法。整体来说，Google 实在是太效率了，收录操作不仅简单且迅速，基本一个小时内就可以检索了。相比之下，百度搜索则鸡肋的很，不仅操作繁杂，而且及时操作成功了收录成功与否还去取决于网站质量以及其其他原因。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;首先如何检测自己的博客能否被检索呢？&lt;/strong&gt;&lt;br&gt;在百度或者Google的搜索框内输入以下内容：&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;site:www.xiemingzhao.com&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;将&lt;code&gt;site:&lt;/code&gt;后面的网址改为你自己的博客地址就行了，如果在搜索结果中能够展示自己博客的页面，那么就说已经被收录且可被搜索到。反之，则没有被收录。&lt;/p&gt;</summary>
    
    
    
    <category term="博客搭建" scheme="https://www.xiemingzhao.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
    <category term="Hexo" scheme="https://www.xiemingzhao.com/tags/Hexo/"/>
    
    <category term="网站收录" scheme="https://www.xiemingzhao.com/tags/%E7%BD%91%E7%AB%99%E6%94%B6%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>Wide and Deep Learning for Recommender Systems (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/e59f436c.html"/>
    <id>https://www.xiemingzhao.com/posts/e59f436c.html</id>
    <published>2019-06-11T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.656Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;hl=zh-CN&amp;sa=X&amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;nossl=1&amp;oi=scholarr">原始论文：Wide &amp; Deep Learning for Recommender Systems</a></p><h2 id="推荐系统之Wide-amp-Deep机器学习算法"><a href="#推荐系统之Wide-amp-Deep机器学习算法" class="headerlink" title="推荐系统之Wide &amp; Deep机器学习算法"></a>推荐系统之Wide &amp; Deep机器学习算法</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个<em>宽的</em>交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。</p><p><strong>关键词</strong>  Wide &amp; Deep学习，推荐系统</p><span id="more"></span><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a><strong>1. 介绍</strong></h3><p>一个推荐系统可以被看作是一个搜索排序系统，其中输入的请求是一个用户和上下文信息的集合，输出则是一个物品列表的排序。给定一个请求，推荐系统的任务就是在数据集中找到相关的物品，并且根据一定的目标，例如点击和购买，将所有的项目进行排序。</p><p>推荐系统的一个挑战是类似于一版的搜索排序问题，就是同时实现记忆和泛化的能力。记忆可以被宽泛地定义为学习物品或特征的频繁共现，并且开发历史数据中可用的相关性。另一方面，泛化是基于相关性的传递性和探索从来没有或很少发生在过去的新特征组合。推荐是基于记忆的，通常更具局部性并且与那些用户已经对其产生过行为的物品直接相关。与记忆相比，泛化倾向于改善推荐物品的多样性。在本文中，我们关注Google Play商店中应用程序推荐的问题，但方法应该适用于通用推荐系统。</p><p>对于工业环境中的大规模在线推荐和排序系统，一般的线性模型例如逻辑回归都是被广泛使用的，因为它们是简单，可扩展和可解释的。模型经常是使用one-hot编码的二值化稀疏特征进行训练的。例如，二进制特征“user_installed_app = netflix”，如果用户安装了Netflix那么该特征具有值1。使用通过对稀疏特征进行交叉积变化可以有效地实现记忆功能，例如AND（user_installed_app = netflix，impres-sion_app = pandora），如果用户安装了Netflix后有显示了Pandora，则其值为1。这解释了特征对的共现与目标标签有多么的相关。泛化功能是可以通过使用那些颗粒度较小的特征来添加的，例如AND（user_installed_category = video，impression_category =music），但手动特征工程常常还是需要的。交叉积变化的一个限制是他们没有办法泛化出那些没有出现在训练数据中的请求-物品特征对。</p><p>基于嵌入的模型，例如因式分解机或深度神经网络，可以通过对每个请求和物品特征学习出一个低维的嵌入向量来泛化出那些看不到的请求-物品特征对，如此可以减少特征工程的负担。然而，当底层的请求-物品矩阵是稀疏和高秩的时候，想要学习出一个有效的请求和物品的低维表示是非常困难的，例如具有特定偏好的用户或具有狭隘吸引力的商机物品。在这种情况下它与大多数的查询项对之间都是没有交互的，但密集的嵌入将会导致对所有的查询-物品对都有一个非零预测，因此可以过度泛化从而产生不相关的推荐。另一方面，有交叉积特征变换的线性模型在不用特别多参数的情况下可以记住这种“特殊规则”。</p><p>在本文中，我们提出Wide &amp; Deep学习框架来在同一个模型中同时完成记忆和泛化的任务，如图1所示，它是通过联合训练出一个线性模型和一个神经网络模型。</p><p>这篇文章的主要贡献包括：</p><ul><li>Wide &amp; Deep学习框架是通过联合训练一个有嵌入层的前向神经网络和一个有特征变换的线性模型，如此可以得到一个基于稀疏输入的一般推荐系统模型。</li><li>Wide &amp; Deep推荐系统的实现和评估是在Google Play上完成的，它是一个移动应用程序商店，其上拥有超过十亿的活跃用户和超过一百万的应用程序。</li><li>我们提供了一个开源的实现，它是通过TensorFlow中的一个高级API实现的。</li></ul><p>尽管思想很简单，我们还是证明了Wide &amp; Deep框架极大地提升了移动应用商店的app下载率，并且同时满足训练和高速服务的需求。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/wide%26deep_1.JPG" alt="wide&amp;deep-1"></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/wide%26deep_2.JPG" alt="wide&amp;deep-2"></p><h3 id="2-推荐系统概述"><a href="#2-推荐系统概述" class="headerlink" title="2. 推荐系统概述"></a><strong>2. 推荐系统概述</strong></h3><p>图2显示了app推荐系统的概述。一个查询，可以包括各种用户和用户访问应用商店时会生成的上下文特征。推荐系统返回应用列表（也被称为展示），在这上面用户可以执行一些特定的行为例如点击或购买。这些用户操作，随着查询和展示，都记录在日志中，作为模型的训练数据。</p><p>由于数据库中有超过一百万的应用，在查询服务的潜在要求（经常是O(10)毫秒）的条件下，为每个查询都对所有的应用进行打分是难以实现的。因此，在收到一个查询后的第一步是<em>检索</em>。检索系统返回一个较短的物品列表，这个列表是使用各种特征对请求的最好匹配，通常是机器学习模型和人为定义规则的一个联合。在降低了候选池之后，排序系统会通过它们打出的分数对所有物品进行排序。这个得分经常是$P(y|x)$，它是表示给定特征x后的定于行为标签y的概率，其中x包括用户的特征（例如国家、语言、人口统计学指标），上下文特征（例如设备、一天中的第几个小时、周几），还有展示特征（例如应用年龄、应用的历史统计）。在本文中，我们聚焦于使用Wide &amp; Deep学习框架的排序模型。</p><h3 id="3-Wide-amp-Deep学习"><a href="#3-Wide-amp-Deep学习" class="headerlink" title="3. Wide &amp; Deep学习"></a><strong>3. Wide &amp; Deep学习</strong></h3><p><strong>3.1 Wide部分</strong><br>宽模型部分是一个广义线性模型，形式一般为$y = w^T x+b$，如图1左侧所示。y是预测，$x=[x_1,x_2,…,x_d]$是一个d维特征的向量，$w=[w_1,w_2,…w_d]$是模型参数且b是偏置项。特征集合包含原始输入的特征以及经过转换的特征。一个最终演的变换就是<em>交叉积变换</em>，如下定义：</p><script type="math/tex; mode=display">\phi_k(x)=\prod_{i=1}^d x_i^{c_{ki}} \ , \ c_{ki} \ \in \ \{0,1\}</script><p>其中$c_{ki}$是一个布尔变量，也就是如果第i个特征是第k个变换$\phi_k$的一部分则其取值为1，否则是0。对于二值特征，当且仅当交叉项的组成特征（例如“gender=female” and “language=en”）全部是1的时候交叉积变换（例如“AND(gender=female, language=en)”）才是1，否则就是0。这就获得了二值特征的交叉项，并且往广义线性模型中增加了非线性。</p><p><strong>3.2 Deep部分</strong><br>深模型部分是一个前向神经网络，如图1中右侧所示。对于类别特征，原始输入是特征字符串（例如“language=en”）。每个这种稀疏、高维类别特征都会首先被转换成一个低维并且稠密的实值向量，通常被称为嵌入向量。嵌入层的维度一般在O(10)到O(100)。嵌入向量会被随机的初始化，然后其值会在训练过程中通过最小化最终损失函数来训练。这些低维的稠密嵌入向量会被喂入神经网络前向通过的隐含层中。特别地，每个隐含层的计算是：</p><script type="math/tex; mode=display">a^{l+1} = f(W^{(l)}a^{(l)} + b^{(l)})</script><p>其中l是层数，f是激活函数，经常被设成整数线性单元(ReLUs)。$a^{(l)}, b^{(l)}和W^{(l)}$分别是激活项、偏置项和模型第l层的权重项。</p><p><strong>3.3 Wide &amp; Deep模型的联合训练</strong><br>宽模型部分和深模型部分会被用加权求和联合到一起，然后输出部分会进行对数概率变换后作为预测结果，在这之后一般会喂入一个普通的逻辑损失函数中进行联合训练。注意到<em>联合训练</em>和<em>合并</em>之间是有区别的。合并，一般是每个模型独自分开训练互不干扰，他们的预测结果只在推断的时候才会联合，训练过程中并不会。相反，联合训练会同时优化所有的参数，是通过在训练的过程中汇总获取宽模型和深模型的所有参数进行计算。模型大小的含义：对于模型合并，由于训练是分开的，每个单独的模型大小通常需要比较的大（例如有特别多的特征和变换）从而来得到<br>一个合理准确的起作用的模型合并。相比之下，对于联合训练中的宽模型部分只需要去实现深度模型的弱势部分就可以了，所以它有一个很小量级的交叉积特征变换，而不是一个全量的宽模型。</p><p>Wide &amp; Deep模型的联合训练是通过使用小批量随机优化从输出层同时进行宽模型和深模型的反向梯度传播来完成的。在实验中，我们使用Follow-the-regularized-leader (FTRL)算法和L1正则项作为宽模型部分的优化器，同时AdaGrad作为深度部分的优化器。</p><p>图1中间部分展示了联合模型。属于逻辑回归的问题，模型的预测结果为：</p><script type="math/tex; mode=display">P(Y=1|x)=\sigma(w_{wide}^T [x,\phi (x)] + w_{deep}^T a^{(l_f)} +b)</script><p>其中Y是二值类别标签，$\sigma(\cdot)$是sigmoid函数，$\phi(x)$是原始特征x的交叉积变换，b是偏置项。$w<em>{wide}$是宽模型权重参数向量，$w</em>{deep}$是应用在最终激活项$a^{(l_f)}$的的权重参数<br>。</p><h3 id="4-系统实现"><a href="#4-系统实现" class="headerlink" title="4. 系统实现"></a><strong>4. 系统实现</strong></h3><p>应用推荐管道的实现包含三个步骤：数据生成，模型训练，以及模型服务，如图3中所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/wide%26deep_3.JPG" alt="wide&amp;deep-3"></p><p><strong>4.1 数据生成</strong><br>在这个步骤，在一个时期的用户和应用展示数据被用来生成训练数据。每个样本对应于一次展示。标签就是应用获取：1代表展示的应用被安装了，否则为0。</p><p>词汇表，是用来将类别特征中的字符串匹配成整数型IDs的，也是在这一步骤中生成的。系统为所有的字符型特征计算IDs的空间，其中特征只计算那些出现次数超过最小次数的。连续型的实值特征会被标准化到[0,1]，方法是将特征值x匹配到该特征的累积分布函数$P(X\leq x)$，分成了$n_q$分位数。第i个分位数标准化后的值是$\frac{i-1}{n_q-1}$。分位数的边界是在数据生成过程中计算的。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/wide%26deep_4.JPG" alt="wide&amp;deep-4"></p><p><strong>4.2 模型训练</strong><br>我们在实验中使用的模型结构如图4所示。在训练中，我们的输入层接手输入数据和词汇表，然后用一个标签一起生成稀疏的和密集的特征。宽模型部分由用户安装应用和展示应用做交叉积变换得到。对于模型的深度部分，一个32维的嵌入向量是从每个类别型特征中学到的。我们将所有的嵌入向量串联在一起形成一个密集的特征，这就构成了一个接近1200维的密集向量。串联的向量接着会被喂入3个ReLU网络层，最优通过逻辑层输出单元。</p><p>Wide &amp; Deep模型是在5000亿个样本上训练得到的。每一次一个新的训练数据集到达时，模型需要被再次训练。然而，每次再训练花费的时间都是特别昂贵的计算成本同时新数据更新模型将会产生一定的延迟。为了战胜这个挑战，我们实现一个热启动的系统，它是用前一个模型的嵌入层和线性模型权重参数来初始化本次新模型。</p><p><strong>4.3 模型服务</strong><br>每一次模型被训练完成和确定之后，我们将其加载到模型服务中。对于每次请求，服务会从应用检索系统中接受到一个应用候选集和用户特征来对背个应用进行打分。然后，应用将会根据得分从高到低进行排序，我们将会按照此顺序将应用展示给用户。分数将会通过运行一个Wide &amp; Deep模型的前向推断得到。</p><p>为了在10ms的需求下服务每一次请求，我们使用多线程并行来优化表现，它是通过并行运行小批量实现的而不是在一个但线程中对所有的候选应用进行打分的。</p><h3 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a><strong>5. 实验结果</strong></h3><p>为了评估Wide &amp; Deep学习在实际推荐系统中的有效性，我们运行了一个实验并在多方面对系统进行了评估：应用获取和服务表现。</p><p><em>表1：不同模型的离线和在线的效果矩阵。在线的获取Gain值是相对于对照组的。</em></p><div class="table-container"><table><thead><tr><th style="text-align:left">Model</th><th style="text-align:center">Offline AUC</th><th style="text-align:center">Online Acqusition Gain</th></tr></thead><tbody><tr><td style="text-align:left">Wide (control)</td><td style="text-align:center">0.726</td><td style="text-align:center">0%</td></tr><tr><td style="text-align:left">Deep</td><td style="text-align:center">0.722</td><td style="text-align:center">+2.9%</td></tr><tr><td style="text-align:left">Wide &amp; Deep</td><td style="text-align:center">0.728</td><td style="text-align:center">+3.9%</td></tr></tbody></table></div><p><strong>5.1 应用获取</strong><br>我们在一个A/B测试框架中进行了3周的在线实验。对于对照组，随机选择1%的用户并使用之前的排序模型来生成推荐排序，先前的模型是一个高度优化后的仅有宽度逻辑回归的模型，它有很丰富的交叉积特征变换。对于实验组，我们随机选取另1%的用户并用Wide &amp; Deep模型来生成推荐排序，训练数据使用同样的特征集合。如表1中所示，相对于对照组，Wide &amp; Deep提高了主页面上的应用获取率大约+3.9%（统计显著）。结果也和另一1%用户组进行对比，这一组仅仅使用了深度模型结构和相同的特征，同样的Wide &amp; Deep模型有1+%的一个收益（统计显著的）。</p><p>除了线上实验，我们也展示了离线对抗集的AUC。然而Wide &amp; Deep有一个略高的离线AUC，对在线流量的影响更为显着。一个可能的原因是离线数据集的展示和标签是固定的额，而在线系统可以通过混合记忆和泛化来生成新的探索性的推荐，并且可以从新的用户反馈中学习到更多。</p><p><strong>5.2 服务表现</strong><br>在面临我们商业性移动应用商店的时候，高级别流量高吞吐量和低延迟的服务要求是一个挑战。在流量巅峰，我们的推荐服务在每秒内对超过1000万个应用进行打分。在单线程的时候，在一个单批量中对所有候选app进行打分将花费31毫秒。我们使用多线程实现，并将每一批量分成更小的批量，这显著地降低用户端延迟到14毫秒（包括服务高峰期），结果如表2所示。</p><p><em>表2：批量大小和线程个数的服务延迟对比</em></p><div class="table-container"><table><thead><tr><th style="text-align:center">Batch size</th><th style="text-align:center">Number of Threads</th><th style="text-align:center">Serving Latency (ms)</th></tr></thead><tbody><tr><td style="text-align:center">200</td><td style="text-align:center">1</td><td style="text-align:center">31</td></tr><tr><td style="text-align:center">100</td><td style="text-align:center">2</td><td style="text-align:center">17</td></tr><tr><td style="text-align:center">50</td><td style="text-align:center">4</td><td style="text-align:center">4</td></tr></tbody></table></div><h3 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6. 相关工作"></a><strong>6. 相关工作</strong></h3><p>将带有交叉积特征变换的宽线性模型和带有密集嵌入的深度神经网络模型联合到一起的想法是受到前人工作启发的，例如因式分解机这种加入了泛化能力的线性模型，它通过将两个变量之间的交叉项分解成两个变量之间的点积。在本文中，我们通过在嵌入层通过神经网络之间的时候而不是点积来学习更高地非线性交叉项从而达到扩展模型的能力。</p><p>在语言模型中，循环神经网络（RNNs）和带有n-gram特征最大熵模型的联合训练已经被提出来了，通过学习输入层和输出层之间的直接权重能够显著地降低RNN的复杂度（例如隐含层的大小）。在计算机视觉中，深度残差学习已经被用于降低训练深度模型的困难度，并且通过跨越一层或多层的捷径连接达到了提高准确率的效果。带有图模型神经网络的联合训练已经被应用在了从图片中评估人类姿势。在我们提出的这个前向神经网络和线性模型的联合训练的工作中，在稀疏特征和输出单元之间带有直接连接，这是为了通用化带有稀疏输入数据的推荐和排序问题。</p><p>在推荐系统文献中，协同深度学习已经通过结合内容信息的深度学习和评分矩阵的协同过滤被探索了。同样也有很多关于移动应用推荐系统的先前工作，例如将CF用在用户的应用使用记录上的AppJoy。不同于基于CF的或者基于内容方法的这些先前工作，我们的推荐系统是在用户和展示数据上联合训练Wide &amp; Deep模型。</p><h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a><strong>7. 结论</strong></h3><p>记忆和泛化对于推荐系统来说都很重要。宽线性模型通过使用交叉积特征变换能够有效的基于稀疏特征之间的交叉项，而深度神经网络可以通过低维嵌入层来泛化出那些重要确又看不见的特征交叉项。我们呈现的Wide &amp; Deep学习框架是为了联合这两种模型的各自长处。我们在Google Play这个大规模的商业应用商店上对我们这个框架进行了产品化和评估。在线实验的结果证明了相对于仅用宽和深度模型来说，Wide &amp; Deep模型在应用获取上带来了显著地提升。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;http://scholar.google.com.hk/scholar_url?url=https://dl.acm.org/ft_gateway.cfm%3Fid%3D2988454%26type%3Dpdf&amp;amp;hl=zh-CN&amp;amp;sa=X&amp;amp;scisig=AAGBfm0TVpSA7DpxrGGn23_Zbb27fZpvyQ&amp;amp;nossl=1&amp;amp;oi=scholarr&quot;&gt;原始论文：Wide &amp;amp; Deep Learning for Recommender Systems&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;推荐系统之Wide-amp-Deep机器学习算法&quot;&gt;&lt;a href=&quot;#推荐系统之Wide-amp-Deep机器学习算法&quot; class=&quot;headerlink&quot; title=&quot;推荐系统之Wide &amp;amp; Deep机器学习算法&quot;&gt;&lt;/a&gt;推荐系统之Wide &amp;amp; Deep机器学习算法&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;不包含非线性特征变换的一般线性模型被广泛地应用在具有稀疏输入的大规模回归和分类问题中。通过一个&lt;em&gt;宽的&lt;/em&gt;交叉积特征变换来实现对特征交叉的记忆是很有效和可解释的，而泛化能力需要更多的特征工程工作。考虑少用特征工程，深度神经网络可以更好地起到品泛化的作用，它会从稀疏的特征中学习到那些低维度看不见的密集嵌入。然而，具有嵌入的深度神经网络很容易过度泛化，并在用户-物品交互稀疏和稠密的时候会推荐一些不太相关的项物品。在本文中，我们提出广泛和深度学习——联合训练宽线性模型和深层神经网络——如此来结合记忆模型和泛化模型的好处从而构成更好的推荐系统。我们在Google Play上制作并评估了该系统，它是一个活跃的商业移动应用商店，上面超过10亿活跃用户和超过一百万个应用程序。在线实验结果表明相对于仅用wide模型和deep模型而言，Wide＆Deep显着增加了app的获取。我们也在TensorFlow中开源了我们的实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;  Wide &amp;amp; Deep学习，推荐系统&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="推荐系统" scheme="https://www.xiemingzhao.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Wide &amp; Deep" scheme="https://www.xiemingzhao.com/tags/Wide-Deep/"/>
    
  </entry>
  
  <entry>
    <title>An overview of gradient descent optimization algorithms (论文解析)</title>
    <link href="https://www.xiemingzhao.com/posts/eafa0d01.html"/>
    <id>https://www.xiemingzhao.com/posts/eafa0d01.html</id>
    <published>2019-06-10T16:00:00.000Z</published>
    <updated>2025-01-12T12:48:46.652Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://ruder.io/optimizing-gradient-descent/">原始论文：An overview of gradient descent optimization algorithms</a></p><h2 id="梯度下降优化算法综述"><a href="#梯度下降优化算法综述" class="headerlink" title="梯度下降优化算法综述"></a>梯度下降优化算法综述</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。</p><h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1 引言</strong></h3><p>梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。</p><span id="more"></span><p>本文旨在让读者对不同的优化梯度下降的算法有直观的认识，以帮助读者使用这些算法。在第2部分，我们首先介绍梯度下降的不同变形形式。在第3部分，我们将简要总结在训练的过程中所面临的挑战。随后，在第4部分，我们将介绍最常用的优化算法，包括这些算法在解决以上挑战时的动机以及如何得到更新规则的推导形式。在第5部分，我们将简单讨论在并行和分布式环境中优化梯度下降的算法和框架。最后，在第6部分，我们将思考对优化梯度下降有用的一些其他策略。</p><p>梯度下降法是最小化目标函数$J(\theta)$的一种方法，其中，$θ \in \mathbb R^d$为模型参数，梯度下降法利用目标函数关于参数的梯度$\triangledown_{\theta}J(\theta)$的反方向更新参数。学习率$\eta$决定达到最小值或者局部最小值过程中所采用的步长的大小。即，我们沿着目标函数的斜面下降的方向，直到到达谷底。如果你对梯度下降法不熟悉，你可以从<a href="http://cs231n.github.io/optimization-1/">此处资料</a>找到介绍神经网络优化的材料。</p><h3 id="2-梯度下降法的变形形式"><a href="#2-梯度下降法的变形形式" class="headerlink" title="2 梯度下降法的变形形式"></a><strong>2 梯度下降法的变形形式</strong></h3><p>梯度下降法有3中变形形式，它们之间的区别为我们在计算目标函数的梯度时使用到多少数据。根据数据量的不同，我们在参数更新的精度和更新过程中所需要的时间两个方面做出权衡。</p><h4 id="2-1-批梯度下降法"><a href="#2-1-批梯度下降法" class="headerlink" title="2.1 批梯度下降法"></a><strong>2.1 批梯度下降法</strong></h4><p>Vanilla梯度下降法，又称为批梯度下降法（batch gradient descent），在整个训练数据集上计算损失函数关于参数$\theta$的梯度：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta)</script><p>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，同时，批梯度下降法无法处理超出内存容量限制的数据集。批梯度下降法同样也不能在线更新模型，即在运行的过程中，不能增加新的样本。</p><p>批梯度下降法的代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs):</span><br><span class="line">    params_grad = evaluate_gradient(loss_function, data, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure><br>对于给定的迭代次数，首先，我们利用全部数据集计算损失函数关于参数向量params的梯度向量params_grad。注意，最新的深度学习库中提供了自动求导的功能，可以有效地计算关于参数梯度。如果你自己求梯度，那么，梯度检查是一个不错的主意（关于如何正确检查梯度的一些技巧可以参见<a href="http://cs231n.github.io/neural-networks-3/">此处资料</a>）。</p><p>然后，我们利用梯度的方向和学习率更新参数，学习率决定我们将以多大的步长更新参数。对于凸误差函数，批梯度下降法能够保证收敛到全局最小值，对于非凸函数，则收敛到一个局部最小值。</p><h4 id="2-2-随机梯度下降法"><a href="#2-2-随机梯度下降法" class="headerlink" title="2.2 随机梯度下降法"></a><strong>2.2 随机梯度下降法</strong></h4><p>相反，随机梯度下降法（stochastic gradient descent, SGD）根据每一条训练样本$x^{(i)}$和标签$y^{(i)}$更新参数：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i)};y^{(i)})</script><p>对于大数据集，因为批梯度下降法在每一个参数更新之前，会对相似的样本计算梯度，所以在计算过程中会有冗余。而SGD在每一次更新中只执行一次，从而消除了冗余。因而，通常SGD的运行速度更快，同时，可以用于在线学习。SGD以高方差频繁地更新，导致目标函数出现如图1所示的剧烈波动。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/optimizer-01.JPG" alt="optimizer-01.jpg"></p><p>与批梯度下降法的收敛会使得损失函数陷入局部最小相比，由于SGD的波动性，一方面，波动性使得SGD可以跳到新的和潜在更好的局部最优。另一方面，这使得最终收敛到特定最小值的过程变得复杂，因为SGD会一直持续波动。然而，已经证明当我们缓慢减小学习率，SGD与批梯度下降法具有相同的收敛行为，对于非凸优化和凸优化，可以分别收敛到局部最小值和全局最小值。与批梯度下降的代码相比，SGD的代码片段仅仅是在对训练样本的遍历和利用每一条样本计算梯度的过程中增加一层循环。注意，如6.1节中的解释，在每一次循环中，我们打乱训练样本。</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for example in data:        params_grad = evaluate_gradient(loss_function, example, params)        params = params - learning_rate * params_grad</code></pre><h4 id="2-3-小批量梯度下降法"><a href="#2-3-小批量梯度下降法" class="headerlink" title="2.3 小批量梯度下降法"></a><strong>2.3 小批量梯度下降法</strong></h4><p>小批量梯度下降法最终结合了上述两种方法的优点，在每次更新时使用n个小批量训练样本：</p><script type="math/tex; mode=display">\theta = \theta - \eta \cdot \triangledown_{\theta}J(\theta;x^{(i:i+n)};y^{(i:i+n)})</script><p>这种方法，a)减少参数更新的方差，这样可以得到更加稳定的收敛结果；b)可以利用最新的深度学习库中高度优化的矩阵优化方法，高效地求解每个小批量数据的梯度。通常，小批量数据的大小在50到256之间，也可以根据不同的应用有所变化。当训练神经网络模型时，小批量梯度下降法是典型的选择算法，当使用小批量梯度下降法时，也将其称为SGD。注意：在下文的改进的SGD中，为了简单，我们省略了参数$x^{(i:i+n)};y^{(i:i+n)}$。</p><p>在代码中，不是在所有样本上做迭代，我们现在只是在大小为50的小批量数据上做迭代：</p><pre><code class="lang-python">for i in range(nb_epochs):    np.random.shuffle(data)    for batch in get_batches(data, batch_size=50):        params_grad = evaluate_gradient(loss_function, batch, params)        params = params - learning_rate * params_grad</code></pre><h3 id="3-挑战"><a href="#3-挑战" class="headerlink" title="3 挑战"></a><strong>3 挑战</strong></h3><p>虽然Vanilla小批量梯度下降法并不能保证较好的收敛性，但是需要强调的是，这也给我们留下了如下的一些挑战：</p><p>选择一个合适的学习率可能是困难的。学习率太小会导致收敛的速度很慢，学习率太大会妨碍收敛，导致损失函数在最小值附近波动甚至偏离最小值。<br>学习率调整[17]试图在训练的过程中通过例如退火的方法调整学习率，即根据预定义的策略或者当相邻两代之间的下降值小于某个阈值时减小学习率。然而，策略和阈值需要预先设定好，因此无法适应数据集的特点[4]。<br>此外，对所有的参数更新使用同样的学习率。如果数据是稀疏的，同时，特征的频率差异很大时，我们也许不想以同样的学习率更新所有的参数，对于出现次数较少的特征，我们对其执行更大的学习率。<br>高度非凸误差函数普遍出现在神经网络中，在优化这类函数时，另一个关键的挑战是使函数避免陷入无数次优的局部最小值。Dauphin等人[5]指出出现这种困难实际上并不是来自局部最小值，而是来自鞍点，即那些在一个维度上是递增的，而在另一个维度上是递减的。这些鞍点通常被具有相同误差的点包围，因为在任意维度上的梯度都近似为0，所以SGD很难从这些鞍点中逃开。</p><h3 id="4-梯度下降优化算法"><a href="#4-梯度下降优化算法" class="headerlink" title="4 梯度下降优化算法"></a><strong>4 梯度下降优化算法</strong></h3><p>下面，我们将列举一些算法，这些算法被深度学习社区广泛用来处理前面提到的挑战。我们不会讨论在实际中不适合在高维数据集中计算的算法，例如诸如牛顿法的二阶方法。</p><h4 id="4-1-动量法"><a href="#4-1-动量法" class="headerlink" title="4.1 动量法"></a><strong>4.1 动量法</strong></h4><p>SGD很难通过陡谷，即在一个维度上的表面弯曲程度远大于其他维度的区域[19]，这种情况通常出现在局部最优点附近。在这种情况下，SGD摇摆地通过陡谷的斜坡，同时，沿着底部到局部最优点的路径上只是缓慢地前进，这个过程如图2a所示。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/optimizer-02.JPG" alt="optimizer-02.jpg"></p><p>如图2b所示，动量法[16]是一种帮助SGD在相关方向上加速并抑制摇摆的一种方法。动量法将历史步长的更新向量的一个分量$\gamma$增加到当前的更新向量中（部分实现中交换了公式中的符号）</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta) \\\theta = \theta - v_t</script><p>动量项$\gamma$通常设置为0.9或者类似的值。</p><p>从本质上说，动量法，就像我们从山上推下一个球，球在滚下来的过程中累积动量，变得越来越快（直到达到终极速度，如果有空气阻力的存在，则$\gamma&lt;1$）。同样的事情也发生在参数的更新过程中：对于在梯度点处具有相同的方向的维度，其动量项增大，对于在梯度点处改变方向的维度，其动量项减小。因此，我们可以得到更快的收敛速度，同时可以减少摇摆。</p><h4 id="4-2-Nesterov加速梯度下降法"><a href="#4-2-Nesterov加速梯度下降法" class="headerlink" title="4.2 Nesterov加速梯度下降法"></a><strong>4.2 Nesterov加速梯度下降法</strong></h4><p>然而，球从山上滚下的时候，盲目地沿着斜率方向，往往并不能令人满意。我们希望有一个智能的球，这个球能够知道它将要去哪，以至于在重新遇到斜率上升时能够知道减速。</p><p>Nesterov加速梯度下降法（Nesterov accelerated gradient，NAG）[13]是一种能够给动量项这样的预知能力的方法。我们知道，我们利用动量项$\gamma v<em>{t-1}$来更新参数θ。通过计算$\theta - \gamma v</em>{t-1}$能够告诉我们参数未来位置的一个近似值（梯度并不是完全更新），这也就是告诉我们参数大致将变为多少。通过计算关于参数未来的近似位置的梯度，而不是关于当前的参数$\theta$的梯度，我们可以高效的求解 ：</p><script type="math/tex; mode=display">v_t = \gamma v_{t-1} + \eta \triangledown_{\theta}J(\theta - \gamma v_{t-1}) \\\theta = \theta - v_t</script><p>同时，我们设置动量项$\gamma$大约为0.9。动量法首先计算当前的梯度值（图3中的小的蓝色向量），然后在更新的累积梯度（大的蓝色向量）方向上前进一大步，Nesterov加速梯度下降法NAG首先在先前累积梯度（棕色的向量）方向上前进一大步，计算梯度值，然后做一个修正（绿色的向量）。这个具有预见性的更新防止我们前进得太快，同时增强了算法的响应能力，这一点在很多的任务中对于RNN的性能提升有着重要的意义[2]。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/optimizer-03.JPG" alt="optimizer-03.jpg"></p><p>对于NAG的直观理解的另一种解释可以参见<a href="http://cs231n.github.io/neural-networks-3/">此处资料</a>，同时Ilya Sutskever在其博士论文[18]中给出更详细的综述。</p><p>既然我们能够使得我们的更新适应误差函数的斜率以相应地加速SGD，我们同样也想要使得我们的更新能够适应每一个单独参数，以根据每个参数的重要性决定大的或者小的更新。</p><h4 id="4-3-Adagrad"><a href="#4-3-Adagrad" class="headerlink" title="4.3 Adagrad"></a><strong>4.3 Adagrad</strong></h4><p>Adagrad[7]是这样的一种基于梯度的优化算法：让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此，Adagrad非常适合处理稀疏数据。Dean等人[6]发现Adagrad能够极大提高了SGD的鲁棒性并将其应用于Google的大规模神经网络的训练，其中包含了YouTube视频中的猫的识别。此外，Pennington等人[15]利用Adagrad训练Glove词向量，因为低频词比高频词需要更大的步长。</p><p>前面，我们每次更新所有的参数$\theta$时，每一个参数$\theta<em>i$都使用的是相同的学习率$\eta$。由于Adagrad在t时刻对每一个参数$\theta_i$使用了不同的学习率，我们首先介绍Adagrad对每一个参数的更新，然后我们对其向量化。为了简洁，令$g</em>{t,i}$为在t时刻目标函数关于参数$\theta_i$的梯度：</p><script type="math/tex; mode=display">g_{t,i} = \triangledown_{\theta}J(\theta_i)</script><p>在t时刻，对每个参数$\theta_i$的更新过程变为：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \eta \cdot g_{t,i}</script><p>对于上述的更新规则，在t时刻，基于对$\theta_i$计算过的历史梯度，Adagrad修正了对每一个参数$\theta_i$的学习率：</p><script type="math/tex; mode=display">\theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}</script><p>其中，$G_t \in \mathbb R^{d \times d}$是一个对角矩阵，对角线上的元素i,i是直到t时刻为止，所有关于$\theta_i$的梯度的平方和（Duchi等人[7]将该矩阵作为包含所有先前梯度的外积的完整矩阵的替代，因为即使是对于中等数量的参数d，矩阵的均方根的计算都是不切实际的。），$\epsilon$是平滑项，用于防止除数为0（通常大约设置为1e−8）。<strong>比较有意思的是，如果没有平方根的操作，算法的效果会变得很差。</strong></p><p>由于$G_t$的对角线上包含了关于所有参数θ的历史梯度的平方和，现在，我们可以通过$G_t$和$g_t$之间的元素向量乘法$\odot$向量化上述的操作：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t</script><p>Adagrad算法的一个主要优点是无需手动调整学习率。在大多数的应用场景中，通常采用常数0.01。</p><p>Adagrad的一个主要缺点是它在分母中累加梯度的平方：由于没增加一个正项，在整个训练过程中，累加的和会持续增长。这会导致学习率变小以至于最终变得无限小，在学习率无限小时，Adagrad算法将无法取得额外的信息。接下来的算法旨在解决这个不足。</p><h4 id="4-4-Adadelta"><a href="#4-4-Adadelta" class="headerlink" title="4.4 Adadelta"></a><strong>4.4 Adadelta</strong></h4><p>Adadelta[21]是Adagrad的一种扩展算法，以处理Adagrad学习速率单调递减的问题。不是计算所有的梯度平方，Adadelta将计算计算历史梯度的窗口大小限制为一个固定值w。</p><p>在Adadelta中，无需存储先前的w个平方梯度，而是将梯度的平方递归地表示成所有历史梯度平方的均值。在t时刻的均值$E[g^2]_t$只取决于先前的均值和当前的梯度（分量$\gamma$类似于动量项）：</p><script type="math/tex; mode=display">E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma)g_t^2</script><p>我们将$\gamma$设置成与动量项相似的值，即0.9左右。为了简单起见，我们利用参数更新向量$\Delta \theta_t$重新表示SGD的更新过程：</p><script type="math/tex; mode=display">\Delta \theta_t = - \eta \cdot g_{t,i} \\\theta_{t+1} = \theta_t + \Delta \theta_t</script><p>我们先前得到的Adagrad参数更新向量变为：</p><script type="math/tex; mode=display">\Delta \theta_t = -\frac{\eta}{\sqrt{G_t +\epsilon}} \odot g_t</script><p>现在，我们简单将对角矩阵$G_t$替换成历史梯度的均值$E[g^2]_t$：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}}g_t</script><p>由于分母仅仅是梯度的均方根（root mean squared，RMS）误差，我们可以简写为：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{\eta}{RMS|g|_t}g_t</script><p>作者指出上述更新公式中的每个部分（与SGD，动量法或者Adagrad）并不一致，即更新规则中必须与参数具有相同的假设单位。为了实现这个要求，作者首次定义了另一个指数衰减均值，这次不是梯度平方，而是参数的平方的更新：</p><script type="math/tex; mode=display">E[\Delta \theta^2]_t = \gamma E[\Delta \theta^2]_{t-1} +(1-\gamma) \Delta \theta^2_t</script><p>因此，参数更新的均方根误差为：</p><script type="math/tex; mode=display">RMS[\Delta \theta]_t = \sqrt{E[\Delta \theta^2]_t + \epsilon}</script><p>由于$RMS[\Delta \theta]<em>t$是未知的，我们利用参数的均方根误差来近似更新。利用$RMS[\Delta \theta]</em>{t−1}$替换先前的更新规则中的学习率$\eta$，最终得到Adadelta的更新规则：</p><script type="math/tex; mode=display">\Delta \theta_t = - \frac{RMS[\theta]_{t−1}}{RMS|g|_t} g_t \\\theta_{t+1} = \theta_t +\Delta \theta_t</script><p>使用Adadelta算法，我们甚至都无需设置默认的学习率，因为更新规则中已经移除了学习率。</p><h4 id="4-5-RMSprop"><a href="#4-5-RMSprop" class="headerlink" title="4.5 RMSprop"></a><strong>4.5 RMSprop</strong></h4><p>RMSprop是一个未被发表的自适应学习率的算法，该算法由Geoff Hinton在其<a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Coursera课堂的课程6e</a>中提出。</p><p>RMSprop和Adadelta在相同的时间里被独立的提出，都起源于对Adagrad的极速递减的学习率问题的求解。实际上，RMSprop是先前我们得到的Adadelta的第一个更新向量的特例：</p><script type="math/tex; mode=display">E[g^2]_t = 0.9 E[g^2]_{t-1} + 0.1 g^2_t \\\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t</script><p>同样，RMSprop将学习率分解成一个平方梯度的指数衰减的平均。Hinton建议将$\gamma$设置为0.9，对于学习率$\eta$，一个好的固定值为0.001。</p><h4 id="4-6-Adam"><a href="#4-6-Adam" class="headerlink" title="4.6 Adam"></a><strong>4.6 Adam</strong></h4><p>自适应矩估计（Adaptive Moment Estimation，Adam）[9]是另一种自适应学习率的算法，Adam对每一个参数都计算自适应的学习率。除了像Adadelta和RMSprop一样存储一个指数衰减的历史平方梯度的平均$v_t$，Adam同时还保存一个历史梯度的指数衰减均值$m_t$，类似于动量：</p><script type="math/tex; mode=display">m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t \\v_t = \beta_2 v_{t-1} + (1-\beta_2) g^2_t</script><p>$m_t$和$v_t$分别是对梯度的一阶矩（均值）和二阶矩（非确定的方差）的估计，正如该算法的名称。当$m_t$和$v_t$初始化为0向量时，Adam的作者发现它们都偏向于0，尤其是在初始化的步骤和当衰减率很小的时候（例如$\beta_1$和$\beta_2$趋向于1）。</p><p>通过计算偏差校正的一阶矩和二阶矩估计来抵消偏差：</p><script type="math/tex; mode=display">\hat m_t = \frac{m_t}{1-\beta_1^t} \\\hat v_t = \frac{v_t}{1-\beta_2^t}</script><p>正如我们在Adadelta和RMSprop中看到的那样，他们利用上述的公式更新参数，由此生成了Adam的更新规则：</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat v_t} + \epsilon} \hat m_t</script><p>作者建议$\beta_1$取默认值为0.9，$\beta_2$为0.999，$\epsilon$为10−8。他们从经验上表明Adam在实际中表现很好，同时，与其他的自适应学习算法相比，其更有优势。</p><h4 id="4-7-算法可视化"><a href="#4-7-算法可视化" class="headerlink" title="4.7 算法可视化"></a><strong>4.7 算法可视化</strong></h4><p>下面两张图给出了上述优化算法的优化行为的直观理解。（还可以看看这里关于Karpathy对相同的图片的描述以及另一个简明关于算法讨论的概述）。</p><p>在图4a中，我们看到不同算法在损失曲面的等高线上走的不同路线。所有的算法都是从同一个点出发并选择不同路径到达最优点。注意：Adagrad，Adadelta和RMSprop能够立即转移到正确的移动方向上并以类似的速度收敛，而动量法和NAG会导致偏离，想像一下球从山上滚下的画面。然而，NAG能够在偏离之后快速修正其路线，因为NAG通过对最优点的预见增强其响应能力。</p><p>图4b中展示了不同算法在鞍点出的行为，鞍点即为一个点在一个维度上的斜率为正，而在其他维度上的斜率为负，正如我们前面提及的，鞍点对SGD的训练造成很大困难。这里注意，SGD，动量法和NAG在鞍点处很难打破对称性，尽管后面两个算法最终设法逃离了鞍点。而Adagrad，RMSprop和Adadelta能够快速想着梯度为负的方向移动，其中Adadelta走在最前面。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/optimizers-04.gif" alt="optimizers-04.gif"></p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/optimizers-05.gif" alt="optimizers-05.gif"></p><p>正如我们所看到的，自适应学习速率的方法，即 Adagrad、 Adadelta、 RMSprop 和Adam，最适合这些场景下最合适，并在这些场景下得到最好的收敛性。</p><h4 id="4-8-选择使用哪种优化算法？"><a href="#4-8-选择使用哪种优化算法？" class="headerlink" title="4.8 选择使用哪种优化算法？"></a><strong>4.8 选择使用哪种优化算法？</strong></h4><p>那么，我们应该选择使用哪种优化算法呢？如果输入数据是稀疏的，选择任一自适应学习率算法可能会得到最好的结果。选用这类算法的另一个好处是无需调整学习率，选用默认值就可能达到最好的结果。</p><p>总的来说，RMSprop是Adagrad的扩展形式，用于处理在Adagrad中急速递减的学习率。RMSprop与Adadelta相同，所不同的是Adadelta在更新规则中使用参数的均方根进行更新。最后，Adam是将偏差校正和动量加入到RMSprop中。在这样的情况下，RMSprop、Adadelta和Adam是很相似的算法并且在相似的环境中性能都不错。Kingma等人[9]指出在优化后期由于梯度变得越来越稀疏，偏差校正能够帮助Adam微弱地胜过RMSprop。综合看来，Adam可能是最佳的选择。</p><p>有趣的是，最近许多论文中采用不带动量的SGD和一种简单的学习率的退火策略。已表明，通常SGD能够找到最小值点，但是比其他优化的SGD花费更多的时间，与其他算法相比，SGD更加依赖鲁棒的初始化和退火策略，同时，SGD可能会陷入鞍点，而不是局部极小值点。因此，如果你关心的是快速收敛和训练一个深层的或者复杂的神经网络，你应该选择一个自适应学习率的方法。</p><h3 id="5-并行和分布式SGD"><a href="#5-并行和分布式SGD" class="headerlink" title="5 并行和分布式SGD"></a><strong>5 并行和分布式SGD</strong></h3><p>当存在大量的大规模数据和廉价的集群时，利用分布式SGD来加速是一个显然的选择。SGD本身有固有的顺序：一步一步，我们进一步进展到最小。SGD提供了良好的收敛性，但SGD的运行缓慢，特别是对于大型数据集。相反，SGD异步运行速度更快，但客户端之间非最理想的通信会导致差的收敛。此外，我们也可以在一台机器上并行SGD，这样就无需大的计算集群。以下是已经提出的优化的并行和分布式的SGD的算法和框架。</p><h4 id="5-1-Hogwild"><a href="#5-1-Hogwild" class="headerlink" title="5.1 Hogwild!"></a><strong>5.1 Hogwild!</strong></h4><p>Niu等人[14]提出称为Hogwild!的更新机制，Hogwild!允许在多个CPU上并行执行SGD更新。在无需对参数加锁的情况下，处理器可以访问共享的内存。这种方法只适用于稀疏的输入数据，因为每一次更新只会修改一部分参数。在这种情况下，该更新策略几乎可以达到一个最优的收敛速率，因为CPU之间不可能重写有用的信息。</p><h4 id="5-2-Downpour-SGD"><a href="#5-2-Downpour-SGD" class="headerlink" title="5.2 Downpour SGD"></a><strong>5.2 Downpour SGD</strong></h4><p>Downpour SGD是SGD的一种异步的变形形式，在Google，Dean等人[6]在他们的DistBelief框架（TensorFlow的前身）中使用了该方法。Downpour SGD在训练集的子集上并行运行多个模型的副本。这些模型将各自的更新发送给一个参数服务器，参数服务器跨越了多台机器。每一台机器负责存储和更新模型的一部分参数。然而，因为副本之间是彼此不互相通信的，即通过共享权重或者更新，因此可能会导致参数发散而不利于收敛。</p><h4 id="5-3-延迟容忍SGD"><a href="#5-3-延迟容忍SGD" class="headerlink" title="5.3 延迟容忍SGD"></a><strong>5.3 延迟容忍SGD</strong></h4><p>通过容忍延迟算法的开发，McMahan和Streeter[11]将AdaGraad扩展成并行的模式，该方法不仅适应于历史梯度，同时适应于更新延迟。该方法已经在实践中被证实是有效的。</p><h4 id="5-4-TensorFlow"><a href="#5-4-TensorFlow" class="headerlink" title="5.4 TensorFlow"></a><strong>5.4 TensorFlow</strong></h4><p>TensorFlow[1]是Google近期开源的框架，该框架用于实现和部署大规模机器学习模型。TensorFlow是基于DistBelief开发，同时TensorFlow已经在内部用来在大量移动设备和大规模分布式系统的执行计算。在2016年4月发布的分布式版本依赖于图计算，图计算即是对每一个设备将图划分成多个子图，同时，通过发送、接收节点对完成节点之间的通信。</p><h4 id="5-5-弹性平均SGD"><a href="#5-5-弹性平均SGD" class="headerlink" title="5.5 弹性平均SGD"></a><strong>5.5 弹性平均SGD</strong></h4><p>Zhang等人[22]提出的弹性平均SGD（Elastic Averaging SGD，EASGD）连接了异步SGD的参数客户端和一个弹性力，即参数服务器存储的一个中心变量。EASGD使得局部变量能够从中心变量震荡得更远，这在理论上使得在参数空间中能够得到更多的探索。经验表明这种增强的探索能力通过发现新的局部最优点，能够提高整体的性能。</p><h3 id="6-优化SGD的其他策略"><a href="#6-优化SGD的其他策略" class="headerlink" title="6 优化SGD的其他策略"></a><strong>6 优化SGD的其他策略</strong></h3><p>最后，我们介绍可以与前面提及到的任一算法配合使用的其他的一些策略，以进一步提高SGD的性能。对于其他的一些常用技巧的概述可以参见[10]。</p><h4 id="6-1-数据集的洗牌和课程学习"><a href="#6-1-数据集的洗牌和课程学习" class="headerlink" title="6.1 数据集的洗牌和课程学习"></a><strong>6.1 数据集的洗牌和课程学习</strong></h4><p>总的来说，我们希望避免向我们的模型中以一定意义的顺序提供训练数据，因为这样会使得优化算法产生偏差。因此，在每一轮迭代后对训练数据洗牌是一个不错的主意。</p><p>另一方面，在很多情况下，我们是逐步解决问题的，而将训练集按照某个有意义的顺序排列会提高模型的性能和SGD的收敛性，如何将训练集建立一个有意义的排列被称为课程学习[3]。</p><p>Zaremba and Sutskever[20]只能使用课程学习训练LSTM来评估简单程序，并表明组合或混合策略比单一的策略更好，通过增加难度来排列示例。</p><h4 id="6-2-批量归一化"><a href="#6-2-批量归一化" class="headerlink" title="6.2 批量归一化"></a><strong>6.2 批量归一化</strong></h4><p>为了便于学习，我们通常用0均值和单位方差初始化我们的参数的初始值来归一化。 随着不断训练，参数得到不同的程度的更新，我们失去了这种归一化，随着网络变得越来越深，这种现象会降低训练速度，且放大参数变化。</p><p>批量归一化[8]在每次小批量数据反向传播之后重新对参数进行0均值单位方差标准化。通过将模型架构的一部分归一化，我们能够使用更高的学习率，更少关注初始化参数。批量归一化还充当正则化的作用，减少（有时甚至消除）Dropout的必要性。</p><h4 id="6-3-Early-stopping"><a href="#6-3-Early-stopping" class="headerlink" title="6.3 Early stopping"></a><strong>6.3 Early stopping</strong></h4><p>如Geoff Hinton所说：“Early Stopping是美丽好免费午餐”（NIPS 2015 Tutorial slides）。你因此必须在训练的过程中时常在验证集上监测误差，在验证集上如果损失函数不再显著地降低，那么应该提前结束训练。</p><h4 id="6-4-梯度噪音"><a href="#6-4-梯度噪音" class="headerlink" title="6.4 梯度噪音"></a><strong>6.4 梯度噪音</strong></h4><p>Neelakantan等人[12]在每个梯度更新中增加满足高斯分布$N(0,\sigma^2_t)$的噪音：</p><script type="math/tex; mode=display">g_{t,i} = g_{t,i} + N(0,\sigma^2_t)</script><p>高斯分布的方差需要根据如下的策略退火：</p><script type="math/tex; mode=display">\sigma_t^2 = \frac{\eta}{(1+t)^\gamma}</script><p>他们指出增加了噪音，使得网络对不好的初始化更加鲁棒，同时对深层的和复杂的网络的训练特别有益。他们猜测增加的噪音使得模型更优机会逃离当前的局部最优点，以发现新的局部最优点，这在更深层的模型中更加常见。</p><h3 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a><strong>7 总结</strong></h3><p>在这篇博客文章中，我们初步研究了梯度下降的三个变形形式，其中，小批量梯度下降是最受欢迎的。 然后我们研究了最常用于优化SGD的算法：动量法，Nesterov加速梯度，Adagrad，Adadelta，RMSprop，Adam以及不同的优化异步SGD的算法。 最后，我们已经考虑其他一些改善SGD的策略，如洗牌和课程学习，批量归一化和early stopping。</p><p><a href="https://blog.csdn.net/google19890102/article/details/69942970">参考博文：梯度下降优化算法综述-zhiyong_will</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;http://ruder.io/optimizing-gradient-descent/&quot;&gt;原始论文：An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;梯度下降优化算法综述&quot;&gt;&lt;a href=&quot;#梯度下降优化算法综述&quot; class=&quot;headerlink&quot; title=&quot;梯度下降优化算法综述&quot;&gt;&lt;/a&gt;梯度下降优化算法综述&lt;/h2&gt;&lt;h3 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;虽然梯度下降优化算法越来越受欢迎，但通常作为黑盒优化器使用，因此很难对其优点和缺点的进行实际的解释。本文旨在让读者对不同的算法有直观的认识，以帮助读者使用这些算法。在本综述中，我们介绍梯度下降的不同变形形式，总结这些算法面临的挑战，介绍最常用的优化算法，回顾并行和分布式架构，以及调研用于优化梯度下降的其他的策略。&lt;/p&gt;
&lt;h3 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 引言&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;梯度下降法是最著名的优化算法之一，也是迄今优化神经网络时最常用的方法。同时，在每一个最新的深度学习库中都包含了各种优化的梯度下降法的实现（例如：参见lasagne，caffe和keras的文档）。然而，这些算法通常是作为黑盒优化器使用，因此，很难对其优点和缺点的进行实际的解释。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="论文解析" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87%E8%A7%A3%E6%9E%90/"/>
    
    
    <category term="机器学习" scheme="https://www.xiemingzhao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="Gradient Descent" scheme="https://www.xiemingzhao.com/tags/Gradient-Descent/"/>
    
    <category term="Optimization" scheme="https://www.xiemingzhao.com/tags/Optimization/"/>
    
  </entry>
  
</feed>
