<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小火箭的博客</title>
  
  <subtitle>愿世界和平！！！</subtitle>
  <link href="https://www.xiemingzhao.com/atom.xml" rel="self"/>
  
  <link href="https://www.xiemingzhao.com/"/>
  <updated>2025-04-04T17:49:14.082Z</updated>
  <id>https://www.xiemingzhao.com/</id>
  
  <author>
    <name>小火箭</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Transformer 解析</title>
    <link href="https://www.xiemingzhao.com/posts/transformer.html"/>
    <id>https://www.xiemingzhao.com/posts/transformer.html</id>
    <published>2022-07-23T16:00:00.000Z</published>
    <updated>2025-04-04T17:49:14.082Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>算法工程师在成长道路上基本绕不开深度学习，而 <code>Transformer</code> 模型更是其中的经典，它在2017年的<a href="https://arxiv.org/abs/1706.03762">《Attention is All You Need》</a>论文中被提出，直接掀起了 <code>Attention</code> 机制在深度模型中的广泛应用潮流。</p><p>在该模型中有许多奇妙的想法启发了诸多算法工程师的学习创造，为了让自己回顾复习更加方便，亦或让在学习的读者更轻松地理解，便写了这篇文章。形式上，在参考诸多优秀文章和博客后，这里还是采用结构与代码并行阐述的模式。</p><span id="more"></span><h2 id="2-Transformer-概述"><a href="#2-Transformer-概述" class="headerlink" title="2 Transformer 概述"></a>2 Transformer 概述</h2><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer0.png" alt="transformer0"></p><p>如上图所示的是论文中对 Transformer 模型的结构概述，自己初学时对此图有些难以理解。回过头来看，实际上作者默认读者是一个对深度学习较为熟悉的，所以隐去了部分细节信息，仅将最核心的建模思想绘制了出来。</p><p>在这里，我想再降低一下门槛，提高复习和阅读的舒适度。需要指出的是，论文提出该模型是基于<strong>nlp 中翻译任务</strong>的，所以是一个 <code>seq2seq</code> 的结构，如下图所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer1.png" alt="transformer1"></p><p>图中表明了输入的句子经过多个编码器 <code>encoder</code> 后再经过多个解码器 <code>decoder</code> 得到最后的预估结果。那么重点就在于以下四个部分：</p><ul><li>input</li><li>encoder</li><li>decoder</li><li>output</li></ul><p>结合上述的模型图，将这四个部分详细展示的话可以表示成如下结构。实际上此图与论文中的结构图如出一辙，但是相对更易于理解一些。下面将基于此结构，结合 <a href="https://github.com/Kyubyong/transformer.git">Kyubyong</a> 的 tf 实现代码，详细分析每个模块。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer2.png" alt="transformer2"></p><h2 id="3-模块解析"><a href="#3-模块解析" class="headerlink" title="3 模块解析"></a>3 模块解析</h2><h3 id="3-1-Input"><a href="#3-1-Input" class="headerlink" title="3.1 Input"></a>3.1 Input</h3><p>模型核心的入口便是 <code>train</code> 方法模块，如下所示，在 <code>input</code> 有的情况下，前馈网络是比较清晰简洁的，只有 <code>encode</code> 和 <code>decode</code>，与模型结构图一致。其余的代码便是主要用来构建训练 <code>loss</code> 和优化器 <code>opt</code> 的。需要注意的是 <code>encode</code> 模块并不完全等价于模型结构图中的 <code>encoder</code>，后者是前者中的一部分。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, xs, ys</span>):</span><br><span class="line">   <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   Returns</span></span><br><span class="line"><span class="string">   loss: scalar.</span></span><br><span class="line"><span class="string">   train_op: training operation</span></span><br><span class="line"><span class="string">   global_step: scalar.</span></span><br><span class="line"><span class="string">   summaries: training summary node</span></span><br><span class="line"><span class="string">   &#x27;&#x27;&#x27;</span></span><br><span class="line">   <span class="comment"># forward 前向</span></span><br><span class="line">   memory, sents1, src_masks = <span class="variable language_">self</span>.encode(xs)    <span class="comment"># 编码</span></span><br><span class="line">   logits, preds, y, sents2 = <span class="variable language_">self</span>.decode(ys, memory, src_masks)    <span class="comment"># 解码</span></span><br><span class="line"> </span><br><span class="line">   <span class="comment"># train scheme</span></span><br><span class="line">   y_ = label_smoothing(tf.one_hot(y, depth=<span class="variable language_">self</span>.hp.vocab_size))    <span class="comment"># 平滑标签</span></span><br><span class="line">   ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)    <span class="comment"># softmax分类</span></span><br><span class="line">   nonpadding = tf.to_float(tf.not_equal(y, <span class="variable language_">self</span>.token2idx[<span class="string">&quot;&lt;pad&gt;&quot;</span>]))  <span class="comment"># 0: &lt;pad&gt;</span></span><br><span class="line">   loss = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + <span class="number">1e-7</span>)</span><br><span class="line"></span><br><span class="line">   global_step = tf.train.get_or_create_global_step()</span><br><span class="line">   lr = noam_scheme(<span class="variable language_">self</span>.hp.lr, global_step, <span class="variable language_">self</span>.hp.warmup_steps)</span><br><span class="line">   optimizer = tf.train.AdamOptimizer(lr)</span><br><span class="line">   train_op = optimizer.minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">   tf.summary.scalar(<span class="string">&#x27;lr&#x27;</span>, lr)</span><br><span class="line">   tf.summary.scalar(<span class="string">&quot;loss&quot;</span>, loss)</span><br><span class="line">   tf.summary.scalar(<span class="string">&quot;global_step&quot;</span>, global_step)</span><br><span class="line"></span><br><span class="line">   summaries = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> loss, train_op, global_step, summaries</span><br></pre></td></tr></table></figure></p><p>进一步的，我们深入 <code>encode</code> 去看 <code>input</code> 在进入 <code>encoder</code> 前的一些预处理，如下代码所示。可以看到输入 <code>xs</code> 实际上包含三个部分：</p><ul><li><code>x</code>: 被补全的句子映射的 tokenid 序列</li><li><code>seqlens</code>: 句子的长度</li><li><code>sents</code>: 原始句子</li></ul><p>首先根据 <code>tokenid</code> 是否为0构建了 <code>src_masks</code> 源句掩码，接着将输入 <code>x</code> 进行词向量嵌入。</p><blockquote><p>这里需要注意，code 中作者将词向量进行了缩放，系数是 $d_{model}^{0.5}$。而这一部分原始论文中是没有提及的。</p></blockquote><p>之后，还进行了两步处理：</p><ul><li>加上 positional_encoding：为了融入位置信息；</li><li>接一层 dropout：为了防止过拟合。</li></ul><p>到此，输入的预处理便结束了，之后就如模型结构图所示，开始进入多个 <code>encoder</code> 进行编码了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, xs, training=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    memory: encoder outputs. (N, T1, d_model)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;encoder&quot;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        x, seqlens, sents1 = xs    <span class="comment"># 被补全的句子，句子长度，原句</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># src_masks 源句掩码</span></span><br><span class="line">        src_masks = tf.math.equal(x, <span class="number">0</span>) <span class="comment"># (N, T1) 掩码，标记补全位置</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># embedding 嵌入</span></span><br><span class="line">        enc = tf.nn.embedding_lookup(<span class="variable language_">self</span>.embeddings, x) <span class="comment"># (N, T1, d_model)    # 词嵌入 Input Embedding</span></span><br><span class="line">        enc *= <span class="variable language_">self</span>.hp.d_model**<span class="number">0.5</span> <span class="comment"># scale 对enc缩放，但是原论文中没有发现相关内容</span></span><br><span class="line"> </span><br><span class="line">        enc += positional_encoding(enc, <span class="variable language_">self</span>.hp.maxlen1)    <span class="comment"># 位置嵌入</span></span><br><span class="line">        enc = tf.layers.dropout(enc, <span class="variable language_">self</span>.hp.dropout_rate, training=training)     <span class="comment">#Dropout 防止过拟合</span></span><br><span class="line">        <span class="comment"># 截止现在输入已被嵌入完毕</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">## Blocks Encoder 块</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.hp.num_blocks):    <span class="comment"># 设定的Encoder块</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_blocks_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i), reuse=tf.AUTO_REUSE):    <span class="comment">#当前是第几个Encoder块</span></span><br><span class="line">                <span class="comment"># self-attention    多头注意力机制</span></span><br><span class="line">                enc = multihead_attention(queries=enc,</span><br><span class="line">                                          keys=enc,</span><br><span class="line">                                          values=enc,</span><br><span class="line">                                          key_masks=src_masks,</span><br><span class="line">                                          num_heads=<span class="variable language_">self</span>.hp.num_heads,</span><br><span class="line">                                          dropout_rate=<span class="variable language_">self</span>.hp.dropout_rate,</span><br><span class="line">                                          training=training,</span><br><span class="line">                                          causality=<span class="literal">False</span>)    <span class="comment"># 多头注意力机制</span></span><br><span class="line">                <span class="comment"># feed forward    前向传播</span></span><br><span class="line">                enc = ff(enc, num_units=[<span class="variable language_">self</span>.hp.d_ff, <span class="variable language_">self</span>.hp.d_model])</span><br><span class="line">    memory = enc <span class="comment"># 记住当前进度</span></span><br><span class="line">    <span class="keyword">return</span> memory, sents1, src_masks</span><br></pre></td></tr></table></figure><h3 id="3-2-Positional-encoding"><a href="#3-2-Positional-encoding" class="headerlink" title="3.2 Positional encoding"></a>3.2 Positional encoding</h3><p>前面提到为了融入位置信息，引入了 <code>positional_encoding</code> 的模块。而位置编码的需求：</p><ol><li>需要体现同一个单词在不同位置的区别；</li><li>需要体现一定的先后次序关系；</li><li>并且在一定范围内的编码差异不应该依赖于文本长度，具有一定不变性。</li></ol><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer3.png" alt="transformer3"></p><p>官方的做法是：</p><script type="math/tex; mode=display">PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})</script><script type="math/tex; mode=display">PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})</script><p>其中：</p><ul><li><code>pos</code> 是指词在句中的位置;</li><li><code>i</code> 是指位置嵌入 emb 的位置序号。</li></ul><p>整个模块的代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">positional_encoding</span>(<span class="params">inputs,</span></span><br><span class="line"><span class="params">                        maxlen,</span></span><br><span class="line"><span class="params">                        masking=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                        scope=<span class="string">&quot;positional_encoding&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Sinusoidal Positional_Encoding. See 3.5</span></span><br><span class="line"><span class="string">    inputs: 3d tensor. (N, T, E)</span></span><br><span class="line"><span class="string">    maxlen: scalar. Must be &gt;= T</span></span><br><span class="line"><span class="string">    masking: Boolean. If True, padding positions are set to zeros.</span></span><br><span class="line"><span class="string">    scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">    returns</span></span><br><span class="line"><span class="string">    3d tensor that has the same shape as inputs.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"> </span><br><span class="line">    E = inputs.get_shape().as_list()[-<span class="number">1</span>] <span class="comment"># static 获取此向量维度 d_model</span></span><br><span class="line">    N, T = tf.shape(inputs)[<span class="number">0</span>], tf.shape(inputs)[<span class="number">1</span>] <span class="comment"># dynamic N为batch_size，T为最长句子长度</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=tf.AUTO_REUSE):</span><br><span class="line">        <span class="comment"># position indices    位置索引</span></span><br><span class="line">        position_ind = tf.tile(tf.expand_dims(tf.<span class="built_in">range</span>(T), <span class="number">0</span>), [N, <span class="number">1</span>]) <span class="comment"># (N, T) 对张量进行扩展 1,T → N,T</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># First part of the PE function: sin and cos argument 位置嵌入方法</span></span><br><span class="line">        position_enc = np.array([</span><br><span class="line">            [pos / np.power(<span class="number">10000</span>, (i-i%<span class="number">2</span>)/E) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(E)]</span><br><span class="line">            <span class="keyword">for</span> pos <span class="keyword">in</span> <span class="built_in">range</span>(maxlen)])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Second part, apply the cosine to even columns and sin to odds.  不同位置 使用sin和cos方法</span></span><br><span class="line">        position_enc[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(position_enc[:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i</span></span><br><span class="line">        position_enc[:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(position_enc[:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1</span></span><br><span class="line">        position_enc = tf.convert_to_tensor(position_enc, tf.float32) <span class="comment"># (maxlen, E)</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># lookup</span></span><br><span class="line">        outputs = tf.nn.embedding_lookup(position_enc, position_ind)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># masks</span></span><br><span class="line">        <span class="keyword">if</span> masking:    <span class="comment"># 是否需要掩码</span></span><br><span class="line">            outputs = tf.where(tf.equal(inputs, <span class="number">0</span>), inputs, outputs) </span><br><span class="line">        <span class="comment"># inputs中值为0的地方（为True的地方）保持值不变，其余元素替换为outputs结果。因为0的地方就是掩码的地方，不需要有所谓的位置嵌入。</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> tf.to_float(outputs)</span><br></pre></td></tr></table></figure><p>论文中对该嵌入方法生成的 <code>embdding</code> 进行了可视化，如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer4.png" alt="transformer4"></p><p>为何如此设计呢？从公式看，<code>sin &amp; cos</code> 的交替使用只是为了使编码更丰富，在哪些维度上使用 sin，哪些使用 cos，不是很重要，都是模型可以调整适应的。而论文给的解释是：</p><blockquote><p>对任意确定的偏移 k，$PE<em>{pos+k}$ 可以表示为 $PE</em>{pos}$ 的函数。</p></blockquote><p>推导的结果是:</p><script type="math/tex; mode=display">PE(pos + k, 2i) = PE(pos, 2i) * constant^k_{2i + 1} + constant^k_i * PE(pos, 2i + 1)</script><p>需要指出的是：</p><ol><li>这个函数形式很可能是基于经验得到的，并且应该有不少可以替代的方法；</li><li>谷歌后期的作品 <code>BERT</code> 已经换用位置嵌入(positional embedding)来学习了。</li></ol><h3 id="3-3-Multi-Head-Attention"><a href="#3-3-Multi-Head-Attention" class="headerlink" title="3.3 Multi Head Attention"></a>3.3 Multi Head Attention</h3><h4 id="3-3-1-机制概述"><a href="#3-3-1-机制概述" class="headerlink" title="3.3.1 机制概述"></a>3.3.1 机制概述</h4><p>多头注意力机制是 <code>Transformer</code> 的核心，且这里的 <code>Attention</code> 被称为 <code>self-attention</code>，是为了区别另一种 <code>target-attention</code>。名字不是特别重要，重点是理解逻辑和实现。这里先抛出对此的看法：<strong>模型在理解句中某个词的时候，需要结合上下文，而 <code>Multihead Attention</code> 便是用来从不同角度度量句中单个词与上下文各个词之间关联性的机制。</strong></p><p>文字可能没有图片直观，这里以一个可视化的例子来呈现：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer5.png" alt="transformer5"></p><p>如上图所示，当模型想要理解句子 “The animal didn’t cross the street because it was too tired” 中 it 含义的时候，attention 机制可以计算上下文中各个词与它的相关性，图中颜色的深浅便代表相关性大小。</p><p>所以，<code>Multihead Attention</code> 模块的任务就是<strong>将原本独立的词向量（维度d_k）经过一系列的计算过程，最终映射到一组新的向量(维度d_v)，新向量包含了上下文、位置等有助于词义理解的信息</strong>。</p><h4 id="3-3-2-Q、K、V变换"><a href="#3-3-2-Q、K、V变换" class="headerlink" title="3.3.2 Q、K、V变换"></a>3.3.2 Q、K、V变换</h4><p>模型 <code>Multihead Attention</code> 模块的输入是 embedding 后的一串词向量，而 Attention 机制中原始是对 Query 计算与 Key 的 Weight 后，叠加 Value 计算加权和，所以需要 $Query,Key,Value$ 三个矩阵。</p><p>作者便基于 Input 矩阵，通过矩阵变换来生成 Q、K、V，如下图所示，<strong>由于 Query 和 Key、Value 来源于同一个Input</strong>，故这种机制也称为 <code>self-attention</code>。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer6.png" alt="transformer6"></p><p>如上图所示，假设 Input 是“Thinking Matchines”句子，只有2个词向量。假设每个词映射为图中的 $1 \times 4$ 的词向量，当我们使用图中所示的3个变换矩阵 $W^Q,W^K,W^V$ 来对 Input 进行变换 (即 $W \times X$) 后，便可以得到变换后的$Q,K,V$矩阵，即每个词向量转换成图中维度为 $1 \times 3$ 的 $q,k,v$。</p><p><strong>注意：这些新向量的维度比输入词向量的维度要小（原文 nlp 任务是 512–&gt;64，图中 case 是4-&gt;3），并不是必须要小的，是为了让多头 attention 的计算更稳定。</strong></p><p>对应的 code 如下所示，其中有一个 <code>Split and concat</code> 模块，这一块本节未提及，是模型中 <code>multi-head</code> 机制的体现，在后文将会详细介绍。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multihead_attention</span>(<span class="params">queries, keys, values, key_masks,</span></span><br><span class="line"><span class="params">                        num_heads=<span class="number">8</span>, </span></span><br><span class="line"><span class="params">                        dropout_rate=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                        training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                        causality=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                        scope=<span class="string">&quot;multihead_attention&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Applies multihead attention. See 3.2.2</span></span><br><span class="line"><span class="string">    queries: A 3d tensor with shape of [N, T_q, d_model].</span></span><br><span class="line"><span class="string">    keys: A 3d tensor with shape of [N, T_k, d_model].</span></span><br><span class="line"><span class="string">    values: A 3d tensor with shape of [N, T_k, d_model].</span></span><br><span class="line"><span class="string">    key_masks: A 2d tensor with shape of [N, key_seqlen]</span></span><br><span class="line"><span class="string">    num_heads: An int. Number of heads.</span></span><br><span class="line"><span class="string">    dropout_rate: A floating point number.</span></span><br><span class="line"><span class="string">    training: Boolean. Controller of mechanism for dropout.</span></span><br><span class="line"><span class="string">    causality: Boolean. If true, units that reference the future are masked.</span></span><br><span class="line"><span class="string">    scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">      A 3d tensor with shape of (N, T_q, C)  </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    d_model = queries.get_shape().as_list()[-<span class="number">1</span>]    <span class="comment"># 获取词向量长度</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=tf.AUTO_REUSE):</span><br><span class="line">        <span class="comment"># Linear projections    # 通过权重矩阵得出Q,K,V矩阵</span></span><br><span class="line">        Q = tf.layers.dense(queries, d_model, use_bias=<span class="literal">True</span>) <span class="comment"># (N, T_q, d_model)</span></span><br><span class="line">        K = tf.layers.dense(keys, d_model, use_bias=<span class="literal">True</span>) <span class="comment"># (N, T_k, d_model)</span></span><br><span class="line">        V = tf.layers.dense(values, d_model, use_bias=<span class="literal">True</span>) <span class="comment"># (N, T_k, d_model)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Split and concat    针对最后一个维度划分为多头，词向量长度512 → 每个头64</span></span><br><span class="line">        Q_ = tf.concat(tf.split(Q, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>) <span class="comment"># (h*N, T_q, d_model/h)</span></span><br><span class="line">        K_ = tf.concat(tf.split(K, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>) <span class="comment"># (h*N, T_k, d_model/h)</span></span><br><span class="line">        V_ = tf.concat(tf.split(V, num_heads, axis=<span class="number">2</span>), axis=<span class="number">0</span>) <span class="comment"># (h*N, T_k, d_model/h)</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Attention 计算自注意力</span></span><br><span class="line">        outputs = scaled_dot_product_attention(Q_, K_, V_, key_masks, causality, dropout_rate, training)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Restore shape 合并多头</span></span><br><span class="line">        outputs = tf.concat(tf.split(outputs, num_heads, axis=<span class="number">0</span>), axis=<span class="number">2</span> ) <span class="comment"># (N, T_q, d_model)</span></span><br><span class="line">              </span><br><span class="line">        <span class="comment"># Residual connection 残差链接</span></span><br><span class="line">        outputs += queries </span><br><span class="line">              </span><br><span class="line">        <span class="comment"># Layer Normalize </span></span><br><span class="line">        outputs = ln(outputs)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h4 id="3-3-3-Attention"><a href="#3-3-3-Attention" class="headerlink" title="3.3.3 Attention"></a>3.3.3 Attention</h4><p>在文中的全称是 <code>scaled_dot_product_attention</code>（缩放的点积注意力机制），这也是 <code>Transformer</code> 的计算核心。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer7.png" alt="transformer7"></p><p>如上图所示，是 Attention 机制的一个计算过程示例。输入有2个词向量($x_1,x_2$)，分别映射成了对应的$q,k,v$向量。</p><p>作为 <code>scaled_dot_product_attention</code> 的输入后需要经过如下几步：</p><ol><li>计算每组 q, k 的点积，即图中的 Score；</li><li>对点积 Score 进行缩放（scaled），即图中的“除以8“，8由$\sqrt{d_k}$计算得到；</li><li>基于每个词维度，对其下所有的 scaled Score 计算 Softmax 得到对应的权重 Weight；</li><li>用3中的权重对所有向量 $v_i$ 做加权求和，得到最终的 Sum 向量作为 output。</li></ol><p>这里需要注意，在第 2 步中对点积的结果 Score 做了 scaled 的原因：</p><blockquote><p>作者提到，这样梯度会更稳定。然后加上softmax操作，归一化分值使得全为正数且加和为1。</p></blockquote><p>后半部分比较好理解，前半部分的原因可从如下角度考虑：假设 Q 和 K 的均值为0，方差为1，它们的矩阵乘积将有均值为0，方差为 $d_k$。因此，$d_k$ 的平方根被用于缩放（而非其他数值）后，因为，<strong>乘积的结果就变成了 0 均值和单位方差，这样会获得一个更平缓的 softmax，也即梯度更稳定不容易出现梯度消失</strong>。</p><p>以上是单个词向量在 Attention 中的计算过程，自然的，多个词向量可以叠加后进行矩阵运算，如下所示。实际上，就是将原来的单词向量$x_i$ ($1 \times d_k$)　堆叠到一起 $X$($N \times d_k$) 进行计算。</p><p>输入 $X$ 到 $Q,K,V$ 的矩阵变换过程：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer8.png" alt="transformer8"></p><p>基于$Q,K,V$的 Attention 计算过程：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer9.png" alt="transformer9"></p><h4 id="3-3-4-Multi-head"><a href="#3-3-4-Multi-head" class="headerlink" title="3.3.4 Multi-head"></a>3.3.4 Multi-head</h4><p>截止上述基本上就是 <code>self-attention</code> 的计算流程了，那么 <code>Multi Attention</code> 中的 <code>multi</code> 就体现在本节的 <code>Multi-head</code> 环节。</p><p>我们先看做法：</p><blockquote><p>使用多组 $W^Q,W^K,W^V$ 矩阵进行变换后进行 Attention 机制的计算，如此便可以得到多组输出向量 $Z$，整个流程如下所示。</p></blockquote><p>基于多组 $W^Q,W^K,W^V$ 矩阵映射成多组 $Q,K,V$：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer10.png" alt="transformer10"></p><p>经过 Attention 多组 $Q,K,V$ 得到多个输出矩阵$Z$：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer11.png" alt="transformer11"></p><p>多个输出矩阵$Z$进行 concat 后再线性变换成等嵌入维度($d_k$)的最终输出矩阵$Z$：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer12.png" alt="transformer12"></p><h4 id="3-3-5-Attention-机制总结"><a href="#3-3-5-Attention-机制总结" class="headerlink" title="3.3.5 Attention 机制总结"></a>3.3.5 Attention 机制总结</h4><p>这里直接看整体流程图：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer13.png" alt="transformer13"></p><p>如上图所示，是一个从左往右的计算流程：</p><ol><li>输入的句子，这里 case 是”Thinking Machines”;</li><li>词嵌入，将词嵌入为 embedding， 其中 R 表示非第 0 个 encoder 的 input 不需要词嵌入，而是上一个 encoder 的 ouput；</li><li>生成多组变换权重矩阵；</li><li>基于多组权重矩阵（多头）变换映射，得到多组 Q,K,V；</li><li>多组 Q,K,V 经过 Attention 后得到多个输出 z，将他们 concat 后进行线性变换得到最终的输出矩阵 Z。</li></ol><blockquote><p>至于为什么要用 Multi Head Attention ？作者提到：</p></blockquote><ol><li>多头机制扩展了模型集中于不同位置的能力。</li><li>多头机制赋予 attention 多种子表达方式。</li></ol><p>该模块的 code 如下所示，其中还有 <code>mask</code> 和 <code>dropout</code> 模块，前者是为了去除输入中 <code>padding</code> 的影响，后者则是为了提高模型稳健性。后者不过多介绍，mask 的 code 也附在了下方。</p><p><strong>方法就是使用一个很小的值，对指定位置进行覆盖填充</strong>。在之后计算 softmax 时，由于我们填充的值很小，所以计算出的概率也会很小，基本就忽略了。</p><p><strong>值得留意的是</strong>：</p><ul><li><code>type in (&quot;k&quot;, &quot;key&quot;, &quot;keys&quot;)</code>:  是 <code>padding mask</code>，因此全零的部分我们让 attention 的权重为一个很小的值 -4.2949673e+09。</li><li><code>type in (&quot;q&quot;, &quot;query&quot;, &quot;queries&quot;)</code>:  类似的，<code>query 序列</code>最后面也有可能是一堆 padding，不过对 queries 做 padding mask 不需要把 padding 加上一个很小的值，只要将其置零就行，因为 outputs 是先 key mask，再经过 softmax，再进行 query mask的。</li><li><code>type in (&quot;f&quot;, &quot;future&quot;, &quot;right&quot;)</code>:  是我们在做 <code>decoder</code> 的 self attention 时要用到的 <code>sequence mask</code>，也就是说在每一步，第 i 个 token 关注到的 attention 只有可能是在第 i 个单词之前的单词，因为它按理来说，看不到后面的单词, 作者用一个下三角矩阵来完成这个操作。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaled_dot_product_attention</span>(<span class="params">Q, K, V, key_masks,</span></span><br><span class="line"><span class="params">                                 causality=<span class="literal">False</span>, dropout_rate=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                                 training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                                 scope=<span class="string">&quot;scaled_dot_product_attention&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;See 3.2.1.</span></span><br><span class="line"><span class="string">    Q: Packed queries. 3d tensor. [N, T_q, d_k].</span></span><br><span class="line"><span class="string">    K: Packed keys. 3d tensor. [N, T_k, d_k].</span></span><br><span class="line"><span class="string">    V: Packed values. 3d tensor. [N, T_k, d_v].</span></span><br><span class="line"><span class="string">    key_masks: A 2d tensor with shape of [N, key_seqlen]</span></span><br><span class="line"><span class="string">    causality: If True, applies masking for future blinding</span></span><br><span class="line"><span class="string">    dropout_rate: A floating point number of [0, 1].</span></span><br><span class="line"><span class="string">    training: boolean for controlling droput</span></span><br><span class="line"><span class="string">    scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=tf.AUTO_REUSE):</span><br><span class="line">        d_k = Q.get_shape().as_list()[-<span class="number">1</span>]</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># dot product</span></span><br><span class="line">        outputs = tf.matmul(Q, tf.transpose(K, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]))  <span class="comment"># (N, T_q, T_k)</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># scale</span></span><br><span class="line">        outputs /= d_k ** <span class="number">0.5</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># key masking</span></span><br><span class="line">        outputs = mask(outputs, key_masks=key_masks, <span class="built_in">type</span>=<span class="string">&quot;key&quot;</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># causality or future blinding masking</span></span><br><span class="line">        <span class="keyword">if</span> causality:</span><br><span class="line">            outputs = mask(outputs, <span class="built_in">type</span>=<span class="string">&quot;future&quot;</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># softmax</span></span><br><span class="line">        outputs = tf.nn.softmax(outputs)</span><br><span class="line">        attention = tf.transpose(outputs, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">        tf.summary.image(<span class="string">&quot;attention&quot;</span>, tf.expand_dims(attention[:<span class="number">1</span>], -<span class="number">1</span>))</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># # query masking</span></span><br><span class="line">        <span class="comment"># outputs = mask(outputs, Q, K, type=&quot;query&quot;)</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># dropout</span></span><br><span class="line">        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=training)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># weighted sum (context vectors)</span></span><br><span class="line">        outputs = tf.matmul(outputs, V)  <span class="comment"># (N, T_q, d_v)</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mask</span>(<span class="params">inputs, key_masks=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Masks paddings on keys or queries to inputs</span></span><br><span class="line"><span class="string">    inputs: 3d tensor. (h*N, T_q, T_k)</span></span><br><span class="line"><span class="string">    key_masks: 3d tensor. (N, 1, T_k)</span></span><br><span class="line"><span class="string">    type: string. &quot;key&quot; | &quot;future&quot; </span></span><br><span class="line"><span class="string">    e.g.,</span></span><br><span class="line"><span class="string">    &gt;&gt; inputs = tf.zeros([2, 2, 3], dtype=tf.float32)</span></span><br><span class="line"><span class="string">    &gt;&gt; key_masks = tf.constant([[0., 0., 1.],</span></span><br><span class="line"><span class="string">                                [0., 1., 1.]])</span></span><br><span class="line"><span class="string">    &gt;&gt; mask(inputs, key_masks=key_masks, type=&quot;key&quot;)</span></span><br><span class="line"><span class="string">    array([[[ 0.0000000e+00,  0.0000000e+00, -4.2949673e+09],</span></span><br><span class="line"><span class="string">        [ 0.0000000e+00,  0.0000000e+00, -4.2949673e+09]],</span></span><br><span class="line"><span class="string">       [[ 0.0000000e+00, -4.2949673e+09, -4.2949673e+09],</span></span><br><span class="line"><span class="string">        [ 0.0000000e+00, -4.2949673e+09, -4.2949673e+09]],</span></span><br><span class="line"><span class="string">       [[ 0.0000000e+00,  0.0000000e+00, -4.2949673e+09],</span></span><br><span class="line"><span class="string">        [ 0.0000000e+00,  0.0000000e+00, -4.2949673e+09]],</span></span><br><span class="line"><span class="string">       [[ 0.0000000e+00, -4.2949673e+09, -4.2949673e+09],</span></span><br><span class="line"><span class="string">        [ 0.0000000e+00, -4.2949673e+09, -4.2949673e+09]]], dtype=float32)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding_num = -<span class="number">2</span> ** <span class="number">32</span> + <span class="number">1</span> <span class="comment">#足够小的负数，保证被填充的位置进入softmax之后概率接近0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span> <span class="keyword">in</span> (<span class="string">&quot;k&quot;</span>, <span class="string">&quot;key&quot;</span>, <span class="string">&quot;keys&quot;</span>): <span class="comment"># padding mask</span></span><br><span class="line">        key_masks = tf.to_float(key_masks)</span><br><span class="line">        key_masks = tf.tile(key_masks, [tf.shape(inputs)[<span class="number">0</span>] // tf.shape(key_masks)[<span class="number">0</span>], <span class="number">1</span>]) <span class="comment"># (h*N, seqlen)</span></span><br><span class="line">        key_masks = tf.expand_dims(key_masks, <span class="number">1</span>)  <span class="comment"># (h*N, 1, seqlen)</span></span><br><span class="line">        outputs = inputs + key_masks * padding_num</span><br><span class="line">    <span class="comment"># elif type in (&quot;q&quot;, &quot;query&quot;, &quot;queries&quot;):</span></span><br><span class="line">    <span class="comment">#     # Generate masks</span></span><br><span class="line">    <span class="comment">#     masks = tf.sign(tf.reduce_sum(tf.abs(queries), axis=-1))  # (N, T_q)</span></span><br><span class="line">    <span class="comment">#     masks = tf.expand_dims(masks, -1)  # (N, T_q, 1)</span></span><br><span class="line">    <span class="comment">#     masks = tf.tile(masks, [1, 1, tf.shape(keys)[1]])  # (N, T_q, T_k)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     # Apply masks to inputs</span></span><br><span class="line">    <span class="comment">#     outputs = inputs*masks</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span> <span class="keyword">in</span> (<span class="string">&quot;f&quot;</span>, <span class="string">&quot;future&quot;</span>, <span class="string">&quot;right&quot;</span>):    <span class="comment"># future mask</span></span><br><span class="line">        diag_vals = tf.ones_like(inputs[<span class="number">0</span>, :, :])  <span class="comment"># (T_q, T_k)    </span></span><br><span class="line">        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()  <span class="comment"># (T_q, T_k)    # 上三角皆为0</span></span><br><span class="line">        future_masks = tf.tile(tf.expand_dims(tril, <span class="number">0</span>), [tf.shape(inputs)[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># (N, T_q, T_k)    # N batch size</span></span><br><span class="line"> </span><br><span class="line">        paddings = tf.ones_like(future_masks) * padding_num</span><br><span class="line">        outputs = tf.where(tf.equal(future_masks, <span class="number">0</span>), paddings, inputs)     <span class="comment"># 上三角中用padding值代替 </span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Check if you entered type correctly!&quot;</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h3 id="3-4-Add-amp-Norm"><a href="#3-4-Add-amp-Norm" class="headerlink" title="3.4 Add &amp; Norm"></a>3.4 Add &amp; Norm</h3><p>在 <code>multihead_attention</code> 模块的代码中有以下2行代码，这边对应着模型结构图 <code>encoder</code> 中的 <code>Add &amp; Norm</code> 模块，如下图所示。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Residual connection</span></span><br><span class="line">outputs += queries </span><br><span class="line"></span><br><span class="line"><span class="comment"># Layer Normalize </span></span><br><span class="line">outputs = ln(outputs)</span><br></pre></td></tr></table></figure></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer14.png" alt="transformer14"></p><p>其中 <code>Add</code> 是类似残差的操作，但与残差不同的是，不是用输入减去输出，而是用输入加上输出。</p><p>而对于 <code>Norm</code>，这里则用的是 <code>Layer Norm</code>，其代码如后文所示。不论是哪一种实际上都是对输入的分布进行调整，调整的通常方式是：</p><script type="math/tex; mode=display">Norm(x_i) = \alpha \times \frac{x_i - u}{\sqrt{\sigma^2_L + \epsilon}} + \beta</script><p>其中，不同的 Norm 方法便对应着不同的 $u,\sigma$ 计算方式。</p><p>这里之所以使用 <code>Layer Norm</code> 而不是 <code>Batch Norm</code> 的原因是：</p><ol><li>BN 比较依赖 BatchSize，偏小不适合，过大耗费 GPU 显存；</li><li>BN 需要 batch 内 features 的维度一致；</li><li>BN 只在训练的时候用，inference 的时候不会用到，因为 inference 的输入不是批量输入；</li><li>每条样本的 token 是同一类型特征，LN 擅长处理，与其他样本不关联，通信成本更少；</li><li>embedding 和 layer size 大，且长度不统一，LN 可以处理且保持分布稳定。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ln</span>(<span class="params">inputs, epsilon = <span class="number">1e-8</span>, scope=<span class="string">&quot;ln&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Applies layer normalization. See https://arxiv.org/abs/1607.06450.</span></span><br><span class="line"><span class="string">    inputs: A tensor with 2 or more dimensions, where the first dimension has `batch_size`.</span></span><br><span class="line"><span class="string">    epsilon: A floating number. A very small number for preventing ZeroDivision Error.</span></span><br><span class="line"><span class="string">    scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A tensor with the same shape and data dtype as `inputs`.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=tf.AUTO_REUSE):</span><br><span class="line">        inputs_shape = inputs.get_shape()    <span class="comment"># 输入形状</span></span><br><span class="line">        params_shape = inputs_shape[-<span class="number">1</span>:]    <span class="comment"># </span></span><br><span class="line">    </span><br><span class="line">        mean, variance = tf.nn.moments(inputs, [-<span class="number">1</span>], keep_dims=<span class="literal">True</span>)    <span class="comment"># 求均值和方差</span></span><br><span class="line">        beta= tf.get_variable(<span class="string">&quot;beta&quot;</span>, params_shape, initializer=tf.zeros_initializer())</span><br><span class="line">        gamma = tf.get_variable(<span class="string">&quot;gamma&quot;</span>, params_shape, initializer=tf.ones_initializer())</span><br><span class="line">        normalized = (inputs - mean) / ( (variance + epsilon) ** (<span class="number">.5</span>) )</span><br><span class="line">        outputs = gamma * normalized + beta</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h3 id="3-5-Feed-Forward"><a href="#3-5-Feed-Forward" class="headerlink" title="3.5 Feed Forward"></a>3.5 Feed Forward</h3><p>承接上述，encoder 中只剩下最后一个环节了，也就是 <code>ff</code> 层（Feed Forward），对比模型图，实际上 <code>ff</code> 后还有一层 <code>Add &amp; Norm</code>，但是一般将其二者合并在一个模块中，统称为 <code>ff</code> 层。</p><p>该模块的 code 如下所示，相对比较清晰，2 层 dense 网络后紧接一个 <code>Residual connection</code> 即将输入直接相加，最后再过一层 <code>Layer Normalization</code> 即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ff</span>(<span class="params">inputs, num_units, scope=<span class="string">&quot;positionwise_feedforward&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;position-wise feed forward net. See 3.3</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    inputs: A 3d tensor with shape of [N, T, C].</span></span><br><span class="line"><span class="string">    num_units: A list of two integers.  </span></span><br><span class="line"><span class="string">                num_units[0]=d_ff: 隐藏层大小（2048）</span></span><br><span class="line"><span class="string">                num_units[1]=d_model: 词向量长度（512）</span></span><br><span class="line"><span class="string">    scope: Optional scope for `variable_scope`.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      A 3d tensor with the same shape and dtype as inputs</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=tf.AUTO_REUSE):</span><br><span class="line">        <span class="comment"># Inner layer</span></span><br><span class="line">        outputs = tf.layers.dense(inputs, num_units[<span class="number">0</span>], activation=tf.nn.relu)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Outer layer </span></span><br><span class="line">        outputs = tf.layers.dense(outputs, num_units[<span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Residual connection</span></span><br><span class="line">        outputs += inputs</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Layer Normalize</span></span><br><span class="line">        outputs = ln(outputs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h3 id="3-6-decoder"><a href="#3-6-decoder" class="headerlink" title="3.6 decoder"></a>3.6 decoder</h3><p>截止上述是完成了模型的 encoder 模块，本节重点介绍 decoder 模块，其在应用形式上与 encoder 略有不同，整体结构如前文模型结构图中已有展示，容易发现有几个特殊之处：</p><ol><li>输入是经过 <code>Sequence Mask</code> 的，也就是掩去未出现的词；</li><li>每个 decoder 有 2 个 <code>multihead_attention</code> 层；</li><li>首层 <code>multihead_attention</code> 的 $Q,K,V$都是来源输入向量，第二层输入中的 $K,V$ 则是来自 encoder 模块的输出作为 memory 来输入。</li></ol><p>整个 decoder 侧的工作原理可以如下动画展示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer15.gif" alt="transformer15"></p><p>其中在最后一层 <code>Linear+Softmax</code> 后是怎么得到单词的，想必了解 nlp 的同学也不会陌生，一般就是转化为对应词表大小的概率分布，取最大的位置词即可，如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/transformer16.png" alt="transformer16"></p><p>整个 decode 的 code 如下所示，可以清晰的看到 decoder 前的处理与 encoder 几乎一致，唯独 mask 模块走的是 <code>Sequence Mask</code>，在前面的 mask 代码有涉及。每个 decoder 中的 2 层 <code>multihead_attention</code> 的输入差异也比较清晰，重点就是将 encode 模块的输出应用在每个 decoder 的第二层 <code>multihead_attention</code> 中。输出的时候，实际上利用了 <code>softmax</code> 的单调性，直接使用 <code>tf.argmax</code> 来获取最大值位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, ys, memory, src_masks, training=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    memory: encoder outputs. (N, T1, d_model)</span></span><br><span class="line"><span class="string">    src_masks: (N, T1)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    logits: (N, T2, V). float32.</span></span><br><span class="line"><span class="string">    y_hat: (N, T2). int32</span></span><br><span class="line"><span class="string">    y: (N, T2). int32</span></span><br><span class="line"><span class="string">    sents2: (N,). string.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;decoder&quot;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        decoder_inputs, y, seqlens, sents2 = ys</span><br><span class="line"></span><br><span class="line">        <span class="comment"># tgt_masks</span></span><br><span class="line">        tgt_masks = tf.math.equal(decoder_inputs, <span class="number">0</span>)  <span class="comment"># (N, T2)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># embedding</span></span><br><span class="line">        dec = tf.nn.embedding_lookup(<span class="variable language_">self</span>.embeddings, decoder_inputs)  <span class="comment"># (N, T2, d_model)</span></span><br><span class="line">        dec *= <span class="variable language_">self</span>.hp.d_model ** <span class="number">0.5</span>  <span class="comment"># scale</span></span><br><span class="line"></span><br><span class="line">        dec += positional_encoding(dec, <span class="variable language_">self</span>.hp.maxlen2)</span><br><span class="line">        dec = tf.layers.dropout(dec, <span class="variable language_">self</span>.hp.dropout_rate, training=training)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Blocks</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.hp.num_blocks):</span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;num_blocks_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i), reuse=tf.AUTO_REUSE):</span><br><span class="line">                <span class="comment"># Masked self-attention (Note that causality is True at this time)</span></span><br><span class="line">                dec = multihead_attention(queries=dec,</span><br><span class="line">                                          keys=dec,</span><br><span class="line">                                          values=dec,</span><br><span class="line">                                          key_masks=tgt_masks,</span><br><span class="line">                                          num_heads=<span class="variable language_">self</span>.hp.num_heads,</span><br><span class="line">                                          dropout_rate=<span class="variable language_">self</span>.hp.dropout_rate,</span><br><span class="line">                                          training=training,</span><br><span class="line">                                          causality=<span class="literal">True</span>,</span><br><span class="line">                                          scope=<span class="string">&quot;self_attention&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Vanilla attention</span></span><br><span class="line">                dec = multihead_attention(queries=dec,</span><br><span class="line">                                          keys=memory,</span><br><span class="line">                                          values=memory,</span><br><span class="line">                                          key_masks=src_masks,</span><br><span class="line">                                          num_heads=<span class="variable language_">self</span>.hp.num_heads,</span><br><span class="line">                                          dropout_rate=<span class="variable language_">self</span>.hp.dropout_rate,</span><br><span class="line">                                          training=training,</span><br><span class="line">                                          causality=<span class="literal">False</span>,</span><br><span class="line">                                          scope=<span class="string">&quot;vanilla_attention&quot;</span>)</span><br><span class="line">                <span class="comment">### Feed Forward</span></span><br><span class="line">                dec = ff(dec, num_units=[<span class="variable language_">self</span>.hp.d_ff, <span class="variable language_">self</span>.hp.d_model])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final linear projection (embedding weights are shared)</span></span><br><span class="line">    weights = tf.transpose(<span class="variable language_">self</span>.embeddings) <span class="comment"># (d_model, vocab_size)</span></span><br><span class="line">    logits = tf.einsum(<span class="string">&#x27;ntd,dk-&gt;ntk&#x27;</span>, dec, weights) <span class="comment"># (N, T2, vocab_size)</span></span><br><span class="line">    y_hat = tf.to_int32(tf.argmax(logits, axis=-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> logits, y_hat, y, sents2</span><br></pre></td></tr></table></figure><h3 id="3-7-特殊模块"><a href="#3-7-特殊模块" class="headerlink" title="3.7 特殊模块"></a>3.7 特殊模块</h3><h4 id="3-7-1-label-smoothing"><a href="#3-7-1-label-smoothing" class="headerlink" title="3.7.1 label_smoothing"></a>3.7.1 label_smoothing</h4><p>如前文提到的 <code>train</code> 模块代码，在 decode 后，紧接的便是 <code>label_smoothing</code> 模块。其作用就是：</p><blockquote><p>平滑一下标签值，比如 <code>ground truth</code> 标签是 1 的，改到 0.9333，本来是 0 的，他改到 0.0333，这是一个比较经典的平滑技术了。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">label_smoothing</span>(<span class="params">inputs, epsilon=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Applies label smoothing. See 5.4 and https://arxiv.org/abs/1512.00567.</span></span><br><span class="line"><span class="string">    inputs: 3d tensor. [N, T, V], where V is the number of vocabulary.</span></span><br><span class="line"><span class="string">    epsilon: Smoothing rate.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    For example,</span></span><br><span class="line"><span class="string">    </span></span><br></pre></td></tr></table></figure><pre><code>import tensorflow as tfinputs = tf.convert_to_tensor([[[0, 0, 1],    [0, 1, 0],   [1, 0, 0]],  [[1, 0, 0],   [1, 0, 0],   [0, 1, 0]]], tf.float32)outputs = label_smoothing(inputs)with tf.Session() as sess:    print(sess.run([outputs]))&gt;&gt;[array([[[ 0.03333334,  0.03333334,  0.93333334],    [ 0.03333334,  0.93333334,  0.03333334],    [ 0.93333334,  0.03333334,  0.03333334]],   [[ 0.93333334,  0.03333334,  0.03333334],    [ 0.93333334,  0.03333334,  0.03333334],    [ 0.03333334,  0.93333334,  0.03333334]]], dtype=float32)]   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">V = inputs.get_shape().as_list()[-1] # number of channels</span><br><span class="line">return ((1-epsilon) * inputs) + (epsilon / V)</span><br></pre></td></tr></table></figure></code></pre><h4 id="3-7-2-noam-scheme"><a href="#3-7-2-noam-scheme" class="headerlink" title="3.7.2 noam_scheme"></a>3.7.2 noam_scheme</h4><p>在模型的学习了上，作者使用了 <code>noam_scheme</code> 这样一个机制来处理。代码如后文所示，使用的学习率递减公式为：</p><script type="math/tex; mode=display">Lr = init_lr * warm_step^{0.5} * min(s * warm_step^{-1.5}, s^{-0.5})</script><p>其中，$init_lr$ 是指<code>初始学习率</code>，$warm_step$ 是<code>指预热步数</code>，而 $s$ 则是代表全局步数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">noam_scheme</span>(<span class="params">init_lr, global_step, warmup_steps=<span class="number">4000.</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Noam scheme learning rate decay</span></span><br><span class="line"><span class="string">    init_lr: initial learning rate. scalar.</span></span><br><span class="line"><span class="string">    global_step: scalar.</span></span><br><span class="line"><span class="string">    warmup_steps: scalar. During warmup_steps, learning rate increases</span></span><br><span class="line"><span class="string">        until it reaches init_lr.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    step = tf.cast(global_step + <span class="number">1</span>, dtype=tf.float32)</span><br><span class="line">    <span class="keyword">return</span> init_lr * warmup_steps ** <span class="number">0.5</span> * tf.minimum(step * warmup_steps ** -<span class="number">1.5</span>, step ** -<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><h3 id="3-8-其他"><a href="#3-8-其他" class="headerlink" title="3.8 其他"></a>3.8 其他</h3><h4 id="3-8-1-项目运行"><a href="#3-8-1-项目运行" class="headerlink" title="3.8.1 项目运行"></a>3.8.1 项目运行</h4><p>该项目运行需要 <code>sentencepiece</code>，其安装的时候留意是否关了 VPN，否则安装会失败，然后可以使用如下代码直接安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install sentencepiece</span><br></pre></td></tr></table></figure><h4 id="3-8-2-uitls模块"><a href="#3-8-2-uitls模块" class="headerlink" title="3.8.2 uitls模块"></a>3.8.2 uitls模块</h4><p><code>Transformer</code> 项目中 utils 模块是训练中使用到的工具算子集合，这里简单较少一下各个算子的作用。</p><ul><li><code>calc_num_batches</code>: 计算样本的 num_batch，就是 total_num/batch_size 取整，再加1；</li><li><code>convert_idx_to_token_tensor</code>: 将 int32 转为字符串张量（string tensor）;</li><li><code>postprocess</code>: 做翻译后的处理，输入一个是翻译的预测列表，还有一个是 id2token 的表，就是用查表的方式把数字序列转化成字符序列，从而形成一句可以理解的话。(如果做中文数据这个就要改一下了，中文不适用BPE等word piece算法)。</li><li><code>save_hparams</code>: 保存超参数。</li><li><code>load_hparams</code>: 加载超参数并覆写parser对象。</li><li><code>save_variable_specs</code>: 保存一些变量的信息，包括变量名，shape，总参数量等等。</li><li><code>get_hypotheses</code>: 得到预测序列。这个方法就是结合前面的 postprocess 方法，来生成 num_samples 个数的有意义的自然语言输出。</li><li><code>calc_bleu</code>: 计算BLEU值。</li></ul><h4 id="3-8-3-data-load模块"><a href="#3-8-3-data-load模块" class="headerlink" title="3.8.3 data_load模块"></a>3.8.3 data_load模块</h4><p>在数据加载中有不少预处理环节，我们重点介绍一下相关算子。</p><ul><li><code>load_vocab</code>: 加载词汇表。参数  vocab_fpath表示词文件的地址，会返回两个字典，一个是 id-&gt;token，一个是 token-&gt;id；</li><li><code>load_data</code>: 加载数据。加载源语和目标语数据，筛除过长的数据，注意是筛除，也就是长度超过maxlen的数据直接丢掉了，没加载进去。</li><li><code>encode</code>: 将字符串转化为数字，这里具体方法是输入的是一个字符序列，然后根据空格切分，然后如果是源语言，则每一句话后面加上“&lt;/s&gt;”，如果是目标语言，则在每一句话前面加上“<S>”，后面加上“&lt;/s&gt;”，然后再转化成数字序列。如果是中文，这里很显然要改。</li><li><code>generator_fn</code>: 生成训练和评估集数据。对于每一个sent1，sent2（源句子，目标句子），sent1经过前面的encode函数转化成x，sent2经过前面的encode函数转化成y之后，decoder的输入decoder_input是y[:-1]，预期输出y是y[1:]。</li><li><code>input_fn</code>: 生成Batch数据。</li><li><code>get_batch</code>: 获取batch数据。</li></ul><p><strong>参考文章</strong><br><a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a><br><a href="https://github.com/Kyubyong/transformer">transformer 源码</a><br><a href="https://zhuanlan.zhihu.com/p/149634836">Transformer和Bert相关知识解</a><br><a href="https://blog.csdn.net/nocml/article/details/110920221">Transformer(二)—论文理解：transformer 结构详解</a><br><a href="https://blog.csdn.net/caroline_wendy/article/details/109337216">Python - 安装sentencepiece异常</a><br><a href="https://blog.csdn.net/yujianmin1990/article/details/85221271">The Illustrated Transformer【译】</a><br><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a><br><a href="https://blog.csdn.net/u012759262/article/details/103999959?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4.control&amp;dist_request_id=58280678-ea4e-4d7f-a2c2-38bd90ab3bda&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-4.control">Attention专场——（2）Self-Attention 代码解析</a><br><a href="https://www.zhihu.com/question/347678607">如何理解Transformer论文中的positional encoding，和三角函数有什么关系？</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;算法工程师在成长道路上基本绕不开深度学习，而 &lt;code&gt;Transformer&lt;/code&gt; 模型更是其中的经典，它在2017年的&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;《Attention is All You Need》&lt;/a&gt;论文中被提出，直接掀起了 &lt;code&gt;Attention&lt;/code&gt; 机制在深度模型中的广泛应用潮流。&lt;/p&gt;
&lt;p&gt;在该模型中有许多奇妙的想法启发了诸多算法工程师的学习创造，为了让自己回顾复习更加方便，亦或让在学习的读者更轻松地理解，便写了这篇文章。形式上，在参考诸多优秀文章和博客后，这里还是采用结构与代码并行阐述的模式。&lt;/p&gt;</summary>
    
    
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="Transformer" scheme="https://www.xiemingzhao.com/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>PID 调控算法</title>
    <link href="https://www.xiemingzhao.com/posts/pidcontrol.html"/>
    <id>https://www.xiemingzhao.com/posts/pidcontrol.html</id>
    <published>2022-07-08T16:00:00.000Z</published>
    <updated>2025-04-04T17:48:51.554Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p><code>PID</code> 全称 <code>Proportional Integral Derivative</code>，拆分项分别是 <strong>比例（Proportional）、积分（Integral）和微分（Derivative）</strong>。是应用最为广泛的控制模型，有 100 余年的历史了，应用场景有四轴飞行器，汽车的定速巡航等。<br>官方流程图：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol0.png" alt="pidcontrol0"></p><span id="more"></span><p>官方公式：</p><script type="math/tex; mode=display">u(t)=K_pe(t)+K_i\int_0^te(\tau)d\tau+K_d\frac{d}{dt}e(t)=K_p[e(t)+\frac{1}{T_i}\int_0^te(\tau)d\tau+T_d\frac{d}{dt}e(t)]</script><p>其中：</p><ul><li>$K_p,K_i,K_d$ 分别是比例、积分、微分项的参数；</li><li>$T_i,T_d$ 分别是积分、微分的时间常数；</li><li>$e$ 为误差项=目标值(SP)-当前值(PV)；</li><li>$t$ 为当前时间，$\tau$ 积分变数；</li></ul><p>看上去很复杂，实际上比较简单，下面我们通过实例仿真的方式介绍下原理和效果。</p><h2 id="2-算法详解"><a href="#2-算法详解" class="headerlink" title="2 算法详解"></a>2 算法详解</h2><p><strong>示例场景</strong>：我们以汽车的ACC巡航功能为例，假设起始速度为0，目标巡航车速为60。<br><strong>最朴素的想法</strong>：以固定的加速度 a 加速到60后停止。<br><strong>问题</strong>：实际上很难做到上述，因为控制器、传感器的输入、输出量是有延迟的，并且还有惯性的存在（比如，加速度并不能够直接从某个值骤降到0）。所以，比如当车速为58的时候，加速度不变，很容易超过60，超过后减速又很容易低于60，如此稳定性极差。</p><h3 id="改进1-PID-中的-P-比例（Proportional）"><a href="#改进1-PID-中的-P-比例（Proportional）" class="headerlink" title="改进1: PID 中的 P-比例（Proportional）"></a>改进1: PID 中的 P-比例（Proportional）</h3><p>既然有上述问题的存在，那么一个简单的缓解办法就是油门（加速度）不能一直不变，需要时刻监控车速，根据车速来调整，越接近目标值的时候，加速或者减速幅度越小，<strong>以便于车速稳定</strong>。</p><p><strong>算法</strong>：当前时刻车速 $V_t$，目标车速 $V_a$，那么误差项 $e_t = V_a - V_t$，那么输出量为 $u_t = K_p * e_t$，即下一个单位时间提速 $u_t$。<br>通过代码模拟实际加速情况如下（$V_a = 60, K_p = 0.8$）：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol1.jpg" alt="pidcontrol1"></p><p>可以发现很快就趋近于目标值了。但实际上还是会存在<strong>问题</strong>：</p><blockquote><p>实际中汽车会收到风阻、地面摩擦力等各种阻力，会使汽车自燃状态下速度逐渐减小，我们假设单位时间汽车车速收到的阻力综合效果会减速 $V_p$。</p></blockquote><p>当我们把模拟代码加入此项后，情况如下（$V_P = 6$）：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol2.jpg" alt="pidcontrol2"></p><p>看上去最终车速停在了目标车速的下方，这个还是比较好证明的。因汽车最终的车速达到稳态后，则会有<strong>加速=阻力损失</strong>的状态，那么就有：</p><script type="math/tex; mode=display">K_p (V_a - V_t) = V_p</script><p>代入参数可以解得最重的稳态速度</p><script type="math/tex; mode=display">V_t = V_a - V_p/K_p = 52.5</script><blockquote><p>问题：这一差距称为<code>稳态误差</code>，因此需要想办法来克服这一误差。</p></blockquote><h3 id="改进2-PID-中的-I-积分（Proportional）"><a href="#改进2-PID-中的-I-积分（Proportional）" class="headerlink" title="改进2: PID 中的 I-积分（Proportional）"></a>改进2: PID 中的 I-积分（Proportional）</h3><p>积分项能够在比例单元的基础上，消除由比例调控造成的余差，能够对含有累计误差的系统进行误差修正，<strong>减小稳态误差</strong>。</p><p>我们来看实际情况中是怎么生效的，I项离散化后就是历史所有 $e<em>t$ 的累计和。$I_t = \sum</em>{t=0}^T e_t$当我们把模拟代码加入此项后，情况如下（$K_i = 0.2$）：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol3.jpg" alt="pidcontrol3"></p><p>可以发现，最终速度可以很好的收敛到目标。</p><p>为什么能够做到这一点呢？相对也比较好证明，基于前面的稳态条件，此处需要达到稳态的话，需要满足：</p><script type="math/tex; mode=display">K_i I_t + K_p \cdot e_t = V_p</script><p>一般 $K_i,K_p$ 都是正数，那么要想达到稳态，必须 $e_t = 0$，否则 $I_t$ 一直处于变化状态。而 $e_t = 0$ 则意味着 $V_t = V_a$，即在稳态达到的时候，车速最终也将在目标速度。</p><h3 id="改进3-PID中的-D-微分（Derivative）"><a href="#改进3-PID中的-D-微分（Derivative）" class="headerlink" title="改进3: PID中的 D-微分（Derivative）"></a>改进3: PID中的 D-微分（Derivative）</h3><p>看似拥有P和I项之后，整个系统效果已经不错了，那么为什么还需要D项呢？</p><p>实际上，在现实工业系统中，大多数控制通道都是有一定延迟之后的。这时候就需要D这一<code>微分项</code>，它具有<code>超前调节</code>的作用，合适的值能够有效减少系统的超调量，<strong>减缓振荡以提高稳定性</strong>。</p><p>我们来对比一下，假设引入系统滞后性参数 $delay = 0.1$:</p><ul><li>下左图为仅有P和I项，可见收敛前有一个比较大的峰值震荡；</li><li>相应的，在此基础上我们引入D项（$K_d=0.1$），结果如下右图，平缓了许多。</li></ul><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol4.jpg" alt="pidcontrol4"></p><p>可以见到，PID中的三项分别是针对实际系统中的情况进行设计的，有时候D项对应的问题不明显的时候（例如系统延迟很低），确实P和I就够用了。</p><p>另一方面，就是各项超参数的设定，虽然也有一些<a href="https://chem.jgvogel.cn/c/1156/1156348.shtml">参数调整的经验</a>，但在实际应用中更多还是靠实际应用效果为准。</p><h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><p>这里展示的是为了介绍构建的最简单的模型 code，实际工业应用远比此复杂，但底层逻辑相通，仅供参考。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> make_interp_spline</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PID</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, P, I, D</span>):</span><br><span class="line">        <span class="variable language_">self</span>.Kp = P</span><br><span class="line">        <span class="variable language_">self</span>.Ki = I</span><br><span class="line">        <span class="variable language_">self</span>.Kd = D</span><br><span class="line">        <span class="variable language_">self</span>.sample_time = <span class="number">0.00</span></span><br><span class="line">        <span class="variable language_">self</span>.current_time = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.last_time = <span class="variable language_">self</span>.current_time</span><br><span class="line">        <span class="variable language_">self</span>.upper = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.lower = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.last_error = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_error = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.inc = []</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_bound</span>(<span class="params">self, upper, lower</span>):</span><br><span class="line">        <span class="variable language_">self</span>.upper = upper</span><br><span class="line">        <span class="variable language_">self</span>.lower = lower</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_target</span>(<span class="params">self, target</span>):</span><br><span class="line">        <span class="variable language_">self</span>.target = target</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, feedback_value</span>):</span><br><span class="line">        error = <span class="variable language_">self</span>.target - feedback_value</span><br><span class="line">        delta_error = error - <span class="variable language_">self</span>.last_error</span><br><span class="line">        <span class="comment"># inc_error = error - 2 * self.last_error + self.pre_error</span></span><br><span class="line">        <span class="variable language_">self</span>.inc.append(error)</span><br><span class="line">        PTerm = <span class="variable language_">self</span>.Kp * error<span class="comment">#比例</span></span><br><span class="line">        ITerm = <span class="variable language_">self</span>.Ki * <span class="built_in">sum</span>(<span class="variable language_">self</span>.inc) <span class="comment">#积分</span></span><br><span class="line">        DTerm = <span class="variable language_">self</span>.Kd * delta_error <span class="comment">#微分</span></span><br><span class="line">        <span class="variable language_">self</span>.output = PTerm + ITerm + DTerm</span><br><span class="line">        <span class="comment"># self.output = min(self.upper,max(self.output, self.lower))</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_error = <span class="variable language_">self</span>.last_error</span><br><span class="line">        <span class="variable language_">self</span>.last_error = error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_pid</span>(<span class="params">P, I , D, L, isdelay = <span class="literal">True</span></span>):</span><br><span class="line">    pid = PID(P, I, D)</span><br><span class="line">    T = <span class="number">60.0</span></span><br><span class="line">    pid.set_target(T)</span><br><span class="line">    pid.set_bound(<span class="number">0.4</span>,-<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line">    END = L</span><br><span class="line">    feedback = <span class="number">0</span></span><br><span class="line">    damper =  <span class="number">0.1</span> * T <span class="comment"># 系统阻力</span></span><br><span class="line">    feedback_list = []</span><br><span class="line">    feedback_list.append(feedback)</span><br><span class="line">    time_list = []</span><br><span class="line">    time_list.append(<span class="number">0</span>)</span><br><span class="line">    setpoint_list = []</span><br><span class="line">    setpoint_list.append(pid.target)</span><br><span class="line">    output_last = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, END):</span><br><span class="line">        pid.update(feedback)</span><br><span class="line">        output = pid.output</span><br><span class="line">        delay = <span class="number">0</span> <span class="keyword">if</span> isdelay <span class="keyword">else</span> output_last * <span class="number">0.1</span></span><br><span class="line">        feedback += output - damper + delay <span class="comment">#PID控制系统的函数</span></span><br><span class="line">        feedback_list.append(feedback)</span><br><span class="line">        setpoint_list.append(pid.target)</span><br><span class="line">        time_list.append(i)</span><br><span class="line">        output_last = output</span><br><span class="line"></span><br><span class="line">    time_sm = np.array(time_list)</span><br><span class="line">    time_smooth = np.linspace(time_sm.<span class="built_in">min</span>(), time_sm.<span class="built_in">max</span>(), <span class="number">300</span>)</span><br><span class="line">    feedback_smooth = make_interp_spline(time_list, feedback_list)(time_smooth)</span><br><span class="line">    plt.figure(<span class="number">0</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.plot(time_smooth, feedback_smooth,<span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">    plt.plot(time_list, setpoint_list,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.xlim((<span class="number">0</span>, L))</span><br><span class="line">    plt.ylim((<span class="built_in">min</span>(feedback_list)-<span class="number">0.5</span>, <span class="built_in">max</span>(feedback_list)+<span class="number">0.5</span>))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;time (s)&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;PID (PV)&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;PID simulation by python&#x27;</span>,fontsize=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylim((<span class="number">0</span>, <span class="number">2</span>*T))</span><br><span class="line"></span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># P</span></span><br><span class="line">    test_pid(<span class="number">0.8</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, L=<span class="number">30</span>)</span><br><span class="line">    <span class="comment"># P + I</span></span><br><span class="line">    test_pid(<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, L=<span class="number">30</span>)</span><br><span class="line">    <span class="comment"># p + I + D</span></span><br><span class="line">    test_pid(<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, L=<span class="number">30</span>, isdelay=<span class="literal">False</span>)</span><br><span class="line">    test_pid(<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, L=<span class="number">30</span>, isdelay=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h2 id="3-流量调控应用"><a href="#3-流量调控应用" class="headerlink" title="3 流量调控应用"></a>3 流量调控应用</h2><p><strong>场景</strong>：在互联网推荐中，经常需要针对一些物料定制分发量。比如新品保最低量，特殊品定量分发等。<br><strong>差异</strong>：不同于ACC越早稳定到目标越好，需要的可能是尽量保留高效的pv，且逐步缓慢式的在规定时间结束前达到目标流量值。</p><p><strong>参数设定：</strong></p><ul><li>某物料日内的流量目标值 $pv_a=2880$；</li><li>跳出条件点击目标 $clk_a=3$;</li><li>分片时间窗口 $P=1h$（平滑pv_a日内波动）；</li><li>调控时间窗口 $W=5m$（p是w的整数倍）；</li></ul><p>那么W将是整个系统的更新频率，每个P内会更新12次；</p><p>假设当前时刻$t$，在某个分片$p$（8-9点）的某个调控窗口$w$（8:20-8:25）内。</p><p><strong>算法步骤：</strong></p><ol><li><p>统计实时流量：</p><ul><li>实时累计曝光$exp_t = 1000$，累计点击$clk_t=1$；</li><li>p和前一p的初始累计曝光$exp<em>p=970,exp</em>{p-1}=840$;</li></ul></li><li><p>判断是否跳出，即$(clk_t&gt;=clk_a)=False$;</p></li><li><p>计算目标：</p><ul><li>$t$所在窗口$p$内的总目标 $target_p=(2880/24)=120$；（简化为均分$pv_a/24$）</li><li>p开始到当前t的累积目标 $target_t = target_p \cdot (25/60) = 50$;</li><li>假设上一p的累积目标 $starget<em>{p-1} = 960$,那么当前 $starget_t = starget</em>{p-1}+ target_t=1010$；</li></ul></li><li><p>计算误差：</p><ul><li>$p$开始到当前$t$实际曝光 $pexp_t = exp_t - exp_p = 30$;</li><li>当前$t$误差 $e_t = target_t - pexp_t = 20$;</li><li>假设 $exp<em>{t-1} = 980$,那么 $e</em>{t-1} = target<em>{t-1} - pexp</em>{t-1} = 25$;</li><li>积分误差 $ie_t = starget_t - exp_t = 10$;</li><li>微分误差 $de<em>t = e_t - e</em>{t-1} = -5$;</li></ul></li><li><p>计算调控输出：</p><ul><li>$u_t = K_p \cdot e_t + K_i \cdot ie_t + K_d \cdot de_t$;</li><li>$u_t = max(min_u, min(u_t, max_u))$ 控制调控上下限；</li><li>应用方式，可以基于$u_t$做插入分发量，或者转为权重进行调控。</li></ul></li></ol><p>当然实际中有很多可以优化点的，比如：</p><ul><li>每个 $p$ 内的 $target_p$ 可以按照日内流量分布来加权计算更准确；</li><li>$u_t$ 应用的时候可以考虑物料具体的效率。</li></ul><p>整体来说，这是一个比较经典的PID算法应用示例，当然也可以看得出，我们还是需要从实际问题出发对算法做一定的调整以便于更好的服务于业务。</p><p><strong>参考文献:</strong><br><a href="https://zhuanlan.zhihu.com/p/448979690">什么是PID？讲个故事，秒懂！</a><br><a href="https://zhuanlan.zhihu.com/p/39573490">PID控制算法原理</a><br><a href="https://chem.jgvogel.cn/c/1156/1156348.shtml">PID算法的一般形式、原理、公式等</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;&lt;code&gt;PID&lt;/code&gt; 全称 &lt;code&gt;Proportional Integral Derivative&lt;/code&gt;，拆分项分别是 &lt;strong&gt;比例（Proportional）、积分（Integral）和微分（Derivative）&lt;/strong&gt;。是应用最为广泛的控制模型，有 100 余年的历史了，应用场景有四轴飞行器，汽车的定速巡航等。&lt;br&gt;官方流程图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/pidcontrol0.png&quot; alt=&quot;pidcontrol0&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="调控算法" scheme="https://www.xiemingzhao.com/tags/%E8%B0%83%E6%8E%A7%E7%AE%97%E6%B3%95/"/>
    
    <category term="PID" scheme="https://www.xiemingzhao.com/tags/PID/"/>
    
  </entry>
  
  <entry>
    <title>MIND（多兴趣）召回模型</title>
    <link href="https://www.xiemingzhao.com/posts/mindmodel.html"/>
    <id>https://www.xiemingzhao.com/posts/mindmodel.html</id>
    <published>2022-06-15T16:00:00.000Z</published>
    <updated>2025-04-04T17:48:35.407Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在深度学习召回算法领域，比较经典的包括了以下2大类：</p><ul><li>基于 <code>item2vec</code> 模型构建在线的i2i召回；</li><li>基于 <code>user2item</code> 泛双塔模型构建在线的u2i召回；</li></ul><blockquote><p>当然还有2阶以上的召回，<code>i2u2i</code>、<code>u2u2i</code>等，在这里不做重点介绍，最终目的都是为了召回 item。</p></blockquote><p>对于第一种，相信大家比较熟知的有从 <code>word2vec</code> 衍生出的<code>item2vec</code>、阿里的<code>deepwalk</code>以及<code>FM</code>等，核心方式都是离线构建出 item 的 Embedding，<strong>在online侧基于用户的行为序列，取其中的 item 作为 trigger 来进行倒排/近邻召回</strong>。</p><span id="more"></span><p>对于第二种，一般比较常用的有微软的 <code>DSSM</code>、<code>Airbnb</code> 的向量召回的以及 <code>YouTubeDNN</code> 模型。他们的核心原理都是构建 user 和 item 的泛化双塔结构，使得 user 和 item 侧的独立生成各自的 Embedding，之后一般进行点积计算余弦相关性来构建 logloss 的优化目标。<strong>online 侧一般基于 user 画像特征，结合 user 侧模型结构实时 infer 出 userEmbedding，并从 item 集合中进行近邻召回 TopK</strong>。</p><p>本文重点介绍的就是2019年阿里团队在 CIKM 上发表的论文<a href="https://arxiv.org/pdf/1904.08030.pdf">《Multi-Interest Network with Dynamic Routing for Recommendation at Tmal》</a>中提出的 <code>MIND（多兴趣）</code>召回模型。</p><h2 id="2-动机"><a href="#2-动机" class="headerlink" title="2 动机"></a>2 动机</h2><blockquote><p>在 u2i 召回领域，最重要便是建立合适的用户<code>兴趣模型</code>，以构建用户兴趣的<code>有效表示</code>。</p></blockquote><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind0.png" alt="mind0"></p><p>如上图所示，便是<strong>经典的电商推荐场景</strong>，在召回阶段需要快速召回数千个与用户相关的候选物品。在文章的业务场景中，每日uv量大约在10亿级别，每个 user 会与上百量级的 item 进行互动，而整个物品池在千万甚至亿级别。所以作者发现<code>用户的兴趣具有显著的多样性</code>。</p><p>那么如何有效地表示这种多样的用户兴趣是最关键的问题，在此之前已有不少方案：</p><ul><li><code>协同过滤</code>(itemcf, usercf)召回，是通过历史交互过的物品或隐藏因子直接表示用户兴趣， 但会遇到<strong>稀疏或计算问题</strong></li><li>基于<code>深度学习</code>的召回，将user表示成 dense embedding，例如 DSSM、YouTubeDNN。但是这种<code>单一embedding表示有局限性</code>，对用户兴趣<strong>多样性表示欠佳，而增加 embedding 维度又会带来计算成本，并且也无法解决信息混合的问题</strong>。</li><li>基于 <code>Attention 机制</code>的兴趣表示，例如经典的 DIN 模型。但是，此结构为了有效提取与 item 的信息，需要针对每一个候选 item 应用 attention 来计算 user 的 embedding，<strong>主要应用场景是精排模块</strong>。当然，self-attention 可以避开候选 item 侧，但是其也就退化成了上一种 u2i 模型。</li></ul><p>为了更好的表示用户多样的兴趣，同时又尽量避开上述方法的弊端，作者提出了 MIND（多兴趣）网络模型。其<code>核心思想</code>便是：</p><blockquote><p><strong>基于胶囊网络的动态路由算法来将用户兴趣表示成多个向量</strong></p></blockquote><h2 id="3-胶囊网络与动态路由"><a href="#3-胶囊网络与动态路由" class="headerlink" title="3 胶囊网络与动态路由"></a>3 胶囊网络与动态路由</h2><p>在介绍 <code>MIND</code> 之前，我们需要介绍一下<code>胶囊网络</code>和<code>动态路由</code>这两个知识点，主要是因为它们是MIND模型作者的借鉴来源，熟悉它们有助于对MIND的理解，当然我们只捡其中最核心相关部分来详解。</p><h3 id="3-1-模型起源"><a href="#3-1-模型起源" class="headerlink" title="3.1 模型起源"></a>3.1 模型起源</h3><p>胶囊网络模型是2017年大名鼎鼎的 Hinton 在文章<a href="https://arxiv.org/pdf/1710.09829.pdf">《Dynamic Routing Between Capsule》</a>中提出的。</p><p>实际上，胶囊网络是为了解决CNN在图像识别上的问题。彼时，CNN识别效果很显著，其具有下面两个特性：</p><ul><li><code>平移不变性（translation invariance ）</code>：即不管图片的内容如何进行平移，CNN还能输出与之前一样的结果。这个性质由全局共享权值和 Pooling 共同得到的；</li><li><code>平移等变性（translation equivariance）</code>：即如果你对其输入施加的变换也会同样反应在输出上。这由局部连接和权值共享决定。</li></ul><p>但是其依然具有与一些问题，那就是<strong>对同一个图像的旋转版本会识别错误</strong>，学术上称为不具有<code>旋转不变性</code>。所以为了缓解这一问题，常常会做<code>数据增强</code>以及<code>pooling</code>的操作去增加鲁棒程度：</p><ul><li><code>数据增强</code>：给图片经过旋转，裁剪，变换等操作，让CNN能学习同一张图片不同的这些形态；</li><li><code>pooling</code>：使得网络减少对特征出现的原始位置的依赖；</li></ul><p>以上两种方式往往可以提高模型的泛化能力，但同时丢失了对位置信息的捕获能力。<strong>胶囊网络就是为了赋予模型理解图像中所发生变化的能力，从而可以更好地概括所感知的内容</strong>。</p><h3 id="3-2-胶囊网络"><a href="#3-2-胶囊网络" class="headerlink" title="3.2 胶囊网络"></a>3.2 胶囊网络</h3><p>接下来重点了解一下<code>Capsule</code>（胶囊网络）的结构，我们将其与传统的神经元结构做一个对比，如下图所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind1.png" alt="mind1"></p><ul><li>上图左侧是标准的神经元结构，其 input 与 output 都是标量，即 <code>scalar to scalar</code> 形式；</li><li>上图右侧便是一个胶囊结构，其 input 与 output 都是 vector，即 <code>vector to vector</code> 形式；</li></ul><p>进一步解析 <code>Capsule</code> 结构，实际上这里的是不包含路由结构的单次胶囊结构。其输入是两个 vector，即 $v_1,v_2$，经过 $W_i$ 线性映射（矩阵乘）后得到新向量 $u_1,u_2$。之后，经过一组 $c_i$ 进行加权和得到汇总向量 $s$，$c_i$ 的计算方式后面会详细介绍。最后将 $s$ 经过<code>Squashing</code>算子便得到了输出向量 $v$。整体计算过程可以汇总如下公式组：</p><script type="math/tex; mode=display">\begin{array}{l}u_i = W_i v_i \\s = \sum c_i u_i \\v = Squashing(s) = \frac{||s||^2}{1 + ||s||^2} \frac{s}{||s||}\end{array}</script><p>对于<code>Squashing</code>算子，我们可以发现:</p><ul><li>其右边的项就是为了做 <code>norm</code>，来<strong>归一化量纲，同时保留了向量的方向</strong>。</li><li>而左侧项则是根据 $s$ 的模 $||s||$ 的大小来对结果进行<strong>压缩，越大，该项约趋于1，相反则趋于0</strong>。</li></ul><p>如此便会有：</p><blockquote><p>当$||s||$比较大的时候，一般是具有大值的长向量，则有$v \approx \frac{s}{||s||}$；<br>当$||s||$比较小的时候，一般是具有小值的短向量，则有$v \approx s||s||$；</p></blockquote><p>为了进一步了解该函数的性质，我们基于标量构建<code>Squashing</code>算子的函数图如下。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind2.png" alt="mind2"></p><p>值得注意的是，实际上$W_i$是需要学习的变量，而$c_i$并不是，其为迭代计算的超参数，重点将在下一节介绍。</p><h3 id="3-3-动态路由"><a href="#3-3-动态路由" class="headerlink" title="3.3 动态路由"></a>3.3 动态路由</h3><p>基于前面的胶囊结构，动态路由实际上就是其中叠加一个迭代计算的过程，如下图所示的是原始论文对该算法的描述。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind3.png" alt="mind3"></p><p>可以看到，先对每个胶囊初始化一个迭代参数$b_i$，并通过其生成权重$c_i$，在每一次迭代完成之后，更新迭代参数$b_i$。</p><p>这样看不够清晰，由于其基于CNN介绍的，包括了多个 Layer。所以我们基于前一节的单层 <code>Capsule</code>（胶囊网络）转化成如下的计算公式：</p><script type="math/tex; mode=display">\begin{array}{l}b_1^0 = 0, b_2^0 = 0 \\for \quad r = 1 \quad to \quad R \\\quad c_1^r, c_2^r = softmax(b_1^r,b_2^r) \\\quad s^r = c_1^r u_1 + c_2^r u_2 \\\quad a^r = Squashing(s^r) \\\quad b_i^r = b_i^{r-1} +a^r u_i\end{array}</script><p>我们来简要说明一下<strong>整个流程</strong>：</p><ul><li>先对每个 capsule 初始化一个$b_i=0$；</li><li>开始R轮迭代，每轮迭代做以下步骤：<blockquote><ol><li>对所有的$b_i$取 softmax，如此使得权重$c_i$总和为1</li><li>基于$c_i$对所有$u_i$进行加权求和得到$s$</li><li>对$s$应用 Squashing 算子，得到结果向量$a$</li><li>按照公式更新所有$b_i$，并开始下一轮迭代</li></ol></blockquote></li></ul><p>可以看到，实际上权重$c_i$与 attention 中的 weights 生成机制很像，只不过在这里经过$b_i$作为迭代的中间参数，$b_i$实际上称为 <code>routing logit</code>。其初始化为0，就使得$c_i$初始值都一样，对每一个 capsule 的关注度一致，没有偏差，在后面经过学习进行迭代。</p><p>我们将这一迭代过程可视化出来更助于理解。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind4.png" alt="mind4"></p><p>实际上，$v_i$<strong>可以称为 Capsule 网络的 input 向量</strong>，首先通过 $W_i$ 将其线性映射为 $u_i$，在这里 $v_i,u_i$ 的维度可能不同，前者是输入维度，后者是胶囊维度。并且，<strong>这一映射过程只在迭代前进行</strong>，迭代中只会用到映射后的 $u_i$。</p><p>在上图中，实际上有2个 capsule 向量，即 $u_1,u_2$，所以对应的会有 $b_1,b_2$ 两个初始参数以及其对应的迭代权重 $c_1,c_2$。<strong>他们的右上角标是指迭代的轮数 r</strong>。</p><p>例如，</p><ol><li>r=0 的时候，$b_1^0=1,b_2^2=0$是初始化参数；</li><li>然后经过 softmax 得到第1轮的 $c_1^1,c_2^1$ 权重；</li><li>经过胶囊网络得到第1轮的结果向量 $a^1$；</li><li>按照公式 $b_i^r = b_i^{r-1} + a^r u_i$ 便可迭代得到第2轮的 $b_1^1,b_2^1$ 参数;</li><li>与是便得到更新后的第2轮的权重 $c_1^2,c_2^2$。</li></ol><p>以此类推，直到最后一步迭代结束将 $a^3$ 最为最终结果向量输出。</p><p>既然 $b_i$ 不是学习得到的，而是迭代得到的，那么这里重点关注一下其更新公式。我们可以发现：</p><blockquote><p>$b_i$ 在第r轮的变化项是 $a^r u_i$，如果该内积项值很大，则说明本轮的结果向量 $a^r$ 与此 <code>capsule</code> 向量 $u_i$ 很相似，那么参数 $b_i^r$ 便会增加，下一轮的权重 $c_i$ 同样变大，那么对应的 $a$ 中包含的 $u_i$ 的成分就会更大，二者向量就更近。<strong>实际上，这个 <code>dynamic routing</code> 的过程被看成是<code>软聚类</code>（soft-clustering）</strong>。</p></blockquote><h3 id="3-4-有效的原因"><a href="#3-4-有效的原因" class="headerlink" title="3.4 有效的原因"></a>3.4 有效的原因</h3><p>我们还以该技术的起源CNN图像识别为例，如下图所示，CNN实际上属于左侧结果，即对于图像的旋转是不变的，前面提过主要是通过一些手段加强训练的。而我们期望能够做到右侧的等变性，即能够感知到图像的变化，但又不影响结果。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind5.png" alt="mind5"></p><p>那为什么融入的 <code>Capsule</code> 网络结构就能够做到呢，我们举一个例子，如下图所示。</p><ul><li>左侧是一个经典的 <code>maxpooling 结构</code>，其仅仅能做到 <code>Invariance</code>（不变性），即对于位置的变化无法感知，但能够做到结果一致。</li><li>右侧是一个 <code>capsule 结构</code>，首先其在结果上能够做到 <code>Invariance</code>（不变性），同时其过程中产生的 <code>capsule</code> 向量是不同的，即能够感知到图像旋转的变化，所以同时做到了 <code>Equivariance</code>（等变性）。</li></ul><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind6.png" alt="mind6"></p><h2 id="4-MIND模型"><a href="#4-MIND模型" class="headerlink" title="4 MIND模型"></a>4 MIND模型</h2><h3 id="4-1-模型概述"><a href="#4-1-模型概述" class="headerlink" title="4.1 模型概述"></a>4.1 模型概述</h3><p>经过前面的介绍，接下来理解 MIND 模型的结构就会简单的多。我们首先将其网络架构展示出来:</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind7.png" alt="mind7"></p><p>整个图大部分都是比较清晰的。</p><ol><li>底部是输入特征的 Embedding Layer，包括：<ul><li><code>用户属性特征</code>（user ID，Age，Gender等，最左侧，<code>concat 操作</code>）</li><li><code>行为序列特征</code>（item ID，Brand ID，Category等，中间部分，<code>pooling 操作</code>）</li><li><code>物品特征</code>（item ID，Brand ID，Category等，最右侧，<code>pooling 操作</code>）</li></ul></li><li>用户行为序列特征会经过 <code>Multi-Interest Extractor Layer（多兴趣提取层）</code>抽取 <code>Interest Capsules</code>，即多个胶囊兴趣向量；</li><li>将生成的 <code>Interest Capsules</code> 与用户属性特征 <strong>concat 到一起，经过两层 ReLU 激活函数的全连接网络</strong>；</li><li>在 <code>training</code> 阶段，继续经过 <code>Label-aware Attention（标签意识注意力）</code>层，最终结合 <code>Sampled Softmax Loss</code>（负采样损失函数）即可完成训练；</li><li>而在左上角表示的是 <code>Serving</code> 的时候，线上直接使用<strong>步骤3的结果（多兴趣向量）进行 TopK 的近邻召回即可</strong>。</li></ol><p>需要注意的是，博主在工作中发现其中<strong>步骤3容易引起很多人误解</strong>：</p><blockquote><p>也就是 <code>Interest Capsules</code> 抽取完之后的紧接着的两层全连接，这里<em>很容易误解成将所有的兴趣向量与用户属性全部打平concat到到一起</em>，然后经过两层FC，那结果不就是一个向量了吗？难道说这里还需要重新再把结果的长向量slice成多个Interest Capsules？<strong>答案显然NO！</strong></p></blockquote><p>仔细研究后文或者 code，便可以知道：<strong>这里的FC（全连接）是应用在 Interest Capsules 与用户属性特征 concat 后的最后一维上</strong>。</p><p>这里列举相关变量维度可能更容易理解：</p><ul><li>假设 用户属性特征 <code>concat</code> 后维度是 (b, 1, n)，b 是 <code>Batch Size</code>，扩展出第二维的1是为了对齐</li><li>而提取的 <code>Interest Capsules</code> 层维度为 (b, k, m), k 是胶囊个数</li><li>全连接层 FC 的 Input 应该是上述二者的 concat 结果，即 (b, k, n+m)</li><li>FC 层是应用在上述结果的最后一层进行线性映射，故其结果维度 (b, k, d)，d 是最终的 capsule 维度，其应该和 item 侧 的embedding pooling 结果一致，如此才能做 Attention。</li></ul><p>接下来我们按照论文结构，介绍其中核心部分。</p><h3 id="4-2-问题定义"><a href="#4-2-问题定义" class="headerlink" title="4.2 问题定义"></a>4.2 问题定义</h3><p>这是一个召回问题，其任务目标毋庸置疑：</p><blockquote><p>根据用户行为和属性等特征抽取多个用户兴趣的向量表示，然后利用其从 item 池子中进行TopK的近邻召回。</p></blockquote><p>模型的输入在前一节已经介绍，主要是一个 <code>user&amp;item</code> 的信息三元组 $(I_u,P_u,F_i)$，其中：</p><ul><li>$I_u$ 代表与用户u交互过的物品集，即用户的历史行为;</li><li>$P_u$ 表示用户的属性，例如性别、年龄等；</li><li>$F_i$ 表示为目标物品i的一些特征，例如 item id 和 category id 等。</li></ul><p>基于上述，模型的<code>核心任务</code>：<br>将用户的属性$P_u$和行为特征$I_u$有效地映射成用户多兴趣 Embedding 向量集合，即</p><script type="math/tex; mode=display">V_u = f_u(I_u, P_u) = (v_u^1, \dots , v_u^k) \in R^{d \times k}</script><p>其中，<strong>d 是用户最终的兴趣向量 Embedding 维度，k 表示兴趣向量的个数。</strong></p><p>如此容易发现：</p><blockquote><p>如果 $k=1$，即只有一个兴趣向量的话，模型本身就退化成传统的召回模型结构了，例如 YouTube DNN 这样。</p></blockquote><p>而目标物品侧的映射方式:</p><script type="math/tex; mode=display">\vec e_i = f_{item}(F_i)</script><p>其中 $\vec e<em>i \in R^{d \times 1}$，于是其维度就和兴趣向量对其了，就支持后面的 <code>Label-aware Attention</code> 操作，而 $f</em>{item}( \cdot )$ 是一个 <code>Embedding &amp; Pooling</code> 层，即<strong>目标 item 的不同属性特征过 Embedding Layer 层后直接进行 sum/avg pooling。</strong></p><p>最后也是将每个兴趣向量通过内积做相似度进行 TopK 的 item 召回：</p><script type="math/tex; mode=display">f_{score} (V_i, \vec e_i) = \max_{1 \le k \le K} \vec e_i \vec V_u^k</script><h3 id="4-3-Multi-Interest-Extractor-Layer（多兴趣提取层）"><a href="#4-3-Multi-Interest-Extractor-Layer（多兴趣提取层）" class="headerlink" title="4.3 Multi-Interest Extractor Layer（多兴趣提取层）"></a>4.3 Multi-Interest Extractor Layer（多兴趣提取层）</h3><h4 id="4-3-1-Dynamic-Routing-Revisit（动态路由）"><a href="#4-3-1-Dynamic-Routing-Revisit（动态路由）" class="headerlink" title="4.3.1 Dynamic Routing Revisit（动态路由）"></a>4.3.1 Dynamic Routing Revisit（动态路由）</h4><p>在胶囊网络内，不管迭代多少次，实际上可以把整个网络看成2层，一个是 input 的低阶胶囊记为 $\vec c<em>i^l \in R^{N_l \times 1}, i \in {1, \cdots , m}$，另一层便是 output 的高阶胶囊记为 $\vec c_j^h \in R^{N_h \times 1}, i \in {1, \cdots , n}$。其中 m, n 表示胶囊的个数，在 MIND 中<strong>m 那就是输入时序列的长度，n便是要抽取的兴趣向量个数</strong>，$N_l, N_h$ 表示两层胶囊的维度。 那么从低阶胶囊抽取高阶胶囊过程中的路由对数$b</em>{ij}$一般如下计算：</p><script type="math/tex; mode=display">b_{ij} = (\vec c_j^h)^T S_{ij} \vec c_I^l</script><p>其中，$S<em>{ij} \in R^{N_j \times N_l}$ 是待学习的转换矩阵。接下来便可由 $b</em>{ij}$ 计算出高低阶胶囊之间的加权权重 $w<em>{ij}$（又称耦合系数），即直接对 $b</em>{ij}$ 进行 softmax 计算即可：</p><script type="math/tex; mode=display">w_{ij} = \frac{\exp{b_{ij}}}{\sum_{k = 1}^m \exp{b_{ik}}}</script><p><strong>注意：这里计算的是某个低阶向量在不同胶囊之间的权重分配（总和为1），而不是某个胶囊里面不同低阶向量的权重分配</strong></p><p>然后，便可以基于上述的权重来计算高阶胶囊j的中间过渡向量$\vec z_j^h$：</p><script type="math/tex; mode=display">\vec z_j^h = \sum_{i=1}^m w_{ij} S_{ij} \vec c_i^l</script><p>最后，便是通过 <code>Squashing</code> 算子对中间变量进行压缩来得到结果的高阶胶囊向量 $\vec c_j^h$：</p><script type="math/tex; mode=display">\vec c_j^h = Squashing(\vec z_j^h) = \frac{||\vec z_j^h||^2}{1 +||\vec z_j^h||^2 } \frac{\vec z_j^h}{||\vec z_j^h||}</script><p>上述是一次迭代的整个过程，看上去貌似与前述的胶囊网络不一样，实则不然。为了进一步促进理解，依然跟上一节一样，我们将<code>单个高阶胶囊</code>$\vec c_j^h$的2轮迭代的动态路由可视化出来，如下图所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind8.png" alt="mind8"></p><p>将需要注意的是：<strong>原论文中的符号与前文和图示有些区别，且无高阶胶囊维度j</strong>：</p><ul><li>论文的 $w<em>{ij}$ -&gt; 图示的胶囊加权权重$c</em>{ir}$</li><li>论文的低阶和高阶胶囊 $\vec c_i^l, \vec c_j^h$ -&gt; 图示的输入和输出向量 $v_i, v$</li><li>论文的聚合向量 $\vec z_j^h$ -&gt; 图示的聚合向量$s$</li><li>论文的转化系数 $S<em>{ij}$ -&gt; 图示的转化矩阵 $W</em>{i}$</li></ul><h4 id="4-3-2-B2I-Dynamic-Routing（B2I动态路由）"><a href="#4-3-2-B2I-Dynamic-Routing（B2I动态路由）" class="headerlink" title="4.3.2 B2I Dynamic Routing（B2I动态路由）"></a>4.3.2 B2I Dynamic Routing（B2I动态路由）</h4><p>MIND 的作者实际上没有使用最原始的动态路由机制，而是使用了做了些许改造的<code>B2I动态路由</code>。它和原始的路由主要有3出处区别：(<strong>本部分以原文符号为主</strong>)</p><ol><li><strong>共享映射矩阵</strong>。<blockquote><p>即所有的$S<em>{ij}$（图中的$W</em>{i}$）使用同一个S，主要原因是：</p></blockquote></li></ol><ul><li>input 胶囊（用户行为序列）的<strong>长度是不等的</strong>，统一映射矩阵利于减少参数提高泛化；</li><li>统一的映射矩阵可将商品映射的<strong>向量统一到同一空间</strong>；</li></ul><ol><li><strong>随机初始化陆游对数 $b_{ij}$</strong><blockquote><p>由于共享了映射矩阵S，那么如果$b<em>{ij}$初始化为 0，那么 softmax 后产生的所有的加权权重 $w</em>{ij}$ 边都是相等的，之后各个兴趣胶囊在迭代中将会始终保持一致。作者实际上采用高斯分布来初始化 $b_{ij}$，<strong>这样使得每个胶囊（用户兴趣聚类中心）差异较大</strong>，从而度量多样的兴趣。实际上与<code>K-means思想</code>有点类似。</p></blockquote></li></ol><p>$b_{ij}$这一点可以从论文中的实验结果看到，使用<strong>方差更大的高斯函数来初始化routing logits</strong>效果更好:</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind9.png" alt="mind9"></p><p><strong>但是，这里需要注意！！！</strong><br>上面的设计并不一定是最优的，博主在实际应用中，发现参数不共享时，$b_{ij}$ 可以初始化为 0，效果反而更好，更有利于兴趣向量差异化，与业界其他业务交流也有类似的。</p><ol><li><strong>动态的兴趣胶囊数量</strong><blockquote><p>作者出发点是<strong>行为个数不一样的用户兴趣向量应该也有差异</strong>，行为越丰富兴趣像两个数相对给多一些，具体兴趣向量个数通过下面公式来确定。</p></blockquote></li></ol><script type="math/tex; mode=display">{K_u}' = max(1, min(K, log_{2}{(|L_u|)}))</script><h3 id="4-4-Label-aware-Attention-Layer（标签意识注意力层）"><a href="#4-4-Label-aware-Attention-Layer（标签意识注意力层）" class="headerlink" title="4.4 Label-aware Attention Layer（标签意识注意力层）"></a>4.4 Label-aware Attention Layer（标签意识注意力层）</h3><p>实际上在多兴趣提取层和标签意识注意力层之间还夹杂着两个步骤：</p><ol><li>将用户的属性 Embedding 分别 concat 到每一个兴趣向量上；</li><li>再经过两层激活函数为 ReLU 的全连接层来对其维度；</li></ol><p>上述两部在前面部分已经介绍过，那么在此之后变得到了可以 feed 进入 Label-aware Attention Layer 的多兴趣向量。该层内的计算结构比较熟知，其实就是传统的 QKV 形式的 <code>Attention 结构</code>：</p><script type="math/tex; mode=display">\vec v_u = Attention(\vec e_i, V_u, V_u) = V_u \quad softmax(pow(V_u^T \vec e_i, p))</script><p>其中，$\vec e_i$表示的目标商品向量，$V_u$就是用户的多兴趣向量组合，里面会有${K_u}’$个有效的兴趣向量。唯一的<strong>区别是，在做完内积操作后进行了一个幂次操作，$p$就是幂次的超参数</strong>。如此便会发现p是一个可调节的参数来调整注意力分布：</p><blockquote><p>当 $p \longrightarrow 0$ 时，不同兴趣胶囊的注意力权重趋于相同；<br>当 $p &gt;&gt; 0$ 时，较大注意力权重的胶囊将会拉大这个优势，极端情况 $p \longrightarrow \infty$ 时，就变成了 <code>hard-attention</code>，即只有一个兴趣胶囊会生效；</p></blockquote><p><strong>值得注意的是，实际应用中（本人也有同样经验），p 小会使得胶囊之间差距缩小，反之可以使得兴趣胶囊差异性增加，实际线上效果也是 <code>hard-attention</code> 模式效果最优（如下图）</strong></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind10.png" alt="mind10"></p><h3 id="4-6-离线训练和线上服务"><a href="#4-6-离线训练和线上服务" class="headerlink" title="4.6 离线训练和线上服务"></a>4.6 离线训练和线上服务</h3><p>听过前面介绍的 Label-aware Attention Layer 生成用户u的聚合兴趣向量之 $\vec v_u$ 后，用户与物品i的<code>交互的概率</code>可以如下计算：</p><script type="math/tex; mode=display">Pr(i|u) = Pr(\vec e_i | \vec v_u) = \frac{exp{(\vec v_u^T \vec e_i)}}{\sum_{j \in I} exp{(\vec v_u^T \vec e_j)}}</script><p><strong>实际上就是一个对有所物品应用 softmax 算子</strong></p><p>整体的<code>目标函数</code>是：</p><script type="math/tex; mode=display">L = \sum_{(u,i) \in D} log{Pr(i|u)}</script><p>其中，D是训练数据包含用户物品交互的集合。</p><blockquote><p>这里与 word2vec 类似，由于最后一层需要对所有物品应用 softmax 算子来计算概率。而有效物品的量一般很大，所以为了简化计算就转化成 <code>SampledSoftmax</code> 的方式，即只保留正样本，通过负采样生成负样本来做 <code>binary task</code>。</p></blockquote><p><strong>线上 serving 的时候</strong>，去除 label-aware 层，仅需要得到一个用户多兴趣向量表示的映射 $f_{user}$ 即可。通过 feed 用户画像信息，得到多个有效的兴趣表示向量，然后分别从物品集合中近邻检索 TopN 个物品即可（总共KN个物品）。</p><p>最后，作者实验了不同兴趣个数K的效果，发现<strong>最大兴趣个数K控制在5-7的时候表现较好</strong>。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/mind11.png" alt="mind11"></p><h2 id="5-code"><a href="#5-code" class="headerlink" title="5 code"></a>5 code</h2><p>这里给出一版自己实现的模型结构，篇幅原因，这里重点展示模型核心结构部分，其他模块省略，仅供参考。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> partitioned_variables</span><br><span class="line"><span class="keyword">from</span> .recModelOpt <span class="keyword">import</span> recModelOpt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> modules <span class="keyword">import</span> dnn, capsuleLayer</span><br><span class="line"><span class="keyword">import</span> modules.featProcessor <span class="keyword">as</span> fp</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> tf.__version__ &gt;= <span class="string">&#x27;2.0&#x27;</span>:</span><br><span class="line">    tf = tf.compat.v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mindSampled</span>(<span class="title class_ inherited__">recModelOpt</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_graph</span>(<span class="params">self, features, mode, params</span>):</span><br><span class="line">            ......</span><br><span class="line">            <span class="comment"># build high_capsules</span></span><br><span class="line">            seqFeats = tf.concat(seqFeatList, axis=<span class="number">2</span>, name=<span class="string">&quot;seqFeats&quot;</span>)</span><br><span class="line">            seqFeats = tf.layers.dense(seqFeats, units=<span class="variable language_">self</span>.high_dim, activation=tf.nn.selu, name=<span class="string">&quot;seqFeatsDim&quot;</span>)</span><br><span class="line">            capsuleNet = capsuleLayer(capsule_config=capsule_config, is_training=is_training)</span><br><span class="line">            high_capsules, num_capsules = capsuleNet(seqFeats, seqLen)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># concatenate with user features</span></span><br><span class="line">            userFeats = tf.tile(tf.expand_dims(user_inputs, axis=<span class="number">1</span>),</span><br><span class="line">                [<span class="number">1</span>, tf.shape(high_capsules)[<span class="number">1</span>], <span class="number">1</span>])</span><br><span class="line">            interest_capsule = tf.concat([high_capsules, userFeats], axis=<span class="number">2</span>, name=<span class="string">&quot;cap_concat&quot;</span>)</span><br><span class="line">            tf.logging.info(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;interest_capsule shape is %s&quot;</span> % <span class="built_in">str</span>(interest_capsule.shape) + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">            interest_capsule = dnn(<span class="built_in">input</span>=interest_capsule, dnnDims=<span class="variable language_">self</span>.userDnn, is_training = is_training,</span><br><span class="line">                            usebn = <span class="literal">False</span>, l2_reg = <span class="variable language_">self</span>.l2_reg, name = <span class="string">&quot;userDnn&quot;</span>)</span><br><span class="line">            <span class="comment"># cap_norm = self.norm(interest_capsule, axis = 2, name = &quot;user_norm&quot;)</span></span><br><span class="line">            <span class="comment"># item_norm = self.norm(self.item_vec, axis = 1, name = &quot;item_norm&quot;)</span></span><br><span class="line"></span><br><span class="line">            cap_att = tf.matmul(interest_capsule, tf.reshape(<span class="variable language_">self</span>.item_vec, [-<span class="number">1</span>, <span class="variable language_">self</span>.high_dim, <span class="number">1</span>]))</span><br><span class="line">            cap_att = tf.reshape(tf.<span class="built_in">pow</span>(cap_att, <span class="variable language_">self</span>.sim_pow), [-<span class="number">1</span>, <span class="variable language_">self</span>.num_interest])</span><br><span class="line">            capsules_mask = tf.sequence_mask(num_capsules, <span class="variable language_">self</span>.num_interest)</span><br><span class="line">            user_capsules = tf.multiply(interest_capsule, tf.to_float(capsules_mask[:, :, <span class="literal">None</span>]), name=<span class="string">&quot;user_capsules&quot;</span>)</span><br><span class="line">            padding = tf.ones_like(cap_att) * (-<span class="number">1e9</span>)</span><br><span class="line">            cap_att = tf.where(capsules_mask, cap_att, padding)</span><br><span class="line">            cap_att = tf.nn.softmax(cap_att, axis=<span class="number">1</span>)</span><br><span class="line">            cap_att_stop = tf.stop_gradient(cap_att)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.hardAtt:</span><br><span class="line">                user_vec = tf.gather(tf.reshape(interest_capsule, [-<span class="number">1</span>, <span class="variable language_">self</span>.high_dim]),</span><br><span class="line">                                        tf.argmax(cap_att_stop, axis=<span class="number">1</span>, output_type=tf.int32) + tf.<span class="built_in">range</span>(</span><br><span class="line">                                        tf.shape(cap_att_stop)[<span class="number">0</span>]) * <span class="variable language_">self</span>.num_interest)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                user_vec = tf.matmul(tf.reshape(cap_att_stop, [tf.shape(cap_att_stop)[<span class="number">0</span>], <span class="number">1</span>, <span class="variable language_">self</span>.num_interest]),</span><br><span class="line">                                     interest_capsule)</span><br><span class="line">            <span class="variable language_">self</span>.user_vec = tf.reshape(user_vec, [-<span class="number">1</span>, <span class="variable language_">self</span>.high_dim], name=<span class="string">&quot;user_embed&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.user_emb = tf.reduce_join(</span><br><span class="line">                tf.reduce_join(tf.as_string(user_capsules), axis=-<span class="number">1</span>, separator=<span class="string">&#x27;,&#x27;</span>),</span><br><span class="line">                axis=-<span class="number">1</span>, separator=<span class="string">&#x27;|&#x27;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.item_emb = tf.reduce_join(tf.as_string(<span class="variable language_">self</span>.item_vec), axis=-<span class="number">1</span>, separator=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">capsuleLayer</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capsule_config, is_training, name = <span class="string">&quot;capsuleNet&quot;</span></span>):</span><br><span class="line">        <span class="comment"># max_seq_len: max behaviour sequence length(history length)</span></span><br><span class="line">        <span class="variable language_">self</span>._max_seq_len = capsule_config.get(<span class="string">&quot;max_seq_len&quot;</span>, <span class="number">10</span>)</span><br><span class="line">        <span class="comment"># max_k: max high capsule number</span></span><br><span class="line">        <span class="variable language_">self</span>._num_interest = capsule_config.get(<span class="string">&quot;num_interest&quot;</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># high_dim: high capsule vector dimension</span></span><br><span class="line">        <span class="variable language_">self</span>._high_dim = capsule_config.get(<span class="string">&quot;high_dim&quot;</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="comment"># number of Expectation-Maximization iterations</span></span><br><span class="line">        <span class="variable language_">self</span>._num_iters = capsule_config.get(<span class="string">&quot;num_iters&quot;</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># routing_logits_scale</span></span><br><span class="line">        <span class="variable language_">self</span>._routing_logits_scale = capsule_config.get(<span class="string">&quot;routing_logits_scale&quot;</span>, <span class="number">1.0</span>)</span><br><span class="line">        <span class="comment"># routing_logits_stddev</span></span><br><span class="line">        <span class="variable language_">self</span>._routing_logits_stddev = capsule_config.get(<span class="string">&quot;routing_logits_stddev&quot;</span>, <span class="number">1.0</span>)</span><br><span class="line">        <span class="variable language_">self</span>.bilinear_type = capsule_config.get(<span class="string">&quot;bilinear_type&quot;</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>._is_training = is_training</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">squash</span>(<span class="params">self, cap_interest</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Squash cap_interest over the last dimension.&quot;&quot;&quot;</span></span><br><span class="line">        cap_norm = tf.reduce_sum(tf.square(cap_interest), axis=-<span class="number">1</span>, keep_dims=<span class="literal">True</span>)</span><br><span class="line">        scalar_factor = cap_norm / (<span class="number">1</span> + cap_norm) / tf.sqrt(cap_norm + <span class="number">1e-8</span>)</span><br><span class="line">        <span class="keyword">return</span> scalar_factor * cap_interest</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">seq_feat_high_builder</span>(<span class="params">self, seq_feat</span>):</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="variable language_">self</span>.name + <span class="string">&#x27;/bilinear&#x27;</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.bilinear_type == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 复用转换矩阵，后面路由对数可高斯初始化</span></span><br><span class="line">                seq_high = tf.layers.dense(seq_feat, <span class="variable language_">self</span>._high_dim, activation=<span class="literal">None</span>, bias_initializer=<span class="literal">None</span>)</span><br><span class="line">                seq_high = tf.tile(seq_high, [<span class="number">1</span>, <span class="number">1</span>, <span class="variable language_">self</span>._num_interest])</span><br><span class="line">            <span class="keyword">elif</span> <span class="variable language_">self</span>.bilinear_type == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># seq_feat_high</span></span><br><span class="line">                seq_high = tf.layers.dense(seq_feat, <span class="variable language_">self</span>._num_interest * <span class="variable language_">self</span>._high_dim, activation=<span class="literal">None</span>,</span><br><span class="line">                                               bias_initializer=<span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="variable language_">self</span>.bilinear_type == <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># seq_feat_high</span></span><br><span class="line">                seq_feat =  tf.reshape(seq_feat, [-<span class="number">1</span>, <span class="variable language_">self</span>._max_seq_len, <span class="variable language_">self</span>._high_dim])</span><br><span class="line">                seq_high = tf.layers.dense(seq_feat, <span class="variable language_">self</span>._max_seq_len * <span class="variable language_">self</span>._num_interest * <span class="variable language_">self</span>._high_dim, activation=<span class="literal">None</span>,</span><br><span class="line">                                               bias_initializer=<span class="literal">None</span>)</span><br><span class="line">                seq_high = tf.reshape(seq_high, [-<span class="number">1</span>, <span class="variable language_">self</span>._max_seq_len, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._high_dim])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 扩增一维trans矩阵</span></span><br><span class="line">                w = tf.get_variable(</span><br><span class="line">                    <span class="variable language_">self</span>.name + <span class="string">&#x27;/transWeight&#x27;</span>, shape=[<span class="number">1</span>, <span class="variable language_">self</span>._max_seq_len, <span class="variable language_">self</span>._num_interest * <span class="variable language_">self</span>._high_dim, <span class="variable language_">self</span>._high_dim],</span><br><span class="line">                    initializer=tf.random_normal_initializer())</span><br><span class="line">                <span class="comment"># [N, T, 1, C]</span></span><br><span class="line">                u = tf.expand_dims(seq_feat, axis=<span class="number">2</span>)</span><br><span class="line">                <span class="comment"># [N, T, num_caps * dim_caps]</span></span><br><span class="line">                seq_high = tf.reduce_sum(w[:, :<span class="variable language_">self</span>._max_seq_len, :, :] * u, axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        seq_high = tf.reshape(seq_high, [-<span class="number">1</span>, <span class="variable language_">self</span>._max_seq_len, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._high_dim])</span><br><span class="line">        seq_high = tf.transpose(seq_high, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">        seq_high = tf.reshape(seq_high, [-<span class="number">1</span>, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len, <span class="variable language_">self</span>._high_dim])</span><br><span class="line">        <span class="keyword">return</span> seq_high</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">routing_logits_builder</span>(<span class="params">self, batch_size</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.bilinear_type &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 非共享转换矩阵，0初始化路由对数</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._is_training:</span><br><span class="line">                <span class="comment"># training的时候全部初始化</span></span><br><span class="line">                routing_logits = tf.stop_gradient(tf.zeros([batch_size, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 否则就是预估的时候同用户需要tile</span></span><br><span class="line">                routing_logits = tf.zeros([<span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len])</span><br><span class="line">                routing_logits = tf.stop_gradient(tf.tile(routing_logits[<span class="literal">None</span>, :, :], [batch_size, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._is_training:</span><br><span class="line">                routing_logits = tf.stop_gradient(tf.truncated_normal(</span><br><span class="line">                    [batch_size, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len],</span><br><span class="line">                    stddev=<span class="variable language_">self</span>._routing_logits_stddev))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                routing_logits = tf.constant(</span><br><span class="line">                    np.random.uniform(</span><br><span class="line">                        high=<span class="variable language_">self</span>._routing_logits_stddev,</span><br><span class="line">                        size=[<span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len]),</span><br><span class="line">                    dtype=tf.float32)</span><br><span class="line">                routing_logits = tf.stop_gradient(tf.tile(routing_logits[<span class="literal">None</span>, :, :], [batch_size, <span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> routing_logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, seq_feat, seq_lens</span>):</span><br><span class="line">        <span class="comment"># seq_feat padding</span></span><br><span class="line">        cur_batch_max_seq_len = tf.shape(seq_feat)[<span class="number">1</span>]</span><br><span class="line">        seq_feat = tf.cond(</span><br><span class="line">            tf.greater(<span class="variable language_">self</span>._max_seq_len, cur_batch_max_seq_len),</span><br><span class="line">            <span class="keyword">lambda</span>: tf.pad(tensor=seq_feat,</span><br><span class="line">                paddings=[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="variable language_">self</span>._max_seq_len - cur_batch_max_seq_len], [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">                name=<span class="string">&#x27;%s/CONSTANT&#x27;</span> % <span class="variable language_">self</span>.name),</span><br><span class="line">            <span class="keyword">lambda</span>: tf.<span class="built_in">slice</span>(seq_feat, [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="variable language_">self</span>._max_seq_len, -<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        seq_feat_high = <span class="variable language_">self</span>.seq_feat_high_builder(seq_feat)</span><br><span class="line">        seq_feat_high_stop = tf.stop_gradient(seq_feat_high, name = <span class="string">&quot;%s/seq_feat_high_stop&quot;</span> % <span class="variable language_">self</span>.name)</span><br><span class="line"></span><br><span class="line">        batch_size = tf.shape(seq_lens)[<span class="number">0</span>]</span><br><span class="line">        routing_logits = <span class="variable language_">self</span>.routing_logits_builder(batch_size)</span><br><span class="line"></span><br><span class="line">        num_capsules = tf.maximum(</span><br><span class="line">            <span class="number">1</span>, tf.minimum(<span class="variable language_">self</span>._num_interest, tf.to_int32(tf.log(tf.to_float(seq_lens)))))</span><br><span class="line">        mask = tf.sequence_mask(seq_lens, <span class="variable language_">self</span>._max_seq_len)</span><br><span class="line">        atten_mask = tf.tile(tf.expand_dims(mask, axis=<span class="number">1</span>), [<span class="number">1</span>, <span class="variable language_">self</span>._num_interest, <span class="number">1</span>])</span><br><span class="line">        paddings = tf.zeros_like(atten_mask, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>._num_iters):</span><br><span class="line">            capsule_softmax_weight = tf.nn.softmax(routing_logits, axis=<span class="number">1</span>)</span><br><span class="line">            capsule_softmax_weight = tf.where(tf.equal(atten_mask, <span class="number">0</span>), paddings, capsule_softmax_weight)</span><br><span class="line">            capsule_softmax_weight = tf.expand_dims(capsule_softmax_weight, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i + <span class="number">1</span> &lt; <span class="variable language_">self</span>._num_iters:</span><br><span class="line">                <span class="comment"># stop_gradient内迭代</span></span><br><span class="line">                interest_capsule = tf.matmul(capsule_softmax_weight, seq_feat_high_stop)</span><br><span class="line">                high_capsules = <span class="variable language_">self</span>.squash(interest_capsule)</span><br><span class="line">                delta_routing = tf.matmul(seq_feat_high_stop, tf.transpose(high_capsules, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>]))</span><br><span class="line">                delta_routing = tf.reshape(delta_routing, [-<span class="number">1</span>, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._max_seq_len])</span><br><span class="line">                routing_logits = routing_logits + delta_routing</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                interest_capsule = tf.matmul(capsule_softmax_weight, seq_feat_high)</span><br><span class="line">                high_capsules = <span class="variable language_">self</span>.squash(interest_capsule)</span><br><span class="line">        high_capsules = tf.reshape(high_capsules, [-<span class="number">1</span>, <span class="variable language_">self</span>._num_interest, <span class="variable language_">self</span>._high_dim])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> high_capsules, num_capsules</span><br></pre></td></tr></table></figure></p><p><strong>参考文献</strong><br><a href="https://www.cnblogs.com/DjangoBlog/articles/11777366.html">MIND召回介绍</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzIwODA4NTIxMQ%3D%3D&amp;chksm=9709cd40a07e445669cedc192ae1a17a40604a7701393dd04f77e1b695aba775af7e46d0293c&amp;idx=1&amp;mid=2247484660&amp;scene=21&amp;sn=90a9b07594d3f5cbfef83dfc003a4eff#wechat_redirect">浅谈胶囊网络与动态路由算法</a><br><a href="https://blog.csdn.net/wuzhongqiang/article/details/123696462">AI上推荐 之 MIND(动态路由与胶囊网络的奇光异彩)</a><br><a href="https://www.jianshu.com/p/88e5f4fc3fd7">召回阶段的多兴趣模型——MIND</a><br><a href="https://zhuanlan.zhihu.com/p/497962651">MIND模型(多兴趣)</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在深度学习召回算法领域，比较经典的包括了以下2大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于 &lt;code&gt;item2vec&lt;/code&gt; 模型构建在线的i2i召回；&lt;/li&gt;
&lt;li&gt;基于 &lt;code&gt;user2item&lt;/code&gt; 泛双塔模型构建在线的u2i召回；&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;当然还有2阶以上的召回，&lt;code&gt;i2u2i&lt;/code&gt;、&lt;code&gt;u2u2i&lt;/code&gt;等，在这里不做重点介绍，最终目的都是为了召回 item。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于第一种，相信大家比较熟知的有从 &lt;code&gt;word2vec&lt;/code&gt; 衍生出的&lt;code&gt;item2vec&lt;/code&gt;、阿里的&lt;code&gt;deepwalk&lt;/code&gt;以及&lt;code&gt;FM&lt;/code&gt;等，核心方式都是离线构建出 item 的 Embedding，&lt;strong&gt;在online侧基于用户的行为序列，取其中的 item 作为 trigger 来进行倒排/近邻召回&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="召回模型" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="MIND" scheme="https://www.xiemingzhao.com/tags/MIND/"/>
    
  </entry>
  
  <entry>
    <title>RankI2I 召回简述</title>
    <link href="https://www.xiemingzhao.com/posts/ranki2imodel.html"/>
    <id>https://www.xiemingzhao.com/posts/ranki2imodel.html</id>
    <published>2022-05-20T16:00:00.000Z</published>
    <updated>2025-04-04T17:46:16.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在推荐系统中，<code>i2i</code>类型的召回往往在多路召回中扮演中重要的角色，具有<strong>效率高、覆盖广、可解释、易调控</strong>等优势。常用的算法一般有<code>swing</code>,<code>icf</code>,<code>wbcos</code>以及<code>item2vec</code>等，虽然不同算法逻辑不同，实际上构建的倒排结果往往具有一定的重复，并且多路 i2i 在线上并存往往也会带来维护成本高，迭代效率低等问题。那么，<code>ranki2i</code> 是较为通用的将各种 i2i 有效整合到一起的一种方案。</p><h2 id="2-算法逻辑"><a href="#2-算法逻辑" class="headerlink" title="2 算法逻辑"></a>2 算法逻辑</h2><p><code>ranki2i</code> 算法承载着两个目标：</p><ul><li>合并分散的 i2i 召回；</li><li>提高 i2i 召回效率。</li></ul><p>为了完成上述 2 个目标，相应的转化成以下两个方案：</p><ul><li>构建一个 i2i 预估模型；</li><li>对所有的 i2i 候选 pair 对进行预估构建截断倒排结果。</li></ul><span id="more"></span><h3 id="2-1-样本"><a href="#2-1-样本" class="headerlink" title="2.1 样本"></a>2.1 样本</h3><p>因为最终是构建 i2i 的预估模型，那么重点的数据来源便是 i2i 后验数据，主要有以下 2 种：</p><ol><li>推荐中已有的 i2i 行为日志数据（线上已有 i2i 类召回）；</li><li>相关推荐等场景的 i2i 行为日志（线上无 i2i 召回）。</li></ol><p><strong>一般第 1 类样本更重要，效果要更好，这也符合训练和预估任务一致性的要求</strong>。</p><p>但无论哪一种，我们都可以从对应日志中提取 <code>user-trigger_item-target_item-label</code> 结构的归因样本。也即某个用户看过某个 trigger_item 后，对于其相关的 target_item 的偏好结果 label 是什么。</p><blockquote><p>如此便有了 ranki2i 正样本（曝光点击）和负样本（曝光未点击），但是和其他召回模型类似，只使用曝光的数据来构建样本往往是有偏的。对于负样本我们还需要大量的负采样，一般可以是全局负采样或 in-batch 负采样，具体 hard neg 和 easy neg 占比需要通过实验来调整。</p></blockquote><p>样本除了归因表之外，另一个要素便是特征体系，由于线上是 i2i 召回，那么主要就是构建 item 特征体系，只要是 item 维度的即可，一般可以从以下几个方面着手：</p><ol><li>统计类特征：曝光pv、点击pv、ctr、cvr、price等；</li><li>属性类特征：类目id，品牌id，适用人群，颜色等；</li><li>上下文特征：召回 channel（swing 等），召回分数（i2i 算法 score）等；</li><li>多模态特征：item 的 nlp 文本向量，图片的 cv 预训练向量等。</li></ol><h3 id="2-2-模型"><a href="#2-2-模型" class="headerlink" title="2.2 模型"></a>2.2 模型</h3><p>因为 i2i 线上往往是使用用户的行为序列中的 item 作为 trigger 去倒排中召回 item。那么结合上述的样本结构，我们就需要构建一个由 <code>trigger_item vs target_item</code> 组成的 pair 对样本，模型结构可以选择<code>双塔模型</code>，两边的特征体系往往一模一样，仅仅是为了训练出<strong>用户一般在看了某个 trigger_item 后最有可能还看哪些 target_item</strong>。</p><p>所以模型的结构往往比较简单：</p><ul><li><code>input</code>：trigger_item 和 target_item 的 features；</li><li><code>forward</code>：input 在 concat 后喂入 NN 即可；</li><li><code>loss</code>：构建 ctr loss，多目标的话也可构建多头网络。</li></ul><h3 id="2-3-预估倒排"><a href="#2-3-预估倒排" class="headerlink" title="2.3 预估倒排"></a>2.3 预估倒排</h3><p>在 <code>ranki2i</code> 样本和模型中，主要为了提高 i2i 的效率，那如何将模型的能力转为 i2i 的效果，并起到对分散的各路 i2i 进行合并的作用呢？</p><blockquote><p>一个比较自然的想法：为了确保分散的各路 i2i 候选集都有参与的机会，那么就将 swing 等所有 i2i 的倒排合并去重后，对所有的 pair 对应用上述 i2i 模型进行预估，然后根据预估结果（ctr预估分或各个多目标分）倒序排列后截断。</p></blockquote><p>如此便得到了融合的 i2i 倒排，由于以下2点，往往此路 i2i 能够替换所有分散的 i2i 的效果：</p><ol><li>基于场景内真实 i2i 样本数据训练得到；</li><li>将所有 i2i 倒排融合后进行排序的结果。</li></ol><h3 id="2-4-其他调优"><a href="#2-4-其他调优" class="headerlink" title="2.4 其他调优"></a>2.4 其他调优</h3><p>在实际应用中，一般效率上是有比较明显的效果。并且能够降低 i2i 线上的复杂度，提高优化效率，否则 i2i 分散在多路中，提升效果难以撬动整体。</p><p>针对 ranki2i 本身依然有不少调优策略，这里简单列举几个博主自己实践中的经验：</p><ol><li>模型需要增量更新一段时间，尽可能覆盖 pair 对；</li><li>负采样上，尽量达到曝光负样本的量级；</li><li>预估长尾 pair 对由于训练不充分（甚至没出现过），需要考虑置信度，比如长度阶段后需要进一步分数截断，或者类目调权。</li><li>在线召回的策略迭代就和单路的差不多，例如拆分长短兴趣召回等。</li></ol><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在推荐系统中，&lt;code&gt;i2i&lt;/code&gt;类型的召回往往在多路召回中扮演中重要的角色，具有&lt;strong&gt;效率高、覆盖广、可解释、易调控&lt;/strong&gt;等优势。常用的算法一般有&lt;code&gt;swing&lt;/code&gt;,&lt;code&gt;icf&lt;/code&gt;,&lt;code&gt;wbcos&lt;/code&gt;以及&lt;code&gt;item2vec&lt;/code&gt;等，虽然不同算法逻辑不同，实际上构建的倒排结果往往具有一定的重复，并且多路 i2i 在线上并存往往也会带来维护成本高，迭代效率低等问题。那么，&lt;code&gt;ranki2i&lt;/code&gt; 是较为通用的将各种 i2i 有效整合到一起的一种方案。&lt;/p&gt;
&lt;h2 id=&quot;2-算法逻辑&quot;&gt;&lt;a href=&quot;#2-算法逻辑&quot; class=&quot;headerlink&quot; title=&quot;2 算法逻辑&quot;&gt;&lt;/a&gt;2 算法逻辑&lt;/h2&gt;&lt;p&gt;&lt;code&gt;ranki2i&lt;/code&gt; 算法承载着两个目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;合并分散的 i2i 召回；&lt;/li&gt;
&lt;li&gt;提高 i2i 召回效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了完成上述 2 个目标，相应的转化成以下两个方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建一个 i2i 预估模型；&lt;/li&gt;
&lt;li&gt;对所有的 i2i 候选 pair 对进行预估构建截断倒排结果。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="召回模型" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="RankI2I" scheme="https://www.xiemingzhao.com/tags/RankI2I/"/>
    
  </entry>
  
  <entry>
    <title>wbcos 召回</title>
    <link href="https://www.xiemingzhao.com/posts/wbcosrecall.html"/>
    <id>https://www.xiemingzhao.com/posts/wbcosrecall.html</id>
    <published>2022-05-08T16:00:00.000Z</published>
    <updated>2025-04-04T17:48:13.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><blockquote><p><code>wb</code> 意为 <code>weight base</code>，wbcos 即加权式的 cos。</p></blockquote><p><strong>思想：其实就是改进的 itemcos 来计算相似度。</strong></p><p>核心在于两点：</p><ul><li>user+session 内的 pair 重复出现的时候如何聚合，主要就是时间衰减和类目等维度加权；</li><li>user+session 间的 pair 如何聚合，主要是 session 丰富度加权；</li></ul><span id="more"></span><h2 id="2-步骤"><a href="#2-步骤" class="headerlink" title="2 步骤"></a>2 步骤</h2><h3 id="step0-样本构造"><a href="#step0-样本构造" class="headerlink" title="step0: 样本构造"></a>step0: 样本构造</h3><p>将用户在 app 全场景的正行为汇总到一起，作为底表 <code>user_action_database</code>。</p><p><em>注意可筛选行为数较多或者较少的，例如：正反馈item个数在[a,b]之间；以及高质量用户，例如经验：在近 n 天内有 order 的用户，以及用户当天点击数不少于 k 等等</em></p><p>保留 <code>user,event,time,session,item,cate,brand</code> 等等维度。</p><h3 id="step1-计算bw"><a href="#step1-计算bw" class="headerlink" title="step1: 计算bw"></a>step1: 计算<code>bw</code></h3><p>在 <code>user+session</code> 维度下，计算：</p><script type="math/tex; mode=display">userBw = \frac{1}{log_2 (3 + itemNum)}</script><p>其中 <code>itemNum</code> 指的是 user 在 session 内的正反馈 item 的去重个数。</p><p><strong>这里的思想很简单：即一个 user 在一个 session 维度下，看的 item 越多，理论上兴趣分布越广，则权重越小；从概率学角度理解集合元素越多，产生某 pair 对的概率越大，分得的权重也越小</strong></p><h3 id="step2-计算-item-的-wb"><a href="#step2-计算-item-的-wb" class="headerlink" title="step2: 计算 item 的 wb"></a>step2: 计算 item 的 <code>wb</code></h3><p>在 user+session 维度下，计算同一 item 的出现次数 <code>itemCnt</code>，截断后作为 <code>itemWb</code>：</p><script type="math/tex; mode=display">itemWb = min(m, itemCnt)</script><p><strong>注意，这里截断 m 是为了后续取 pair 对 topk 时间相近，思想就是：在找出与当前 itemA 行为最近的 itemB 的时候，后者有多次出现的话最多取 m 个（时间最近的）来构建 pair，m 具体需要根据业务数据来确定</strong></p><p>同时计算类目等维度的权重系数 <code>ratio</code>，这里以类目 cate 为例。</p><blockquote><p>即 <code>user_id,session_id</code> 维度下，每个 item_id 对应的类目权重。每个类目的权重可以参考：</p></blockquote><script type="math/tex; mode=display">ratio_k = \frac{cnt(cate_k)}{\sum_i cnt(cate_i)}</script><h3 id="step3-计算-item-pair-相关参数"><a href="#step3-计算-item-pair-相关参数" class="headerlink" title="step3: 计算 item pair 相关参数"></a>step3: 计算 item pair 相关参数</h3><p>在 <code>user+session</code> 维度下，构建 item 的 pair 对，可以设置 item 不同的时候才成 pair，于是每个 pair 就有两个 item，我们记为<code>(litem, ritem)</code>。</p><p>紧接着对每个pair对计算参数 <code>timeGap</code> 和 <code>matchRatio</code>。</p><script type="math/tex; mode=display">timeGap = e^{- \alpha * abs(tsDiff)}</script><p>其中:</p><ul><li>$\alpha$ 是时间衰减的超参数，经验上可取 0.75。</li><li><code>tsDiff</code> 表示的是pair对中的两个正反馈 item 的行为发生时间差，建议使用 hour 的精度。</li></ul><p><code>matchRatio</code>的计算需要融入先验信息，我们以简单的cate维度为例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">matchRatio = </span><br><span class="line">case </span><br><span class="line">when 叶子类目相同 then 1</span><br><span class="line">when 二级类目相同 then 0.9</span><br><span class="line">when 一级类目相同 then 0.8</span><br><span class="line">else 0.3</span><br></pre></td></tr></table></figure><br>可以看得出来，此处是 pair 对中两个 item 的 cate 维度越相同，则先验相关性越高。此处，可以融入其他的先验信息，例如 brand，price 等。</p><h3 id="step4-统计-pair-对的两种频次"><a href="#step4-统计-pair-对的两种频次" class="headerlink" title="step4: 统计 pair 对的两种频次"></a>step4: 统计 pair 对的两种频次</h3><p>首先，统计每一个pair对<code>(litem, ritem)</code>全局的频次，记为<code>pairCnt</code>，并且可以以此筛选除去总出现次数较少的 pair 对，例如<code>pairCnt&gt;=5</code>。</p><p>其次，计算每一个pair对<code>(litem, ritem)</code>在全局有多少个 <code>user+session</code> 出现了，即以 <code>user+session</code> 为 key 去 groupby，来计算 <code>count(distinct user,session)</code>，我们记为 <code>pairUserSessionCnt</code>。</p><blockquote><p><em>这里有些 tf-idf 的思想。</em></p></blockquote><h3 id="step5-计算innerProduct参数。"><a href="#step5-计算innerProduct参数。" class="headerlink" title="step5: 计算innerProduct参数。"></a>step5: 计算<code>innerProduct</code>参数。</h3><p>以上三个参数的计算都是在<code>user+session+pair(litem, ritem)</code>维度之下的，我们记为<code>基准维度</code>。</p><h4 id="首先，计算timeGapWeight"><a href="#首先，计算timeGapWeight" class="headerlink" title="首先，计算timeGapWeight"></a>首先，计算<code>timeGapWeight</code></h4><p>我们知道在<code>基准维度</code>下，<code>matchRatio,pairCnt,pairUserSessionCnt</code>都是一致的，但是同一 pair 对会出现多次，每个 pair 对我们在前面计算过<code>timeGap</code>。而每个 pair 对<code>(litem,ritem)</code>都有自己的<code>itemWb</code>.</p><p>于是我们可以如下计算：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k = litemWb * ritemWb;</span><br><span class="line">在基准维度下，对重复出现的 pair 对的 timeGap（记为timeGaps）取前k个，即：</span><br><span class="line">timeGaps.sort(reverse = True);</span><br><span class="line">最终，timeGapWeight = sum(timeGaps[:k])</span><br></pre></td></tr></table></figure></p><h4 id="然后，我们计算innerProduct"><a href="#然后，我们计算innerProduct" class="headerlink" title="然后，我们计算innerProduct"></a>然后，我们计算<code>innerProduct</code></h4><p>这个就比较简单了，也是在去重后的<code>基准维度</code>上进行计算：</p><script type="math/tex; mode=display">innerProduct = matchRatio * timeGapWeight * lratio * rratio</script><p>其中，<code>lratio</code> 和 <code>rratio</code> 分别是 step3 中计算的左右 item 的类目权重（可选）。</p><p><strong>这里其实可以理解为，同一 user+session 下，多次共现的 pair 对（matchRatio一致），按照其时间间隔权重来加权，两个 ratio 是按照对应类目集中度来加权（可选）</strong>。</p><p>到这里，我们应该在<code>基准维度</code>（<code>user+session+pair(litem, ritem)</code>）下获得了以下特征数据(<strong>此处已经去重了</strong>)：</p><blockquote><p>matchRatio: 匹配度<br>timeGapWeight: 时间间隔权重<br>innerProduct: 内积权重<br>pairCnt: 全局pair的计数<br>pairUserSessionCnt: 出现对应pair的UserSession计数<br>litemWb: pair对中左item的wb<br>ritemWb: pair对右左item的wb<br>lratio: pair对中左item的类目权重ratio<br>rratio: pair对右左item的类目权重ratio<br>userBw: user+session级别的bw</p></blockquote><h3 id="step6-计算pair对的三个参数"><a href="#step6-计算pair对的三个参数" class="headerlink" title="step6: 计算pair对的三个参数"></a>step6: 计算pair对的三个参数</h3><p>首先，我们基于 step5 计算 <code>pairBw</code>：</p><script type="math/tex; mode=display">pairBw = innerProduct * userBw^2</script><p>接着计算 pair 对中左右 item 的加权 wb（item 对应的 userBw）：</p><script type="math/tex; mode=display">leftWb = litemWb * userBw</script><script type="math/tex; mode=display">rightWb = ritemWb * userBw</script><h3 id="step7-计算itemWbLen并聚合-pair-对"><a href="#step7-计算itemWbLen并聚合-pair-对" class="headerlink" title="step7: 计算itemWbLen并聚合 pair 对"></a>step7: 计算<code>itemWbLen</code>并聚合 pair 对</h3><p>首先，我们之前通过截断<code>itemCnt</code>，作为<code>itemWb</code>，在这里我们不再需要<code>基准维度</code>，我们聚合到 pair 维度，以左 item 为 key 聚合出左右 item 的<code>itemWbLen</code>:</p><script type="math/tex; mode=display">litemWbLen = \sqrt {sum(leftWb^2)}</script><script type="math/tex; mode=display">ritemWbLen = \sqrt {sum(rightWb^2)}</script><p>其次，聚合pair对。<br>我们聚合全局的 pair 对，并计算下列参数：</p><script type="math/tex; mode=display">pairBwScore = sum(pairBw)</script><h3 id="step8-计算最终wbScore"><a href="#step8-计算最终wbScore" class="headerlink" title="step8: 计算最终wbScore"></a>step8: 计算最终<code>wbScore</code></h3><p>最后我们将基于pair对维度计算：</p><script type="math/tex; mode=display">wbScore = \frac{pairBwScore}{litemWbLen * ritemWbLen}</script><p>其中，<code>litemWbLen</code>和<code>ritemWbLen</code>分别是 pair 对中左右 item 的<code>itemWbLen</code>值。</p><h2 id="3-后记"><a href="#3-后记" class="headerlink" title="3 后记"></a>3 后记</h2><p><strong>1. 聚合</strong><br>在实际中应用的时候，往往每个分区生产一张 wbcos 分区结果表，我们可以进行多分区维度的<strong>聚合</strong>来减少方差从而提高准确度：<br>一般就是采用如下更新方式</p><script type="math/tex; mode=display">wbScore = \frac{prePairBw + curPairBw}{(prelitemWbLen + curlitemWbLen) + (preritemWbLen + curritemWbLen)}</script><p>其实就是利用多窗口的数据进行指标平滑的思想。或者可以进行滑动平均，比如：</p><script type="math/tex; mode=display">wbScore = \alpha * wbScore_{pre} + (1 - \alpha) * wbScore_{cur}</script><p><strong>2. 计算</strong><br>因为 i2i 召回逻辑上具有对称性，在构建 pair 时，只需要构建单向 pair 对 $(i1, i2)$ 即可。最终构建倒排时，反向 pair 对 $(i2, i1)$ 可以使用同样的相似度分，以减少计算量。</p><p><strong>3. 不同行为的融合</strong><br>在操作中，如何考虑所有的正行为，除<code>clk</code>之外，例如<code>fav</code>和<code>buy</code>等。那么对于不同行为之间的 pair 对就可以采取不一样的操作。主要是 session 内合并的时候所用的权重，在计算<code>innerProduct</code>的时候，<code>timeGapWeight</code>可以在不同行为对之间使用不用的权重。</p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;wb&lt;/code&gt; 意为 &lt;code&gt;weight base&lt;/code&gt;，wbcos 即加权式的 cos。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;思想：其实就是改进的 itemcos 来计算相似度。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;核心在于两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;user+session 内的 pair 重复出现的时候如何聚合，主要就是时间衰减和类目等维度加权；&lt;/li&gt;
&lt;li&gt;user+session 间的 pair 如何聚合，主要是 session 丰富度加权；&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="召回模型" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="wbcos" scheme="https://www.xiemingzhao.com/tags/wbcos/"/>
    
  </entry>
  
  <entry>
    <title>Swing 召回</title>
    <link href="https://www.xiemingzhao.com/posts/swingrecall.html"/>
    <id>https://www.xiemingzhao.com/posts/swingrecall.html</id>
    <published>2022-04-23T16:00:00.000Z</published>
    <updated>2025-04-04T17:47:47.447Z</updated>
    
    <content type="html"><![CDATA[<p><strong>思想：来源于传统的 CF：</strong></p><ul><li>如果多个 user 都只共同点了 i1 和 i2，那么其一定是强关联的，这种关联是通过用户来传递的；</li><li>如果两个 user pair 对之间构成的 swing 结构越多，则每个结构越弱，在这个 pair 对上每个节点分到的权重越低。</li></ul><h2 id="1-原理"><a href="#1-原理" class="headerlink" title="1 原理"></a>1 原理</h2><p><code>Swing</code>意为摇摆或者秋千，它是基于图结构的一种实时推荐算法。主要公式为：</p><script type="math/tex; mode=display">Sim(i, j) = \sum_{u \in U_i \cup U_j} \sum_{v \in U_i \cup U_j} \frac{1}{\alpha + |I_u \cup I_v|}</script><p>结合前面的思想，公式表达的就是为了衡量物品 i 和 j 的<code>相似性</code>：<strong>考察都购买了物品 i 和 j 的用户 u 和 v， 如果这两个用户共同购买的物品越少，则物品 i 和 j 的相似性越高</strong>。</p><span id="more"></span><p>极端情况下，两个用户都购买了某个物品，且两个用户所有购买的物品中，共同购买的物品只有这两个，说明这两个用户兴趣差异非常大，然而却同时购买了这两个物品，则说明这两个物品相似性非常大！</p><p><strong>区别</strong>：<br><code>icf</code>：如果喜欢两个物品的交集用户越多，那么这两个物品间的相似度越高。<br><code>swing</code>：如果同时喜欢两个物品的用户越多，且这些用户之间的重合度越低，那么这两个物品间的相似度越高。</p><!--more--><h2 id="2-计算步骤"><a href="#2-计算步骤" class="headerlink" title="2 计算步骤"></a>2 计算步骤</h2><p>在实际中计算的时候主要分为以下3步：</p><h3 id="step0-计算用户的权重-w-u"><a href="#step0-计算用户的权重-w-u" class="headerlink" title="step0:计算用户的权重$w_u$"></a>step0:计算用户的权重$w_u$</h3><script type="math/tex; mode=display">w_u = \frac{1}{(clkcnt + k)^{\alpha}}</script><p>其中：</p><ul><li>$k$：平滑作用的超参数，可根据具体业务效果确定，比如 5；</li><li>$\alpha$：权重因子，越大对高活用户降权越狠，常用 0.35。</li></ul><p>主要为了通过用户的行为数来衡量兴趣的分散度，从而给定用户行为 item 的权重。</p><blockquote><p><strong>注意在统计 clkcnt 的时候是不去重的。</strong></p></blockquote><h3 id="step1-计算用户pair的权重"><a href="#step1-计算用户pair的权重" class="headerlink" title="step1:计算用户pair的权重"></a>step1:计算用户pair的权重</h3><p>对于点击同 item 的每个 <code>(u1,u2)</code> 的 pair 对，其权重系数：</p><script type="math/tex; mode=display">w_{pair} = w_{u1} * w_{u2}</script><h3 id="stpe2-计算相似度"><a href="#stpe2-计算相似度" class="headerlink" title="stpe2:计算相似度"></a>stpe2:计算相似度</h3><p>对于有被 <code>(u1,u2)</code> 用户 pair 对共同正反馈的 item pair 对<code>(i,j)</code>来说，其相似分：</p><script type="math/tex; mode=display">Sim(i, j) = \sum_{pair}\frac{w_{pair}}{1+intersection}</script><p>其中 <code>intersection</code> 代表每一个用户 pair 对<code>(u1,u2)</code>的共同正行为 item 个数。</p><blockquote><p>此处，分母中的 1 也是一个可调参数。</p></blockquote><p>并且，分母中可以再引入一些权重参数，例如：</p><ol><li>两个用户对左右 item pair 的类目权重；（session内 当前类目点击数/全部类目点击数）</li><li>user 与 item 之间的连接数作为权重；</li></ol><h2 id="3-相关经验"><a href="#3-相关经验" class="headerlink" title="3 相关经验"></a>3 相关经验</h2><p>这里披露部分实践中可能需要注意的模块。</p><p><strong>1. 用户的筛选</strong><br>主要为了保障数据的置信度，需要选择相对正常且行为有参考价值的用户。比如，行为数过少/过多的剔除，当然具体操作还是要结合业务逻辑。</p><p><strong>2. 物料的筛选</strong><br>也是出于同样的目的，当然这里是否操作的影响可能小一些。比如，物料的 pair 对过少的是否排除。</p><p><strong>3. 简化计算</strong><br>因为这里的 pair 是双向等价的，即 $(i1,i2)$ 和 $(i2,i1)$ 的相似度应该的相同。所以不论是 user 还是 item 的 pair 对，往往只需要构建单向的，最后构建倒排的时候，所有 $(i2,i1)$ 复用 $(i1,i2)$ 的相似度即可。</p><p><strong>4. 增量更新</strong><br>与很多召回算法一样，不论更新频率是多少（by day/hour 等），都需要考虑和历史数据合并的问题。这里也是类似的，可以将所有的 pair 先做增量合并，然后按照时间步数衰减合并新老相似度分，分数过低的可以选择截断淘汰。</p><p><strong>参考文章：</strong><br><a href="https://www.jianshu.com/p/a5d46cdc2b4e">【召回】swing 算法</a><br><a href="https://blog.csdn.net/weixin_46838716/article/details/126138597">一文看懂推荐系统：召回02：Swing 模型</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;思想：来源于传统的 CF：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果多个 user 都只共同点了 i1 和 i2，那么其一定是强关联的，这种关联是通过用户来传递的；&lt;/li&gt;
&lt;li&gt;如果两个 user pair 对之间构成的 swing 结构越多，则每个结构越弱，在这个 pair 对上每个节点分到的权重越低。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1-原理&quot;&gt;&lt;a href=&quot;#1-原理&quot; class=&quot;headerlink&quot; title=&quot;1 原理&quot;&gt;&lt;/a&gt;1 原理&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Swing&lt;/code&gt;意为摇摆或者秋千，它是基于图结构的一种实时推荐算法。主要公式为：&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;Sim(i, j) = &#92;sum_{u &#92;in U_i &#92;cup U_j} &#92;sum_{v &#92;in U_i &#92;cup U_j} &#92;frac{1}{&#92;alpha + |I_u &#92;cup I_v|}&lt;/script&gt;&lt;p&gt;结合前面的思想，公式表达的就是为了衡量物品 i 和 j 的&lt;code&gt;相似性&lt;/code&gt;：&lt;strong&gt;考察都购买了物品 i 和 j 的用户 u 和 v， 如果这两个用户共同购买的物品越少，则物品 i 和 j 的相似性越高&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="召回模型" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="swing" scheme="https://www.xiemingzhao.com/tags/swing/"/>
    
  </entry>
  
  <entry>
    <title>推荐模型中的 position bias 和 debias</title>
    <link href="https://www.xiemingzhao.com/posts/biasnet.html"/>
    <id>https://www.xiemingzhao.com/posts/biasnet.html</id>
    <published>2022-03-26T16:00:00.000Z</published>
    <updated>2025-04-02T17:11:05.137Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在推荐系统中一个重要的任务就是 CTR 建模，其本质的思想便是<strong>预估 user 对 item 的点击率</strong>。但是实际中获取的样本往往是在一定条件（时间、机型、位置等）下的后验结果，所以使得建模的 Label 往往是夹杂了这些因素的结果。</p><p>这些影响后验结果的因素一般称为 <code>偏置（bias）项</code>，而去除这些偏置项的过程就称为 <code>消偏（debias）</code>。在这其中最重要的便是 <code>位置偏置（position bias）</code>，即 item 展示在不同位置会有不同的影响，且用户往往更偏向点击靠前的位置。本文将重点介绍业界在 <code>position bias</code> 消除上的一般做法和相关经验。</p><h2 id="2-Position-Bias"><a href="#2-Position-Bias" class="headerlink" title="2 Position Bias"></a>2 Position Bias</h2><p>看下面的图，是笔者实际工作场景中部分位置的 CTR 趋势图。可以明显地看到：</p><ul><li>呈现每 20 个 position 位一个周期；每刷请求的个数是 20.</li><li>周期内位置越靠前，CTR 越大；靠前效率高，用户更偏好点靠前的。</li></ul><span id="more"></span><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet0.png" alt="biasnet0"></p><p>在华为的研究中也论证了用户对 position 靠前的偏好。固定 item 在不同 position 的 CTR 和不固定 item 的趋势差别较为显著。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet1.png" alt="biasnet1"></p><h2 id="3-Position-Debias—特征法"><a href="#3-Position-Debias—特征法" class="headerlink" title="3 Position Debias—特征法"></a>3 Position Debias—特征法</h2><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet2.png" alt="biasnet2"></p><p>比较朴素的想法，便是在特征体系中引入 position, 如上图所示。</p><ul><li>模型 <code>offline training</code> 的时候，把 position 作为特征输入模型，让模型学习 position 带来的后验影响。</li><li>而在 <code>online infer</code> 的时候，并没有 position 这样后验的信息，往往可以选择填充一个默认值，比如 0。</li></ul><p><strong>注意：具体填什么也需要测试，不同默认值的结果差别还不小。</strong></p><h2 id="4-Position-Debias—Shallow-Tower"><a href="#4-Position-Debias—Shallow-Tower" class="headerlink" title="4 Position Debias—Shallow Tower"></a>4 Position Debias—Shallow Tower</h2><p>此方法核心是：<strong>构建一个 Shallow Tower 来预估 Position Debias。</strong></p><p>方法来源是 Youtube 发表在 RecSys 2019上的文章：<a href="https://daiwk.github.io/assets/youtube-multitask.pdf">Recommending What Video to Watch Next: A Multitask Ranking System</a></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet3.png" alt="biasnet3"></p><p>如上图所示，文章阐述在 <code>position debias</code> 上的做法是:</p><ul><li>保持原来的主模型(main model)不变</li><li>新增一个专门拟合 position bias 的浅层网络(shallow tower)</li><li>将 main model 和 shallow tower 的 logit 相加再过 sigmoid 层后构建 loss。</li></ul><p>其中，<code>shallow tower</code> 的输入主要包含 <code>position feature</code>, <code>device info</code> 等会带来 bias 的特征，而加入 device info 的原因是<em>在不同的设备上会观察到不同的位置偏差</em>。</p><blockquote><p>注意：文章提到在 training 的时候，<strong>position 的特征会应用 10% 的 drop-out</strong>，目的是为了防止模型过度依赖 position 特征。在 online infer 的时候，由于没有后验的 position 特征，<strong>直接丢掉 shallow tower 即可</strong>。</p></blockquote><p>在文章中，披露了模型训练结果提取出的 position bias，如下图所示，可以看到随之位置的增长，bias 越大。因为越靠后，用户更有可能看不到。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet4.png" alt="biasnet4"><br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet5.png" alt="biasnet5"></p><blockquote><p>实际上，bias 还可以拓展更多的特征，包括 user 和 item 侧的属性，具体如何还需依赖对业务的理解和实验。</p></blockquote><h2 id="5-Position-Debias—PAL"><a href="#5-Position-Debias—PAL" class="headerlink" title="5 Position Debias—PAL"></a>5 Position Debias—PAL</h2><p>此方法核心是：<strong>将 position bias 从后验点击概率中拆出来，看作是用户看到的概率。</strong></p><p>方法来源是华为发表在 RecSys 2019上的文章：<a href="https://dl.acm.org/doi/abs/10.1145/3298689.3347033">PAL: A Position-bias Aware Learning Framework for CTR Prediction in Live Recommender Systems</a></p><script type="math/tex; mode=display">p(y = 1|x, pos) = p(seen|x, pos) p(y = 1|x, pos, seen)</script><p>如上公式，作者将后验点击概率拆成了2个条件概率的乘积：</p><ul><li>Item 被用户看到的概率</li><li>用户看到 item 后，再点击的概率</li></ul><p>那么可以进一步假设：</p><ul><li>用户是否看到 item 只跟位置有关系</li><li>用户看到 item 后，是否点击 item 与位置无关</li></ul><script type="math/tex; mode=display">p(y = 1|x, pos) = p(seen|pos) p(y = 1|x, seen)</script><p>基于上述假设，就可以建模如下：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/biasnet6.png" alt="biasnet6"></p><p>如上图所示，其中：</p><ul><li><code>ProbSeen</code>： 是预估广告被用户看到的概率</li><li><code>pCTR</code>：是用户看到 item 后，点击的概率</li></ul><p>可以看到与 YouTube 做法的<strong>区别主要有2点：bias net 和 main model 都先过激活层；然后两边的值再相乘。</strong></p><p>最后 loss 是两者的结合：</p><script type="math/tex; mode=display">L(\theta_{ps},\theta_{pCTR}) = \frac{1}{N}\sum_{i = 1}^Nl(y_i,vCTR_i)) = \frac{1}{N}\sum_{i = 1}^N l(y_i,ProbSeen_i \times pCTR_i))</script><p>在 online infer 的时候，也是类似地丢掉 position 相关的 ProbSeen 的网络，只保留 pCTR 部分即可。</p><h2 id="6-拓展思考"><a href="#6-拓展思考" class="headerlink" title="6 拓展思考"></a>6 拓展思考</h2><h3 id="6-1-假设是否成立？"><a href="#6-1-假设是否成立？" class="headerlink" title="6.1 假设是否成立？"></a>6.1 假设是否成立？</h3><p>两种主流的做法都是将 position 等可能造成 bias 影响的信息单独构建 <code>bias net</code>，然后与 <code>main model</code> 进行融合。<br>但是，</p><blockquote><p><em>Position 带来的 bias 是否可以独立于 main model 进行建模？</em><br><em>用户是否看到是否可以简化为只与 position 相关？</em><br><em>Bias net 的作用是否可以简化为与主塔结果的相加再激活/先激活再乘积？</em></p></blockquote><p>上述问题也许没有标准答案。实际上，笔者在实际中还做了另一种方案，即真的只将结果看成 bias 项，那么就简单的与主网络相加即可，实际上结果也不差。为了控制值域依然在 (0,1) 从而不影响 loss 的构建，最终输出变成：</p><script type="math/tex; mode=display">p(y=1|x,pos) = \frac{1}{2}(p(seen|pos) + p(y = 1|x, seen))</script><h3 id="6-2-pCTR-的分布问题"><a href="#6-2-pCTR-的分布问题" class="headerlink" title="6.2 pCTR 的分布问题"></a>6.2 pCTR 的分布问题</h3><p>容易发现，无论哪种 bias net 的融合方式，最后 loss 所使用的 pCTR 已经发生了变化，而在 online 阶段去除 bias net 部分后，保留的 main tower 对应的输出 pCTR 的分布必然会发生变化。最明显的表现就是 <strong>pcoc（sum(clk)/sum(pCTR）将会偏离 1 附近</strong>。</p><p>而这带来的影响就是：</p><blockquote><p>如果后排和重排中使用到 pCTR 的时候，就会出现含义偏离，会带来一些连锁效应，并且不利于数据分析。当然，有的系统可能没有这个要求。</p></blockquote><p>对于这个问题，笔者试过一些缓解方案：</p><ul><li>增加辅助 loss：比如主网络的 pCTR 也增加一个 logloss 来修正齐 pcoc</li><li>增加 pcoc 正则：针对主网络的 pCTR 新增一个 pcoc 偏离 1 的惩罚项，类似于正则的思想</li><li>矫正结果分值：统计主网络输出偏离期望的比例，直接将输出结果根据该值进行矫正即可</li></ul><p>从效果上来说：</p><ul><li>辅助 loss 和正则的方式确实有助于改善 pcoc，但往往也会影响效果，毕竟梯度被分散了；</li><li>矫正的方式最明显，但是会面临校正系数变化的问题。</li></ul><h3 id="6-3-业务效果"><a href="#6-3-业务效果" class="headerlink" title="6.3 业务效果"></a>6.3 业务效果</h3><p>在推荐系统中，一切脱离实验业务效果的优化，往往都不够坚挺。笔者主要在电商推荐领域内，那么这里给出的经验也仅仅针对此类做参考，不一定具有普适性。</p><p>笔者主要实验了 PAL 和 $\frac{1}{2}(p(seen|pos) + p(y = 1|x, seen))$ 的方式，并且都做了预估分值矫正。离线上 auc 往往会有微幅提升。线上的 CTR 和 IPV 一般会有一定涨幅，在笔者的实验中 +1% 左右。<br>但是，一些体验指标变差了，比如负反馈率、猎奇品的占比等。综合分析下来，click 主要涨在猎奇、标题党等低质品的流量增加上，是不利于系统健康的，于是最终实验没有推全。当然，如果是 UGC 或者 Ads 类业务可能会是另一个逻辑，所以仅供参考。</p><p><strong>参考文章</strong><br><a href="https://zhuanlan.zhihu.com/p/342905546">推荐生态中的bias和debias</a><br><a href="https://tech.meituan.com/2021/06/10/deep-position-wise-interaction-network-for-ctr-prediction.html">SIGIR 2021 | 广告系统位置偏差的CTR模型优化方案</a><br><a href="https://zhuanlan.zhihu.com/p/420373594">推荐系统中的bias&amp;&amp;debias(二)：position bias的消偏</a><br><a href="https://daiwk.github.io/assets/youtube-multitask.pdf">Recommending What Video to Watch Next: A Multitask Ranking System</a><br><a href="https://dl.acm.org/doi/abs/10.1145/3298689.3347033">PAL: a position-bias aware learning framework for CTR prediction in live recommender systems</a><br><a href="https://arxiv.org/pdf/2010.03240.pdf">Bias and Debias in Recommender System: A Survey and Future Directions</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在推荐系统中一个重要的任务就是 CTR 建模，其本质的思想便是&lt;strong&gt;预估 user 对 item 的点击率&lt;/strong&gt;。但是实际中获取的样本往往是在一定条件（时间、机型、位置等）下的后验结果，所以使得建模的 Label 往往是夹杂了这些因素的结果。&lt;/p&gt;
&lt;p&gt;这些影响后验结果的因素一般称为 &lt;code&gt;偏置（bias）项&lt;/code&gt;，而去除这些偏置项的过程就称为 &lt;code&gt;消偏（debias）&lt;/code&gt;。在这其中最重要的便是 &lt;code&gt;位置偏置（position bias）&lt;/code&gt;，即 item 展示在不同位置会有不同的影响，且用户往往更偏向点击靠前的位置。本文将重点介绍业界在 &lt;code&gt;position bias&lt;/code&gt; 消除上的一般做法和相关经验。&lt;/p&gt;
&lt;h2 id=&quot;2-Position-Bias&quot;&gt;&lt;a href=&quot;#2-Position-Bias&quot; class=&quot;headerlink&quot; title=&quot;2 Position Bias&quot;&gt;&lt;/a&gt;2 Position Bias&lt;/h2&gt;&lt;p&gt;看下面的图，是笔者实际工作场景中部分位置的 CTR 趋势图。可以明显地看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;呈现每 20 个 position 位一个周期；每刷请求的个数是 20.&lt;/li&gt;
&lt;li&gt;周期内位置越靠前，CTR 越大；靠前效率高，用户更偏好点靠前的。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="精排模型" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="精排" scheme="https://www.xiemingzhao.com/tags/%E7%B2%BE%E6%8E%92/"/>
    
    <category term="debias" scheme="https://www.xiemingzhao.com/tags/debias/"/>
    
  </entry>
  
  <entry>
    <title>YouTubeDNN 和 WCE</title>
    <link href="https://www.xiemingzhao.com/posts/youtubednn.html"/>
    <id>https://www.xiemingzhao.com/posts/youtubednn.html</id>
    <published>2021-12-17T16:00:00.000Z</published>
    <updated>2025-04-04T10:13:21.906Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>这是一篇推荐算法领域经典的论文，它由 YouTube 在2016年发表在 RecSys 上的文章<a href="https://dl.acm.org/doi/pdf/10.1145/2959100.2959190">Deep Neural Networks for YouTube Recommendations</a>。<br>这篇文章是诸多推荐算法工程师的必学经典，可能很多人多次重读都会有新的思考，本文也重点总结文章的核心内容与一些实战经验的思考。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><p>首先便是其展示的系统链路示意图，这块与大多主流方案没有什么区别。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/youtubednn0.png" alt="youtubednn0"></p><p>论文分别介绍了在 <code>recall</code> 和 <code>ranking</code> 两个模块的方案，但可以说，recall 部分的重要性远大于 ranking。就此文章发表后的几年而言，<em>recall 往往还在工业界主流召回的候选方案中，但 ranking 的方案基本已经成为历史，很少再使用了</em>，不过其思想还是值得学习的。</p><span id="more"></span><h3 id="2-1-recall"><a href="#2-1-recall" class="headerlink" title="2.1 recall"></a>2.1 recall</h3><blockquote><p>任务目标：预测用户下一个观看的视频（next watch），一个多分类问题。</p></blockquote><script type="math/tex; mode=display">P(w_t=i|U,C)=\frac{e^{v_i,u}}{\sum_{j \in V} e^{v_j,u}}</script><p>这里先上模型结构，如下图所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/youtubednn1.png" alt="youtubednn1"></p><p><strong>特征</strong></p><ul><li>用户历史看的视频序列，取 embedding 做 <code>average pooling</code>；</li><li>用户历史搜索的 token 序列，也做 <code>average pooling</code>；</li><li>用户的地理位置、性别、年龄等；</li><li>样本年龄（后续单独介绍）。</li></ul><p>之后便是把所有 embedding 进行 concat 拼接，过3层 DNN 以得到 user vector 即 user embedding。</p><p><strong>注意：这里只有 user 的特征输入。</strong></p><blockquote><p>这是召回模型的通用方法，类似于双塔模型。主要是先构建 user embedding 的网络，利于后续线上服务。而与 item 的交互，往往放在最后一个环节。</p></blockquote><p>可以看到，在 user vector 生成后，被分成了 <code>training</code> 和 <code>serving</code> 两个分支。</p><p>先看 <code>training</code> 部分，看上去2步：</p><ol><li>先经过 softmax 层预估 video 的多分类概率；</li><li>然后产出 video vector 供 serving 使用。</li></ol><p>我们假设 3 层的 DNN 后得到的 user vector 是 K 维的，而需要进行多分类的候选集有 M 个 video，那么 training 侧的结构便是：</p><script type="math/tex; mode=display">output = softmax(user_{vec} \cdot W)</script><p>如果 $user_{vec}$ 是 $1 \times K$ 的，那么 $W$ 便是 $K \times M$ 的，如此输出就是 M 维的 softmax 结果。<strong>那么 W 的 M 列 K 维向量即可作为候选集 M 个 video 的 vector。</strong></p><p>其实不用陌生：让我们再次联想召回的双塔模型，是不是就相当于将候选 M 个 video 先过 embedding 层，之后与user vector 做点积，这也是召回模型的经典做法。</p><p>再看 <code>serving</code> 环节，也是经典的召回方案。即：</p><ol><li>离线模型中训练好的 video vector 保存下来；</li><li>将 video vector 构建到 ANN 等向量索引库中；</li><li>线上 serving 的时候，user vector 通过模型实时 infer 得到；</li><li>用 user vector 和索引库进行近邻召回。</li></ol><p><strong>如此的优势</strong>：</p><ul><li>因为每次 serving 需要处理的 video 很多，其 vector 不适合实时生成；</li><li>每次 serving 时 user vector 只需要 infer 一条样本，性能可控，捕捉 user 实时偏好就更重要。</li></ul><p><strong>样本年龄</strong><br>针对论文提到的 <code>Example Age</code> 特征，可能很多人（包括我本人），一开始对此理解是；</p><blockquote><p>视频上架距离 log 的时间差，比如曝光的视频已经上架 48h，那么该特征便是 48。即文中的 <code>Days Since Upload</code>。</p></blockquote><p>然而，结合其他观点和重读论文，应该是：</p><blockquote><p><code>sample log</code> 距离当前的时间作为 <code>example age</code>，比如一条曝光/点击日志 ，发生在 2h 前，在被 training 的时候，也许其 video 已经上架 48h 了，但 example age 特征的取值是前者 2。</p></blockquote><p>作者提到，在加入该特征后，<strong>模型能够较好地学习到视频的 freshness 程度对 popularity 的影响</strong>。体现在下图的 <code>Days Since Upload</code> 后验分布的变化，新模型比 baseline 表现得更接近真实分布。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/youtubednn2.png" alt="youtubednn2"></p><h3 id="2-2-ranking"><a href="#2-2-ranking" class="headerlink" title="2.2 ranking"></a>2.2 ranking</h3><blockquote><p>优化目标：expected watch time，即视频期望观看时长。</p></blockquote><p>这里我们重点介绍一些核心，先上模型结构图：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/youtubednn3.png" alt="youtubednn3"></p><p><strong>特征：</strong></p><ul><li><code>video embedding</code>：<ul><li><code>impression video ID</code>: 当前待评估的video的embedding</li><li><code>watched video IDs</code>: 用户最近观看的N个 video 的 embedding 的 average pooling</li></ul></li><li><code>language embedding</code>:<ul><li><code>user language</code>: 用户语言的 embedding</li><li><code>video language</code>: 当前视频语言的 embedding</li></ul></li><li><code>time since last watch</code>: 用户上次观看同 channel 视频距今的时间</li><li><code>#previous impressions</code>: 该 video 已经被曝光给该用户的次数</li></ul><p>披露的特征设计非常经典且贴合实际业务，也许真实的特征体系比这要更丰富，但论文披露的更多是特征设计的思想。</p><ul><li><code>video embedding</code> 代表了捕捉用户历史行为序列关于当前视频的相关度；</li><li><code>language</code> 非常具有 youtube 全球视频网站的特色，捕捉用户与视频语言差异。</li><li>后面的2个统计值度量了一些时间因素，用户看同 <code>channel</code> 隔了多久以捕捉兴趣衰减，已经曝光的次数代表了用户忽视程度。</li></ul><p>此外，论文提到了一些<code>trick</code>：</p><ul><li>连续型特征做 <code>normalization</code>，利于模型收敛；</li><li>部分统计特征进行了 <code>box-cox 变化</code>，<strong>是一种增加特征非线性输入的办法，辅助模型训练</strong>；</li><li>长尾 video，其 embedding 用 0 来代替，降低长尾影响。</li></ul><p>模型将输入 embedding 进行 concat 后过了一个 3 层 DNN，之后类似 recall 环节，又分成了 training 和 serving 这2个分支，实际上这里是<strong>巧妙地将回归问题转分类了</strong>。</p><ul><li><code>training</code> 时，Weighted LR 方式，label 为是否观看，weight 是观看时长，作用在 loss 上；</li><li><code>serving</code> 时，使用 $e^{wx+b}$ 作为观看时长的预估值，其中指数部分是训练时 sigmoid 的 input 部分。</li></ul><h2 id="3-实践经验"><a href="#3-实践经验" class="headerlink" title="3 实践经验"></a>3 实践经验</h2><p>结合王哲老师的工程10问，这里总结和补充一下个人认为比较重要的实战经验，供自己复盘和其他读者批评。</p><h3 id="3-1-Recall-model-的性能问题"><a href="#3-1-Recall-model-的性能问题" class="headerlink" title="3.1 Recall model 的性能问题"></a>3.1 Recall model 的性能问题</h3><p><code>next watch</code> 的目标下，候选 video 有数百万量级，这在使用 softmax 进行多分类更低效。论文有提到这块，类似于 word2vec 的解决方案，<strong>负采样（negative sampling）或者 分层处理（hierarchical softmax）。</strong>效果是没有太大差异，一般负采样使用更广泛。</p><blockquote><p>其原理是：每次不用预估所有候选，而只采样一定数量（超参数）的样本作为负样本，甚至进一步可以转化成基于点积的二分类。</p></blockquote><h3 id="3-2-Ranking-Model-为什么选择用分类而不是回归？"><a href="#3-2-Ranking-Model-为什么选择用分类而不是回归？" class="headerlink" title="3.2 Ranking Model 为什么选择用分类而不是回归？"></a>3.2 Ranking Model 为什么选择用分类而不是回归？</h3><p>我认为在该问题上主要有2点。</p><ol><li>是业务目标的决策。如果是点击等目标天然满足，这里这不满足此。</li><li>实际工业应用中，以时长等连续型数据作为 Label 时，因其<strong>具有严重的长尾分布特性，这会使得回归模型在拟合过程中容易欠佳</strong>。一般体现在对 Label 值过低和过高的两端样本拟合偏差，MSE、PCOC等预估统计量偏差很大。因而一般会转成分类任务来处理。<br><em>具体原因则和回归模型特性以及样本梯度分布有关系，不过多赘述。相对地，分类模型则在这方面稳健性会高一些。</em></li></ol><h3 id="3-3-Ranking-model-使用-weighted-LR-的原理"><a href="#3-3-Ranking-model-使用-weighted-LR-的原理" class="headerlink" title="3.3 Ranking model 使用 weighted LR 的原理"></a>3.3 Ranking model 使用 weighted LR 的原理</h3><p>我们来理解一下为什么论文中做法能生效？这里阐述一下个人的理解。</p><script type="math/tex; mode=display">p = sigmoid(z)=\frac{e^z}{1 + e^{z}}</script><p>其中 z 是最后一层，即 $z = wx+b$。</p><p>那么 LR 模型的交叉熵 loss 为：</p><script type="math/tex; mode=display">loss = \sum -(\log{p} + \log(1-p))</script><p>那么，如果我们将 label 由“是否观看”变成 $\frac{t}{1+t}$ ，其中 t 是观看时长，那么 loss 就变成：</p><script type="math/tex; mode=display">loss = \sum -(\frac{t}{1+t} \cdot \log{p} + \frac{1}{1+t} \cdot \log(1-p))</script><p>注意！这时候，$p$ 拟合的就是 $\frac{t}{1+t}$，当其不断逼近的时候，就有：</p><script type="math/tex; mode=display">e^{z} \to t</script><p>故，<strong>在 serving 的时候就使用 $e^{z}=e^{wx+b}$作为观看时长 t 的预估值。</strong></p><p>进一步，因大多时候 1+t 等于或接近1，那么 loss 近似等价于：</p><script type="math/tex; mode=display">loss = \sum -(t \cdot \log{p} + 1 \cdot \log(1-p))</script><blockquote><p>注：这里类似王哲老师提到的“概率p往往是一个很小的值”来近似上一个道理。</p></blockquote><p>这便是一个<strong>目标是否观看的 weighted LR 的 loss，且 weight 为观看时间 t。</strong></p><p><strong>补充：</strong><br><code>Weighted LR</code> 实际上就是 <code>WCE(weighted cross entropy) Loss</code>，一般来说有两种方法：</p><ul><li>将正样本按照 weight 做重复 sampling；</li><li>通过改变梯度的 weight 来得到 Weighted LR （论文方法）。</li></ul><p>但是 <code>WCE</code> 有2个缺点：</p><ul><li>其实假设了样本分布服从几何分布，否则可能导致效果不好；</li><li>在低估时（$\hat y &lt; y$）梯度很大，高估时（$\hat y &gt; y$）梯度很小，很容易导致模型高估。</li></ul><h3 id="3-4-如何生成-user-和-video-的-embedding？"><a href="#3-4-如何生成-user-和-video-的-embedding？" class="headerlink" title="3.4 如何生成 user 和 video 的 embedding？"></a>3.4 如何生成 user 和 video 的 embedding？</h3><p>文中介绍用 word2vec 预训练得到。当然，我们知道，也可以使用 embedding layer 去联合训练，且往往这种实践更好，也是现如今的主流做法。</p><h3 id="3-5-example-age-的处理和原因？"><a href="#3-5-example-age-的处理和原因？" class="headerlink" title="3.5 example age 的处理和原因？"></a>3.5 example age 的处理和原因？</h3><p><strong>猜想：可能是从特征维度区分开历史样本的重要度，越新的样本（不是 video）可能对模型参考价值越大。有点类似于 biasnet 的修正作用。</strong></p><blockquote><p>比如有一个 video（不一定新上架） 1h 前有很多正样本，且越来越少，那么模型通过此特征可能能够感知到这种热度的时序变化趋势。</p></blockquote><p>但，对于 youtube 而言，其模型训练应该是：</p><ul><li>实时（至少日内）的；</li><li>批次增量的（即不会回溯更久远的样本）；</li></ul><p>假设样本的切分窗口为 T（比如2h），那么就一定 $0&lt;example age&lt;T$，那么问题来了：</p><blockquote><p>样本只能学习到该特征在（0，T）的分布，但论文图中却展示 Days Since Upload 特征的后验分布改善了。</p></blockquote><p>serving 的时候，虽然说通过置0来消除 example age 的bias，但实际上样本距离当下的时间又发生了变化，即 example age 信息发生了偏移。</p><p><strong>总结</strong>：也许这两个特征都在模型中，且交叉效应大于边际效应。描述 video fresh 程度交给 Days Since Upload 特征，再加上描述 sample fresh 程度的 example age。能够使得前者后验预估的更准确，也能够通过后者修正历史样本的 times bias。</p><h3 id="3-6-为什么对每个用户提取等数量的训练样本？"><a href="#3-6-为什么对每个用户提取等数量的训练样本？" class="headerlink" title="3.6 为什么对每个用户提取等数量的训练样本？"></a>3.6 为什么对每个用户提取等数量的训练样本？</h3><p>原文中提到“这是为了减少高度活跃用户对于loss的过度影响。”但实际上个人觉得这个方法可能不一定最适合。结合逻辑和个人经验，个人认为主要有2点：</p><ul><li>模型学习了一个有偏于真实分布的样本，预估会有偏差；</li><li>本末倒置，使得低活的影响力反而增强，线上 ABtest 的时候，其贡献往往不足，因线上业务收益往往也是高活主导，二八法则；</li></ul><p>虽如此，<strong>倒不是说高活不应该抑制</strong>，对于比较异常的高活，可以针对他们样本欠采样或者加正则，而不是只有通过提高重要性更低的非高活人群的作用。</p><h3 id="3-7-为什么不采取类似RNN的Sequence-model？"><a href="#3-7-为什么不采取类似RNN的Sequence-model？" class="headerlink" title="3.7 为什么不采取类似RNN的Sequence model？"></a>3.7 为什么不采取类似RNN的Sequence model？</h3><p>论文提到主要是过于依赖临近行为，使得推荐结果容易大范围趋同于最近看过的 video。<br>此外，还有一个比较重要的原因便是 serving 时候的 infer 性能问题。</p><h3 id="3-8-为什么长尾的video直接用0向量代替？"><a href="#3-8-为什么长尾的video直接用0向量代替？" class="headerlink" title="3.8 为什么长尾的video直接用0向量代替？"></a>3.8 为什么长尾的video直接用0向量代替？</h3><p>把大量长尾的video截断掉，主要是为了<strong>节省online serving中宝贵的内存资源</strong>。</p><p>但现在问问不会这么粗暴的使用，一般是<strong>将长尾物料进行聚类，以改善他们样本过于稀疏而带来的收敛困难问题</strong>。极端情况就是聚为1类，共享一个 embedding，类似于冷启动一样，当逐渐脱离长尾后再出场拥有独立的 embedding。</p><p><strong>参考文章</strong><br><a href="https://dl.acm.org/doi/pdf/10.1145/2959100.2959190">Deep Neural Networks for YouTube Recommendations</a><br><a href="https://www.cnblogs.com/xumaomao/p/15207305.html">Weighted LR （WCE Weighted cross entropy）</a><br><a href="https://blog.csdn.net/u012328159/article/details/123986042">推荐系统（二十）谷歌YouTubeDNN</a><br><a href="https://zhuanlan.zhihu.com/p/52169807">重读Youtube深度学习推荐系统论文</a><br><a href="https://zhuanlan.zhihu.com/p/52504407">YouTube深度学习推荐系统的十大工程问题</a><br><a href="https://blog.csdn.net/weixin_46838716/article/details/126459692?spm=1001.2014.3001.5502">排序04：视频播放建模</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;这是一篇推荐算法领域经典的论文，它由 YouTube 在2016年发表在 RecSys 上的文章&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/2959100.2959190&quot;&gt;Deep Neural Networks for YouTube Recommendations&lt;/a&gt;。&lt;br&gt;这篇文章是诸多推荐算法工程师的必学经典，可能很多人多次重读都会有新的思考，本文也重点总结文章的核心内容与一些实战经验的思考。&lt;/p&gt;
&lt;h2 id=&quot;2-原理&quot;&gt;&lt;a href=&quot;#2-原理&quot; class=&quot;headerlink&quot; title=&quot;2 原理&quot;&gt;&lt;/a&gt;2 原理&lt;/h2&gt;&lt;p&gt;首先便是其展示的系统链路示意图，这块与大多主流方案没有什么区别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/youtubednn0.png&quot; alt=&quot;youtubednn0&quot;&gt;&lt;/p&gt;
&lt;p&gt;论文分别介绍了在 &lt;code&gt;recall&lt;/code&gt; 和 &lt;code&gt;ranking&lt;/code&gt; 两个模块的方案，但可以说，recall 部分的重要性远大于 ranking。就此文章发表后的几年而言，&lt;em&gt;recall 往往还在工业界主流召回的候选方案中，但 ranking 的方案基本已经成为历史，很少再使用了&lt;/em&gt;，不过其思想还是值得学习的。&lt;/p&gt;</summary>
    
    
    
    <category term="精排模型" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="精排" scheme="https://www.xiemingzhao.com/tags/%E7%B2%BE%E6%8E%92/"/>
    
    <category term="YouTubeDNN" scheme="https://www.xiemingzhao.com/tags/YouTubeDNN/"/>
    
    <category term="WCE" scheme="https://www.xiemingzhao.com/tags/WCE/"/>
    
  </entry>
  
  <entry>
    <title>ExpectationI2I 召回</title>
    <link href="https://www.xiemingzhao.com/posts/expectationi2irecall.html"/>
    <id>https://www.xiemingzhao.com/posts/expectationi2irecall.html</id>
    <published>2021-11-27T16:00:00.000Z</published>
    <updated>2025-04-04T17:45:38.301Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在推荐的发展历史中，Amazon 在 ItemCF 上进行了不少的探索。2003年，其在 IEEE INTERNET COMPUTING 发表的<a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf">《http://Amazon.com Recommendations: Item-to-Item Collaborative Filtering》</a>一文中提出了 ItemCF 推荐算法，引起了不小的波澜。其<code>主要优势是</code>：</p><ul><li>简单可扩展；</li><li>可解释性强；</li><li>实时性高；</li></ul><p>在早期，ItemCF/UserCF 往往被用于推荐主算法，在当下一般作为召回算法。<strong>UserCF 适用于用户数的变化频率小于物品数的变化频率的场景，ItemCF 则相反。当今的互联网环境下确实是更适合 ItemCF 发挥。</strong></p><p>而本文就是为了介绍其新提出的一种改进的 ItemCF 算法 <code>ExpectationI2I</code>，当然有的地方名字可能不一样。这是由 Amazon 在 2017 年的 IEEE INTERNET COMPUTING 上发表的文章<a href="https://assets.amazon.science/76/9e/7eac89c14a838746e91dde0a5e9f/two-decades-of-recommender-systems-at-amazon.pdf">《Two Decades of Recommender Systems at Amazon.com》</a>中介绍的。</p><span id="more"></span><h2 id="2-动机"><a href="#2-动机" class="headerlink" title="2 动机"></a>2 动机</h2><p>主要是在如何定义物品的相关性上，有一定的改进空间。对于两个物品X和Y，在购买了X的用户中，假设有$N_{xy}$购买了Y。那在这里面，实际上有两部分组成：</p><ul><li>一个是因为X和Y<code>相关</code>，而产生的<code>关联购物</code>；</li><li>另一个则是X和Y<code>不相关</code>，仅仅是<code>随机性导致的共同购物</code>。</li></ul><p>所以，我们<strong>核心目标就是要度量其中关联购物的那一部分</strong>。在2003及之前的文章中，其大多使用下面的方法：</p><blockquote><p>首先假设购买X的user有同概率P(Y)购买Y，且 <strong>P(Y)=购买Y的uv/所有购买的uv</strong> 。那么X和Y的共同购买人数 $N<em>{xy}$ 的期望$E</em>{xy}$ = 购买X的uv * P(Y)。</p></blockquote><p>这里在理解上，个人认为<strong>有两点需要注意</strong>：</p><ol><li>$N_{xy}$ 实际上可以在实际中观测到，也<strong>就是X和Y的共同购买uv数，但是包含随机性共同购物</strong>；</li><li>上面实际上不仅假设了购买同概率，还同时默认一个假设：<strong>购买了X的用户群购买Y的概率与全局分布一致</strong>。</li></ol><p>而当出现很多购买两很大的用户时，就容易增加随机性共同购物，从而拉高了预估的结果。故，本文<strong>最核心是：如何度量$N_{xy}$中因随机性而产生的共同购物次数</strong>。那么剔除这一部分就可以得到因X和Y相关性而产生的<code>关联购物</code>次数，这便可以更有效的度量物品之间的相关性。</p><h2 id="3-算法原理"><a href="#3-算法原理" class="headerlink" title="3 算法原理"></a>3 算法原理</h2><p>为了计算购买X的用户会因随机性购买Y的期望$E_{xy}$，我们记：</p><ul><li>对于任意购买了X的用户c，|c|=其购买总次数-购买了X的次数；</li><li>P(Y)=全部用户购买Y的次数/全部用户的全部购买次数；</li><li>那么对于该用户c，在其除X外的|c|次购买中，有购买 Y 的概率$P_{xy} = 1-(1-P(Y))^{|c|}$</li></ul><p>所以$E<em>{xy}$就可以通过对所有购买了X的用户的$P</em>{xy}$求和来得到:</p><script type="math/tex; mode=display">\begin{array}{l}E_{XY} &=& \sum_{c \in X} [1 - (1-P(Y))^{|c|}] = \sum_{c \in X} [1 - \sum_{k=0}^{|c|} C_{|c|}^{k} (-P_Y)^k] \\&=& \sum_{c \in X}[1 - [1 + \sum_{k=1}^{|c|} C_{|c|}^{k} (-P_Y^k)]] = \sum_{c \in X} \sum_{k=1}^{|c|} (-1)^{k+1} C_{|c|}^{k}P_Y^k \\&=& \sum_{c \in X} \sum_{k=1}^{\infty} (-1)^{k+1} C_{|c|}^{k}P_Y^k \quad (since \ C_{|c|}^{k} = 0 \ for \ k>|c| ) \\&=& \sum_{k=1}^{\infty} \sum_{c \in X} (-1)^{k+1} C_{|c|}^{k}P_Y^k \quad (Fubini's \ theorem) \\&=& \sum_{k=1}^{\infty} \alpha_{k}(X) P_Y^k \quad where \ \alpha_k(X) = \sum_{c \in X}(-1)^{k+1} C_{|c|}^{k}\end{array}</script><p>作者提到一些<strong>计算技巧</strong>：</p><ul><li>即实际中$P_Y$一般比较小，所以可以设置一个k的上限 <code>max_k</code> 作为求和多项式的最多项，也即做了<strong>级数求和的近似</strong>。</li><li>另一方面，为了降低复杂度，$P<em>Y$和$\alpha</em>{k}{X}$的各组合项可以提前计算好，降低阶乘重复计算的复杂度。</li></ul><p>到这里，我们已经得到了购买X的用户随机购买Y的一个估计$E<em>{xy}$，据此可以判断真实中观测到的$N</em>{xy}$与随机估计的高低。所以，我们如果用同时购买的uv去除随机性的共同购买次数，得到的便是一个X和Y的关联性购买次数估计值。此便可以作为度量与X相关的商品Y的相关度，实际上作者还认为实际应用中有下面三种估计公式可选：</p><ol><li>$N<em>{xy}-E</em>{xy}$，<strong>会偏向于更流行的Y</strong>;</li><li>$(N<em>{xy}-E</em>{xy})/E_{xy}$，<strong>会使得低销量的物品很容易获得高分数</strong>;</li><li>$(N<em>{xy}-E</em>{xy})/sqrt(E_{xy})$，<strong>在高曝光商品和低销量商品之间找到平衡，需要动态调整</strong>。</li></ol><h2 id="4-实际应用"><a href="#4-实际应用" class="headerlink" title="4 实际应用"></a>4 实际应用</h2><p>在实际应用中，往往没有那么简单。首先我们介绍一下，该算法如何基于实际用户行为来计算，然后笔者将抛出一些问题和自己的优化建议。</p><script type="math/tex; mode=display">\sum_{c \in X} \sum_{k=1}^{|c|} (-1)^{k+1} C_{|c|}^{k}P_Y^k</script><p>现实一般基于上述公式来计算比较方便，原因是先处理好每个 <code>user x item</code> 的统计量，然后按照 user 聚合即可。</p><p><code>step1</code><br>构建所有行为（点击收藏等）的表，保留行为数量在合理区间 [n1,n2] 内的 user，保留 session 数量 &gt;m1 的 item_id<br>t1: user_id,item_id,time,session_id</p><p><code>step2</code><br>基于t1自join生成记录 session 内行为 pair 对表<br>t2: user_id,session_id,left_item_id,left_time,right_item_id,right_time,time_delta</p><p><code>step3</code><br>基于t2统计全局 pair 对数,session 去重 pair 对数统计表,计算 $N_{xy}$，<br>t3: left_item_id,right_item_id,cnt,user_session_cnt</p><p><code>step4</code><br>基于 expect_all_user_action 统计 user_id,item_id 共现的 session_id 次数<br>t4: user_id,item_id,sessioncnt</p><p><code>step5:</code><br>这一步最重要，<strong>我们需要计算 user x item 的|c|，下面记为 parm_c</strong>。记录 user_id,item_id 的统计参数<br>t5: user_id,item_id,clk_pv,clk_pv_all,parm_c(clk_pv_all-clk_pv)</p><p><strong>为了降低计算复杂度，这里的 parm_c 可以做上限截断</strong>。有了 parm<em>c 后就可以计算 $\sum</em>{k=1}^{|c|} (-1)^{k+1} C_{|c|}^{k}P_Y^k$。</p><p><code>step6:</code><br>基于t5对 user 进行聚合，统计 item<em>id 维度的参数<br>t6: item_id,clk_cnt,clk_all,clk_prob,parm_c_list<br>**其中 clk_prob 便是$P_Y$，即一个物品在全局被随机点击的概率。parm_c_list 则是将物品在所有的 user 上的 parm_c汇总到一起，为了后面来计算 $E</em>{xy}$。**</p><p><code>step7:</code><br>基于t6构建 item pair，来拼接 $N<em>{xy}$，并计算最重要的 $E</em>{xy}$<br>t7: left<em>item_id,right_item_id,Nxy,left_parm_c_list,right_clk_prob,Exy<br>其中，$E</em>{xy}$ 可以通过 left_parm_c_list,right_clk_prob 来计算。例如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> comb</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ExpectScore</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, parm_c_list, clk_prob</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">get_exy</span>(<span class="params">parm_c, clk_prob</span>):</span><br><span class="line">            ans = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(parm_c):</span><br><span class="line">                ans += <span class="built_in">pow</span>(-<span class="number">1</span>, (k + <span class="number">1</span>)%<span class="number">2</span>) * <span class="built_in">pow</span>(prob_num,i) * comb(parm_c, i)</span><br><span class="line">                <span class="keyword">if</span> s_tmp[<span class="built_in">str</span>(i)+<span class="string">&#x27;.0&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="built_in">list</span>(res_t.values()))</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> parm_c <span class="keyword">in</span> parm_c_list.split(<span class="string">&#x27;,&#x27;</span>):</span><br><span class="line">                res += get_exy(parm_c, clk_prob)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sum</span>(res)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0000</span></span><br></pre></td></tr></table></figure></p><p><code>step8:</code><br>已经拿到了最重要的两个统计项$N<em>{xy},E</em>{xy}$，计算最终结果分，并对每个 left_item_id 的所有 right_item_id 降序排列截断构建倒排即可。<br>t8: left_item_id,right_item_id, sc, rank<br>其中，</p><ul><li>sc 就是前述融合分数公式来计算得到的;</li><li>rank 便是按照sc降序排列得到的排名。</li></ul><p>实际上，如果计算中由于 parm<em>c 的上限截取的比较大，那么在计算$E</em>{xy}$中会频繁的遇到较大值的排列组合$C_{|c|}^{k}$的计算，有可能速度会比较慢。而在全局|c|的上限固定的情况下，我们可以利用<strong>空间换时间来优化</strong>这个：</p><blockquote><ul><li>因为|c|的上限固定，会使得$C<em>{|c|}^{k}$的计算比较高频重复，所以可以提前遍历全部有效k(即k&lt;=｜c|)的$C</em>{|c|}^{k}$结果；</li><li>然后，将表t5中的 parm<em>c 替换成存储各拆分项$C</em>{|c|}^{k}$的结果，在表t6中的 parm_c_list 也类似存储各个 user 的 parm_c 对应的各个拆分项；</li><li>最后，在表t7的$E<em>{xy}$计算环节，就不用计算排列组合项$$C</em>{|c|}^{k}$$，只需要将存好的<code>comb(parm_c, i)</code>项带入进行计算即可。</li></ul></blockquote><h2 id="5-问题与思考"><a href="#5-问题与思考" class="headerlink" title="5 问题与思考"></a>5 问题与思考</h2><p>实际上，如前文所述，这种算法不喜欢 user 行为覆盖过多的物品，<strong>高活用户对其不友好</strong>。而像 item2vec 或者 wbcos 这种对此就不敏感，因为基于 user 行为序列内构建样本 pair 对的。</p><p>在前面，介绍了 <code>ExpectationI2I</code> 算法的原理，实际构建方式，以及优化计算复杂度的方案。然而，实际应用中往往还存不少 badcase，我们需要对一些环节做一些精细的优化，这里列出部分问题和方案的思考，供备忘和参考。</p><p><strong>1. 有效行为数据的筛选逻辑</strong><br>部分行为过少或过多的极端用户会影响算法稳定性，所以在应用中我们也提到了n1,n2以及m1等边界超参数。这些参数的具体选值需要根据具体场景数据分布来确定，整体目标就是剔除不稳健的用户行为数据。</p><p><strong>2. 类目的信息，例如不同类目的惩罚或者加权；</strong><br>在构建的pair对上计算各统计项的时候，需要考虑类目相关度的一个影响，比如同类目是否进行加权，异类目是否进行降权，或者直接根据类目分布来进行权重调整，目的就是为了降低行为中偶然性类目的搭便车情况，降低算法的badcase率。</p><p><strong>3. 融合分公式的调整；</strong><br>在算法原理模块，已经介绍了论文作者提出的三种公式及其特性。在实际应用中，往往还需要进行一定的调整，否则很容易出现一些badcase。例如一种改进公式$\frac{N<em>{xy}-E</em>{xy}}{1 + \sqrt{E_{xy}}}$，总之还是以实际线上实验数据为准。</p><p><strong>4. 天级别数据的增量融合；</strong><br>在应用次算法的时候，往往面临一个行为数据时间窗口的选取，一次性选择太多，计算量会过大，选择太少数据会不准确。那么，一般可以采用每日增量更新。有两种方式：</p><ul><li>增量更新$N<em>{xy},E</em>{xy}$两个统计项，分别赋予历史值和增量值合适的权重；</li><li>增量直接更新表t8中最终的分数sc，然后构建新的排序。</li></ul><p><strong>参考文献</strong><br><a href="https://zhuanlan.zhihu.com/p/27656480">【翻译+批注】亚马逊推荐二十年</a><br><a href="https://www.jianshu.com/p/248209fd1038">【论文阅读】Two Decades of Recommender Systems at Amazon.com</a><br><a href="https://assets.amazon.science/76/9e/7eac89c14a838746e91dde0a5e9f/two-decades-of-recommender-systems-at-amazon.pdf">Two Decades of Recommender Systems at Amazon.com</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在推荐的发展历史中，Amazon 在 ItemCF 上进行了不少的探索。2003年，其在 IEEE INTERNET COMPUTING 发表的&lt;a href=&quot;https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf&quot;&gt;《http://Amazon.com Recommendations: Item-to-Item Collaborative Filtering》&lt;/a&gt;一文中提出了 ItemCF 推荐算法，引起了不小的波澜。其&lt;code&gt;主要优势是&lt;/code&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简单可扩展；&lt;/li&gt;
&lt;li&gt;可解释性强；&lt;/li&gt;
&lt;li&gt;实时性高；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在早期，ItemCF/UserCF 往往被用于推荐主算法，在当下一般作为召回算法。&lt;strong&gt;UserCF 适用于用户数的变化频率小于物品数的变化频率的场景，ItemCF 则相反。当今的互联网环境下确实是更适合 ItemCF 发挥。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;而本文就是为了介绍其新提出的一种改进的 ItemCF 算法 &lt;code&gt;ExpectationI2I&lt;/code&gt;，当然有的地方名字可能不一样。这是由 Amazon 在 2017 年的 IEEE INTERNET COMPUTING 上发表的文章&lt;a href=&quot;https://assets.amazon.science/76/9e/7eac89c14a838746e91dde0a5e9f/two-decades-of-recommender-systems-at-amazon.pdf&quot;&gt;《Two Decades of Recommender Systems at Amazon.com》&lt;/a&gt;中介绍的。&lt;/p&gt;</summary>
    
    
    
    <category term="召回模型" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%8F%AC%E5%9B%9E%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="ExpectationI2I" scheme="https://www.xiemingzhao.com/tags/ExpectationI2I/"/>
    
  </entry>
  
  <entry>
    <title>知识蒸馏简述（Knowledge Distillation）</title>
    <link href="https://www.xiemingzhao.com/posts/distillationmodel.html"/>
    <id>https://www.xiemingzhao.com/posts/distillationmodel.html</id>
    <published>2021-09-15T16:00:00.000Z</published>
    <updated>2025-04-04T17:47:19.387Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>目前有很多复杂的模型可以来完成不同的任务，但是部署重量级模型的集成在许多情况下并不总是可行的。有时，你的单个模型可能太大，以至于通常不可能将其部署到资源受限的环境中。这就是为什么我们一直在研究一些模型优化方法 ——量化和剪枝</p><h2 id="2-Softmax的故事"><a href="#2-Softmax的故事" class="headerlink" title="2 Softmax的故事"></a>2 Softmax的故事</h2><p>当处理一个分类问题时，使用 softmax 作为神经网络的最后一个激活单元是非常典型的用法。这是为什么呢？<strong>因为softmax函数接受一组 logit 为输入并输出离散类别上的概率分布</strong>。比如，手写数字识别中，神经网络可能有较高的置信度认为图像为1。不过，也有轻微的可能性认为图像为7。如果我们只处理像[1,0]这样的独热编码标签(其中1和0分别是图像为1和7的概率)，那么这些信息就无法获得。</p><span id="more"></span><p>人类已经很好地利用了这种相对关系。更多的例子包括，长得很像猫的狗，棕红色的，猫一样的老虎等等。正如 Hinton 等人所认为的</p><blockquote><p>一辆宝马被误认为是一辆垃圾车的可能性很小，但比被误认为是一个胡萝卜的可能性仍然要高很多倍。</p></blockquote><p>这些知识可以帮助我们在各种情况下进行极好的概括。这个思考过程帮助我们更深入地了解我们的模型对输入数据的想法。它应该与我们考虑输入数据的方式一致。</p><p><strong>而模型的 softmax 信息比独热编码标签更有用，因为本身的结果就是一种分布，人类认识世界又何尝不是如此</strong>。</p><h2 id="3-模型蒸馏的流程"><a href="#3-模型蒸馏的流程" class="headerlink" title="3 模型蒸馏的流程"></a>3 模型蒸馏的流程</h2><ul><li>在原始数据集上训练一个复杂但效果好的大模型，将此作为 <code>teacher model</code>；</li><li>基于教师模型在数据集上的预估结果 <code>soft label</code>，重新在数据集上训练一个轻量的模型，并尽量保留效果，此便是<code>student model</code>。</li></ul><blockquote><p>最终目的是得到一个小而美的模型以便于在生产中进行部署使用。</p></blockquote><p>本文以一个<strong>图像分类</strong>的例子，我们可以扩展前面的思想：</p><ul><li>训练一个在图像数据集上表现良好的教师模型。</li><li>在这里，交叉熵损失将根据数据集中的真实标签计算。</li><li>在相同的数据集上训练一个较小的学生模型，但是使用来自教师模型(softmax输出)的预测作为 ground-truth 标签。</li></ul><p>这些 softmax 输出称为软标签 <code>soft label</code>，原始的标签即为 <code>hard label</code>。</p><h2 id="4-使用soft-label的原理"><a href="#4-使用soft-label的原理" class="headerlink" title="4 使用soft label的原理"></a>4 使用soft label的原理</h2><p>在容量方面，我们的学生模型比教师模型要小。</p><p>因此，如果你的数据集足够复杂，那么较小的student模型可能不太适合捕捉训练目标所需的隐藏表示。我们在软标签上训练学生模型来弥补这一点，它提供了比独热编码标签更有意义的信息。在某种意义上，我们通过暴露一些训练数据集来训练学生模型来模仿教师模型的输出。</p><h2 id="5-损失函数的构建"><a href="#5-损失函数的构建" class="headerlink" title="5 损失函数的构建"></a>5 损失函数的构建</h2><blockquote><p>实际中存在<code>弱概率</code>的问题是：它们没有捕捉到学生模型有效学习所需的信息。</p></blockquote><p>例如，如果概率分布像[0.99, 0.01]，几乎不可能传递图像具有数字7的特征的知识。</p><p>Hinton 等人解决这个问题的方法是：<strong>在将原始 logits 传递给 softmax 之前，将教师模型的原始 logits 按一定的温度进行缩放</strong>。</p><p>这样，就会在可用的类标签中得到更广泛的分布。然后用同样的温度用于训练学生模型。</p><p>我们可以把学生模型的修正损失函数写成这个方程的形式：</p><script type="math/tex; mode=display">L_{KDCE}=-\sum_i p_i \log s_i</script><p>其中，$p_i$是教师模型得到软概率分布，si的表达式为：</p><script type="math/tex; mode=display">s_i=-\frac{exp(z_i/T)}{\sum_j exp(z_j/T)}</script><p>具体到代码的实现如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_kd_loss</span>(<span class="params">student_logits, teacher_logits, </span></span><br><span class="line"><span class="params">                true_labels, temperature,</span></span><br><span class="line"><span class="params">                alpha, beta</span>):</span><br><span class="line">    </span><br><span class="line">    teacher_probs = tf.nn.softmax(teacher_logits / temperature)</span><br><span class="line">    kd_loss = tf.keras.losses.categorical_crossentropy(</span><br><span class="line">        teacher_probs, student_logits / temperature, </span><br><span class="line">        from_logits=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> kd_loss</span><br></pre></td></tr></table></figure></p><h2 id="6-合并使用软硬标签"><a href="#6-合并使用软硬标签" class="headerlink" title="6 合并使用软硬标签"></a>6 合并使用软硬标签</h2><p>Hinton 等人还探索了在真实标签(通常是 one-hot 编码)和学生模型的预测之间使用传统交叉熵损失的想法。当训练数据集很小，并且软标签没有足够的信号供学生模型采集时，这一点尤其有用。</p><p>当它与扩展的 softmax 相结合时，这种方法的工作效果明显更好，而整体损失函数成为两者之间的加权平均。</p><script type="math/tex; mode=display">L=\frac{\alpha * L_{KDCE}+\beta * L_{CE}}{(\alpha + \beta)}</script><p>其中</p><script type="math/tex; mode=display">L_{CE}=-\sum_i y_i \log z_i</script><p>而$y_i$和$z_i$分别就是原始的标签即<code>hard label</code>和学生模型的原始预测结果。</p><p>具体代码实现可以如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_kd_loss</span>(<span class="params">student_logits, teacher_logits, </span></span><br><span class="line"><span class="params">                true_labels, temperature,</span></span><br><span class="line"><span class="params">                alpha, beta</span>):</span><br><span class="line">    teacher_probs = tf.nn.softmax(teacher_logits / temperature)</span><br><span class="line">    kd_loss = tf.keras.losses.categorical_crossentropy(</span><br><span class="line">        teacher_probs, student_logits / temperature, </span><br><span class="line">        from_logits=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    ce_loss = tf.keras.losses.sparse_categorical_crossentropy(</span><br><span class="line">        true_labels, student_logits, from_logits=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    total_loss = (alpha * kd_loss) + (beta * ce_loss)</span><br><span class="line">    <span class="keyword">return</span> total_loss / (alpha + beta)</span><br></pre></td></tr></table></figure></p><p>结合起来看便可以知道一个是基于软标签训练的，而另一个就是基于原始硬标签训练的。并且在实际使用中，<strong>一般的$\alpha$取值要大于$\beta$比较好</strong>，以便更多的吸收教师模型的信息。</p><h2 id="7-直接拟合软标签"><a href="#7-直接拟合软标签" class="headerlink" title="7 直接拟合软标签"></a>7 直接拟合软标签</h2><p>既然我们想学习教师模型的信息，最粗暴的做法便是以教师模型的结果<code>soft label</code>作为目标，直接进行回归。Caruana 等人便是如此，操作原始 logits，而不是 softmax 值。这个工作流程如下：</p><ul><li>这部分保持相同:训练一个教师模型。这里交叉熵损失将根据数据集中的真实标签计算。</li><li>现在，为了训练学生模型，训练目标变成分别最小化来自教师和学生模型的原始对数之间的平均平方误差。</li></ul><script type="math/tex; mode=display">L_{KDMSE}=\sum_i||z_i^{\theta_student} - z_{i(teacher)}^{fixed}||^2</script><p>具体代码实现可如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mse = tf.keras.losses.MeanSquaredError()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mse_kd_loss</span>(<span class="params">teacher_logits, student_logits</span>):</span><br><span class="line">    <span class="keyword">return</span> mse(teacher_logits, student_logits)</span><br></pre></td></tr></table></figure></p><p>使用这个损失函数的一个<strong>潜在缺点是它是无界的</strong>。原始 logits 可以捕获噪声，而一个小模型可能无法很好的拟合。这就是为什么为了使这个损失函数很好地适合蒸馏状态，学生模型需要更大一点。</p><p>Tang 等人探索了在两个损失之间插值的想法：<strong>扩展 softmax 和 MSE 损失</strong>。数学上，它看起来是这样的：</p><script type="math/tex; mode=display">L=(1-\alpha) \cdot L_{KDMSE} + \alpha \cdot L_{KDCE}</script><p>根据经验，他们发现当 $\alpha = 0$ 时，(在NLP任务上)可以获得最佳的性能。</p><h2 id="8-实践中的一些经验"><a href="#8-实践中的一些经验" class="headerlink" title="8 实践中的一些经验"></a>8 实践中的一些经验</h2><h3 id="8-1-使用数据增强"><a href="#8-1-使用数据增强" class="headerlink" title="8.1 使用数据增强"></a>8.1 使用数据增强</h3><p>他们在NLP数据集上展示了这个想法，但这也适用于其他领域。为了更好地指导学生模型训练，使用数据增强会有帮助，特别是当你处理的数据较少的时候。因为我们通常保持学生模型比教师模型小得多，所以我们希望学生模型能够获得更多不同的数据，从而更好地捕捉领域知识。</p><h3 id="8-2-使用未标记的数据"><a href="#8-2-使用未标记的数据" class="headerlink" title="8.2 使用未标记的数据"></a>8.2 使用未标记的数据</h3><blockquote><p>在像 Noisy Student Training 和 SimCLRV2 这样的文章中，作者在训练学生模型时使用了额外的未标记数据。</p></blockquote><p>因此，你将使用你的 teacher 模型来生成未标记数据集上的 ground-truth 分布。这在很大程度上有助于提高模型的可泛化性。<strong>这种方法只有在你所处理的数据集中有未标记数据可用时才可行</strong>。有时，情况可能并非如此(例如，医疗保健)。也有研究数据平衡和数据过滤等技术，以缓解在训练学生模型时合并未标记数据可能出现的问题。</p><h3 id="8-3-在训练教师模型时不要使用标签平滑"><a href="#8-3-在训练教师模型时不要使用标签平滑" class="headerlink" title="8.3 在训练教师模型时不要使用标签平滑"></a>8.3 在训练教师模型时不要使用标签平滑</h3><p><code>标签平滑</code>是一种技术，<strong>用来放松由模型产生的高可信度预测</strong>。它有助于减少过拟合，但不建议在训练教师模型时使用标签平滑，因为无论如何，它的 logits 是按一定的温度缩放的。因此，一般不推荐在知识蒸馏的情况下使用标签平滑。</p><h3 id="8-4-使用更高的温度值"><a href="#8-4-使用更高的温度值" class="headerlink" title="8.4 使用更高的温度值"></a>8.4 使用更高的温度值</h3><p>Hinton 等人建议使用更高的温度值来 soften 教师模型预测的分布，这样软标签可以为学生模型提供更多的信息。这在处理小型数据集时特别有用。对于更大的数据集，信息可以通过训练样本的数量来获得。</p><h2 id="9-代码"><a href="#9-代码" class="headerlink" title="9 代码"></a>9 代码</h2><p>具体的实现代码，可以参考<a href="https://github.com/DushyantaDhyani/kdtf">DushyantaDhyani</a>代码，是比较简洁易懂的。<br>值得注意的是：</p><ol><li><p>其在训练教师模型的时候使用的是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logits = tf.add(tf.matmul(fc1, <span class="variable language_">self</span>.weights[<span class="string">&#x27;out&#x27;</span>]), <span class="variable language_">self</span>.biases[<span class="string">&#x27;out&#x27;</span>]) / <span class="variable language_">self</span>.softmax_temperature</span><br></pre></td></tr></table></figure></li><li><p>在训练学生模型的时候，使用了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.total_loss += tf.square(<span class="variable language_">self</span>.softmax_temperature) * <span class="variable language_">self</span>.loss_op_soft</span><br></pre></td></tr></table></figure><p>并不是单独定义$\alpha$和$\beta$的。</p></li></ol><p><strong>参考文章</strong><br><a href="https://mp.weixin.qq.com/s/IAk61KBKgOBsx9X2zINlfg">神经网络中的蒸馏技术，从Softmax开始说起</a><br><a href="https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk">Distilling Knowledge in Neural Networks</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;目前有很多复杂的模型可以来完成不同的任务，但是部署重量级模型的集成在许多情况下并不总是可行的。有时，你的单个模型可能太大，以至于通常不可能将其部署到资源受限的环境中。这就是为什么我们一直在研究一些模型优化方法 ——量化和剪枝&lt;/p&gt;
&lt;h2 id=&quot;2-Softmax的故事&quot;&gt;&lt;a href=&quot;#2-Softmax的故事&quot; class=&quot;headerlink&quot; title=&quot;2 Softmax的故事&quot;&gt;&lt;/a&gt;2 Softmax的故事&lt;/h2&gt;&lt;p&gt;当处理一个分类问题时，使用 softmax 作为神经网络的最后一个激活单元是非常典型的用法。这是为什么呢？&lt;strong&gt;因为softmax函数接受一组 logit 为输入并输出离散类别上的概率分布&lt;/strong&gt;。比如，手写数字识别中，神经网络可能有较高的置信度认为图像为1。不过，也有轻微的可能性认为图像为7。如果我们只处理像[1,0]这样的独热编码标签(其中1和0分别是图像为1和7的概率)，那么这些信息就无法获得。&lt;/p&gt;</summary>
    
    
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="蒸馏模型" scheme="https://www.xiemingzhao.com/tags/%E8%92%B8%E9%A6%8F%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>从 MMOE 到 PLE 模型</title>
    <link href="https://www.xiemingzhao.com/posts/frommmoetople.html"/>
    <id>https://www.xiemingzhao.com/posts/frommmoetople.html</id>
    <published>2021-06-20T16:00:00.000Z</published>
    <updated>2025-04-04T10:13:21.834Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在当下以深度学习为基调的推荐系统中，传统的单目标优化往往会带来一些不健康的生态指标变化，例如仅优化 CTR 可能会使得用户深层行为下降，往往推出一些博眼球和标题党等内容或商品。所以就催生了利用模型对 CLICK 后的各种深层行为的学习，最常用的便是 CVR（转化率），当然还有 cfr（收藏率）以及 viewtime（浏览时长）等等目标，视具体场景的业务指标而定。</p><p>为了解决上述问题，最原始的方法便是<code>多模型多分数融合</code>，也即对不同目标单独构建模型，线上独立打分进行融合，但是这样带来的问题便是深度行为的样本一般不足，难以使得模型学习的很好，而且独立建模成本高昂。为了进一步提效，目前主流的方法便是统一模型进行不同目标的<code>联合训练</code>，而模型内部不同任务之间存在一定信息共享。如此，</p><ul><li>一方面使得相关任务之间能够互相分享和补充信息，促进各任务学习能力；</li><li>另一方面，梯度在反向传播的时候，能够兼顾多个任务模式，提高模型的泛化能力。</li></ul><span id="more"></span><p>多任务学习模型有很多种，例如阿里的 ESSM 模型，谷歌的 MMOE 模型，包括本文重点介绍的 CGC 和 PLE 模型，来自由腾讯团队发表的获得 RecSys2020 最佳长论文奖得文章：<a href="https://dl.acm.org/doi/abs/10.1145/3383313.3412236">Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations</a>。当然还有很多其他变种的多任务模型，而在接下来得内容将聚焦介绍模型结构得迭代变化。</p><h2 id="2-目标"><a href="#2-目标" class="headerlink" title="2 目标"></a>2 目标</h2><p>实践中上述的理想目标往往会不及预期，主要原因在于, 当任务之间相关性较高的时候，能够一定程度通过信息共享来促进模型的学习效率，但不太相关时会产生<code>负迁移（negative transfer）</code>，即网络表现变差。前面提到谷歌提出的<code>MMOE</code>模型就是为了缓解负迁移现象。但，另一方面，工业实践中往往还面临一个普遍的问题，那就是<code>跷跷板现象（seesaw phenomenon）</code>。也就是在多任务联合训练中，往往部分任务能够相对于独立训练获得提升，但同时伴随着其他个别任务效果下降。</p><p>本人在实际工作中也遇到了上述问题，<code>跷跷板现象</code>是比较明显的结果导向，例如 cfr（收藏率）提升了，但 ctr（点击率）下降了。而对于<code>负迁移</code>问题，比较好验证其触因，可以直接计算样本中不同任务 label 之间的相关性。以博主自己的一个实际工作场景为例：</p><blockquote><p>在某电商瀑布流的推荐中，样本中核心 label 有 ctr（点击）、ccr（查看细分sku）、cfr(收藏)、cvr（下单）。当然不仅限于这些，对于场景核心 label 的选取主要取决于业务目标和 label 的覆盖度。部分同学在实际中可能会认为行为之间应该具有较强的相关性，然而实际上结果可能大相径庭。如下表所示是实际样本的一个统计结果（大约一天几亿量级的数据），可以发现在渗透漏斗链路上，离 ctr 越远的行为相关性越低。</p></blockquote><p>本文介绍的从 MMOE 迭代到 PLE 的模型，其提出者目的正是为了缓解上述问题。PLE 模型也是被部署在了腾讯的视频推荐系统中，其线上多目标<code>分数融合</code>方式如下：</p><script type="math/tex; mode=display">\begin{array}{r}score = pVTR^{w_{VTR}} \times pVCR^{w_{VCR}} \times pSHR^{w_{SHR}} \times \dots \times pCMR^{w_{CMR}} \times f(video\_len)\end{array}</script><p>其中，公式中每一项右上角的 $w$ 都是权重超参数。video_len 表示视频的原始时长，其有一个映射函数 $f$，是一个 non-linear 函数，可取 sigmoid 或者 log 函数。模型结构如下所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople0.png" alt="mmoetople0"></p><p>在这里，<code>VCR (View Completion Rate)</code>和<code>VTR (View-Through-Rate)</code>是最重要的2个指标。VCR 是指视频完成度，例如1min的视频看了0.5min，便有VCR=0.5。以此作为 Label 可以构建一个回归问题，以 MSE 作为评估指标。VTR 则是指是否是一次有效观看，这一般可以构建成一个二分类模型，AUC 作为评估目标。</p><p>值得注意的是，此Label的打标签一般因业务场景不同而有所区别:</p><ul><li>需要通过列表主动点击到落地详情页的时候，一般 VTR 对应的 Label 就是用户是否主动点击；</li><li>如果是单列自动播放的视频流的时候，就会存在视频的默认播放问题，需要进行一定的阈值截断来进行 Label 的打标签；</li></ul><p>如上所述，实际上两个任务的关系很复杂。以腾讯实际场景为例，VTR是播放动作和VCR的耦合结果，因为在有wifi下，部分场景有自动播放机制，播放率相对就较高，就需要设定有效播放时长的阈值。没有自动播放机制时候，相对更为简单，且播放率会较低。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople1.png" alt="mmoetople1"></p><p>如上图所示，是其团队对比了一些主流 MTL 模型在 VCR 和 VTR 任务上相对单任务模型的离线对比结果。从图中可以看到，大多 MTL 模型都是一个任务好于单任务模型另一个则较差，这便是前文提到的<code>跷跷板现象（seesaw phenomenon）</code>。以<code>MMOE</code>为例，其在 VTR 上有一定收益，但是在 VCR 上几乎无收益。核心原因在于，其 Experts 是被所有任务共享，会有噪声，且他们之间没有交互，联合训练有折扣。</p><p>而该团队提出的 PLE 模型在实验对比中最好，其线上实验也取得了2.23%的view-count和1.84%的阅读时长提升效果。我们可以先将其<strong>核心优化点</strong>总结成如下：</p><ul><li>解耦 Experts 网络，改进了模型结构；</li><li>优化了多目标 loss 融合的方法，提高了训练的效率；</li></ul><h2 id="3-MMOE"><a href="#3-MMOE" class="headerlink" title="3 MMOE"></a>3 MMOE</h2><p>前文提到很多与<code>MMOE</code>(Multi-gate Mixture-of-Experts)模型的对比，咱们先来回顾一下该模型的结构。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople2.png" alt="mmoetople2"></p><p>如上图所示，该模型实际上是在多个 Expert 基础上，对每一个任务的 Tower 都构建一个 Gate 网络。整个模型可以用数理表达式：</p><script type="math/tex; mode=display">\begin{array}{l}f^k(x)=\sum_{i=1}^n g^k(x)_{i} f_{i}(x)\\g^k(x)=Softmax(W_{gk}x)\end{array}</script><p>其中，$g^k$ 表示第 k 个任务中的用来控制 experts 结果的门控网络。</p><p><strong>该网络的目的是使得每个 Task 通过自己独立的 Gate 网络来学习不同的 Experts 网络的组合模式</strong>。模型的 loss 一般是各个任务的 loss 加和，如果其中某个任务的 loss 占比过高，则梯度主要沿着其下降的方向更新，有可能降低其他任务的精度。</p><h2 id="4-CGC"><a href="#4-CGC" class="headerlink" title="4 CGC"></a>4 CGC</h2><p>这里介绍的<code>CGC</code>（Customized Gate Control）模型是一种单层多任务网络结构，它是本文介绍的最终版本PLE模型的简单版本或者说其组成部分。下面展示的是其网络结构：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople3.png" alt="mmoetople3"></p><p>如上图所示，各模块结构的含义如下：</p><ul><li><code>shared experts</code>：共享的专家网络组，即上图 Experts Shared 中的$E_{S,1}$等；</li><li><code>task-specific expert</code>：各个任务专享的专家网络组，例如 Experts A；</li><li><code>task-specific tower</code>：各个任务的输出塔，例如 Tower A；</li><li><code>task-specific Gating</code>：各个任务的门控网络，例如 Tower A的入口与Experts的连接处；</li></ul><p>从上述结构可以看得出来，<code>shared experts</code> 会与所有任务链接，学习共享信息，而 <code>task-specific expert</code> 只会受到自己任务的影响，<code>task-specific tower</code> 则是由 <code>task-specificGating</code> 将对应的 <code>task-specific expert</code> 和 <code>shared experts</code> 组合后作为其输入的。这一过程可以表述称如下数理公式：</p><script type="math/tex; mode=display">\begin{array}{l}y^k(x)=t^k(g^k(x))\\g^k(x)=w^k(x)S^k(x)\\w^k(x)=Softmax(W^k_g x)\\S^k(x)=[E^T_{(k,1)},E^T_{(k,2)},\dots ,E^T_{(k,m_k)},E^T_{(s,1)},E^T_{(s,2)},\dots ,E^T_{(s,m_s)}]\end{array}</script><p>其中，公式(1)表示任务k的输出结果，公式(3)表示门控网络的结构，公式(2)则表示基于门控网络将公式(4)中的专家网络组融合的过程。可以发现其与MMOE最大的区别便是不同Task之间除了共享的 <code>Shared Experts</code> 网络组之外还有各自独享的 <code>Task-specific Experts</code>，这也是接下来的 PLE 模型的核心组成模块。</p><h2 id="5-PLE"><a href="#5-PLE" class="headerlink" title="5 PLE"></a>5 PLE</h2><p>基于 <code>CGC</code> 的结构，<code>PLE</code>（Progressive Layered Extraction）则是一个升级版本的结构，它扩增了 Experts 之间的交互，结构如下所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople4.png" alt="mmoetople4"></p><p>可以清晰的看到，其与CGC不同的是增加了多级的 <code>Extraction Networks</code>，而每一级的<code>Extraction Networks</code> 基本与CGC一致，旨在提取更高级别的共享信息。可以发现，每层 <code>Shared Experts</code> 吸收了下层的所有网络结构信息，而任务独享的 <code>Task-specific Experts</code> 则仅从其自己对应模块和<code>Shared Experts</code>中获取共享信息。整个过程可以简化成：</p><script type="math/tex; mode=display">y^k(X)=t^k(g^{k,N}(x))</script><h2 id="6-MTL-类型总结"><a href="#6-MTL-类型总结" class="headerlink" title="6 MTL 类型总结"></a>6 MTL 类型总结</h2><h3 id="6-1-Single-Level-MTL"><a href="#6-1-Single-Level-MTL" class="headerlink" title="6.1 Single-Level MTL"></a>6.1 Single-Level MTL</h3><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople5.png" alt="mmoetople5"></p><p>如上图所示，是5个经典的Single-Level MTL模型：</p><ol><li><p><code>Hard Parameter Sharing</code>：最常见的MTL模型，底层的模块是share的，然后共享层的输出分别进入到每个Task的Tower中。当两个Task相关性较高时，用这种结构效果一般不错，但任务相关性不高时，会存在负迁移现象，导致效果不理想。</p></li><li><p><code>Asymmetry Sharing</code>（不对称共享）：不同Task的底层模块有各自对应的输出，但其中部分任务的输出会被其他Task所使用，而部分任务则使用自己独有的输出。交叉共享的部分需要认为定义，变数较多。</p></li><li><p><code>Customized Sharing</code>（自定义共享）：不同Task的底层模块不仅有各自独立的输出，还有共享的输出。2和3这两种结构同样是论文提出的，但相对不重点。</p></li><li><p><code>MMOE</code>：是大家比较熟悉的经典 MTL。底层包含多个 Expert，然后基于门控机制，不同任务会对不同 Expert 的输出进行过滤。</p></li><li><p><code>CGC</code>：这就是本文重点介绍的一个，与 MMOE 的区别就是每个 Task 有自己独享的 Experts。</p></li></ol><h3 id="6-2-Multi-Level-MTL"><a href="#6-2-Multi-Level-MTL" class="headerlink" title="6.2 Multi-Level MTL"></a>6.2 Multi-Level MTL</h3><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople6.png" alt="mmoetople6"></p><p>如上图所示，是4个经典的 <code>Single-Level MTL</code> 模型：</p><ol><li><p><code>Cross-Stitch Network</code>（”十字绣”网络）：出自论文<a href="https://arxiv.org/pdf/1604.03539.pdf">《Cross-stitch Networks for Multi-task Learning》</a>。</p></li><li><p><code>Sluice Network</code>（水闸网络）：出自论文《<a href="https://arxiv.org/pdf/1705.08142v1.pdf">Sluice networks: Learning what to share between loosely related tasks</a>》.</p></li><li><p><code>ML-MMOE</code>：前文已经有介绍。</p></li><li><p><code>PLE</code>：这便是本文重点介绍的对象。</p></li></ol><h2 id="7-MTL-的-Loss-优化"><a href="#7-MTL-的-Loss-优化" class="headerlink" title="7 MTL 的 Loss 优化"></a>7 MTL 的 Loss 优化</h2><p>在传统的MTL任务中，一般设定各个任务样本空间一致，然后训练的时候将各个任务的 loss 加权求和作为模型优化的总 loss 即可：</p><script type="math/tex; mode=display">L(\theta_1, \dots , \theta_K, \theta_s)=\sum_{k=1}^K w_k L_k(\theta_k, \theta_s)</script><p>但实际上，<strong>不同Task的样本空间可能是不一致的</strong>。如下图所示。例如，假设 item 的 share 按钮在详情页，那么用户必须先 click 后，才能进行  share的动作，所以 share 的样本应该是 click 的一个子集，而不能粗暴的将没有 click（自然没有share）的样本也作为 share 的负样本，如此是有偏的。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoetople7.png" alt="mmoetople7"></p><p>故，最终PLE在训练的时候 loss 构建如下：</p><script type="math/tex; mode=display">L_k(\theta_k,\theta_s)=\frac{1}{\sum_i \delta_k^i} \sum_i \delta_k^i loss_k(\hat y_k^i (\theta_k, \theta_s),y_k^i)</script><p>其中，$\delta_k^i$是一个示性变量，表示第i个样本是否属于第k个 Task 的样本空间，实际上起到了样本  loss入场的筛选过滤作用。</p><p>除此之外，该团队还从 <code>Multi-task learning</code> 对 <code>loss weight</code> 敏感的角度出发，为了兼顾静态 weight 不如动态 weight 有效，并且不用像阿里提出的帕累托最优这种复杂的方式来优化。他们最终采用人共设置初始 loss weight，但是在不同的 train step 会进行 update，具体方式如下所示：</p><script type="math/tex; mode=display">w_k^{(t)}=w_{k,0} \times \gamma_k^t</script><p>其中，$w_{k,0}$是人工设置的初始 loss wight，$\gamma_k$也是权重衰减的超参数，$t$则是 training step。</p><p>此优化确实较为合理，笔者在实际中也取得了效果。从数理角度理解，拆分样本空间后，预测的是每个阶段行为的条件概率，而不是联合改了，相对模式更容易学习。但是，<strong>此优化不仅限于PLE模型，实际上对任何一个MTL模型都适配的。</strong></p><h2 id="8-Code"><a href="#8-Code" class="headerlink" title="8 Code"></a>8 Code</h2><p>由于本文重点讲解的是 PLE 模型，且 CGC 模型也是 PLE 的一个组成部分，所以 MMOE 和 CGC 的 code 在此就不提，咱们重点介绍一下 PLE 模型的结构模块代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .multiTaskModel <span class="keyword">import</span> multiTaskModel</span><br><span class="line"><span class="keyword">from</span> modules.experts <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gate</span>(<span class="params"><span class="built_in">input</span>, unit, name = <span class="string">&quot;gate&quot;</span></span>):</span><br><span class="line">    net = tf.layers.dense(inputs=<span class="built_in">input</span>, units=unit, name=<span class="string">&#x27;%s/dense&#x27;</span> % name)</span><br><span class="line">    gate = tf.nn.softmax(net, axis=<span class="number">1</span>, name=<span class="string">&#x27;%s/softmax&#x27;</span> % name)</span><br><span class="line">    <span class="keyword">return</span> gate</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pleLayer</span>(<span class="params">input_list, num_expert, num_task, dnn_dims, is_training, name = <span class="string">&quot;pleLayer&quot;</span></span>):</span><br><span class="line">    expert_feat_list = []</span><br><span class="line">    <span class="comment"># num_task + 1 experts</span></span><br><span class="line">    <span class="keyword">for</span> label_id <span class="keyword">in</span> <span class="built_in">range</span>(num_task + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> expert_id <span class="keyword">in</span> <span class="built_in">range</span>(num_expert):</span><br><span class="line">            <span class="comment"># buile expert</span></span><br><span class="line">            expert_dnn = dnn(input_list[label_id], dnn_dims, is_training=is_training, usebn=<span class="literal">True</span>, activation=<span class="string">&quot;tf.nn.leaky_relu&quot;</span>,</span><br><span class="line">                             name=<span class="string">&#x27;%s/label%d/dnn%d&#x27;</span> % (name, label_id, expert_id))</span><br><span class="line">            expert_feat_list.append(expert_dnn)</span><br><span class="line"></span><br><span class="line">    experts_output_list = []</span><br><span class="line">    <span class="keyword">for</span> task_id <span class="keyword">in</span> <span class="built_in">range</span>(num_task):</span><br><span class="line">        <span class="comment"># build gate, unit equals task &amp; share expert&#x27;s nums</span></span><br><span class="line">        gate_feat = gate(<span class="built_in">input</span> = input_list[task_id], unit = num_expert * <span class="number">2</span>, name = <span class="string">&#x27;%s/gate%d&#x27;</span> % (name,task_id))</span><br><span class="line">        gate_feat = tf.expand_dims(gate_feat, -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># staking，task &amp; share experts</span></span><br><span class="line">        experts_feat = tf.stack(expert_feat_list[task_id*num_expert:(task_id+<span class="number">1</span>)*num_expert] +</span><br><span class="line">                                expert_feat_list[-num_expert:], axis=<span class="number">1</span>, name=<span class="string">&quot;%s/feat&quot;</span> % name)</span><br><span class="line">        <span class="comment"># attention</span></span><br><span class="line">        task_input = tf.multiply(experts_feat, gate_feat, name = <span class="string">&#x27;%s/task%d/multiply&#x27;</span> % (name,task_id))</span><br><span class="line">        <span class="comment"># reduce dim for tower input</span></span><br><span class="line">        task_input = tf.reduce_sum(task_input, axis=<span class="number">1</span>, name = <span class="string">&#x27;%s/task%d/output&#x27;</span> % (name,task_id))</span><br><span class="line">        experts_output_list.append(task_input)</span><br><span class="line">    <span class="comment"># share expert gate</span></span><br><span class="line">    gate_feat = gate(<span class="built_in">input</span>=input_list[num_task], unit=num_expert * (num_task+<span class="number">1</span>), name=<span class="string">&#x27;%s/gateshare&#x27;</span> % (name))</span><br><span class="line">    gate_feat = tf.expand_dims(gate_feat, -<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># staking， all experts</span></span><br><span class="line">    experts_feat = tf.stack(expert_feat_list, axis=<span class="number">1</span>, name=<span class="string">&quot;%s/featshare&quot;</span> % name)</span><br><span class="line">    <span class="comment"># attention</span></span><br><span class="line">    task_input = tf.multiply(experts_feat, gate_feat, name=<span class="string">&#x27;%s/taskshare/multiply&#x27;</span> % (name))</span><br><span class="line">    <span class="comment"># reduce dim for tower input</span></span><br><span class="line">    task_input = tf.reduce_sum(task_input, axis=<span class="number">1</span>, name=<span class="string">&#x27;%s/taskshare/output&#x27;</span> % (name))</span><br><span class="line">    experts_output_list.append(task_input)</span><br><span class="line">    <span class="keyword">return</span> experts_output_list    </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ple</span>(<span class="title class_ inherited__">multiTaskModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params</span>):</span><br><span class="line">        <span class="variable language_">self</span>.expertNum = <span class="number">4</span></span><br><span class="line">        <span class="variable language_">self</span>.expertDims = [<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>]</span><br><span class="line">        <span class="variable language_">self</span>.extractLevel = <span class="number">3</span></span><br><span class="line">        <span class="built_in">super</span>(ple, <span class="variable language_">self</span>).__init__(params)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_graph</span>(<span class="params">self, features, is_training, params</span>):</span><br><span class="line">        dnn_feats = params[<span class="string">&#x27;feature_columns&#x27;</span>][<span class="string">&#x27;dnn_feats&#x27;</span>]</span><br><span class="line">        <span class="built_in">input</span> = tf.feature_column.input_layer(features, dnn_feats)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># task_input_list[-1] is share experts input</span></span><br><span class="line">        task_input_list = [<span class="built_in">input</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.lable_size + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> level <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.extractLevel):</span><br><span class="line">            task_input_list = pleLayer(task_input_list, <span class="variable language_">self</span>.expertNum, <span class="variable language_">self</span>.lable_size, dnn_dims = <span class="variable language_">self</span>.expertDims,</span><br><span class="line">                                       is_training=is_training, name = <span class="string">&quot;pleLayer%d&quot;</span> % level)</span><br><span class="line"></span><br><span class="line">        tower_outputs = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.lable_size):</span><br><span class="line">            tower_dnn = dnn(task_input_list[i], <span class="variable language_">self</span>.dnnDims, name=<span class="string">&quot;tower_%d&quot;</span> % i, is_training=is_training)</span><br><span class="line">            tower_output = tf.layers.dense(inputs=tower_dnn, units=<span class="number">1</span>, name=<span class="string">&#x27;tower_output_%d&#x27;</span> % i,</span><br><span class="line">                                           activation=tf.nn.sigmoid)</span><br><span class="line">            tower_outputs[<span class="string">&#x27;tower_output_%d&#x27;</span> % i] = tower_output</span><br><span class="line">        <span class="variable language_">self</span>.ctr_pred = tf.reshape(tower_outputs[<span class="string">&quot;tower_output_0&quot;</span>], [-<span class="number">1</span>], name=<span class="string">&quot;ctr&quot;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.cvr_pred = tf.reshape(tower_outputs[<span class="string">&quot;tower_output_1&quot;</span>], [-<span class="number">1</span>], name=<span class="string">&quot;cvr&quot;</span>)</span><br></pre></td></tr></table></figure><br>代码整体没有什么难度，基本上就按照模型结构图来实现即可。唯一需要注意便是关键聚合层的维度对齐，支持灵活控制模型各个 Experts 模块的结构调整即可。</p><p><strong>参考文献</strong><br><a href="https://mp.weixin.qq.com/s?__biz=MzU2ODA0NTUyOQ==&amp;mid=2247490093&amp;idx=1&amp;sn=58cec36693c33742d7f5673246b0813f&amp;chksm=fc92a09bcbe5298db648d48fefc90e173bdb13890c600538b0152bd7bd58971da02724e063e0&amp;scene=126&amp;sessionid=1605088596&amp;key=301d1d633ed7664ead5e72db2696e63bc0cc9f81eba3c1fa7ce072479ea99f43857c7776607b03640f45fdd4c6a0989118dcd674dfc926a6fc2baa36ed8a60dde9a196fdc04f8cd521d08bfac5c0f97b344563ee9cac3cd782d65fef03e0f14c9af2bf7c11622ea04661600b67c4f51f5aece7889b00f144c7a177883642d2f4&amp;ascene=1&amp;uin=Mjg1NTU5MTQxMA==&amp;devicetype=Windows+10+x64&amp;version=6300002f&amp;lang=zh_CN&amp;exportkey=A6HrIa8MEBjQ0POQs4ps3Pk=&amp;pass_ticket=8hNub+Fu4yLIlzlFzkmkkQMUkX4moojyuksiXcSdcWti8q5+iG2QZTCpgM1wGGdz&amp;wx_header=0">腾讯 at RecSys2020最佳长论文 - 多任务学习模型PLE</a><br><a href="https://zhuanlan.zhihu.com/p/52566508">深度神经网络中的多任务学习汇总</a><br><a href="https://zhuanlan.zhihu.com/p/354055223">【论文笔记日更10】腾讯PLE模型（RecSys 2020最佳论文）</a><br><a href="https://mp.weixin.qq.com/s/1ZZvEfQUDQat6nFnF67GcQ">多目标优化（三）recsys2020最佳长论文奖PLE</a><br><a href="https://github.com/ShaoQiBNU/Google_MTL">Google多任务模型</a><br><a href="https://zhuanlan.zhihu.com/p/291406172">多目标学习在推荐系统的应用(MMOE/ESMM/PLE)</a><br><a href="https://lumingdong.cn/multi-task-learning-in-recommendation-system.html">推荐系统中的多任务学习</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在当下以深度学习为基调的推荐系统中，传统的单目标优化往往会带来一些不健康的生态指标变化，例如仅优化 CTR 可能会使得用户深层行为下降，往往推出一些博眼球和标题党等内容或商品。所以就催生了利用模型对 CLICK 后的各种深层行为的学习，最常用的便是 CVR（转化率），当然还有 cfr（收藏率）以及 viewtime（浏览时长）等等目标，视具体场景的业务指标而定。&lt;/p&gt;
&lt;p&gt;为了解决上述问题，最原始的方法便是&lt;code&gt;多模型多分数融合&lt;/code&gt;，也即对不同目标单独构建模型，线上独立打分进行融合，但是这样带来的问题便是深度行为的样本一般不足，难以使得模型学习的很好，而且独立建模成本高昂。为了进一步提效，目前主流的方法便是统一模型进行不同目标的&lt;code&gt;联合训练&lt;/code&gt;，而模型内部不同任务之间存在一定信息共享。如此，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一方面使得相关任务之间能够互相分享和补充信息，促进各任务学习能力；&lt;/li&gt;
&lt;li&gt;另一方面，梯度在反向传播的时候，能够兼顾多个任务模式，提高模型的泛化能力。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="精排模型" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="精排" scheme="https://www.xiemingzhao.com/tags/%E7%B2%BE%E6%8E%92/"/>
    
    <category term="PLE" scheme="https://www.xiemingzhao.com/tags/PLE/"/>
    
    <category term="CGC" scheme="https://www.xiemingzhao.com/tags/CGC/"/>
    
    <category term="MTL" scheme="https://www.xiemingzhao.com/tags/MTL/"/>
    
  </entry>
  
  <entry>
    <title>MMOE 模型解析</title>
    <link href="https://www.xiemingzhao.com/posts/mmoemodel.html"/>
    <id>https://www.xiemingzhao.com/posts/mmoemodel.html</id>
    <published>2021-06-05T16:00:00.000Z</published>
    <updated>2025-04-02T16:07:31.268Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>本文介绍的<code>MMOE</code>模型全称是<code>Multi-gate Mixture-of-Experts</code>，来自 Google 在 2018 年 KDD 上发表的论文<a href="https://dl.acm.org/doi/pdf/10.1145/3219819.3220007">Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</a>。核心目标是改善多任务学习在任务之间不太相关的时候效果不好的问题。下面有两个相关学习资源：</p><ul><li>视频简介的<a href="https://www.youtube.com/watch?v=Dweg47Tswxw">youtube地址</a>;</li><li>一个用keras框架实现的<a href="https://github.com/drawbridge/keras-mmoe">开源地址</a>。</li></ul><h2 id="2-动机"><a href="#2-动机" class="headerlink" title="2 动机"></a>2 动机</h2><p>多任务学习一般是为了在训练多个相关任务的时候可以使得它们之间能够共享信息，提高学习效率和模型的泛化能力。但实际应用中往往难以如此理想化，因为<strong>任务之间往往相关性不够强</strong>，这时候就容易产生以下两个问题：</p><blockquote><p><code>负迁移（negative transfer）</code>：即网络表现变差<br><code>跷跷板现象（seesaw phenomenon）</code>：也就是个别任务相对于独立训练获得提升，但其他任务效果下降。</p></blockquote><span id="more"></span><p>论文团队在实际中也做了这方面的实验，它们仿真了不同相关性的数据集，然后在他们上面测试模型的训练效果，如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoe0.png" alt="mmoe0"></p><p>上图中的 <code>correlation</code> 是 <code>Pearson相关性系数</code>，从中可以看出相关性越高 loss 收敛的速度越快，值越小，说明效果越好。</p><p>在实际中，大多数任务也不足够相关，例如笔者自身的经验，在某电商瀑布流推荐场景，其中点击与查看价格相关性尚可（约0.48），但是收藏乃至成交等越深的行为与其相关性就越差了（&lt;0.1）。有时候也不能够直接判断任务之间的相关性，但无论如何，解决相关性不高的多任务学习本身就是一个很有实际意义的工作。</p><h2 id="3-模MMOE型"><a href="#3-模MMOE型" class="headerlink" title="3 模MMOE型"></a>3 模MMOE型</h2><p>在<code>MMOE</code>模型提出来之前，也有一些相关的探索，论文作者也提到他们与<code>MMOE</code>之间的关系。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoe1.png" alt="mmoe1"></p><p>入上图所示，(a) 和 (b)是两个较为基础的<code>shared embedding</code>模型。</p><p>图 (a) 表示的是<code>Shared-Bottom model</code>，input 层之后进入模型 shared 的 bottom 模块，一般也就是一个 DNN 结构。之后，分别进入每个任务自己的 Tower，例如图中的 Tower A 和 Tower B，得到最终每个 Task 的 output。整个过程可以简单的用下述公式来表述：</p><script type="math/tex; mode=display">y^k = h^k (f(x))</script><p>其中，</p><ul><li>k 表示第几个目标 Task;</li><li>h 表示每个 Task 各自的 Tower 网络;</li><li>f 则表示地步共享的 bootom 网络。</li></ul><p>图 (b) 表示的是<code>MOE模型</code>，其与（a）比较显著的区别有2处：</p><ul><li>input 层后共享的 bootom 结构改成了多个 Experts 网络，图中是3个，并且各自参数不共享；</li><li>input 层出了进入共享的 Experts 网络外，还用来生成 Task 各自的 Gate 网络，作为 Experts 进入每个 Task Tower 网络的门控权重。</li></ul><p>可以发现，MOE 通过 input 生成 Gate 是为了赋予每个 Experts 网络进入 Task Tower 的权重，也是一种 <code>Attention</code> 的思想。其模型结构也以简单的总结如下公式：</p><script type="math/tex; mode=display">y^k = h^k(\sum_{i=1}^n g_i f_i(x))</script><script type="math/tex; mode=display">g = Softmax(W_{g}x)</script><p>其中，g 便是 Gate网络，i 表示第 i 个 Experts 网络。可以发现在 Gate 网络对 Experts 的输出进行加权求和之后，直接进入每个 Task 的 Tower 网络，所以每个 Tower 的 input 是一样的。</p><p>图 (b) 表示的是<code>MMOE模型</code>，也是论文作者提出的结构。其与 <code>MOE</code> 最大的区别就是：</p><blockquote><p>对于每个 Task 都有用自己独享的 Gate 网络结构。</p></blockquote><p>如此，每个 Task 可以根据任务需要，利用自己的 Gate 网络计算每个 Experts 进入 Tower 的权重，Gate 部分可简述为下列公式：</p><script type="math/tex; mode=display">Gate^k = Softmax(W_{gk}x)</script><p>在实际中，作者实验也证明相关性较高的任务 MMOE 其实效果不明显，与 MOE 相差无异。<strong>但是在相关性较差的数据上，效果就与MOE拉开一定的差异</strong>，如下图所示。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/mmoe2.png" alt="mmoe2"></p><p>不过这也和数据集和操作过程有一定关系，笔者在实际工作中发现<strong>两个相关问题</strong>：</p><ul><li>在大数据集且控制其他变量条件下，MMOE 往往很难与一般的 Shared-bootom 网络结构显著的拉开差距；</li><li>在多场景建模中往往会有一定的的价值拟合不同空间的样本和目标；</li><li>还有一种<code>假提升</code>情况，也就是模型收敛速度较快，但是最终水位相差无几。<br>（举例，例如在实际新模型回刷数据中，将 base model 和 MMOE 都从某一天开始刷数据，会发现在 AUC 或者 loss 等指标上，MMOE 很快并且连续一段时间始终好于 base model，然而随着数据的积累，这种 diff 逐渐较小直至最终极其微小，这一般就是新模型收敛速度快的原因，会给算法工程师一个很大幅度的<code>假提升</code>现象。）</li></ul><h2 id="4-Code"><a href="#4-Code" class="headerlink" title="4 Code"></a>4 Code</h2><p>MMOE 这里有两个 coding 的矩阵提速的点：</p><ul><li>在构建Shared-Experts网络结构的时候，Expert 网络的个数可以作为一个维度，即直接生成一个<code>三维tensor</code>：$input_dim \times expert_unit \times experts_num$</li><li>Gate 网络也可以将 Task 的个数作为其一个维度来一次性生成一个三维 tensor:$input_dim \times experts_num \times tasks_num$</li></ul><p>以上技巧在前文提到的keras框架实现的<a href="https://github.com/drawbridge/keras-mmoe">开源地址</a>中有所体现。这里展示一个笔者自己按照图结构一个一个模块写出来的版本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> .multiTaskModel <span class="keyword">import</span> multiTaskModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gate</span>(<span class="params"><span class="built_in">input</span>, unit, name = <span class="string">&quot;gate&quot;</span></span>):</span><br><span class="line">    net = tf.layers.dense(inputs=<span class="built_in">input</span>, units=unit, name=<span class="string">&#x27;%s/dense&#x27;</span> % name)</span><br><span class="line">    gate = tf.nn.softmax(net, axis=<span class="number">1</span>, name=<span class="string">&#x27;%s/softmax&#x27;</span> % name)</span><br><span class="line">    <span class="keyword">return</span> gate</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">experts</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_expert, num_task, dnn_dims, name = <span class="string">&quot;experts&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.num_expert = num_expert</span><br><span class="line">        <span class="variable language_">self</span>.num_task = num_task</span><br><span class="line">        <span class="variable language_">self</span>.dnn_dims = dnn_dims</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, <span class="built_in">input</span>, is_training</span>):</span><br><span class="line">        expert_feat_list = []</span><br><span class="line">        <span class="keyword">for</span> expert_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_expert):</span><br><span class="line">            <span class="comment"># buile expert</span></span><br><span class="line">            expert_dnn = dnn(<span class="built_in">input</span>, <span class="variable language_">self</span>.dnn_dims, is_training=is_training, usebn=<span class="literal">True</span>, activation=<span class="string">&quot;tf.nn.leaky_relu&quot;</span>,</span><br><span class="line">                             name=<span class="string">&#x27;%s/dnn%d&#x27;</span> % (<span class="variable language_">self</span>.name, expert_id))</span><br><span class="line">            expert_feat_list.append(expert_dnn)</span><br><span class="line">        <span class="comment"># staking，Bxnum_expertxdim not Bx(num_expertxdim)</span></span><br><span class="line">        experts_feat = tf.stack(expert_feat_list, axis=<span class="number">1</span>, name=<span class="string">&quot;%s/feat&quot;</span> % <span class="variable language_">self</span>.name)</span><br><span class="line"></span><br><span class="line">        experts_output_list = []</span><br><span class="line">        <span class="keyword">for</span> task_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_task):</span><br><span class="line">            <span class="comment"># build gate</span></span><br><span class="line">            gate_feat = gate(<span class="built_in">input</span>=<span class="built_in">input</span>, unit=<span class="variable language_">self</span>.num_expert, name=<span class="string">&#x27;%s/gate%d&#x27;</span> % (<span class="variable language_">self</span>.name, task_id))</span><br><span class="line">            gate_feat = tf.expand_dims(gate_feat, -<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># attention</span></span><br><span class="line">            task_input = tf.multiply(experts_feat, gate_feat, name=<span class="string">&#x27;%s/task%d/multiply&#x27;</span> % (<span class="variable language_">self</span>.name, task_id))</span><br><span class="line">            <span class="comment"># reduce dim for tower input</span></span><br><span class="line">            task_input = tf.reduce_sum(task_input, axis=<span class="number">1</span>, name=<span class="string">&#x27;%s/task%d/output&#x27;</span> % (<span class="variable language_">self</span>.name, task_id))</span><br><span class="line">            experts_output_list.append(task_input)</span><br><span class="line">        <span class="keyword">return</span> experts_output_list</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mmoe</span>(<span class="title class_ inherited__">multiTaskModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params</span>):</span><br><span class="line">        <span class="variable language_">self</span>.expertNum = <span class="number">3</span></span><br><span class="line">        <span class="variable language_">self</span>.expertDims = [<span class="number">512</span>,<span class="number">256</span>,<span class="number">128</span>]</span><br><span class="line">        <span class="built_in">super</span>(mmoe, <span class="variable language_">self</span>).__init__(params)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_graph</span>(<span class="params">self, features, mode, params</span>):</span><br><span class="line">        is_training = (mode == tf.estimator.ModeKeys.TRAIN)</span><br><span class="line">        user_feats = params[<span class="string">&#x27;feature_columns&#x27;</span>][<span class="string">&#x27;user_feats&#x27;</span>]</span><br><span class="line">        item_feats = params[<span class="string">&#x27;feature_columns&#x27;</span>][<span class="string">&#x27;item_feats&#x27;</span>]</span><br><span class="line">        partitioner = partitioned_variables.min_max_variable_partitioner(max_partitions=<span class="variable language_">self</span>.ps_num,</span><br><span class="line">                                                                         min_slice_size=<span class="number">8</span> * <span class="number">1024</span> * <span class="number">1024</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;embedding_scope&quot;</span>, values=features.values(), partitioner=partitioner) <span class="keyword">as</span> scope:</span><br><span class="line">            user_inputs = tf.feature_column.input_layer(features, user_feats)</span><br><span class="line">            item_inputs = tf.feature_column.input_layer(features, item_feats)</span><br><span class="line">            tf.logging.info(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;user_inputs shape is %s&quot;</span> % <span class="built_in">str</span>(user_inputs.shape) + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line">            tf.logging.info(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;item_inputs shape is %s&quot;</span> % <span class="built_in">str</span>(item_inputs.shape) + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.task_type != [<span class="string">&quot;predict&quot;</span>] <span class="keyword">and</span> mode == tf.estimator.ModeKeys.PREDICT:</span><br><span class="line">                batchSize = tf.reshape(features[<span class="string">&quot;batchSize&quot;</span>], [])</span><br><span class="line">                user_inputs = tf.tile(user_inputs, [batchSize, <span class="number">1</span>])</span><br><span class="line">            embed_inputs = tf.concat([user_inputs, item_inputs], axis=<span class="number">1</span>)</span><br><span class="line">            tf.logging.info(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;embed_inputs shape is %s&quot;</span> % <span class="built_in">str</span>(embed_inputs.shape) + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        nn_partitioner = partitioned_variables.min_max_variable_partitioner(max_partitions=<span class="variable language_">self</span>.ps_num,</span><br><span class="line">                                                                            min_slice_size=<span class="number">1</span> * <span class="number">64</span> * <span class="number">1024</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;nn_scope&quot;</span>, partitioner=nn_partitioner) <span class="keyword">as</span> nn_scope:</span><br><span class="line">            expertsNet = experts(<span class="variable language_">self</span>.expertNum, <span class="variable language_">self</span>.lable_size, dnn_dims = <span class="variable language_">self</span>.expertDims)</span><br><span class="line">            task_input_list = expertsNet(embed_inputs, is_training=is_training)</span><br><span class="line">            tower_outputs = &#123;&#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.lable_size):</span><br><span class="line">                tower_dnn = dnn(task_input_list[i], <span class="variable language_">self</span>.dnnDims, name=<span class="string">&quot;tower_%d&quot;</span> % i, is_training=is_training)</span><br><span class="line">                tower_output = tf.layers.dense(inputs=tower_dnn, units=<span class="number">1</span>, name=<span class="string">&#x27;tower_output_%d&#x27;</span> % i,</span><br><span class="line">                                               activation=tf.nn.sigmoid)</span><br><span class="line">                tower_outputs[<span class="string">&#x27;tower_output_%d&#x27;</span> % i] = tower_output</span><br><span class="line">            <span class="variable language_">self</span>.ctr_pred = tf.reshape(tower_outputs[<span class="string">&quot;tower_output_0&quot;</span>], [-<span class="number">1</span>], name = <span class="string">&quot;ctr&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.cvr_pred = tf.reshape(tower_outputs[<span class="string">&quot;tower_output_1&quot;</span>], [-<span class="number">1</span>], name = <span class="string">&quot;cvr&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>参考文献</strong><br><a href="https://zhuanlan.zhihu.com/p/145288000">多任务学习之MMOE模型</a><br><a href="https://mp.weixin.qq.com/s/EuJ2BOdMqR0zyRtUcdn0kA">多任务学习模型详解：Multi-gate Mixture-of-Experts（MMoE ，Google，KDD2018）</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;本文介绍的&lt;code&gt;MMOE&lt;/code&gt;模型全称是&lt;code&gt;Multi-gate Mixture-of-Experts&lt;/code&gt;，来自 Google 在 2018 年 KDD 上发表的论文&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3219819.3220007&quot;&gt;Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts&lt;/a&gt;。核心目标是改善多任务学习在任务之间不太相关的时候效果不好的问题。下面有两个相关学习资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视频简介的&lt;a href=&quot;https://www.youtube.com/watch?v=Dweg47Tswxw&quot;&gt;youtube地址&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;一个用keras框架实现的&lt;a href=&quot;https://github.com/drawbridge/keras-mmoe&quot;&gt;开源地址&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;2-动机&quot;&gt;&lt;a href=&quot;#2-动机&quot; class=&quot;headerlink&quot; title=&quot;2 动机&quot;&gt;&lt;/a&gt;2 动机&lt;/h2&gt;&lt;p&gt;多任务学习一般是为了在训练多个相关任务的时候可以使得它们之间能够共享信息，提高学习效率和模型的泛化能力。但实际应用中往往难以如此理想化，因为&lt;strong&gt;任务之间往往相关性不够强&lt;/strong&gt;，这时候就容易产生以下两个问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;负迁移（negative transfer）&lt;/code&gt;：即网络表现变差&lt;br&gt;&lt;code&gt;跷跷板现象（seesaw phenomenon）&lt;/code&gt;：也就是个别任务相对于独立训练获得提升，但其他任务效果下降。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="精排模型" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="MMOE" scheme="https://www.xiemingzhao.com/tags/MMOE/"/>
    
    <category term="精排" scheme="https://www.xiemingzhao.com/tags/%E7%B2%BE%E6%8E%92/"/>
    
  </entry>
  
  <entry>
    <title>深度学习的常用损失函数</title>
    <link href="https://www.xiemingzhao.com/posts/popularlossfuncs.html"/>
    <id>https://www.xiemingzhao.com/posts/popularlossfuncs.html</id>
    <published>2021-04-22T16:00:00.000Z</published>
    <updated>2025-04-04T10:11:15.523Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>在深度学习中，<code>损失函数</code>（Loss Function）至关重要，它决定着深度模型的训练学习的方式，其设计的恰当与否，往往会影响到最终模型的有效性。<br>虽然在很多通用型任务上，业内逐渐形成使用惯例，（如点击率建模，默认都用对数损失，logloss），但对损失函数的认识越清楚，会有助于算法工程师在面临新任务时，在模型设计上事半功倍。</p><h2 id="2-常用损失函数"><a href="#2-常用损失函数" class="headerlink" title="2 常用损失函数"></a>2 常用损失函数</h2><blockquote><p>损失函数的任务是：针对一个样本，度量模型的预估值 logit 即$\hat y$和对应真实 Label 即$y$之间的差异。</p></blockquote><p>不同的损失函数有不同的含义，主要是模型学习逼近样本分布的方式。所以它是一个非负实值函数，主要<strong>特点为：恒非负；误差越小，函数值越小；收敛快。</strong></p><span id="more"></span><p>基于<strong>距离度量</strong>的损失函数</p><ul><li>均方差损失函数（MSE）；</li><li>L2 损失函数；</li><li>L1 损失函数；</li><li>Smooth L1损失函数；</li><li>huber 损失函数；</li></ul><p>基于<strong>概率分布度量</strong>的损失函数</p><ul><li>Logloss；</li><li>KL 散度函数（相对熵）；</li><li>Cross Entropy 损失；</li><li>Softmax 损失函数；</li><li>Focal loss。</li></ul><h3 id="2-1-均方差损失函数（MSE）"><a href="#2-1-均方差损失函数（MSE）" class="headerlink" title="2.1 均方差损失函数（MSE）"></a>2.1 均方差损失函数（MSE）</h3><script type="math/tex; mode=display">MSE = \frac{1}{n} \sum_{i=1}^n (y_i - p_i)^2</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p>该损失函数一般是用在回归问题中，用于度量样本点到回归曲线的距离。<strong>它对离群点比较敏感，所以它不适合离群点较多的数据集。</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MSE_Loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_pred:list，代表模型预测的一组数据</span></span><br><span class="line"><span class="string">    y_true:list，代表真实样本对应的一组数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_pred)==<span class="built_in">len</span>(y_true)</span><br><span class="line">    y_pred=np.array(y_pred)</span><br><span class="line">    y_true=np.array(y_true)</span><br><span class="line">    loss=np.<span class="built_in">sum</span>(np.square(y_pred - y_true)) / <span class="built_in">len</span>(y_pred)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure></p><h3 id="2-2-L2-损失函数"><a href="#2-2-L2-损失函数" class="headerlink" title="2.2 L2 损失函数"></a>2.2 L2 损失函数</h3><script type="math/tex; mode=display">L2 = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - p_i)^2}</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p>L2 函数，即<code>最小平方误差</code>（(Least Square Error(LSE))，也叫作<code>欧氏距离</code>。其在独立、同分布的高斯噪声情况下，它能提供最大似然估计，所以常用在回归、模式识别、图像任务中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">L2_Loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_pred:list，代表模型预测的一组数据</span></span><br><span class="line"><span class="string">    y_true:list，代表真实样本对应的一组数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_pred)==<span class="built_in">len</span>(y_true)</span><br><span class="line">    y_pred=np.array(y_pred)</span><br><span class="line">    y_true=np.array(y_true)</span><br><span class="line">    loss=np.sqrt(np.<span class="built_in">sum</span>(np.square(y_pred - y_true)) / <span class="built_in">len</span>(y_pred))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure></p><h3 id="2-3-L1-损失函数"><a href="#2-3-L1-损失函数" class="headerlink" title="2.3 L1 损失函数"></a>2.3 L1 损失函数</h3><script type="math/tex; mode=display">L1 = \sum_{i=1}^n |y_i - p_i|</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p>L1 Loss 即<code>最小绝对误差</code>(Least Abosulote Error(LAE))，又称为<code>曼哈顿距离</code>，表示残差的绝对值之和。</p><p>但它有2个缺点：</p><ul><li>残差为零处却不可导；</li><li>梯度始终相同。</li></ul><p>更适用于有较多离群点的数据集，但由于上述的缺点使得不利于模型的收敛。为了缓解此问题，实际中如果使用的话，往往使用后文介绍的优化版 Smooth L1 Loss。</p><p>这里顺便提一个与其非常接近的 MAE，即平均绝对误差：</p><script type="math/tex; mode=display">MAE = \frac{1}{n} \sum_{i=1}^n |y_i - p_i|</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">L1Loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_pred:list，代表模型预测的一组数据</span></span><br><span class="line"><span class="string">    y_true:list，代表真实样本对应的一组数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_pred)==<span class="built_in">len</span>(y_true)</span><br><span class="line">    y_pred=np.array(y_pred)</span><br><span class="line">    y_true=np.array(y_true)</span><br><span class="line">    loss=np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(y_pred - y_true)) / <span class="built_in">len</span>(y_pred)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="2-4-Smooth-L1损失函数"><a href="#2-4-Smooth-L1损失函数" class="headerlink" title="2.4 Smooth L1损失函数"></a>2.4 Smooth L1损失函数</h3><script type="math/tex; mode=display">Smooth L1 =\begin{cases}\frac{1}{2}(Y-f(x))^2 & \quad\text{|Y-f(x)|<1} \\|Y-f(x)|-\frac{1}{2} & \quad\text{|Y-f(x)|>=1} &\end{cases}</script><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/lossfunc0.png" alt="lossfunc0"></p><p>该函数是由 Girshick R 在 Fast R-CNN 中提出的，<strong>主要用在目标检测中防止梯度爆炸</strong>。其实际上是一个分段函数：</p><ul><li>在[-1,1]，等价L2损失，解决了L1的不光滑问题；</li><li>在[-1,1]区间外，是L1损失，解决了L2离群点梯度易爆炸的问题。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Smooth_L1_Loss</span>(<span class="params">y_true_pred,y_true</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true_pred)==<span class="built_in">len</span>(y_true)</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i_y_true_pred,i_y_true <span class="keyword">in</span> <span class="built_in">zip</span>(y_true_pred,y_true):</span><br><span class="line">        tmp = <span class="built_in">abs</span>(i_y_true-i_y_true_pred)</span><br><span class="line">        <span class="keyword">if</span> tmp&lt;<span class="number">1</span>:</span><br><span class="line">            loss+=<span class="number">0.5</span>*(tmp**<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss+=tmp-<span class="number">0.5</span></span><br><span class="line">     <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="2-5-huber-损失函数"><a href="#2-5-huber-损失函数" class="headerlink" title="2.5 huber 损失函数"></a>2.5 huber 损失函数</h3><script type="math/tex; mode=display">\left.\left.\left. Huber=\left\{\begin{array}{ll}\frac{1}{2}(Y-f(x))^2 & |\mathrm{Y-f(x)}|<=\delta \\\delta|Y-f(x)|-\frac{1}{2}\delta^2 & |\mathrm{Y-f(x)}|>\delta\end{array}\right.\right.\right.\right.</script><p><code>Huber</code> 损失是 MSE 和 MAE 的结合，又称作 Smooth Mean Absolute Error Loss。</p><p>它克服了L1和L2的缺点：</p><ul><li>不仅使损失函数具有连续的导数；</li><li>而且利用MSE梯度随误差减小的特性，可取得更精确的最小值。</li></ul><p>但是，它有自己的缺点，不仅引入了额外的参数，而且选择合适的参数比较困难。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">huber_loss</span>(<span class="params">y_pred,y_true,delta=<span class="number">1.0</span></span>):</span><br><span class="line">   <span class="keyword">assert</span> <span class="built_in">len</span>(y_pred)==<span class="built_in">len</span>(y_true)</span><br><span class="line">   loss=<span class="number">0</span></span><br><span class="line">   <span class="keyword">for</span> i_y_pred,i_y_true <span class="keyword">in</span> <span class="built_in">zip</span>(y_pred,y_true):</span><br><span class="line">       tmp = <span class="built_in">abs</span>(i_y_true-i_y_pred)</span><br><span class="line">       <span class="keyword">if</span> tmp&lt;=delta:</span><br><span class="line">           loss+=<span class="number">0.5</span>*(tmp**<span class="number">2</span>)</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           loss+=tmp*delta-<span class="number">0.5</span>*delta**<span class="number">2</span></span><br><span class="line">   <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="2-6-KL-散度函数（相对熵）"><a href="#2-6-KL-散度函数（相对熵）" class="headerlink" title="2.6 KL 散度函数（相对熵）"></a>2.6 KL 散度函数（相对熵）</h3><script type="math/tex; mode=display">KL = \sum_{i=1}^n y_i \times log(\frac{y_i}{p_i})</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p><code>KL散度</code>（ Kullback-Leibler divergence）也被称为<code>相对熵</code>，是一种<strong>非对称度量方法，即A、B两个分布，A对比B计算和B对A计算结果不一样。</strong></p><p>相对熵是恒大于等于0的，当且仅当两分布相同时，相对熵等于0。KL散度可以用于比较文本标签或图像的相似性。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">kl_loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_true,y_pred，分别是两个概率分布</span></span><br><span class="line"><span class="string">    比如：y_true=[0.1,0.2,0.8]</span></span><br><span class="line"><span class="string">        y_pred=[0.3,0.3,0.4]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true)==<span class="built_in">len</span>(y_pred)</span><br><span class="line">    KL=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> y,fx <span class="keyword">in</span> <span class="built_in">zip</span>(y_true,y_pred):</span><br><span class="line">        KL+=y*np.log(y/fx)</span><br><span class="line">    <span class="keyword">return</span> KL</span><br></pre></td></tr></table></figure></p><h3 id="2-7-Cross-Entropy-损失"><a href="#2-7-Cross-Entropy-损失" class="headerlink" title="2.7 Cross Entropy 损失"></a>2.7 Cross Entropy 损失</h3><script type="math/tex; mode=display">CE = -\frac{1}{n} \sum_{i=1}^n \sum_{j = 1}^m y_{ij} log(p_{ij})</script><p>其中，n 是样本数，m 是类别数，$y<em>{ij}$是样本 i 所属类别 j 的示性变量，即属于时位1，否则为0，$p</em>{ij}$表示预测的样本 i 属于类别 j 的概率。</p><p><code>交叉熵</code>是信息论中的一个概念，最初用于估算平均编码长度，在深度学习中往往用于评估当前训练得到的概率分布与真实分布的差异情况。</p><p>为了使神经网络的每一层输出从线性组合转为<strong>非线性逼近，以提高模型的预测精度</strong>，一般配合softmax激活函数，在多分类问题中常常被使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">CrossEntropy_loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_true,y_pred，分别是两个概率分布list</span></span><br><span class="line"><span class="string">    比如：y_true=[[0.1,0.9],[0.2,0.8],[0.4,0.6]]</span></span><br><span class="line"><span class="string">         y_pred=[[0.3,0.7],[0.1,0.9],[0.4,0.6]]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true)==<span class="built_in">len</span>(y_pred)</span><br><span class="line">    cate_size = <span class="built_in">len</span>(y_true[<span class="number">0</span>])</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> y,fx <span class="keyword">in</span> <span class="built_in">zip</span>(y_true,y_pred):</span><br><span class="line">        loss+=-<span class="built_in">sum</span>([y[i] * np.log(fx[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cate_size)]</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="2-8-LogLoss-函数"><a href="#2-8-LogLoss-函数" class="headerlink" title="2.8 LogLoss 函数"></a>2.8 LogLoss 函数</h3><script type="math/tex; mode=display">LogLoss = -\frac{1}{n}\sum_{i=1}^n (y_i log(p_i) + (1 - y_i) log(1 - p_i))</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p><code>对数损失</code>（logarithm loss）也被称为<code>对数似然损失</code>，实际上<strong>是交叉熵损失在二分类任务下的特例</strong>。其假设样本服从伯努利分布，利用极大似然估计的思想求得极值，它常作为二分类问题的损失函数，一般结合 sigmoid 输出函数使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Log_loss</span>(<span class="params">y_true:<span class="built_in">list</span>,y_pred:<span class="built_in">list</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    y_true,y_pred，分别是两个概率分布</span></span><br><span class="line"><span class="string">    比如：y_true=[0.1,0.2,0.8]</span></span><br><span class="line"><span class="string">         y_pred=[0.3,0.3,0.4]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(y_true)==<span class="built_in">len</span>(y_pred)</span><br><span class="line">    loss=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> y,fx <span class="keyword">in</span> <span class="built_in">zip</span>(y_true,y_pred):</span><br><span class="line">        loss+=-y * np.log(fx)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="2-9-Focal-loss"><a href="#2-9-Focal-loss" class="headerlink" title="2.9 Focal loss"></a>2.9 Focal loss</h3><script type="math/tex; mode=display">FL = -\frac{1}{n}\sum_{i=1}^n (\alpha (1-p_i)^{\gamma} y_i log(p_i) + (1 - \alpha) p_i^{\gamma} (1 - y_i) log(1 - p_i))</script><p>其中，n 是样本量，$y_i$是第 i 样本的真实 label，$p_i$是模型的预测结果。</p><p><code>Focal Loss</code> 的引入主要是为了<strong>解决难易样本不均衡的问题，注意有区别于正负样本不均衡的问题</strong>。易分样本虽然损失很低，但是数量太多，对模型的效果提升贡献很小，模型应该重点关注那些难分样本.<br>因此需要把置信度高的损失再降低一些性质：</p><ul><li>当样本分类错误时，$p_t$趋于0，调变因子趋于1，使得损失函数几乎不受影响;</li><li>如果正确分类，$p_t$将趋于1，调变因子将趋向于0，使得损耗非常接近于0，从而降低了该特定示例的权重。</li></ul><p>如下图，聚焦参数（γ）平滑地调整易于分类的样本向下加权的速率。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/lossfunc1.png" alt="lossfunc1"></p><p>其中：</p><script type="math/tex; mode=display">p_{\mathbf{t}}=\begin{cases}p & \mathrm{if~}y=1 \\1-p & \text{otherwise} & &\end{cases}</script><h2 id="3-交叉熵的渊源"><a href="#3-交叉熵的渊源" class="headerlink" title="3 交叉熵的渊源"></a>3 交叉熵的渊源</h2><h3 id="3-1-交叉熵与信息论"><a href="#3-1-交叉熵与信息论" class="headerlink" title="3.1 交叉熵与信息论"></a>3.1 交叉熵与信息论</h3><p>交叉熵（Cross Entropy）出自 Shannon <code>信息论</code>，主要<strong>用于度量两个概率分布间的差异性信息。</strong></p><p>假设 p 表示真实分布，q 表示预估分布，那么 $H(p,q)$ 就称为交叉熵：</p><script type="math/tex; mode=display">H(p,q) = \sum_i p_i \cdot log \frac{1}{q_i} = -\sum_i p_ilog(q_i)</script><p>要追溯它的源头，需要再回到信息论中，<code>信息量</code>的表示方式：$I(x) = -log(p(x))$<br>$x$表示一个事件，$p(x)$表示事件 x 发生的概率，$I(x)$则表示信息量。<br>根据$log$函数的性质，<strong>事件发生概率越小时，它一旦发生后的信息量就越大。</strong></p><p>假设随机变量 x，有两个独立的概率分布 $P(x)$ 和 $Q(x)$，怎么度量两个分布的差异呢？</p><p>使用 <code>KL 散度</code>（Kullback-Leibler (KL) divergence），又称<code>相对熵</code>。</p><p>KL散度的计算公式：</p><script type="math/tex; mode=display">D_{KL}(q||p) = \sum_{i = 1}^n q(x_i) log \frac{q(x_i)}{p(x_i)}</script><p>其中，n为事件的所有可能性种类，D 的值越小，表示 Q 分布和 P 分布越接近。</p><p>我们简单做一下分解：</p><script type="math/tex; mode=display">\begin{aligned}& \mathrm{} \\D_{KL}(q||p) & =\sum_{i=1}^n q(x_{i})\log q(x_{i})-\sum_{i=1}^n q(x_{i})\log p(x_{i}) \\& =-H(q(x))+H(q,p)\end{aligned}</script><p>到这里，你可能已经发现他们之间的关联了。</p><p>在深度学习中的分类任务，我们<strong>想要度量模型预估是否准确，就可以通过度量样本的真实分布（Label）与预估分布（Predict）之间的距离来判断</strong>。我们令：</p><ul><li>真实分布（Label）：Q(x)</li><li>预估分布（Predict）：P(x)</li></ul><p>真实分布往往就是训练样本，是给定不变的，所以在$D_{KL}(q||p)$中需要关注和优化的就只有分解后的第二项$H(q,p)$，即<code>交叉熵</code>。</p><p>如果我们令 n 表示样本数，m 表示分类数，$y<em>{ij}$是样本 label，$p</em>{ij}$表示预测的概率。批量的交叉熵便是：</p><script type="math/tex; mode=display">CE = -\frac{1}{n} \sum_{i=1}^n \sum_{j = 1}^m y_{ij} log(p_{ij})</script><p>如果在<strong>二分类任务中</strong>，那么 $y_{ij}$ 就只有 0 和 1 两类，所以交叉熵可以简化为：</p><script type="math/tex; mode=display">CE = -\frac{1}{n} \sum_{i=1}^n (y_i log(p_{i}) + (1 - y_i)log(1 - p_{i}))</script><p>相信你已经看出来了，这就是 <code>LogLoss</code>。</p><p>我们以 Logloss 为例，接着用<strong>极大值点的方式（导数为0）来求解极大似然估计</strong>：</p><script type="math/tex; mode=display">\begin{aligned}& \mathrm{} \\\sum_{i=1}^n (y_i \frac{1}{p_{i}} + (1 - y_i)\frac{1}{p_{i} - 1}) = 0 \\\sum_{i=1}^n (p_i - y_i) = 0 \\\bar p = \frac{1}{n} \sum_{i=1}^n y_i\end{aligned}</script><p>这就解释了实际应用中，对于<strong>二分类任务（比如ctr预估）模型的预估期望是等于 Label 的均值的</strong>，所以我们往往用 <code>pcoc</code> 来判断模型在局部样本上是高估还是低估。</p><h3 id="3-2-交叉熵与极大似然"><a href="#3-2-交叉熵与极大似然" class="headerlink" title="3.2 交叉熵与极大似然"></a>3.2 交叉熵与极大似然</h3><p>区别：</p><ul><li>交叉熵是度量分布差距的大小，越大代表越不相近；</li><li>似然函数是度量分布一样的概率，越大代表越相近。</li></ul><p><strong>实际上，最小化交叉熵函数的本质就是对数似然函数的最大化。</strong></p><blockquote><p>最大似然估计中采样需满足假设：独立同分布实验。</p></blockquote><p>我们假设独立采样 n 个样本，样本分布为 q，预估分布为 p，那么就有：</p><script type="math/tex; mode=display">\begin{gathered}L=\frac{1}{n}\sum_{i=1}^{n}log\prod_{j=1}^{m}p_{ij}^{q_{ij}}=\frac{1}{n}\sum_{i=1}^{n}log(p_{1}^{q_{1}}.p_{2}^{q_{2}}...p_{m}^{q_{m}}) \\=\frac{1}{n}\sum_{i=1}^n(q_1log(p_1)+q_2log(p_2)+...+q_m log(p_m)) \\=\frac{1}{n}\sum_{i=1}^n\sum_{j=1}^m q_ilog(p_i)\end{gathered}</script><p>可以发现，实际上就是交叉熵的绝对值。</p><h3 id="3-3-交叉熵损失的优势"><a href="#3-3-交叉熵损失的优势" class="headerlink" title="3.3 交叉熵损失的优势"></a>3.3 交叉熵损失的优势</h3><blockquote><p>为什么不能使用均方差做为分类问题的损失函数？</p></blockquote><p><strong>均方差损失适合回归</strong>：与激活函数叠加是个凸函数，即可以得到最优解。</p><p><strong>均方差损失不适合分类：</strong></p><ul><li>与激活函数（Sigmoid/Softmax）叠加不是凸函数，就很难得到最优解。</li><li>求导结果复杂，运算量比较大。</li></ul><p><strong>交叉熵适合分类：</strong></p><ul><li>可以保证区间内单调；</li><li>梯度计算简单，纯减法。</li></ul><p>正如上面所述，交叉上损失在梯度计算上也有优势。我们以常用的二分类任务为例，单条样本交叉熵公式为：</p><script type="math/tex; mode=display">C = -(y log(p) + (1 - y)log(1-p))</script><p>其中，y 是 label，p 是深度模型输出，如果结合输出层和激活函数，就有：</p><script type="math/tex; mode=display">p = \sigma{(z)} , z = w x + b</script><p>我们就可以分别推导出<strong>参数$w,b$的梯度，如下所示，可以发现非常简洁，只与$p - y$有关，即预估误差越大，梯度更新越快。</strong></p><script type="math/tex; mode=display">\begin{gathered}\frac{\partial C}{\partial p} &=& -(y \frac{1}{p} + \frac{y - 1}{1 - p})\\&=& -(y \frac{1}{p(1 - p)} - \frac{1}{1 - p})\\\frac{\partial C}{\partial z} &=& \frac{\partial C}{\partial p} \frac{\partial p}{\partial z} \\&=& -(y \frac{1}{p(1 - p)} - \frac{1}{1 - p}) \cdot \sigma'(z) \\&=& -(y \frac{1}{p(1 - p)} - \frac{1}{1 - p}) \cdot \sigma(z)(1 - \sigma(z)) \\&=& p - y \\\frac{\partial C}{\partial w} &=& \frac{\partial C}{\partial z} \frac{\partial z}{\partial w} = (p - y)x \\\frac{\partial C}{\partial b} &=& \frac{\partial C}{\partial z} \frac{\partial z}{\partial b} = (p - y)\end{gathered}</script><p>同样的，如果是多分类，使用 softmax 激活函数 + 交叉熵损失，也有类似的性质。虽然推导起来复杂一些，但结果也是只和$p - y$有关，这里不再赘述。</p><p><strong>参考文章：</strong><br><a href="https://blog.csdn.net/light169/article/details/124602481">深度学习之损失函数</a><br><a href="https://cloud.tencent.com/developer/article/1950150">六个深度学习常用损失函数总览</a><br><a href="https://www.nowcoder.com/discuss/353148846177984512">深度学习——损失函数</a><br><a href="https://mp.weixin.qq.com/s?subscene=23&amp;__biz=MzAxOTQ2NzUxOQ==&amp;mid=2651912913&amp;idx=1&amp;sn=68f62cb548b35ec93f18027458352434&amp;chksm=8022c741b7554e57616ac8dcd80a11acd7a8a6ada181f4584c602c9f242815f5863ed96b4529&amp;scene=7&amp;key=9c1744d1bffeab4b0c8d19d08eff803bc5bf556e7dad290931316859107869eae11c8d2ef08d1c445c32f9564b88b15a7ddefa9ecba47e9f30595d3194cb93202f018216f272734d0502965e5172c528b84d6f7ee4a2970563bd1594a1ee84cb78bedc97a8d73b1f2c1c8b796374470272fd4c44a5a5badebefe79f797dd9006&amp;ascene=0&amp;uin=NzY2MzMyNDAx&amp;devicetype=Windows+10+x64&amp;version=62090538&amp;lang=zh_CN&amp;exportkey=AbDFP%2Fy90lQvupKLsin%2BqIY%3D&amp;pass_ticket=xXJHSvXALrdXBNLifG37ggdjbeqxXtSOQYVggNqQRRey1Vm1lBPWCAlvlwRUGwZW&amp;wx_header=0">监督学习中的损失函数及应用研究</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;在深度学习中，&lt;code&gt;损失函数&lt;/code&gt;（Loss Function）至关重要，它决定着深度模型的训练学习的方式，其设计的恰当与否，往往会影响到最终模型的有效性。&lt;br&gt;虽然在很多通用型任务上，业内逐渐形成使用惯例，（如点击率建模，默认都用对数损失，logloss），但对损失函数的认识越清楚，会有助于算法工程师在面临新任务时，在模型设计上事半功倍。&lt;/p&gt;
&lt;h2 id=&quot;2-常用损失函数&quot;&gt;&lt;a href=&quot;#2-常用损失函数&quot; class=&quot;headerlink&quot; title=&quot;2 常用损失函数&quot;&gt;&lt;/a&gt;2 常用损失函数&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;损失函数的任务是：针对一个样本，度量模型的预估值 logit 即$&#92;hat y$和对应真实 Label 即$y$之间的差异。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不同的损失函数有不同的含义，主要是模型学习逼近样本分布的方式。所以它是一个非负实值函数，主要&lt;strong&gt;特点为：恒非负；误差越小，函数值越小；收敛快。&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="损失函数" scheme="https://www.xiemingzhao.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
    <category term="loss fuction" scheme="https://www.xiemingzhao.com/tags/loss-fuction/"/>
    
  </entry>
  
  <entry>
    <title>Batch Normalization 小记</title>
    <link href="https://www.xiemingzhao.com/posts/batchnormnotes.html"/>
    <id>https://www.xiemingzhao.com/posts/batchnormnotes.html</id>
    <published>2021-04-04T16:00:00.000Z</published>
    <updated>2025-04-01T16:37:00.621Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>如果你是一个玩深度学习的算法工程师，那么相信你对批标准化（<code>Batch Normalization</code>）一定不陌生。在实际训练深度模型中，<strong>BN 往往用来加速模型收敛或者缓解梯度消失/爆炸的问题</strong>。笔者在实际使用过程中也有一定的收获和思考，收获是不同的使用姿势确实能够带来不一样的效果。思考就是，虽然大致知道BN的原理和公式，但是创建 BN 这个方法的出发点和一些边界问题的思考始终萦绕在周围。在此做一个汇总整理，旨在帮助和我一样有此困惑的朋友们。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><h3 id="2-1-优化原理"><a href="#2-1-优化原理" class="headerlink" title="2.1 优化原理"></a>2.1 优化原理</h3><p>训练网络深度的加深可能会带来梯度迭代上的<code>梯度消失</code>（Gradient Vanishing)或者<code>梯度爆炸</code>(Gradient Explore)问题。这两个问题的产生原理这里不做赘述，一般都是由于网络层数过深，梯度链式传导带来的结果。</p><span id="more"></span><p>网络训练过程中参数不断改变导致后续每一层输入的分布也发生变化，而学习的过程又要使每一层适应输入的分布，所以一般只能选取较低的学习率和较小值来初始化。这种分布的变化一般称之为<code>internal covariate shift</code>。</p><p><em><code>Convariate Shift</code>是指训练集的样本数据和目标样本集分布不一致时，训练得到的模型无法很好的<code>Generalization</code>。</em></p><p>在训练网络模型的时候经常会对输入做均值归0化，有的做白化，都是为了加速训练。<em>但是能够加速的原理是什么呢？</em></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/batchnormnotes0.png" alt="batchnormnotes0"></p><p>如上图所示，假设初始的样本数据分布如图a所示。当我们进行模型拟合的时候，以单层网络$y = Wx+b$为例，由于参数初始化的时候都是0均值附近的很小值，所以拟合曲线一般都会过原点，如上图 b 红色虚线所示，想要达到收敛的情况就会比较慢。但是，如果将数据平移至原点附近，如图 c 所示，陷入可以加快拟合速度。更甚者对数据做去相关，如图 d 所示，样本间的区分度就会更高。</p><p>而做标准化的方式也有多种，<strong>效果比较好的是PCA，但是在复杂的网络中需要计算协方差矩阵、求逆等操作，计算量很大，此外，反向传播时，标准化操作不一定可导</strong>。这时候<code>Batch Normalization</code>的优势就体现了出来。</p><p><code>Bactch Normalization</code>是来标准化某些层或者所有层的输入，从而<strong>固定每层输入信息的均值和方差</strong>。一般就是要让数据具有0均值和单位方差:</p><script type="math/tex; mode=display">\hat x ^{(k)} = \frac{x^{(k)} - E[x^{(k)}]}{\sqrt {Var[x^{(k)}]}}</script><p><strong>公式中的均值和方差，用一个Batch的均值和方差作为对整个数据集均值和方差的估计。</strong></p><blockquote><p>但是，如果仅仅这么简单的做是有问题的。</p></blockquote><p>我们以下图常用的激活函数<code>sigmoid</code>为例，如果把数据限制到0均值单位方差，那么相当于只使用了激活函数中近似线性的部分，这显然会降低模型表达能力。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/batchnormnotes1.jpg" alt="batchnormnotes1"></p><p>所以，就可以在上述的基础上，增加一个平移和缩放的变换，用来保持模型的表达能力：</p><script type="math/tex; mode=display">y^{(k)} = \gamma^{(k)} \hat x^{(k)} + \beta ^{(k)}</script><h3 id="2-2-模型推理"><a href="#2-2-模型推理" class="headerlink" title="2.2 模型推理"></a>2.2 模型推理</h3><p>实际使用的时候，模型前向传输网络依然使用下列的公式进行数据的标准化：</p><script type="math/tex; mode=display">\hat x = \frac{x - E[x]}{\sqrt{Var[x]+\epsilon}}</script><p><strong>注意：这里的$E[x]$和$Var[x]$不同于训练时候的值，并不是当前batch的统计结果，而是针对整个数据集的统计值。</strong></p><blockquote><p>但是，怎么获取呢？</p></blockquote><ul><li>训练时，均值、方差分别是该批次内数据相应维度的均值与方差；</li><li>推理时，均值、方差是基于所有批次的期望计算所得：</li></ul><p>为了最后在模型 infer 过程中更加准确，需要<strong>记录每一个训练的Batch的均值和方差</strong>，其实就是一个<code>无偏估计</code>：</p><script type="math/tex; mode=display">E[x] \epsilon \gets E_{B}[u_B]</script><script type="math/tex; mode=display">Var[x] \epsilon \gets \frac{m}{m-1}E_B[\sigma^2_B]</script><p>大部分经验说应该把BN放在激活函数之前，这是因为：</p><ul><li>本身就是为了解决梯度消失/爆炸的问题；</li><li>$Wx+b$具有更加一致和非稀疏的分布。</li></ul><p><em>但是也有人做实验表明放在激活函数后面效果更好。</em></p><h2 id="3-tf实战"><a href="#3-tf实战" class="headerlink" title="3 tf实战"></a>3 tf实战</h2><p>介绍了那么多理论，那实际中如何在网络中使用BN层呢？这里将介绍一些对应的tensorflow的API以及使用的小Tips。</p><h3 id="3-1-BN-的-API"><a href="#3-1-BN-的-API" class="headerlink" title="3.1 BN 的 API"></a>3.1 BN 的 API</h3><p>首先Batch Normalization在TensorFlow中有三个接口调用 (不包括slim、Keras模块中的)，分别是：</p><ul><li><a href="https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization">tf.layers.batch_normalization</a></li><li><a href="https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization">tf.nn.batch_normalization</a></li><li><a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/batch_normalization">tf.contrib.layers.batch_norm</a></li></ul><p><code>tf.layers.batch_normalization</code>和<code>tf.contrib.layers.batch_norm</code>可以用来构建待训练的神经网络模型，而<code>tf.nn.batch_normalization</code>一般只用来构建推理模型，原因是后者只定义了初始的网络结构，没有考虑训练和推理时候的参数更新问题。由于<code>tf.contrib</code>包的不稳定性，一般实际中使用最多的就是<code>tf.layers.batch_normalization</code>。</p><p>首先，看一下<code>tf.layers.batch_normalization</code>接口方法的定义：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.batch_normalization(</span><br><span class="line">    inputs,</span><br><span class="line">    axis=-<span class="number">1</span>,</span><br><span class="line">    momentum=<span class="number">0.99</span>,</span><br><span class="line">    epsilon=<span class="number">0.001</span>,</span><br><span class="line">    center=<span class="literal">True</span>,</span><br><span class="line">    scale=<span class="literal">True</span>,</span><br><span class="line">    beta_initializer=tf.zeros_initializer(),</span><br><span class="line">    gamma_initializer=tf.ones_initializer(),</span><br><span class="line">    moving_mean_initializer=tf.zeros_initializer(),</span><br><span class="line">    moving_variance_initializer=tf.ones_initializer(),</span><br><span class="line">    beta_regularizer=<span class="literal">None</span>,</span><br><span class="line">    gamma_regularizer=<span class="literal">None</span>,</span><br><span class="line">    beta_constraint=<span class="literal">None</span>,</span><br><span class="line">    gamma_constraint=<span class="literal">None</span>,</span><br><span class="line">    training=<span class="literal">False</span>,</span><br><span class="line">    trainable=<span class="literal">True</span>,</span><br><span class="line">    name=<span class="literal">None</span>,</span><br><span class="line">    reuse=<span class="literal">None</span>,</span><br><span class="line">    renorm=<span class="literal">False</span>,</span><br><span class="line">    renorm_clipping=<span class="literal">None</span>,</span><br><span class="line">    renorm_momentum=<span class="number">0.99</span>,</span><br><span class="line">    fused=<span class="literal">None</span>,</span><br><span class="line">    virtual_batch_size=<span class="literal">None</span>,</span><br><span class="line">    adjustment=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>其中，有几个主要参数需要了解一下：</p><ul><li><code>axis</code>的值取决于按照<code>input</code>的哪一个维度进行BN，例如输入为<code>channel_last format</code>，即<code>[batch_size, height, width, channel]</code>，则<code>axis</code>应该设定为4，如果为<code>channel_first format</code>，则<code>axis</code>应该设定为1.</li><li><code>momentum</code>的值用在训练时，滑动平均的方式计算滑动平均值<code>moving_mean</code>和滑动方差<code>moving_variance</code>。</li><li><code>center</code>为<code>True</code>时，添加位移因子<code>beta</code>到该BN层，否则不添加。添加<code>beta</code>是对BN层的变换加入位移操作。<strong>注意，<code>beta</code>一般设定为可训练参数，即trainable=True</strong>。</li><li><code>scale</code>为True是，添加缩放因子<code>gamma</code>到该BN层，否则不添加。添加gamma是对BN层的变化加入缩放操作。<strong>注意，gamma一般设定为可训练参数，即trainable=True</strong>。</li><li><code>training</code>表示模型当前的模式，如果为True，则模型在训练模式，否则为推理模式。<strong>要非常注意这个模式的设定!!!</strong>，这个参数默认值为False。如果在训练时采用了默认值False，则滑动均值<code>moving_mean</code>和滑动方差<code>moving_variance</code>都不会根据当前batch的数据更新，这就意味着<strong>在推理模式下，均值和方差都是其初始值，因为这两个值并没有在训练迭代过程中滑动更新</strong>。</li></ul><h3 id="3-2-BN-的-code"><a href="#3-2-BN-的-code" class="headerlink" title="3.2 BN 的 code"></a>3.2 BN 的 code</h3><p>TensorFlow中模型训练时的梯度计算、参数优化等<code>train_op</code>并没有依赖滑动均值<code>moving_mean</code>和滑动方差<code>moving_variance</code>，则moving_mean和moving_variance不会自动更新，只能在<code>tf.GraphKeys.GLOBAL_VARIABLES</code>中，所以<strong>必须加入负责更新这些参数的<code>update_ops</code>到依赖中</strong>，且应该在执行前向计算结束后、后向计算开始前执行update_ops，所以添加依赖的位置不能出错。在前文提到的$\beta$和$\gamma$是可训练变量，存放于<code>tf.GraphKeys.TRAINABLE_VARIABLES</code>。实际中，只需要在构建模型代码中，添加完所有BN层之后获取update_ops就不会出错!!！这是TensorFlow的图计算模式造成的编程影响，在其他深度学习框架中可能会有差别。</p><p><strong>训练</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_norm = tf.layers.batch_normalization(x, training=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line">train_op = optimizer.minimize(loss)</span><br><span class="line">train_op = tf.group([train_op, update_ops])</span><br></pre></td></tr></table></figure></p><p><strong>模型保存</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">saver = tf.train.Saver(tf.global_variables())</span><br><span class="line">saver.save(sess, <span class="string">&quot;your_path&quot;</span>)</span><br></pre></td></tr></table></figure></p><p><strong>预测</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_norm = tf.layers.batch_normalization(x, training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver(tf.global_variables())</span><br><span class="line">saver.restore(sess, <span class="string">&quot;your_path&quot;</span>)</span><br></pre></td></tr></table></figure></p><p><strong>estimator</strong><br>如果你使用的是高阶API：estimator进行训练的话，那么就比较麻烦，因为它的session没有暴露出来，你没办法直接使用，需要换个方式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_fn_build</span>(<span class="params">init_checkpoint=<span class="literal">None</span>, lr=<span class="number">0.001</span>, model_dir=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_model_fn</span>(<span class="params">features, labels, mode, params</span>):</span><br><span class="line"></span><br><span class="line">        x = features[<span class="string">&#x27;inputs&#x27;</span>]</span><br><span class="line">        y = features[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#####################在这里定义你自己的网络模型###################</span></span><br><span class="line">        x_norm = tf.layers.batch_normalization(x, training=mode == tf.estimator.ModeKeys.TRAIN)</span><br><span class="line">        pre = tf.layers.dense(x_norm, <span class="number">1</span>)</span><br><span class="line">        loss = tf.reduce_mean(tf.<span class="built_in">pow</span>(pre - y, <span class="number">2</span>), name=<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">        <span class="comment">######################在这里定义你自己的网络模型###################</span></span><br><span class="line"></span><br><span class="line">        lr = params[<span class="string">&#x27;lr&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">######################进入eval和predict之前，都经过这一步加载过程###################</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载保存的模型</span></span><br><span class="line">        <span class="comment"># 为了加载batch_normalization的参数，需要global_variables</span></span><br><span class="line">        tvars = tf.global_variables()</span><br><span class="line">        initialized_variable_names = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> params[<span class="string">&#x27;init_checkpoint&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> tf.train.latest_checkpoint(model_dir) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            checkpoint = params[<span class="string">&#x27;init_checkpoint&#x27;</span>] <span class="keyword">or</span> tf.train.latest_checkpoint(model_dir)</span><br><span class="line">            (assignment_map, initialized_variable_names</span><br><span class="line">             ) = get_assignment_map_from_checkpoint(tvars, checkpoint)</span><br><span class="line">            tf.train.init_from_checkpoint(checkpoint, assignment_map)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># tf.logging.info(&quot;**** Trainable Variables ****&quot;)</span></span><br><span class="line">        <span class="comment"># for var in tvars:</span></span><br><span class="line">        <span class="comment">#     init_string = &quot;&quot;</span></span><br><span class="line">        <span class="comment">#     if var.name in initialized_variable_names:</span></span><br><span class="line">        <span class="comment">#         init_string = &quot;, *INIT_FROM_CKPT*&quot;</span></span><br><span class="line">        <span class="comment">#     tf.logging.info(&quot;  name = %s, shape = %s%s&quot;, var.name, var.shape,</span></span><br><span class="line">        <span class="comment">#                     init_string)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">######################进入eval和predict之前，都经过这一步加载过程###################</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == tf.estimator.ModeKeys.TRAIN:</span><br><span class="line">            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line">            train_op = optimizer.minimize(loss)</span><br><span class="line">            train_op = tf.group([train_op, update_ops])</span><br><span class="line">            <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == tf.estimator.ModeKeys.EVAL:</span><br><span class="line">            metrics = &#123;<span class="string">&quot;accuracy&quot;</span>: tf.metrics.accuracy(features[<span class="string">&#x27;label&#x27;</span>], pred)&#125;</span><br><span class="line">            <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, eval_metric_ops=metrics, loss=loss)</span><br><span class="line"></span><br><span class="line">        predictions = &#123;<span class="string">&#x27;predictions&#x27;</span>: pred&#125;</span><br><span class="line">        predictions.update(&#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> features.items()&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.estimator.EstimatorSpec(mode, predictions=predictions)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.estimator.Estimator(_model_fn, model_dir=model_dir, config=config,</span><br><span class="line">                                  params=&#123;<span class="string">&quot;lr&quot;</span>: lr, <span class="string">&quot;init_checkpoint&quot;</span>: init_checkpoint&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_assignment_map_from_checkpoint</span>(<span class="params">tvars, init_checkpoint</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute the union of the current variables and checkpoint variables.&quot;&quot;&quot;</span></span><br><span class="line">    assignment_map = &#123;&#125;</span><br><span class="line">    initialized_variable_names = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    name_to_variable = collections.OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> var <span class="keyword">in</span> tvars:</span><br><span class="line">        name = var.name</span><br><span class="line">        m = re.<span class="keyword">match</span>(<span class="string">&quot;^(.*):\\d+$&quot;</span>, name)</span><br><span class="line">        <span class="keyword">if</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            name = m.group(<span class="number">1</span>)</span><br><span class="line">        name_to_variable[name] = var</span><br><span class="line"></span><br><span class="line">    init_vars = tf.train.list_variables(init_checkpoint)</span><br><span class="line"></span><br><span class="line">    assignment_map = collections.OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> init_vars:</span><br><span class="line">        (name, var) = (x[<span class="number">0</span>], x[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> name_to_variable:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        assignment_map[name] = name</span><br><span class="line">        initialized_variable_names[name] = <span class="number">1</span></span><br><span class="line">        initialized_variable_names[name + <span class="string">&quot;:0&quot;</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (assignment_map, initialized_variable_names)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h3 id="3-3-一些总结"><a href="#3-3-一些总结" class="headerlink" title="3.3 一些总结"></a>3.3 一些总结</h3><p>笔者在使用中有一些对比结论：</p><ul><li>首先 bn 层往往放在 dense 层和 activation 层（一般 ReLU）之间，有助于加速收敛和防止过拟合；</li><li>尽量不在 sigmoid 的激活层前加，可能会使得模型难以收敛；</li><li>输出层之前一般不能加；</li><li>training 的参数及其重要。</li></ul><p><strong>参考文章</strong><br><a href="https://blog.csdn.net/shuzfan/article/details/50723877">解读Batch Normalization</a><br><a href="https://blog.csdn.net/caicaiatnbu/article/details/72742293?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-10.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-10.no_search_link">[TensorFlow 学习笔记-05]批标准化(Bacth Normalization，BN)</a><br><a href="https://blog.csdn.net/sgyuanshi/article/details/115268969">tensorflow中batch_normalization的正确使用姿势</a><br><a href="https://www.jianshu.com/p/437fb1a5823e">Batch Normalization的正确打开方式</a><br><a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;如果你是一个玩深度学习的算法工程师，那么相信你对批标准化（&lt;code&gt;Batch Normalization&lt;/code&gt;）一定不陌生。在实际训练深度模型中，&lt;strong&gt;BN 往往用来加速模型收敛或者缓解梯度消失/爆炸的问题&lt;/strong&gt;。笔者在实际使用过程中也有一定的收获和思考，收获是不同的使用姿势确实能够带来不一样的效果。思考就是，虽然大致知道BN的原理和公式，但是创建 BN 这个方法的出发点和一些边界问题的思考始终萦绕在周围。在此做一个汇总整理，旨在帮助和我一样有此困惑的朋友们。&lt;/p&gt;
&lt;h2 id=&quot;2-原理&quot;&gt;&lt;a href=&quot;#2-原理&quot; class=&quot;headerlink&quot; title=&quot;2 原理&quot;&gt;&lt;/a&gt;2 原理&lt;/h2&gt;&lt;h3 id=&quot;2-1-优化原理&quot;&gt;&lt;a href=&quot;#2-1-优化原理&quot; class=&quot;headerlink&quot; title=&quot;2.1 优化原理&quot;&gt;&lt;/a&gt;2.1 优化原理&lt;/h3&gt;&lt;p&gt;训练网络深度的加深可能会带来梯度迭代上的&lt;code&gt;梯度消失&lt;/code&gt;（Gradient Vanishing)或者&lt;code&gt;梯度爆炸&lt;/code&gt;(Gradient Explore)问题。这两个问题的产生原理这里不做赘述，一般都是由于网络层数过深，梯度链式传导带来的结果。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="批标准化" scheme="https://www.xiemingzhao.com/tags/%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/"/>
    
    <category term="BN" scheme="https://www.xiemingzhao.com/tags/BN/"/>
    
  </entry>
  
  <entry>
    <title>SNE 和 t-SNE 算法</title>
    <link href="https://www.xiemingzhao.com/posts/senalgo.html"/>
    <id>https://www.xiemingzhao.com/posts/senalgo.html</id>
    <published>2021-03-03T16:00:00.000Z</published>
    <updated>2025-04-01T16:33:14.807Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>实际研究中有很多的<code>降维算法</code>，例如经典的线性降维算法<code>PCA</code>，相信很多人都比较熟悉了。而在这里，我们要介绍的是一个经典的降维算法<code>t-SNE</code>，它往往用来对高维数据做非线性降维来进行可视化分析。参考了不少大牛的文章，加上一些自己的思考，从一个小白的角度来总结一下该算法的原理和使用姿势。</p><h3 id="1-1-维数灾难"><a href="#1-1-维数灾难" class="headerlink" title="1.1 维数灾难"></a>1.1 维数灾难</h3><p><code>维数灾难</code>（curse of dimensionality）：描述的是高维空间中若干迥异于低维空间、甚至反直觉的现象。</p><p>在这里我们要阐述两个理论：</p><ol><li>高维空间中数据样本极其稀疏。<br>如下图所示，高维数据降维到低维空间将发生“拥挤问题（Crowding Problem）。</li></ol><span id="more"></span><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen0.jpg" alt="sen0"></p><ol><li>高维单位空间中数据几乎全部位于超立方体的边缘。</li></ol><h3 id="1-2-数理佐证"><a href="#1-2-数理佐证" class="headerlink" title="1.2 数理佐证"></a>1.2 数理佐证</h3><p>以上两个理论并不是空口而谈，我们能够用几何学来证明。首先，在高维空间中的单位超立方体的体积是：</p><script type="math/tex; mode=display">V_{hypercube} = 1^d = 1</script><p>对应的内切球体积为：</p><script type="math/tex; mode=display">V_{hypersphere} = \frac{\pi^{n/2}}{\Gamma(n/2 + 1)} \cdot 0.5^d</script><p>两者的商取极限就有：</p><script type="math/tex; mode=display">lim_{d \to +\infty} \frac{V_{hypersphere}}{V_{hypercube}} = 0</script><p>上述表明：<strong>在极端的高维情况下，单元空间只有边角，而没有中心</strong>。数据也只能处于边缘上，而远离中心。</p><p>由此我们又能推出结论：<strong>欧式距离会失效</strong></p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen1.jpg" alt="sen1"></p><p>上图描述的是高维空间中大距离和小距离的差异越来越不明显：</p><script type="math/tex; mode=display">lim_{d \to +\infty} \frac{dist_{max} - dist_{min}}{d_{min}} = 0</script><p>所以<strong>降维的基本作用</strong>：</p><ul><li>缓解维数灾难，使得欧式距离重新生效；</li><li>数据预处理，降噪去冗余；</li><li>可视化分析。</li></ul><h3 id="1-3-SNE算法的思想基础"><a href="#1-3-SNE算法的思想基础" class="headerlink" title="1.3 SNE算法的思想基础"></a>1.3 SNE算法的思想基础</h3><p><strong>SNE 的两个思想要点</strong>：</p><ul><li>构建一个高维对象之间的概率分布，使得对象间的相似度和被选择的概率成正相关；</li><li>将高维的数据映射到低维空间，使得两个空间的概率分布尽可能相似；</li></ul><p>看下面的图，比较形似。高维空间中的数据点对应低维空间的数据点，通过一个链接关系牵引使得两个空间中对应数据点的分布类似。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen2.jpg" alt="sen2"></p><p>SNE 两个主要步骤：</p><ul><li>将欧氏距离转化为条件概率来表征点间相似度（pairwise similarity）。</li><li>使用梯度下降算法来使低维分布学习/拟合高维分布。</li></ul><h2 id="2-SNE的算法原理"><a href="#2-SNE的算法原理" class="headerlink" title="2 SNE的算法原理"></a>2 SNE的算法原理</h2><p>给定一组高维空间的数据样本：$(x_1, … , x_N)$，<strong>其中<code>N</code>表示的是样本数，并不是维度</strong>。前面我们提到，在高维空间中，欧式距离将会失效，所以这里会将其转化成<code>条件概率</code>来度量两个样本数据之间的相似度或者说距离。</p><h3 id="2-1-相似性度量-条件概率"><a href="#2-1-相似性度量-条件概率" class="headerlink" title="2.1 相似性度量-条件概率"></a>2.1 相似性度量-条件概率</h3><p>那么对于样本点$x<em>i$来说，上面提到的相似性度量$p</em>{j|i}$就是以高斯分布来选择$x_j$作为近邻点的条件概率：</p><script type="math/tex; mode=display">p_{j \mid i} = \frac{\exp(- \mid  \mid  x_i -x_j  \mid  \mid  ^2 / (2 \sigma^2_i ))} {\sum_{k \neq i} \exp(- \mid  \mid  x_i - x_k  \mid  \mid  ^2 / (2 \sigma^2_i))}</script><p>这里需要指出三点：</p><ol><li>对除 i 外其他所有 j 都计算一个条件概率后，形成一个概率分布列，所以分母需要归一化；</li><li>设定 $p_{i|i}=0$，因为我们关注的是两两之间的相似度。</li><li>有一个参数是 $\sigma_i$，对于不同的点 $x_i$ 取值不一样。</li></ol><p>另一方面，如前面所述，降维就是将高维映射到低维，那么我们对上述的高维样本点$(x_1, … , x_N)$，构造出低维空间中对应的样本点$(y_1, … , y_N)$。同样的，该空间中也有对应的度量相似度的条件概率：</p><script type="math/tex; mode=display">q_ {j \mid i} = \frac{\exp(- \mid  \mid  x_i -x_j  \mid  \mid  ^2)} {\sum_{k \neq i} \exp(- \mid  \mid  x_i - x_k  \mid  \mid  ^2)}</script><p><strong>注意：这里我们令$\sigma_i = \frac{1}{\sqrt 2}$，若方差取其他值，对结果影响仅仅是缩放而已。</strong></p><h3 id="2-2-高低维空间分布一致性"><a href="#2-2-高低维空间分布一致性" class="headerlink" title="2.2 高低维空间分布一致性"></a>2.2 高低维空间分布一致性</h3><p>到这里，我们已经定义了原始高维空间的样本数据以及映射到低位空间后的对应数据点，以及两个空间中度量样本相似度的条件概率。基于前文的算法思想：<strong>我们需要做的就是让低维空间的数据分布尽可能的靠近或者拟合高维空间中的样本分布</strong>。提到度量分布的一致程度，很自然的能够想到<code>KL散度</code>。</p><script type="math/tex; mode=display">C = \sum_i KL(P_i  \mid  \mid  Q_i) = \sum_i \sum_j p_{j \mid i} \log \frac{p_{j \mid i}}{q_{j \mid i}}</script><p>其中，$P<em>i(k = j) = p</em>{j|i}$和$Q<em>i(k = j) = q</em>{j|i}$是两个分布列。所以，我们期望，在降维效果好的时候局部分布保留相似性，即$p<em>{i|j} = q</em>{i|j}$。</p><blockquote><p>这里需要注意：<strong>KL散度具有不对称性</strong>。</p></blockquote><p><em>则如果高维数据相邻而低维数据分开（即p大q小），则cost很大；相反，如果高维数据分开而低维数据相邻（即p小q大），则cost很小。</em></p><p>所以，<strong>SNE倾向于保留高维数据的局部结构</strong>。</p><h3 id="2-3-困惑度-perplexity"><a href="#2-3-困惑度-perplexity" class="headerlink" title="2.3 困惑度(perplexity)"></a>2.3 困惑度(perplexity)</h3><p>前面的公式中我们提到了不同的点具有不同的$\sigma_i$，而$P_i$的熵会随着$\sigma_i$的增加而增加。</p><script type="math/tex; mode=display">Perp(P_i) = 2^{H(P_i)} = 2^{-\sum_j p_{j \mid i} \log_2 p_{j \mid i}}</script><blockquote><p>注意：困惑度设的大，则显然σ_i也大。两者是单调关系，因此可以使用<code>二分查找</code>。</p></blockquote><p>虽然该取值对效果具有一定的鲁棒性，但一般<strong>建议困惑度设为5-50</strong>比较好，它可以解释为<strong>一个点附近的有效近邻点个数</strong>。</p><h3 id="2-4-梯度求解"><a href="#2-4-梯度求解" class="headerlink" title="2.4 梯度求解"></a>2.4 梯度求解</h3><p>前面已经介绍了 lossfunc，简单推导可知其梯度公式为：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial y_i} = 2 \sum_j (p_{j \mid i} - q_{j \mid i} + p_{i \mid j} - q_{i \mid j})(y_i - y_j)</script><p>其结构与 softmax 类似。我们知道$\sum -y \log p$对应的梯度为$y-p$可以简单推导得知SNE的lossfunc中的i在j下的条件概率情况的梯度是$2(p<em>{i \mid j}-q</em>{i \mid j})(y<em>i-y_j)$， 同样j在i下的条件概率的梯度是$2(p</em>{j \mid i}-q_{j \mid i})(y_i-y_j)$.</p><p>为了加速优化过程和避免陷入局部最优解，我们需要引入动量，即之前的梯度累加的指数衰减项：</p><script type="math/tex; mode=display">y_i^{(t)} = y_i^{(t-1)} + \eta \frac{\partial C}{\partial y_i} + \alpha(t)(y_i^{(t-1)} - y_i^{(t-2)})</script><blockquote><p>在初始优化的阶段，每次迭代中可以引入一些高斯噪声，之后像模拟退火一样逐渐减小该噪声，可以用来避免陷入局部最优解。因此，SNE在选择高斯噪声，以及学习速率，什么时候开始衰减，动量选择等等超参数上，需要跑多次优化才可以。</p></blockquote><h3 id="2-5-SNE的问题"><a href="#2-5-SNE的问题" class="headerlink" title="2.5 SNE的问题"></a>2.5 SNE的问题</h3><p>虽然上述给出了SNE算法的原理和求解方式，但实际上其是比较难以优化的，而且存在<code>crowding problem</code>(拥挤问题)：</p><blockquote><p>由于降维后的空间压缩，会使得哪怕高维空间中离得较远的点，在低维空间中留不出这么多空间来映射。于是到最后高维空间中的点，尤其是远距离和中等距离的点，在低维空间中统统被塞在了一起。</p></blockquote><p>这里的原理在前文已经详细介绍过，是一个比较重要的问题。所以，Hinton 等人又提出了 t-SNE 的方法。与 SNE 不同，主要如下:</p><ul><li>使用对称版的SNE，简化梯度公式</li><li>低维空间下，使用t分布替代高斯分布表达两点之间的相似度</li></ul><h2 id="3-对称-SNE-Symmetric-SNE"><a href="#3-对称-SNE-Symmetric-SNE" class="headerlink" title="3 对称 SNE(Symmetric SNE)"></a>3 对称 SNE(Symmetric SNE)</h2><p>我们首先简单介绍一下<code>对称SNE</code>，它也是一种缓解拥挤问题的办法。它的主要思想就是<strong>使用联合概率分布来替换条件概率分布</strong>。我们假设P是高维空间里的各个点的联合概率分布，Q是对应的低维空间，目前函数：</p><script type="math/tex; mode=display">C = KL(P \mid  \mid Q) = \sum_i \sum_j p_{i,j} \log \frac{p_{ij}}{q_{ij}}</script><p>这里的$p<em>{ii}, q</em>{ii}$为0，我们将这种SNE称之为 <code>symmetric SNE</code> (对称SNE)，因为他假设了对于任意i,$p<em>{ij} = p</em>{ji}, q<em>{ij} = q</em>{ji}$，因此概率分布可以改写为:</p><script type="math/tex; mode=display">p_{ij} = \frac{\exp(- \mid  \mid x_i - x_j \mid  \mid ^2 / 2\sigma^2)}{\sum_{k \neq l} \exp(- \mid  \mid x_k-x_l \mid  \mid ^2 / 2\sigma^2)}  \ \ \ \ q_{ij} = \frac{\exp(- \mid  \mid y_i - y_j \mid  \mid ^2)}{\sum_{k \neq l} \exp(- \mid  \mid y_k-y_l \mid  \mid ^2)}</script><p>公式整体简洁一些，但是如果$x_i$是异常值，将会使得$||x_i - x_j||^2$很大，那么对应的lossfunc就会很小，会使得训练不好。为了解决此问题，我们可以将联合概率分布修改为：</p><script type="math/tex; mode=display">p_{ij} = \frac{p_{i|j} + p_{j|i}}{2}</script><p>如此便可以保证$\sum<em>j p</em>{ij} &gt; \frac{1}{2n}$，即每一个样本都会贡献一定的lossfunc，并且使得梯度变成：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial y_i} = 4 \sum_j (p_{ij} - q_{ij})(y_i - y_j)</script><p><strong>实际使用中<code>对称SNE</code>往往不会比<code>SNE</code>的效果差</strong>。</p><h2 id="4-t-SNE算法"><a href="#4-t-SNE算法" class="headerlink" title="4 t-SNE算法"></a>4 t-SNE算法</h2><h3 id="4-1-t分布的应用到SNE"><a href="#4-1-t分布的应用到SNE" class="headerlink" title="4.1 t分布的应用到SNE"></a>4.1 t分布的应用到SNE</h3><p>上面介绍了SNE的问题和对称SNE，更正统的做法便是<code>t-SNE</code>算法：</p><blockquote><p>在不同空间使用不同的分布来将距离转换成概率分布，高维空间中一般用<code>高斯分布</code>，而在对应的低维空间中我们一般使用更加长尾的<code>t-分布</code>，如此便可以使得高维度下中低等的距离在映射后能够有一个较大的距离。</p></blockquote><p>首先我们知道<code>t-分布</code>的概率密度函数（PDF）形式为：</p><script type="math/tex; mode=display">f(t) = \frac{\Gamma(\frac{v+1}{2})}{\sqrt{v \pi} \Gamma(\frac{v}{2})} (1 + \frac{t^2}{v})^{-\frac{v+1}{2}}</script><p>其中v代表数据的自由度，当$v=1$的时候一般称为<code>柯西分布</code>（Cauchy distribution），这就是我们在低维空间中将要使用的具体分布：</p><script type="math/tex; mode=display">f(t) = \frac{1}{\pi(1 + t^2)}</script><p>而当$v = \infty$的时候就称为<code>高斯/正态分布</code>(Guassian/Normal distribution)，也就是原始数据高维空间中使用的分布：</p><script type="math/tex; mode=display">f(t) = \frac{1}{\sqrt{2 \pi}} e^{- \frac{t^2}{2}}</script><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen3.png" alt="sen3"></p><p>上图展示了所介绍的两个分布的对比图，可以发现<code>t-分布</code>相对厚尾许多，能够更好的捕捉真实数据特征。</p><p>回到SNE求解那里，我们使用<code>t-分布</code>带入变换之后，将得到：</p><script type="math/tex; mode=display">q_{ij} = \frac{(1 +  \mid  \mid y_i -y_j \mid  \mid ^2)^{-1}}{\sum_{k \neq l} (1 +  \mid  \mid y_i -y_j \mid  \mid ^2)^{-1}}</script><p>对应的梯度为：</p><script type="math/tex; mode=display">\frac{\delta C}{\delta y_i} = 4 \sum_j(p_{ij}-q_{ij})(y_i-y_j)(1+ \mid  \mid y_i-y_j \mid  \mid ^2)^{-1}</script><p>为了更好的展示为什么使用<code>t-分布</code>可以通过“把尾巴抬高”来缓解SNE的拥挤问题，我们将两个分布的映射对比图画出如下所示。其中，横轴表示距离，纵轴表示相似度。我们可以发现t-分布很好的满足了我们的需求，即：</p><ul><li>对于较大相似度的点，即图中上方的红线，表明t分布在低维空间中的距离需要稍小一点；</li><li>对于低相似度的点，即图中下方的红线，表明t分布在低维空间中的距离需要更远。</li></ul><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen4.png" alt="sen4"></p><h3 id="4-2-t-SNE缺点"><a href="#4-2-t-SNE缺点" class="headerlink" title="4.2 t-SNE缺点"></a>4.2 t-SNE缺点</h3><ol><li>时间、空间复杂度为O(n^2)，计算代价昂贵。百万量级的数据需要几小时，对于PCA可能只需要几分钟。</li><li>升级版 Barnes-Hut t-SNE 可以让复杂度降为O(nlogn)，但只限于获得二维和三维的嵌入。（sklearn中可以直接使用参数method=’barnes_hut’）</li><li>由于代价函数非凸，多次执行算法的结果是随机的（名字中“Stochatsic”的由来？），需要多次运行选取最好的结果。</li><li>全局结构不能很清楚的保留。<strong>这个问题可以通过先用PCA降维到一个合理的维度（如50）后再用t-SNE来缓解</strong>，前置的PCA步骤也可以起到去除噪声等功能。（sklearn中可以直接使用参数init=’pca’）</li></ol><h3 id="4-3-小补充"><a href="#4-3-小补充" class="headerlink" title="4.3 小补充"></a>4.3 小补充</h3><p>优化过程中可以尝试的两个 trick:</p><ol><li><code>提前压缩</code>(early compression)：开始初始化的时候，各个点要离得近一点。这样小的距离，方便各个聚类中心的移动。可以通过引入L2正则项(距离的平方和)来实现。</li><li><code>提前夸大</code>(early exaggeration)：在开始优化阶段，pij 乘以一个大于1的数进行扩大，来避免因为 qij 太小导致优化太慢的问题。比如前50次迭代，pij 乘以4。</li></ol><p>最后附上一幅常见的t-SNE降维过程效果图：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen5.gif" alt="sen5"></p><h2 id="5-t-SNE实战coding"><a href="#5-t-SNE实战coding" class="headerlink" title="5 t-SNE实战coding"></a>5 t-SNE实战coding</h2><p>我们来看两个简单的例子。</p><ol><li><p>假设现在有一组3维数据，我需要将其降维到2维进行可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hello_tSNE</span>():</span><br><span class="line">    X = np.array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">    tsne = TSNE(n_components=<span class="number">2</span>)</span><br><span class="line">    tsne.fit_transform(X)</span><br><span class="line">    <span class="built_in">print</span>(tsne.embedding_)</span><br></pre></td></tr></table></figure></li><li><p>高维S曲线数据的降维可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">S curve visualization</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># # Next line to silence pyflakes. This import is needed.</span></span><br><span class="line"><span class="comment"># Axes3D</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tSNE_forS</span>():</span><br><span class="line">    n_points = <span class="number">1000</span></span><br><span class="line">    <span class="comment"># 生成S曲线的样本数据</span></span><br><span class="line">    <span class="comment"># X是一个(1000, 3)的2维数据，color是一个(1000,)的1维数据</span></span><br><span class="line">    X, color = datasets.make_s_curve(n_points, random_state=<span class="number">0</span>)</span><br><span class="line">    n_neighbors = <span class="number">10</span></span><br><span class="line">    n_components = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">    <span class="comment"># 创建了一个figure，标题为&quot;Manifold Learning with 1000 points, 10 neighbors&quot;</span></span><br><span class="line">    plt.suptitle(<span class="string">&quot;Manifold Learning with %i points, %i neighbors&quot;</span></span><br><span class="line">                 % (<span class="number">1000</span>, n_neighbors), fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;绘制S曲线的3D图像&#x27;&#x27;&#x27;</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">211</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    ax.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], X[:, <span class="number">2</span>], c=color, cmap=plt.cm.Spectral)</span><br><span class="line">    ax.view_init(<span class="number">4</span>, -<span class="number">72</span>)  <span class="comment"># 初始化视角</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;t-SNE&#x27;&#x27;&#x27;</span></span><br><span class="line">    t0 = time()</span><br><span class="line">    tsne = manifold.TSNE(n_components=n_components, init=<span class="string">&#x27;pca&#x27;</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    Y = tsne.fit_transform(X)  <span class="comment"># 转换后的输出</span></span><br><span class="line">    t1 = time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;t-SNE: %.2g sec&quot;</span> % (t1 - t0))  <span class="comment"># 算法用时</span></span><br><span class="line">    ax = fig.add_subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    plt.scatter(Y[:, <span class="number">0</span>], Y[:, <span class="number">1</span>], c=color, cmap=plt.cm.Spectral)</span><br><span class="line">    plt.title(<span class="string">&quot;t-SNE (%.2g sec)&quot;</span> % (t1 - t0))</span><br><span class="line">    ax.xaxis.set_major_formatter(NullFormatter())  <span class="comment"># 设置标签显示格式为空</span></span><br><span class="line">    ax.yaxis.set_major_formatter(NullFormatter())</span><br><span class="line">    <span class="comment"># plt.axis(&#x27;tight&#x27;)</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></li></ol><p>效果：<br><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/cluster/sen6.png" alt="sen6"></p><p><strong>参考文章</strong><br><a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Visualizing Data using t-SNE</a><br><a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html">t-SNE完整笔记</a><br><a href="https://blog.csdn.net/hustqb/article/details/78144384">数据降维与可视化——t-SNE</a><br><a href="https://www.jiqizhixin.com/articles/2017-11-13-7">详解可视化利器 t-SNE 算法：数无形时少直觉</a><br><a href="https://www.jianshu.com/p/700f017cd330">t-SNE降维原理</a><br><a href="https://kknews.cc/education/83ajqm4.html">t-SNE：最好的降维方法之一</a><br><a href="https://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/">从SNE到t-SNE再到LargeVis</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;实际研究中有很多的&lt;code&gt;降维算法&lt;/code&gt;，例如经典的线性降维算法&lt;code&gt;PCA&lt;/code&gt;，相信很多人都比较熟悉了。而在这里，我们要介绍的是一个经典的降维算法&lt;code&gt;t-SNE&lt;/code&gt;，它往往用来对高维数据做非线性降维来进行可视化分析。参考了不少大牛的文章，加上一些自己的思考，从一个小白的角度来总结一下该算法的原理和使用姿势。&lt;/p&gt;
&lt;h3 id=&quot;1-1-维数灾难&quot;&gt;&lt;a href=&quot;#1-1-维数灾难&quot; class=&quot;headerlink&quot; title=&quot;1.1 维数灾难&quot;&gt;&lt;/a&gt;1.1 维数灾难&lt;/h3&gt;&lt;p&gt;&lt;code&gt;维数灾难&lt;/code&gt;（curse of dimensionality）：描述的是高维空间中若干迥异于低维空间、甚至反直觉的现象。&lt;/p&gt;
&lt;p&gt;在这里我们要阐述两个理论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;高维空间中数据样本极其稀疏。&lt;br&gt;如下图所示，高维数据降维到低维空间将发生“拥挤问题（Crowding Problem）。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="降维" scheme="https://www.xiemingzhao.com/tags/%E9%99%8D%E7%BB%B4/"/>
    
    <category term="SNE" scheme="https://www.xiemingzhao.com/tags/SNE/"/>
    
  </entry>
  
  <entry>
    <title>word2vec 详解</title>
    <link href="https://www.xiemingzhao.com/posts/word2vec.html"/>
    <id>https://www.xiemingzhao.com/posts/word2vec.html</id>
    <published>2020-12-12T16:00:00.000Z</published>
    <updated>2025-04-01T17:10:48.260Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>很多算法工程师认为 Embedding 技术是机器学习中最迷人的一种思想，在过去的近10年中，该技术在各个深度学习领域大放异彩。已经逐步进化到了近几年基于 BERT 和 GPT2 等模型的语境化嵌入。本文重点基于原始论文<a href="https://arxiv.org/pdf/1301.3781v3.pdf">Efficient Estimation of Word Representations in Vector Space</a>，整理 word2vec 相关技术的基础原理和应用经验，旨在利于自己回溯巩固和他人参考学习。</p><p>首先 Embedding 的思想是如何来的呢？我们知道计算机底层只能识别数字，并基于其进行逻辑等计算。而世间大多的实体或概念都不是以数据形式存在的，如何让计算机能够记住甚至理解是一件很难的事情。</p><span id="more"></span><p>如果我们能够将实体或概念以一种有意义的代数向量的形式输入给计算机，那么计算机对于它们的存储、理解和计算将会极大的友好。比如，对于一个人，如果我们重点关注他的性别、年龄、身高、体重、胸围、存款这些信息，那么我们可以将其记为以下形式：</p><p>[1,18,180,70,90,100]</p><p>其中每个维度的数值对应该维度的信息，也即性别=男（1）、年龄=18、身高=180cm、体重=70kg、胸围=90cm、存款=100W。当然你可以继续扩增更多的维度，维度信息越多，计算机对这个对象认识的更全面。</p><h2 id="2-Word-Embedding"><a href="#2-Word-Embedding" class="headerlink" title="2 Word Embedding"></a>2 Word Embedding</h2><p>在 NLP 领域，计算对于词的理解一直是一个很重要的问题。如前文所述，Word Embedding <code>目的</code>就是<strong>把词汇表中的单词或者短语（words or phrases）映射成由实数构成的向量</strong>上，而其<code>方法</code>一般是<strong>从数据中自动学习输入空间到 Distributed representation 空间的映射 f</strong>。</p><h3 id="2-1-One-hot"><a href="#2-1-One-hot" class="headerlink" title="2.1 One-hot"></a>2.1 One-hot</h3><p><code>One-hot</code> 编码又称<code>独热编码</code>，具体方法是：用一个N位状态寄存器来对N个状态进行编码，N是指所编码特征的空间大小。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gender:[&quot;male&quot;, &quot;female&quot;]</span><br><span class="line">country:[&quot;US&quot;, &quot;China&quot;,&quot;Japan&quot;,&quot;France&quot;,&quot;Italy&quot;]</span><br></pre></td></tr></table></figure><p>这两个特征的每一个取值可以被 One-hot 编码为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gender = [[1,0], [0,1]]</span><br><span class="line">country = [[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1]]</span><br></pre></td></tr></table></figure></p><p>如此，One-hot 编码的优缺点还是很明显的。</p><ul><li>优点：解决了分类器不好处理离散数据的问题，在一定程度上也起到了扩充特征的作用。</li><li>缺点：1. 不考虑词的顺序；2. 假设词之间相互独立；3. 向量是高度稀疏的；4. 容易出现维度爆炸。</li></ul><h3 id="2-2-Dristributed-representation"><a href="#2-2-Dristributed-representation" class="headerlink" title="2.2 Dristributed representation"></a>2.2 Dristributed representation</h3><p>根据One-hot的缺点，我们更希望用诸如“语义”，“复数”，“时态”等维度去描述一个单词。每一个维度不再是0或1，而是连续的实数，表示不同的程度。</p><p>Dristributed representation 可以解决 One hot representation 的问题，它的<strong>思路是通过训练，将每个词都映射到一个较短的稠密词向量上来。</strong></p><p>例如，king 这个词可能从一个非常稀疏的空间映射到一个稠密的四维空间，假设[0.99,0.99,0.05,0.7]。那这个映射一般要满足：</p><ul><li>这个映射是一一映射；</li><li>映射后的向量不会丢失之前所包含的信息。</li></ul><p>这个过程就成为 <code>Word Embedding</code> （词嵌入），而一个好的词嵌入一般能够获得有意义的词向量，例如一个经典的case，即可以从词向量上发现:</p><script type="math/tex; mode=display">\vec King - \vec Man + \vec Womman = \vec Queen</script><h3 id="2-3-Cocurrence-matrix"><a href="#2-3-Cocurrence-matrix" class="headerlink" title="2.3 Cocurrence matrix"></a>2.3 Cocurrence matrix</h3><p><strong>一般认为某个词的意思跟它临近的单词是紧密相关的</strong>。这时可以设定一个窗口（大小一般是5~10），如下窗口大小是2，那么在这个窗口内，与 rests 共同出现的单词就有 life、he、in、peace。然后我们就利用这种共现关系来生成词向量。</p><blockquote><p>… Bereft of life he rests in peace! If you hadn’t nailed him …</p></blockquote><p>假设窗口大小为1，此时，将得到一个对称矩阵——<code>共现矩阵</code>，如此就可以实现将 word 变成向量的设想，在共现矩阵每一行（或每一列）都是对应单词的一个向量表示。如下所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec0.png" alt="word2vec"></p><h2 id="3-word2vec"><a href="#3-word2vec" class="headerlink" title="3. word2vec"></a>3. word2vec</h2><h3 id="3-1-基本模型结构"><a href="#3-1-基本模型结构" class="headerlink" title="3.1 基本模型结构"></a>3.1 基本模型结构</h3><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec1.png" alt="word2vec1"></p><p>如上图所示，是 word2vec 的基本模型结构，其目的是：</p><p><strong>利用单词本身的 one-hot 编码来完成的预测（即不同场景下的context），然后利用训练过程中映射矩阵中对应的向量来作为单词的表示。</strong></p><p>简述一下上图的流程：</p><ol><li>输入是 One-hot 编码，通过与映射矩阵$W_{V \times N}$得到隐层的行向量；</li><li>从隐层到输出层，有另一个映射矩阵$W’_{N \times V}$，与前面的行向量相乘得到输出向量；</li><li>之后经过 softmax 层，便得到每个词的概率。</li></ol><p>整个过程用数学来表达就是：</p><script type="math/tex; mode=display">u_j = W'W^T x = { w'_{ij} } = {v'}_{w_j}^{T} {v}_{w_i}^T</script><script type="math/tex; mode=display">p{w_j | w_i} = y_i = \frac{exp(u_j)}{\sum_{ {j}'=1}^V exp(u'_j)} = \frac{exp({v'}_{w_j}^T v_{w_i})}{\sum_{ {j}'=1}^V exp({v'}_{w_{j'} }^T  v_{w_i}) )}</script><p>其中 $u<em>i$ 代表了输出向量中第 i 个单词的概率， $v</em>{w<em>i}$ 和 ${v’}</em>{w_{j’ } }^T$ 分别代表了 $W$ 中对应的行向量和 $W’$ 中对应的列向量。</p><h3 id="3-2-CBOW-Continuous-Bags-of-word"><a href="#3-2-CBOW-Continuous-Bags-of-word" class="headerlink" title="3.2 CBOW(Continuous Bags-of-word)"></a>3.2 CBOW(Continuous Bags-of-word)</h3><p>基于上述，我们来看一个经典的模型结构，<code>CBOW</code>，即连续词袋模型。与基准模型结构不同的是，<strong>CBOW 模型利用输入 context 多个词的向量均值作为输入</strong>。</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec2.jpg" alt="word2vec2"></p><p>如上图所示，用数学描述即：</p><script type="math/tex; mode=display">h = \frac{1}{C} W^T (x_1 ++ x_2 + \dots + x_C) = \frac{1}{C}(v_{w_1} + v_{w_2} + \dots + v_{w_C})</script><p>其中，C 为 context 的词语数量，所以CBOW的损失函数为：</p><script type="math/tex; mode=display">\begin{array}{l}E & = & -log p(w_O|w_{I,1}, \dots , w_{I,C}) \\& = & - u_{j^*} + log \sum_{ {j}' = 1} ^ V exp(u_{ {j}'}) \\& = & - v'_{w_O} \cdot h + log \sum_{ {j}' = 1} ^ V exp({v'}_{w_j}^T) \cdot h\end{array}</script><h3 id="3-3-Skip-Gram-Model"><a href="#3-3-Skip-Gram-Model" class="headerlink" title="3.3 Skip-Gram Model"></a>3.3 Skip-Gram Model</h3><blockquote><p><code>核心区别</code>：Skip-gram 是预测一个词的上下文，而 CBOW 是用上下文预测这个词，即 y 有多个词。</p></blockquote><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec3.png" alt="word2vec3"></p><p>在传递过程中，其不再输出单个的多项分布（即一个词语的 one-hot 编码），而是利用共享的参数输出映射矩阵输出 C 个多项分布（此处  C 为context词语的数量）：</p><script type="math/tex; mode=display">p(w_{c,j} = w_{O,c}|w_I) = y_{c,j} = \frac{exp(u_{c,j})}{\sum_{ {j'} - 1}^V exp(u_{j'})}</script><p>其中：</p><ul><li>$w_{c,j}$是输出层第 c 部分中的第 j 个数字；</li><li>$w_{O,c}$是输出 context 词中第 c 个数字；</li><li>$w_I$ 是输入的唯一单词；</li><li>$y_{c,j}$ 是输出层第 c 部分中的第 j 个单元；</li><li>$u_{c,j}$是输出层第 c 部分上第 j 个单元的净输入。</li></ul><p>由于输出时映射矩阵的参数共享，所以有：</p><script type="math/tex; mode=display">u_{c,j} = u_j = {v'}_{w_j}^T \cdot h, \quad for  c = 1, 2, \dots , C</script><p>在Skip-Gram中的 loss function 为：</p><script type="math/tex; mode=display">\begin{array}{l}E & = & -log p(w_{O,1}, w_{O,2}, \dots , w_{O,C} | w_I) \\& = & - log \prod_{c = 1} ^C \frac{exp(u_{j'})}{\sum_{ {j'}-1}^V exp(u_{j'})} \\& = & -\sum_{c = 1}^C u_{j_c^*} + C \cdot log \sum_{ {j'}-1}^V exp(u_{j'})\end{array}</script><h2 id="4-输出层-softmax-优化"><a href="#4-输出层-softmax-优化" class="headerlink" title="4 输出层 softmax 优化"></a>4 输出层 softmax 优化</h2><p>我们回顾 <code>word2vec</code> 算法，容易发现其在输出层为了预估词的概率，需要经过 sotmax 层。而，当词典空间很大的时候，<strong>softmax层容易成为整个算法的计算瓶颈</strong>。一般会有两种方法可以解决，<code>Hierarchical SoftMax</code> 和 <code>Negative Sampling</code>。</p><h3 id="4-1-Hierarchical-SoftMax"><a href="#4-1-Hierarchical-SoftMax" class="headerlink" title="4.1 Hierarchical SoftMax"></a>4.1 Hierarchical SoftMax</h3><p><code>哈夫曼（Huffman）树</code>是一种二叉树数据结构，基于其衍生的 <code>Hierarchical SoftMax</code> 能够有效地的降低 Softmax 的计算复杂度。我们首先介绍一下如何构建一颗哈夫曼（Huffman）树。</p><p>假设待构建的 n 个权值（一般是词频）为 ${w_1, w_2, \dots , w_n}$，可以通过以下步骤来构建 Huffman 树：</p><ol><li>将 ${w_1, w_2, \dots , w_n}$作为森林中 n 棵树的根节点；</li><li>选取森林中根权值最小的2棵树，分别作为左右子树合成新树，且新根节点的权值为左右子树根节点权值之和；</li><li>用新合成的数替换森林中原来的2个子树，重复上述过程直至仅剩一棵树。</li></ol><p>假设，有下面的一句：</p><blockquote><p>I love data science. I love big data. I am who I am.</p></blockquote><p>对应的词频表为：</p><div class="table-container"><table><thead><tr><th>word</th><th>code</th><th>freq</th><th>bits</th></tr></thead><tbody><tr><td>I</td><td>10</td><td>4</td><td>8</td></tr><tr><td>love</td><td>110</td><td>2</td><td>6</td></tr><tr><td>data</td><td>010</td><td>2</td><td>6</td></tr><tr><td>science</td><td>11110</td><td>1</td><td>5</td></tr><tr><td>big</td><td>11111</td><td>1</td><td>5</td></tr><tr><td>am</td><td>011</td><td>2</td><td>6</td></tr><tr><td>who</td><td>1110</td><td>1</td><td>4</td></tr><tr><td>.</td><td>00</td><td>3</td><td>6</td></tr></tbody></table></div><p>根据构建流程，实际上经过7次合并后完成 Huffman 树的构建：</p><ol><li>T1: (science, big) = 2</li><li>T2: (who, T1) = 3</li><li>T3: (data, am) = 4</li><li>T4: (love, T2) = 5</li><li>T5: (., T3) = 7</li><li>T6: (I, T4) = 9</li><li>T7: (T5, T6) = 15</li></ol><p>按照上述步骤构建完成的<code>Huffman树</code>一般如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec4.png" alt="word2vec4"></p><p>可以发现：<strong>每个词都为树中的叶子节点，即高频词计算路径短，低频词计算路劲长</strong></p><p>剩下的步骤：</p><ol><li>将每个节点的选择构建成一个简单的二分类问题（比如LR），这样每个词语输入节点时都面临一个二项分布的问题。</li><li>通过Skip-Gram中“一预测多”的思想，利用根节点的输入词来预测多个输出的叶子节点，这样每个节点输出的概率为对应路径中的多项分布概率相乘。</li><li>最后遍历词典中的所有输入，完成整个数的节点参数确定，最后利用每个节点路径上的概率来形成对应单词的隐向量。</li></ol><p>由于在构建 Huffman 树的时候，保证了数的深度为 $log{|V|}$ ，因此在分层Softmax中只需做 $log{|V|}$ 次二分类即可求得最后预测单词的概率大小。</p><h3 id="4-2-Negative-Sampling"><a href="#4-2-Negative-Sampling" class="headerlink" title="4.2 Negative Sampling"></a>4.2 Negative Sampling</h3><p>除了上述的<code>分层Softmax</code>方法，另一个更为经典和常用的便是<code>Negative Sampling</code>（负采样）方法。它的核心思想是：</p><blockquote><p>放弃全局 Softmax 计算的过程，按照固定概率采样一定量的子集作为负例，从而转化成计算这些负例的sigmoid二分类过程，可以大大降低计算复杂度。</p></blockquote><script type="math/tex; mode=display">E = -\log{\sigma{(v_{w_o}^T h) } } - \sum_{w_j \in W_{neg } } \log{\sigma{(-v_{w_j}^T h) } }</script><p>上述便是新的 Loss 函数，公式中前者是 input 词，后部分为负采样得到的负样本词。容易发现，网络的计算空间从$|V|$降低到了$|w<em>O \cup W</em>{neg}|$。<strong>而这本质上是对训练集进行了采样，从而减小了训练集的大小。</strong></p><h2 id="5-问题思考"><a href="#5-问题思考" class="headerlink" title="5 问题思考"></a>5 问题思考</h2><h3 id="5-1-负采样方式"><a href="#5-1-负采样方式" class="headerlink" title="5.1 负采样方式"></a>5.1 负采样方式</h3><blockquote><p>算法的采样要求：高频词被采到的概率要大于低频词。<br>所以答案是非均匀采样，而是<code>带权采样</code>。</p></blockquote><p>之所以如此，是因为在大语料数据集中，有很多高频但信息量少的词，例如”the, a”等。对它们的下采样不仅可以加速还可以提高词向量的质量。为了平衡高低频词，一般采用如下权重：</p><script type="math/tex; mode=display">P(w_i) = 1 - \sqrt{\frac{t}{f(w_i) } }</script><p>其中，$f(w_i)$是单词$w_i$出现频率，参数$t$根据经验值一般取$10^{-5}$。如此可以确保频率超过$t$的词可以被欠采样，且不会影响原单词的频率相对大小。</p><h3 id="5-2-模型中两个embedding的取舍"><a href="#5-2-模型中两个embedding的取舍" class="headerlink" title="5.2 模型中两个embedding的取舍"></a>5.2 模型中两个embedding的取舍</h3><p>在word2vec模型的训练阶段，一般创建2个词表矩阵，<strong>Embedding 矩阵和 Context 矩阵</strong>。它们的大小都是 vocab_size x embedding_size，其中 vocab_size 是词表大小，embedding_size 是词向量维度。如下图所示：</p><p><img src="https://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/deepmodel/word2vec5.png" alt="word2vec5"></p><blockquote><p>训练结束后，一般丢弃 Context 矩阵，并使用 Embeddings 矩阵作为下一项任务的已被训练好的嵌入。那为什么这么做呢？</p></blockquote><p>在 Stack Overflow 上的问题<a href="https://stackoverflow.com/questions/29381505/why-does-word2vec-use-2-representations-for-each-word">Why does word2vec use 2 representations for each word?</a>中有提到一个直觉性的解释，核心就是<strong>前者是中心词下的 embedding ，后者是 context 时下的 embedding ，他所表征的是两种不同的分布。</strong></p><p>实际上，个人在实际应用中做了一些试错，这里记录共享一下：</p><ol><li>使用中心词表 embedding 一定程度符合问题的定义：为了获取中心词 emb，从而采样 context 来构建样本训练的；</li><li>中心词和上下文词的 embedding 表都可以单独使用，但是不能交叉使用，比如2个近义词在两个独立词表中 emb 有意义，跨表 embedding 的关联性会失去；</li><li>从 <code>CBOW</code> 和 <code>Skip-gram</code> 的算法逻辑看，中心词和上下文词 embedding 实际上是一个角色互换。</li></ol><h3 id="5-3-CBOW-amp-Skip-Gram-的优劣"><a href="#5-3-CBOW-amp-Skip-Gram-的优劣" class="headerlink" title="5.3 CBOW &amp; Skip-Gram 的优劣"></a>5.3 CBOW &amp; Skip-Gram 的优劣</h3><p>先总结一下结论：</p><ul><li>当语料较少时使用 CBOW 方法比较好，当语料较多时采用 skip-gram 表示比较好。</li><li>Skip-gram 训练时间长，但是对低频词(生僻词)效果好；</li><li>CBOW 训练时间短，对低频词效果比较差。</li></ul><p>对于上述的结论貌似业界较为统一，但是对于这个结论的原理解释众说纷纭，这里个人觉得下面这种逻辑分析更为合理。首先注意 CBOW 和 skip-gram 的训练形式区别：</p><ul><li>CBOW 是使用周围词预测中心词，周围词的emb表是最终使用的。其对于每个中心词的一组采样样本训练的 gradient 会同时反馈给周围词上；</li><li>skip-gram 则相反，使用中心词预测周围词，中心词的 emb 表是最重使用的。那么中心词每组采样样本训练的 gradient 都会调整中心词的 emb；</li></ul><p>如上情况，可能会认为两者虽然中心词和上下文词虽然角色不一样，但只是互换了位置，训练的次数和结果理应差不多。然而，当默认使用 embedding 词表的时候，情况是不一样的:</p><blockquote><p><strong>skip-gram 的主词表中每个 emb 的训练次数多于 CBOW 的</strong>。</p></blockquote><p>因为，在 skip-gram 中，中心词的 emb 表是主词表，其每次会抽样 K 个上下文词，这保证了主词表对应的每个上下文词都训练到 K 次。<br>而 CBOW 则不同，因为其上下文词是主词表，中心词是用来训练上下文词的  emb，而由于采样概率的问题，虽然也会采样 K 个上下文词，但依然不能保证下文词对应的主词表的每个emb 都能够至少训练 K 次。</p><h3 id="5-4-拓展应用"><a href="#5-4-拓展应用" class="headerlink" title="5.4 拓展应用"></a>5.4 拓展应用</h3><p>个人在实际工作和应用中，深刻的感受到 word2vec 的强大绝不止于预训练词向量这么简单，其算法原理的思想才是核心，可以应用在很多地方，也深深影响着我自己。</p><p>这里总结几个应用的场景：</p><ol><li>最传统的便是nlp中文本词向量的预训练；</li><li>搜索推荐场景做 item2vec，可以用来输入精排或直接做向量召回；</li><li>召回/粗排模型样本的采样逻辑，如样本的负采样完全可以参考此逻辑。</li></ol><p><strong>参考文献</strong><br><a href="https://blog.csdn.net/weixin_39910711/article/details/103696103">机器学习算法（十三）：word2vec</a><br><a href="https://zhuanlan.zhihu.com/p/447776752">Embedding知识点 —— word2Vec详解</a><br><a href="https://blog.csdn.net/weixin_42279926/article/details/106403211">word2vec对each word使用两个embedding的原因</a><br><a href="https://mp.weixin.qq.com/s/oIxCPNXEUEvnjC0ESNQvCg">图解Word2vec</a><br><a href="https://zhuanlan.zhihu.com/p/26306795">NLP秒懂词向量Word2vec的本质</a><br><a href="https://blog.csdn.net/lanyu_01/article/details/80097350">《word2vec Parameter Learning Explained》论文学习笔记</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;很多算法工程师认为 Embedding 技术是机器学习中最迷人的一种思想，在过去的近10年中，该技术在各个深度学习领域大放异彩。已经逐步进化到了近几年基于 BERT 和 GPT2 等模型的语境化嵌入。本文重点基于原始论文&lt;a href=&quot;https://arxiv.org/pdf/1301.3781v3.pdf&quot;&gt;Efficient Estimation of Word Representations in Vector Space&lt;/a&gt;，整理 word2vec 相关技术的基础原理和应用经验，旨在利于自己回溯巩固和他人参考学习。&lt;/p&gt;
&lt;p&gt;首先 Embedding 的思想是如何来的呢？我们知道计算机底层只能识别数字，并基于其进行逻辑等计算。而世间大多的实体或概念都不是以数据形式存在的，如何让计算机能够记住甚至理解是一件很难的事情。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="word2vec" scheme="https://www.xiemingzhao.com/tags/word2vec/"/>
    
  </entry>
  
  <entry>
    <title>深度学习中的激活函数们</title>
    <link href="https://www.xiemingzhao.com/posts/activefunc.html"/>
    <id>https://www.xiemingzhao.com/posts/activefunc.html</id>
    <published>2020-06-17T16:00:00.000Z</published>
    <updated>2025-03-31T16:31:34.948Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>本文参考多方资料总结了一下当前在深度模型中常遇到的几种激活函数。</p><p>在神经网络中，激活函数主要有两个用途：</p><ul><li>引入非线性</li><li>充分组合特征</li></ul><p>其中<strong>非线性</strong>激活函数允许网络复制复杂的非线性行为。正如绝大多数神经网络借助某种形式的梯度下降进行优化，激活函数需要是<strong>可微分</strong>（或者至少是几乎完全可微分的）。此外，复杂的激活函数也许产生一些梯度消失或爆炸的问题。因此，神经网络倾向于部署若干个特定的激活函数（identity、sigmoid、ReLU 及其变体）。<br>因此，神经网络中激励函数的作用通俗上讲就是将多个线性输入转换为非线性的关系。如果不使用激励函数的话，神经网络的每层都只是做线性变换，即使是多层输入叠加后也还是线性变换。通过激励函数引入非线性因素后，使神经网络的表达能力更强了。</p><span id="more"></span><h2 id="2-常见激活函数"><a href="#2-常见激活函数" class="headerlink" title="2 常见激活函数"></a>2 常见激活函数</h2><p>下面是多个激活函数的图示及其一阶导数，图的右侧是一些与神经网络相关的属性。</p><p><code>单调性（Montonic）</code>： 单调性使得在激活函数处的梯度方向不会经常改变，从而让训练更容易收敛</p><p><code>连续性（Continuous）</code>：个人认为作者想表达可微性，可微性保证了在优化中梯度的可计算性</p><p><code>非饱和性（saturation）</code>：饱和指的是在某些区间梯度接近于零（即梯度消失），使得参数无法继续更新的问题。</p><p>在深度神经网络中，前面层上的梯度是来自于后面层上梯度的乘乘积。当存在过多的层次时，就出现了内在本质上的不稳定场景，如<code>梯度消失</code>和<code>梯度爆炸</code></p><p><code>梯度消失（Vanishing Gradient）</code>：某些区间梯度接近于零；前面的层比后面的层梯度变化更小，故变化更慢，从而引起了梯度消失问题</p><p><code>梯度爆炸(Exploding Gradient)</code>:  某些区间梯度接近于无穷大或者权重过大；前面层比后面层梯度变化更快，会引起梯度爆炸问题</p><h3 id="2-1-Step"><a href="#2-1-Step" class="headerlink" title="2.1 Step"></a>2.1 Step</h3><p>它的函数和倒数表达式是：</p><script type="math/tex; mode=display">f(x)=\left\{\begin{matrix}1 \quad for \ x \ge 0 \\  0 \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">f'(x)=\left\{\begin{matrix}0 \quad for \ x \ne 0 \\  ? \quad for \ x = 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc1.png" alt="activefunc1"></p><p>激活函数 Step 更倾向于理论而不是实际，它模仿了生物神经元要么全有要么全无的属性。它无法应用于神经网络，因为其导数是 0（除了零点导数无定义以外），这意味着基于梯度的优化方法并不可行。</p><h3 id="2-2-Identity"><a href="#2-2-Identity" class="headerlink" title="2.2 Identity"></a>2.2 Identity</h3><script type="math/tex; mode=display">Identity(x)=x</script><script type="math/tex; mode=display">Identity'(x)=1</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc2.png" alt="activefunc2"><br>通过激活函数 Identity，节点的输入等于输出。它完美适合于潜在行为是线性（与线性回归相似）的任务。当存在非线性，单独使用该激活函数是不够的，但它依然可以在最终输出节点上作为激活函数用于回归任务。</p><h3 id="2-3-ReLU"><a href="#2-3-ReLU" class="headerlink" title="2.3 ReLU"></a>2.3 ReLU</h3><script type="math/tex; mode=display">ReLU(x)=\left\{\begin{matrix}x \quad for \ x \ge 0 \\  0 \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">ReLU'(x)=\left\{\begin{matrix}1 \quad for \ x \ge 0 \\  0 \quad for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc3.png" alt="activefunc3"></p><p>修正线性单元（Rectified linear unit，ReLU）是神经网络中最常用的激活函数。</p><p>优点：<br>1，解决了gradient vanishing （梯度消失）问题（在正区间）<br>2，计算方便，求导方便，计算速度非常快，只需要判断输入是否大于0<br>3，收敛速度远远大于 Sigmoid函数和 tanh函数，可以加速网络训练</p><p>缺点：</p><ol><li>由于负数部分恒为零，会导致一些神经元无法激活</li><li>输出不是以0为中心</li></ol><p>缺点的致因：</p><ol><li>非常不幸的参数初始化，这种情况比较少见</li><li>learning rate 太高，导致在训练过程中参数更新太大，不幸使网络进入这种状态。</li></ol><p>另，<strong>ReLU 激活函数在零点不可导</strong>，求导按左导数来计算，是0。</p><h3 id="2-4-Sigmoid"><a href="#2-4-Sigmoid" class="headerlink" title="2.4 Sigmoid"></a>2.4 Sigmoid</h3><script type="math/tex; mode=display">Sig(x)=\frac{1}{1 + e^{-x}}</script><script type="math/tex; mode=display">Sig'(x)=Sig(x)(1-Sig(x))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc4.png" alt="activefunc4"></p><p>Sigmoid 因其在 logistic 回归中的重要地位而被人熟知，值域在 0 到 1 之间。Logistic Sigmoid（或者按通常的叫法，Sigmoid）激活函数给神经网络引进了概率的概念。它的导数是非零的，并且很容易计算（是其初始输出的函数）。然而，在分类任务中，sigmoid 正逐渐被 Tanh 函数取代作为标准的激活函数，因为后者为奇函数（关于原点对称）。</p><p>主要是其有一些缺点：</p><ul><li>容易出现梯度弥散或者梯度饱和；</li><li>Sigmoid函数的output不是0均值（zero-centered）；</li><li>对其解析式中含有幂函数，计算机求解时相对比较耗时。</li></ul><h3 id="2-5-Tanh"><a href="#2-5-Tanh" class="headerlink" title="2.5 Tanh"></a>2.5 Tanh</h3><script type="math/tex; mode=display">tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}</script><script type="math/tex; mode=display">tanh'(x)=1-tanh^2(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc5.png" alt="activefunc5"></p><p>在分类任务中，双曲正切函数（Tanh）逐渐取代 Sigmoid 函数作为标准的激活函数，其具有很多神经网络所钟爱的特征。它是完全可微分的，反对称，对称中心在原点。输出均值是0，使得其收敛速度要比Sigmoid快，减少迭代次数。为了解决学习缓慢和/或梯度消失问题，可以使用这个函数的更加平缓的变体（log-log、softsign、symmetrical sigmoid 等等）.</p><h3 id="2-6-Leaky-ReLU"><a href="#2-6-Leaky-ReLU" class="headerlink" title="2.6 Leaky ReLU"></a>2.6 Leaky ReLU</h3><script type="math/tex; mode=display">LeakyReLU(x)=\left\{\begin{matrix}x \quad &for \ x \ge 0 \\  0.01 x \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">LeakyReLU'(x)=\left\{\begin{matrix}1 \quad &for \ x \ge 0 \\  0.01 \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc6.png" alt="activefunc6"></p><p>经典（以及广泛使用的）ReLU 激活函数的变体，带泄露修正线性单元（Leaky ReLU）的输出对负值输入有很小的坡度。由于导数总是不为零，这能减少静默神经元的出现，允许基于梯度的学习（虽然会很慢）。</p><h3 id="2-7-PReLU"><a href="#2-7-PReLU" class="headerlink" title="2.7 PReLU"></a>2.7 PReLU</h3><script type="math/tex; mode=display">PReLU(x)=\left\{\begin{matrix}x \quad for \ x \ge 0 \\  \alpha x \quad for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">PReLU'(x)=\left\{\begin{matrix}1 \quad for \ x \ge 0 \\  \alpha \quad for \ x < 0\end{matrix}\right.</script><p><strong>其中$\alpha$一般取根据数据来确定.</strong></p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc7.png" alt="activefunc7"></p><p>参数化修正线性单元（Parameteric Rectified Linear Unit，PReLU）属于 ReLU 修正类激活函数的一员。它和 RReLU 以及 Leaky ReLU 有一些共同点，即为负值输入添加了一个线性项。而最关键的区别是，这个线性项的斜率实际上是在模型训练中学习到的。如果$\alpha$是一个很小的固定值（如 ai=0.01），则PReLU 退化为 Leaky ReLU（LReLU）。有实验证明：与 ReLU 相比，LReLU 对最终结果几乎没有什么影响。</p><h3 id="2-8-RReLU"><a href="#2-8-RReLU" class="headerlink" title="2.8 RReLU"></a>2.8 RReLU</h3><script type="math/tex; mode=display">RReLU(x_{ji})=\left\{\begin{matrix}x_{ji} \quad &for \ x_{ji} \ge 0 \\  \alpha_{ji} x_{ji} \quad &for \ x_{ji} < 0\end{matrix}\right.</script><p>where</p><script type="math/tex; mode=display">\alpha_{ji} \sim U(l,u),l<u \ and \ l,u \in [0,1)</script><script type="math/tex; mode=display">RReLU'(x)=\left\{\begin{matrix}1 \quad for \ x \ge 0 \\  \alpha \quad for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc8.png" alt="activefunc8"></p><p>随机带泄露的修正线性单元（Randomized Leaky Rectified Linear Unit，RReLU 也是 Leaky ReLU的一个变体。在 PReLU中，负值的斜率在训练中是随机的，在之后的测试中就变成了固定的了。RReLU 的亮点在于，在训练环节中，aji 是从一个均匀的分布 U(I, u) 中随机抽取的数值。</p><p>这里我们要上一个经典的三者对比图：<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc9.png" alt="activefunc10"><br>其中 PReLU 中的 ai 是根据数据变换的；Leaky ReLU中的 ai 是固定的；RReLU中的 aji 是在一个给定的范围内随机抽取的值，这个值在测试环境就会固定下来。</p><h3 id="2-9-ELU"><a href="#2-9-ELU" class="headerlink" title="2.9 ELU"></a>2.9 ELU</h3><script type="math/tex; mode=display">ELU(x)=\left\{\begin{matrix}x \quad &for \ x \ge 0 \\  \alpha (e^x-1) \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">ELU'(x)=\left\{\begin{matrix}1 \quad &for \ x \ge 0 \\  \alpha e^x \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc10.png" alt="activefunc10"></p><p>指数线性单元（Exponential Linear Unit，ELU）也属于 ReLU 修正类激活函数的一员。和 PReLU 以及 RReLU 类似，为负值输入添加了一个非零输出。和其它修正类激活函数不同的是，它包括一个负指数项，从而防止静默神经元出现，导数收敛为零，从而提高学习效率。<br>根据一些研究，ELUs 分类精确度是高于 ReLUs的。ELU在正值区间的值为x本身，这样减轻了梯度弥散问题（x&gt;0区间导数处处为1），这点跟ReLU、Leaky ReLU相似。而在负值区间，ELU在输入取较小值类似于 Leaky ReLU ，理论上虽然好于 ReLU，但是实际使用中目前并没有好的证据 ELU 总是优于 ReLU。时具有软饱和的特性，提升了对噪声的鲁棒性。类似于 Leaky ReLU ，理论上虽然好于 ReLU，但是实际使用中目前并没有好的证据 ELU 总是优于 ReLU。</p><h3 id="2-10-SELU"><a href="#2-10-SELU" class="headerlink" title="2.10 SELU"></a>2.10 SELU</h3><script type="math/tex; mode=display">SELU(x)=\lambda\left\{\begin{matrix}x \quad &for \ x \ge 0 \\  \alpha (e^x-1) \quad &for \ x < 0\end{matrix}\right.</script><script type="math/tex; mode=display">with \lambda=1.0507, \alpha=1.67326</script><script type="math/tex; mode=display">SELU'(x)=\left\{\begin{matrix}\lambda \quad &for \ x \ge 0 \\  \lambda \alpha e^x \\ =\lambda(SELU(x)+\alpha) \quad &for \ x < 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc11.png" alt="activefunc11"><br>扩展指数线性单元（Scaled Exponential Linear Unit，SELU）是激活函数指数线性单元（ELU）的一个变种。其中λ和α是固定数值（分别为 1.0507 和 1.6726）。这些值背后的推论（零均值/单位方差）构成了自归一化神经网络的基础（SNN）。值看似是乱讲的，实际上是作者推导出来的，详情也可以看<a href="https://github.com/bioinf-jku/SNNs">作者的github</a>。</p><h3 id="2-11-SReLU"><a href="#2-11-SReLU" class="headerlink" title="2.11 SReLU"></a>2.11 SReLU</h3><script type="math/tex; mode=display">SReLU(x)=\left\{\begin{matrix}t_l + a_l(x-t_l) &for \ x \le t_l \\  x &for \ t_l < x < t_r \\ t_r + a_r(x - t_r) &for \ x \ge t_r\end{matrix}\right.</script><script type="math/tex; mode=display">SReLU'(x)=\left\{\begin{matrix}a_l &for \ x \le t_l \\  1 &for \ t_l < x < t_r \\a_r &for \ x \ge t_r\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc12.png" alt="activefunc12"><br>S 型整流线性激活单元（S-shaped Rectified Linear Activation Unit，SReLU）属于以 ReLU 为代表的整流激活函数族。它由三个分段线性函数组成。其中两种函数的斜度，以及函数相交的位置会在模型训练中被学习。</p><h3 id="2-12-Hard-Sigmoid"><a href="#2-12-Hard-Sigmoid" class="headerlink" title="2.12 Hard Sigmoid"></a>2.12 Hard Sigmoid</h3><script type="math/tex; mode=display">Hard Sigmoid(x)=max(0, min(1, \frac{x+1}{2}))</script><script type="math/tex; mode=display">Hard Sigmoid'(x)=\left\{\begin{matrix}0 &for \ x \le t_l \\  0.5 &for \ t_l < x < t_r \\0 &for \ x \ge t_r\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc13.png" alt="activefunc13"><br>Hard Sigmoid 是 Logistic Sigmoid 激活函数的分段线性近似。它更易计算，这使得学习计算的速度更快，尽管首次派生值为零可能导致静默神经元/过慢的学习速率（详见 ReLU）。</p><h3 id="2-13-Hard-Tanh"><a href="#2-13-Hard-Tanh" class="headerlink" title="2.13 Hard Tanh"></a>2.13 Hard Tanh</h3><script type="math/tex; mode=display">Hard Tanh(x)=\left\{\begin{matrix}-1 &for \ x < -1 \\  x &for \ -1 \le x \le 1 \\1 &for \ x > 1\end{matrix}\right.</script><script type="math/tex; mode=display">Hard Tanh'(x)=\left\{\begin{matrix}0 &for \ x < -1 \\  1 &for \ -1 \le x \le 1 \\0 &for \ x > 1\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc14.png" alt="activefunc14"></p><p>Hard Tanh 是 Tanh 激活函数的线性分段近似。相较而言，它更易计算，这使得学习计算的速度更快，尽管首次派生值为零可能导致静默神经元/过慢的学习速率（详见 ReLU）。</p><h3 id="2-14-LeCun-Tanh"><a href="#2-14-LeCun-Tanh" class="headerlink" title="2.14 LeCun Tanh"></a>2.14 LeCun Tanh</h3><script type="math/tex; mode=display">LeCun Tanh(x)=1.7519tanh(\frac{2}{3} x)</script><script type="math/tex; mode=display">LeCun Tanh'(x)=1.7519 * \frac{2}{3} (1 - tanh^2(\frac{2}{3} x))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc15.png" alt="activefunc15"></p><p>LeCun Tanh（也被称作 Scaled Tanh）是 Tanh 激活函数的扩展版本。它具有以下几个可以改善学习的属性：f(± 1) = ±1；二阶导数在 x=1 最大化；且有效增益接近 1。</p><h3 id="2-15-ArcTan"><a href="#2-15-ArcTan" class="headerlink" title="2.15 ArcTan"></a>2.15 ArcTan</h3><script type="math/tex; mode=display">ArcTan(x)=tan^{-1}(x)</script><script type="math/tex; mode=display">ArcTan'(x)=\frac{1}{x^2 + 1}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc16.png" alt="activefunc16"><br>视觉上类似于双曲正切（Tanh）函数，ArcTan 激活函数更加平坦，这让它比其他双曲线更加清晰。在默认情况下，其输出范围在-π/2 和π/2 之间。其导数趋向于零的速度也更慢，这意味着学习的效率更高。但这也意味着，导数的计算比 Tanh 更加昂贵。</p><h3 id="2-16-Softsign"><a href="#2-16-Softsign" class="headerlink" title="2.16 Softsign"></a>2.16 Softsign</h3><script type="math/tex; mode=display">Softsign(x)=\frac{x}{1 + |x|}</script><script type="math/tex; mode=display">Softsign'(x)=\frac{1}{(|x| + 1)^2}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc17.png" alt="activefunc17"></p><p>Softsign 是 Tanh 激活函数的另一个替代选择。就像 Tanh 一样，Softsign 是反对称、去中心、可微分，并返回-1 和 1 之间的值。其更平坦的曲线与更慢的下降导数表明它可以更高效地学习。另一方面，导数的计算比 Tanh 更麻烦。</p><h3 id="2-17-SoftPlus"><a href="#2-17-SoftPlus" class="headerlink" title="2.17 SoftPlus"></a>2.17 SoftPlus</h3><script type="math/tex; mode=display">SoftPlus(x)=ln(1 + e^x)</script><script type="math/tex; mode=display">SoftPlus'(x)=\frac{1}{1 + e ^{-x}}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc18.png" alt="activefunc18"></p><p>作为 ReLU 的一个不错的替代选择，SoftPlus 能够返回任何大于 0 的值。与 ReLU 不同，SoftPlus 的导数是连续的、非零的，无处不在，从而防止出现静默神经元。然而，SoftPlus 另一个不同于 ReLU 的地方在于其不对称性，不以零为中心，这兴许会妨碍学习。此外，由于导数常常小于 1，也可能出现梯度消失的问题。</p><h3 id="2-18-Signum"><a href="#2-18-Signum" class="headerlink" title="2.18 Signum"></a>2.18 Signum</h3><script type="math/tex; mode=display">Signum(x)=\left\{\begin{matrix}1 &for \ x > 0 \\  -1 &for \ x < 0 \\0 &for \ x = 0\end{matrix}\right.</script><script type="math/tex; mode=display">Signum'(x)=\left\{\begin{matrix}0 &for \ x \ne 0 \\  ? &for \ x = 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc19.png" alt="activefunc19"></p><p>激活函数 Signum（或者简写为 Sign）是二值阶跃激活函数的扩展版本。它的值域为 [-1,1]，原点值是 0。尽管缺少阶跃函数的生物动机，Signum 依然是反对称的，这对激活函数来说是一个有利的特征。</p><h3 id="2-19-Bent-Identity"><a href="#2-19-Bent-Identity" class="headerlink" title="2.19 Bent Identity"></a>2.19 Bent Identity</h3><script type="math/tex; mode=display">Bent Identity(x)=\frac{\sqrt{x ^ 2 + 1} - 1}{2} + x</script><script type="math/tex; mode=display">Bent Identity'(x)=\frac{x}{2 \sqrt{x ^ 2 + 1}} + 1</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc20.png" alt="activefunc20"><br>激活函数 Bent Identity 是介于 Identity 与 ReLU 之间的一种折衷选择。它允许非线性行为，尽管其非零导数有效提升了学习并克服了与 ReLU 相关的静默神经元的问题。由于其导数可在 1 的任意一侧返回值，因此它可能容易受到梯度爆炸和消失的影响。</p><h3 id="2-20-Symmetrical-Sigmoid"><a href="#2-20-Symmetrical-Sigmoid" class="headerlink" title="2.20 Symmetrical Sigmoid"></a>2.20 Symmetrical Sigmoid</h3><script type="math/tex; mode=display">Symmetrical Sigmoid(x)=tanh(x/2)=\frac{1 - e^{-x}}{1 + e^{-x}}</script><script type="math/tex; mode=display">Symmetrical Sigmoid'(x)=0.5 (1 - tanh^2(x/2))</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc21.png" alt="activefunc21"><br>Symmetrical Sigmoid 是另一个 Tanh 激活函数的变种（实际上，它相当于输入减半的 Tanh）。和 Tanh 一样，它是反对称的、零中心、可微分的，值域在 -1 到 1 之间。它更平坦的形状和更慢的下降派生表明它可以更有效地进行学习。</p><h3 id="2-21-Log-Log"><a href="#2-21-Log-Log" class="headerlink" title="2.21 Log Log"></a>2.21 Log Log</h3><script type="math/tex; mode=display">Log Log(x)=1 - e^{-e^x}</script><script type="math/tex; mode=display">Log Log'(x)=e^x(e^{-e^x})=e^{x-e^x}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc22.png" alt="activefunc22"><br>Log Log 激活函数（由上图 f(x) 可知该函数为以 e 为底的嵌套指数函数）的值域为 [0,1]，Complementary Log Log 激活函数有潜力替代经典的 Sigmoid 激活函数。该函数饱和地更快，且零点值要高于 0.5。</p><h3 id="2-22-Gaussian"><a href="#2-22-Gaussian" class="headerlink" title="2.22 Gaussian"></a>2.22 Gaussian</h3><script type="math/tex; mode=display">Gaussian(x)=e^{-x^2}</script><script type="math/tex; mode=display">Gaussian'(x)=-2xe^{-x^2}</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc23.png" alt="activefunc23"><br>高斯激活函数（Gaussian）并不是径向基函数网络（RBFN）中常用的高斯核函数，高斯激活函数在多层感知机类的模型中并不是很流行。该函数处处可微且为偶函数，但一阶导会很快收敛到零。</p><h3 id="2-23-Absolute"><a href="#2-23-Absolute" class="headerlink" title="2.23 Absolute"></a>2.23 Absolute</h3><script type="math/tex; mode=display">Absolute(x)=|x|</script><script type="math/tex; mode=display">Absolute'(x)=\left\{\begin{matrix}-1 &for \ x < 0 \\  ? &for \ x = 0 \\1 &for x > 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc24.png" alt="activefunc24"><br>顾名思义，绝对值（Absolute）激活函数返回输入的绝对值。该函数的导数除了零点外处处有定义，且导数的量值处处为 1。这种激活函数一定不会出现梯度爆炸或消失的情况。</p><h3 id="2-24-Sinusoid"><a href="#2-24-Sinusoid" class="headerlink" title="2.24 Sinusoid"></a>2.24 Sinusoid</h3><script type="math/tex; mode=display">Sinusoid(x)=sin(x)</script><script type="math/tex; mode=display">Sinusoid'(x)=cos(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc25.png" alt="activefunc25"></p><p>如同余弦函数，Sinusoid（或简单正弦函数）激活函数为神经网络引入了周期性。该函数的值域为 [-1,1]，且导数处处连续。此外，Sinusoid 激活函数为零点对称的奇函数。</p><h3 id="2-25-Cos"><a href="#2-25-Cos" class="headerlink" title="2.25 Cos"></a>2.25 Cos</h3><script type="math/tex; mode=display">Cos(x)=cos(x)</script><script type="math/tex; mode=display">Cos'(x)=sin(x)</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc26.png" alt="activefunc26"></p><p>如同正弦函数，余弦激活函数（Cos/Cosine）为神经网络引入了周期性。它的值域为 [-1,1]，且导数处处连续。和 Sinusoid 函数不同，余弦函数为不以零点对称的偶函数。</p><h3 id="2-26-Sinc"><a href="#2-26-Sinc" class="headerlink" title="2.26 Sinc"></a>2.26 Sinc</h3><script type="math/tex; mode=display">Sinc(x)=\left\{\begin{matrix}1 &for \ x = 0 \\\frac{sin(x)}{x} &for x \ne 0\end{matrix}\right.</script><script type="math/tex; mode=display">Sinc'(x)=\left\{\begin{matrix}0 &for \ x = 0 \\\frac{cos(x)}{x} - \frac{sin(x)}{x^2} &for x \ne 0\end{matrix}\right.</script><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/notes/activefunc27.png" alt="activefunc27"><br>Sinc 函数（全称是 Cardinal Sine）在信号处理中尤为重要，因为它表征了矩形函数的傅立叶变换（Fourier transform）。作为一种激活函数，它的优势在于处处可微和对称的特性，不过它比较容易产生梯度消失的问题。</p><p><strong>参考文章</strong><br><a href="https://www.cnblogs.com/wj-1314/p/12015278.html">深度学习笔记——常用的激活（激励）函数</a><br><a href="https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/">Visualising Activation Functions in Neural Networks</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;本文参考多方资料总结了一下当前在深度模型中常遇到的几种激活函数。&lt;/p&gt;
&lt;p&gt;在神经网络中，激活函数主要有两个用途：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入非线性&lt;/li&gt;
&lt;li&gt;充分组合特征&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中&lt;strong&gt;非线性&lt;/strong&gt;激活函数允许网络复制复杂的非线性行为。正如绝大多数神经网络借助某种形式的梯度下降进行优化，激活函数需要是&lt;strong&gt;可微分&lt;/strong&gt;（或者至少是几乎完全可微分的）。此外，复杂的激活函数也许产生一些梯度消失或爆炸的问题。因此，神经网络倾向于部署若干个特定的激活函数（identity、sigmoid、ReLU 及其变体）。&lt;br&gt;因此，神经网络中激励函数的作用通俗上讲就是将多个线性输入转换为非线性的关系。如果不使用激励函数的话，神经网络的每层都只是做线性变换，即使是多层输入叠加后也还是线性变换。通过激励函数引入非线性因素后，使神经网络的表达能力更强了。&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="深度学习" scheme="https://www.xiemingzhao.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="激活函数" scheme="https://www.xiemingzhao.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>布谷鸟过滤器(Cuckcoo Filter)</title>
    <link href="https://www.xiemingzhao.com/posts/cuckooFilter.html"/>
    <id>https://www.xiemingzhao.com/posts/cuckooFilter.html</id>
    <published>2020-05-28T16:00:00.000Z</published>
    <updated>2025-03-31T16:42:01.792Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在了解了布隆过滤器的缺点之后，如果想要解决就可以来学习一下布谷鸟过滤器。其最早是在2001年的论文<a href="https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf">《Cuckoo Filter: Practically Better Than Bloom》</a>中提出的。论文中也很直接的抨击布隆过滤器的缺点，表明自己可以有效支持反向删除操作。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><p>先来介绍最简单的<code>布谷鸟过滤器</code>的工作原理。假设我们有：</p><ul><li>两个Hash表，T1和T2；</li><li>两个Hash函数，H1和H2。</li></ul><span id="more"></span><p>当一个不存在的元素需要进行插入的时候：</p><ol><li>先使用H1计算出其在T1的位置，如果空就插入；</li><li>如果不空，就再利用H2计算其在T2的位置，如果空就放入；</li><li>如果依然不空，那就<code>鸠占鹊巢</code>，把当前位置的元素踢出去，再把待插入的元素插入即可。这也是布谷鸟过滤器名称的来源。</li></ol><p>以上就是布谷鸟过滤器的主要原理，看到这里肯定各种疑问:</p><blockquote><p>被踢出的怎么办？会不会存在循环踢出？等等问题，研究人员也都进行了解决。</p></blockquote><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter1.png" alt="cuckooFilter1"></p><p>首先，不同于布谷鸟的是，布谷鸟哈希算法会帮这些受害者（被挤走的数据）寻找其它的位置。参考上面论文中的图(a)：</p><blockquote><p>当x想要插入的时候，发现在T1和T2中对应的位置都存在了元素，那就随机把 T1 表对应位置上的 y 踢出去吧，而 y 的另一个位置被 z 元素占领了。于是 y 毫不留情把 z 也踢了出去。z 发现自己的备用位置还空着（虽然这个备用位置也是元素 v 的备用位置），赶紧就位。</p></blockquote><p>经过上述的插入过程后，整个数据结构就从(a)图中的左变成了右。这种类似于套娃的解决方式看是可行，但是总是有<code>出现循环踢出</code>导致放不进 x 的问题。比如上图中的(b)。</p><p>当遇到这种情况时候，说明<strong>布谷鸟 hash 已经到了极限情况，应该进行扩容，或者 hash 函数的优化</strong>。所以，你再次去看伪代码的时候，你会明白里面的 <code>MaxLoop</code> 的含义是什么了。这个 <code>MaxLoop</code> 的含义就是<strong>为了避免相互踢出的这个过程执行次数太多，设置的一个阈值</strong>。</p><h2 id="3-优化"><a href="#3-优化" class="headerlink" title="3 优化"></a>3 优化</h2><h3 id="3-1-思路"><a href="#3-1-思路" class="headerlink" title="3.1 思路"></a>3.1 思路</h3><p>看过上述的原理，相信依然对其性能和效果存在质疑。这里首先抛出论文中提到的短处。</p><blockquote><p>虽然<code>MaxLoop</code>能够避免太多循环踢出，但是这使得在完美的情况下，也就是没有发生哈希冲突之前，它的空间利用率最高只有 50%。</p></blockquote><p>对于上述的问题，一般会有下面的优化方法：</p><ol><li>增加 hash 函数，这样可以大大降低碰撞的概率，将空间利用率提高到 95% 左右。</li><li>在数组的每个位置上挂上多个座位，这样即使两个元素被 hash 在了同一个位置，也可以随意放一个。这种方案的空间利用率只有 85% 左右，但是查询效率会很高。</li></ol><h3 id="3-2-特殊的-hash-函数"><a href="#3-2-特殊的-hash-函数" class="headerlink" title="3.2 特殊的 hash 函数"></a>3.2 特殊的 hash 函数</h3><p>论文在实际的优化中，一个很重要的就是构建了特殊的 Hash 函数。回忆一下布谷鸟 Hash，它存储的是插入元素的原始值，比如 x 会经过两个 hash 函数，如果我们记数组的长度为 L，那么就是这样的：</p><ul><li>p1 = H1(x) % L</li><li>p2 = H2(x) % L</li></ul><p>而布谷鸟过滤器计算位置时候实际上是：</p><ul><li>H1(x) = Hash(x)</li><li>H2(x) = H1(x) $\oplus$ Hash(x’s fingerprint)</li></ul><p>可以看到，虽然有两个Hash函数，<strong>但实际上内部只有一个Hash函数构成</strong>，在H2中使用了H1和待插入元素 x 的指纹Hash结果，然后再做异或运算。</p><p><code>指纹</code>其实就是插入的元素进行一个 Hash 计算，而 Hash 计算的产物就是 几个 bit 位。<strong>布谷鸟过滤器里面存储的就是元素的“指纹”。删除数据的时候，也只是抹掉该位置上的“指纹”而已</strong>。</p><p><strong>注意：异或运算确保了一个重要的性质，这两个位置具有对偶性</strong>。</p><blockquote><p>只要保证 Hash(x’s fingerprint) !=0，那么就可以确保 H2!=H1，也就可以确保，不会出现自己踢自己的死循环问题。</p></blockquote><p><em>为什么要对“指纹”进行一个 hash 计算之后再进行异或运算呢？</em></p><blockquote><p>如果不进行 hash 计算，假设“指纹”的长度是 8bit，那么其对偶位置算出来，距离当前位置最远也才 256。所以，对“指纹”进行哈希处理可确保被踢出去的元素，可以重新定位到哈希表中完全不同的存储桶中，从而减少哈希冲突并提高表利用率。</p></blockquote><p><em>它没有对数组的长度进行取模，那么它怎么保证计算出来的下标一定是落在数组中的呢？</em></p><blockquote><p>其强制数组的长度必须是 2 的指数倍。一定是这样的：10000000…（n个0）。这个限制带来的好处就是，进行异或运算时，可以保证计算出来的下标一定是落在数组中的。</p></blockquote><h3 id="3-3-空间利用率"><a href="#3-3-空间利用率" class="headerlink" title="3.3 空间利用率"></a>3.3 空间利用率</h3><p>由于是对元素进行 hash 计算，那么必然会出现“指纹”相同的情况，也就是会出现误判的情况。没有存储原数据，所以牺牲了数据的准确性，但是只保存了几个 bit，因此提升了空间效率。</p><p>在完美的情况下，也就是没有发生哈希冲突之前，它的空间利用率最高只有 50%。因为没有发生冲突，说明至少有一半的位置是空着的。这个比率还是很低的，前面提到了优化方案，论文中也是基于只有2个Hash的条件下来进行优化的，也即<strong>增加数组的维度</strong>。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter2.png" alt="cuckooFilter2"></p><p>参考上面论文中的图(c)，我们可以发现对数组进行展开，从一维变成了二维，这样每个位置可以放4个元素了。如此，论文中表述到，当 hash 函数固定为 2 个的时候，如果一个下标只能放一个元素，那么空间利用率是 50%。</p><blockquote><p>但是如果一个下标可以放 2，4，8 个元素的时候，空间利用率就会飙升到 84%，95%，98%。</p></blockquote><h3 id="3-4-最后的弊端"><a href="#3-4-最后的弊端" class="headerlink" title="3.4 最后的弊端"></a>3.4 最后的弊端</h3><p>布谷鸟过滤器整个了解下来，看起来一切都是这么的完美。各项指标都比布隆过滤器好，<strong>主打的是支持删除的操作</strong>。但实际上其依然存在不小的弊端。</p><blockquote><p>对重复数据进行限制：如果需要布谷鸟过滤器支持删除，它必须知道一个数据插入过多少次。不能让同一个数据插入 kb+1 次。其中 k 是 Hash 函数的个数，b 是一个下标的位置能放几个元素。</p></blockquote><p>举例：比如 2 个 hash 函数，一个二维数组，它的每个下标最多可以插入 4 个元素。那么对于同一个元素，最多支持插入 8 次。<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter3.png" alt="cuckooFilter3"></p><p>why 已经插入了 8 次了，如果再次插入一个 why，则会出现循环踢出的问题，直到最大循环次数，然后返回一个 false。想要避免这个问题，就需要维护一个记录表，记录每个元素插入的次数就行了。但是这成本一下子就大了起来。</p><p>虽然布谷鸟过滤器也不算完美无暇，但是从技术上和实际应用上看，这无异又是人类的一次技术迭代。下面的图是各种过滤器的指标对比。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/cuckooFilter4.png" alt="cuckooFilter4"></p><p>补充一个冷知识，虽然布谷鸟过滤器在2001年就被大佬 <code>Burton Howard Bloom</code> 提出来了，不少海内外博主一直想要看看这位大佬是和容颜。但是，海内外全网都没有，是一个彻彻底底的低调技术大佬。</p><p><strong>参考文章</strong><br><a href="https://segmentfault.com/a/1190000039156246">布隆，牛逼！布谷鸟，牛逼！</a><br><a href="https://www.163.com/dy/article/G55C599D05372639.html">聊聊Redis布隆过滤器与布谷鸟过滤器？一文避坑</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在了解了布隆过滤器的缺点之后，如果想要解决就可以来学习一下布谷鸟过滤器。其最早是在2001年的论文&lt;a href=&quot;https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf&quot;&gt;《Cuckoo Filter: Practically Better Than Bloom》&lt;/a&gt;中提出的。论文中也很直接的抨击布隆过滤器的缺点，表明自己可以有效支持反向删除操作。&lt;/p&gt;
&lt;h2 id=&quot;2-原理&quot;&gt;&lt;a href=&quot;#2-原理&quot; class=&quot;headerlink&quot; title=&quot;2 原理&quot;&gt;&lt;/a&gt;2 原理&lt;/h2&gt;&lt;p&gt;先来介绍最简单的&lt;code&gt;布谷鸟过滤器&lt;/code&gt;的工作原理。假设我们有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个Hash表，T1和T2；&lt;/li&gt;
&lt;li&gt;两个Hash函数，H1和H2。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据结构" scheme="https://www.xiemingzhao.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器(Bloom Filter)</title>
    <link href="https://www.xiemingzhao.com/posts/bloomFilter.html"/>
    <id>https://www.xiemingzhao.com/posts/bloomFilter.html</id>
    <published>2020-05-23T16:00:00.000Z</published>
    <updated>2025-03-31T16:39:27.048Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h2><p>在实际工作中，我们经常涉及判断一个对象或者数据是否存在于内存或者数据库。往往大家会想到HashMap，但是这时候有一个问题,存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，可行性就差了。<br>另一方面，如果很多请求是在请求数据库根本不存在的数据,那么数据库就要频繁响应这种不必要的IO查询,如果再多一些,数据库大多数IO都在响应这种毫无意义的请求操作,为了解决这一个问题，过滤器由此诞生！</p><h2 id="2-布隆过滤器"><a href="#2-布隆过滤器" class="headerlink" title="2 布隆过滤器"></a>2 布隆过滤器</h2><blockquote><p>过滤原理：布隆过滤器(Bloom Filter)大概的思路就是，当你请求的信息来的时候，先检查一下你查询的数据我这有没有，有的话将请求压给数据库,没有的话直接返回。</p></blockquote><span id="more"></span><p><strong>布隆过滤器是一个 bit 向量或者说 bit 数组</strong>。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter1.jpg" alt="bloomFilter1"></p><p>如图，一个<code>bitmap</code>用于记录，bitmap原始数值全都是0。<br>当一个数据存进来的时候：</p><ul><li>用三个Hash函数分别计算三次Hash值，并且将bitmap对应的位置设置为1，上图中 bitmap 的1,3,6位置被标记为1；</li><li>这时候如果一个数据请求过来，依然用之前的三个Hash函数计算Hash值，如果是同一个数据的话，势必依旧是映射到1，3，6位，那么就可以判断这个数据之前存储过；</li><li>如果新的数据映射的三个位置，有一个匹配不上，加入映射到1,3,7位，由于7位是0，也就是这个数据之前并没有加入进数据库，所以直接返回。</li></ul><h2 id="3-存在的问题"><a href="#3-存在的问题" class="headerlink" title="3 存在的问题"></a>3 存在的问题</h2><h3 id="3-1-误判"><a href="#3-1-误判" class="headerlink" title="3.1 误判"></a>3.1 误判</h3><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter2.jpg" alt="bloomFilter2"></p><p>如上图所示，假如有这么一个情景，放入数据包1，将bitmap的1,3,6位设置为了1。放入数据包2时将bitmap的3,6,7位设置为了1，此时一个并没有存过的数据包请求3。做三次哈希之后，对应的bitmap位点分别是1,6,7。这个数据之前并没有存进去过，但是由于数据包1和2存入时将对应的点设置为了1，所以请求3也会压到数据库上，这种情况会随着存入的数据增加而增加。</p><p>所以，布隆过滤器只能够得出<strong>两种结论</strong>：</p><ul><li>当hash对应的位置出现0的时候，就表明一定不存在；</li><li>当全是1的时候，由于误判的可能，只能表明可能存在。</li></ul><h3 id="3-2-无法删除"><a href="#3-2-无法删除" class="headerlink" title="3.2 无法删除"></a>3.2 无法删除</h3><p><strong>布隆过滤器无法删除的原因有二</strong>：</p><ol><li>由于有误判的可能，并不确定数据是否存在数据库里，例如数据包3。</li><li>当你删除某一个数据包对应位图上的标志后，可能影响其他的数据包。</li></ol><blockquote><p>例如上面例子中，如果删除数据包1，也就意味着会将 bitmap 1,3,6位设置为0。此时数据包2来请求时，会显示不存在，因为3,6两位已经被设置为0。</p></blockquote><p>为此还出现了一个<code>改进版的布隆过滤器</code>，即 <code>Counting Bloom filter</code>，可以用来测试元素计数个数是否绝对小于某个阈值，如下图所示。</p><p>这个过滤器的思路：将布隆过滤器的bitmap更换成数组，当数组某位置被映射一次时就+1，当删除时就-1，这样就避免了普通布隆过滤器删除数据后需要重新计算其余数据包Hash的问题。</p><p>但实际上也无法解决删除的问题，原因是由于一开始就存在误判的可能，如果在删除的时候，一个本来不存在的由于误判而进行了删除，就会使得其他原本正确的出现错误计数。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter3.jpg" alt="bloomFilter3"></p><p><em>这个问题造就了其软肋，布隆过滤器就好比是印迹，来过来就会有痕迹，就算走了也无法清理干净</em>。</p><p>比如你的系统里本来只留下 1kw 个元素，但是整体上来过了上亿的流水元素，布隆过滤器很无奈，它会将这些流失的元素的印迹也会永远存放在那里。随着时间的流失，这个过滤器会越来越拥挤，直到有一天你发现它的误判率太高了，不得不进行重建。</p><h3 id="3-3-其他问题"><a href="#3-3-其他问题" class="headerlink" title="3.3 其他问题"></a>3.3 其他问题</h3><p><strong>查询性能弱</strong><br>是因为布隆过滤器需要使用多个 hash 函数探测位图中多个不同的位点，这些位点在内存上跨度很大，会导致 CPU 缓存行命中率低。</p><p><strong>空间效率低</strong><br>是因为在相同的误判率下，布谷鸟过滤器的空间利用率要明显高于布隆，空间上大概能节省 40% 多。不过布隆过滤器并没有要求位图的长度必须是 2 的指数，而布谷鸟过滤器必须有这个要求。从这一点出发，似乎布隆过滤器的空间伸缩性更强一些。</p><h3 id="3-4-参数选择"><a href="#3-4-参数选择" class="headerlink" title="3.4 参数选择"></a>3.4 参数选择</h3><p>布隆过滤器在构建时，有<strong>两个重要的参数</strong>：</p><ul><li>一个是Hash函数的个数 k；</li><li>另一个是 bit 数组的大小 m。</li></ul><p>过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。<br>另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。</p><p>我们参考如下一个图：<br><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/papers/bloomFilter4.png" alt="bloomFilter4"></p><p>其中：</p><ul><li>k 是Hash函数的个数；</li><li>m 是布隆过滤器数组的长度；</li><li>n 是需要插入元素的个数；</li><li>p 是误报率。</li></ul><h3 id="3-5-误报率"><a href="#3-5-误报率" class="headerlink" title="3.5 误报率"></a>3.5 误报率</h3><p>如果 m 是位数组中的比特数，则在插入元素期间某一特定比特位不被某个哈希函数设置为 1 的概率是：</p><script type="math/tex; mode=display">1 - \frac{1}{m}</script><p>如果哈希函数的数量是 k，则通过 k 个哈希函数都未将该位设置为 1 的概率是：</p><script type="math/tex; mode=display">(1 - \frac{1}{m})^k</script><p>那么，如果我们插入了 n 个元素，某个位为 1 的概率，我们利用反向概率就可以求得为：</p><script type="math/tex; mode=display">1 - (1 - \frac{1}{m})^{kn}</script><p>现在我们要判断一个元素是否在集合中，假设这个元素本不在集合中，理论上来讲，经过 k 个哈希函数计算后得到的位数组的 k 个位置的值都应该是 0，如果发生了误判，即这 k 个位置的值都为 1，这就对应着<code>误判率</code>如下：</p><script type="math/tex; mode=display">p=(1 - [1 - \frac{1}{m}]^{kn})^k \approx (1 - e^{-\frac{kn}{m}})^k</script><p>参考极限公式：</p><script type="math/tex; mode=display">\lim_{x \to \infty} (1 - \frac{1}{x})^{-x}=e</script><h3 id="3-6-最优的k"><a href="#3-6-最优的k" class="headerlink" title="3.6 最优的k"></a>3.6 最优的k</h3><p>这里<strong>存在两个互斥</strong>：</p><ul><li>如果哈希函数的个数多，那么在对一个不属于集合的元素进行查询时得到0的概率就大；</li><li>如果哈希函数的个数少，那么位数组中的0就多。</li></ul><p>为了得到最优的哈希函数个数，我们需要根据上一节中的<code>错误率</code>公式进行计算。</p><p>我们首先对误判率两边取对数：</p><script type="math/tex; mode=display">ln(p) = k ln(1-e^{-\frac{kn}{m}})</script><p>我们的目的是求最优的k，且最优就表明误判率p要是最小，所以两边对k求导：</p><script type="math/tex; mode=display">\frac{1}{p} \cdot p' = ln(1 - e^{-\frac{nk}{m}}) + \frac{k e^{-\frac{nk}{m}} \frac{n}{m}}{1 - e^{-\frac{nk}{m}}}</script><p>另$p’=0$就有：</p><script type="math/tex; mode=display">ln(1 - e^{-\frac{nk}{m}}) + \frac{k e^{-\frac{nk}{m}} \frac{n}{m}}{1 - e^{-\frac{nk}{m}}} = 0</script><script type="math/tex; mode=display">(1 - e^{-\frac{nk}{m}}) \cdot ln(1 - e^{-\frac{nk}{m}}) = -k e^{-\frac{nk}{m}} \frac{n}{m}</script><script type="math/tex; mode=display">(1 - e^{-\frac{nk}{m}}) \cdot ln(1 - e^{-\frac{nk}{m}}) = e^{-\frac{nk}{m}}(-\frac{nk}{m})</script><p>所以：</p><script type="math/tex; mode=display">1 - e^{-\frac{nk}{m}} = e^{-\frac{nk}{m}}</script><script type="math/tex; mode=display">e^{-\frac{nk}{m}} = 1/2</script><script type="math/tex; mode=display">\frac{kn}{m} = ln2</script><script type="math/tex; mode=display">k = \frac{m}{n}ln2</script><h3 id="3-7-最优的m"><a href="#3-7-最优的m" class="headerlink" title="3.7 最优的m"></a>3.7 最优的m</h3><p>根据上面求出的最优 k，我们带入误判率 p 的公式就有：</p><script type="math/tex; mode=display">p=(1 - e^{-\frac{kn}{m}})^k=(1 - e^{-(\frac{m}{n}ln2)\frac{n}{m}})^k=\frac{1}{2}^k</script><p>将最优的 k 代入：</p><script type="math/tex; mode=display">p = 2^{-ln2 \cdot\frac{m}{n}}</script><p>两边同时取 ln 就有：</p><script type="math/tex; mode=display">lnp = ln2 \cdot (-ln2)\frac{m}{n}</script><script type="math/tex; mode=display">m = -\frac{n \cdot lnp}{(ln2)^2}</script><h3 id="3-8-估算-BF-的元素数量n"><a href="#3-8-估算-BF-的元素数量n" class="headerlink" title="3.8 估算 BF 的元素数量n"></a>3.8 估算 BF 的元素数量n</h3><script type="math/tex; mode=display">n = -\frac{m}{k}ln(1 - \frac{t}{m})</script><p>其中:</p><ul><li>n 是估计 BF 中的元素个数;</li><li>t 是位数组中被置为 1 的位的个数。</li></ul><h2 id="4-代码参考"><a href="#4-代码参考" class="headerlink" title="4 代码参考"></a>4 代码参考</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mmh3</span><br><span class="line"><span class="keyword">from</span> bitarray <span class="keyword">import</span> bitarray</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># zhihu_crawler.bloom_filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Implement a simple bloom filter with murmurhash algorithm.</span></span><br><span class="line"><span class="comment"># Bloom filter is used to check wether an element exists in a collection, and it has a good performance in big data situation.</span></span><br><span class="line"><span class="comment"># It may has positive rate depend on hash functions and elements count.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BIT_SIZE = <span class="number">5000000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BloomFilter</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># Initialize bloom filter, set size and all bits to 0</span></span><br><span class="line">        bit_array = bitarray(BIT_SIZE)</span><br><span class="line">        bit_array.setall(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.bit_array = bit_array</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Add a url, and set points in bitarray to 1 (Points count is equal to hash funcs count.)</span></span><br><span class="line">        <span class="comment"># Here use 7 hash functions.</span></span><br><span class="line">        point_list = <span class="variable language_">self</span>.get_postions(url)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> point_list:</span><br><span class="line">            <span class="variable language_">self</span>.bit_array[b] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">contains</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Check if a url is in a collection</span></span><br><span class="line">        point_list = <span class="variable language_">self</span>.get_postions(url)</span><br><span class="line"></span><br><span class="line">        result = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> point_list:</span><br><span class="line">            result = result <span class="keyword">and</span> <span class="variable language_">self</span>.bit_array[b]</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_postions</span>(<span class="params">self, url</span>):</span><br><span class="line">        <span class="comment"># Get points positions in bit vector.</span></span><br><span class="line">        point1 = mmh3.<span class="built_in">hash</span>(url, <span class="number">41</span>) % BIT_SIZE</span><br><span class="line">        point2 = mmh3.<span class="built_in">hash</span>(url, <span class="number">42</span>) % BIT_SIZE</span><br><span class="line">        point3 = mmh3.<span class="built_in">hash</span>(url, <span class="number">43</span>) % BIT_SIZE</span><br><span class="line">        point4 = mmh3.<span class="built_in">hash</span>(url, <span class="number">44</span>) % BIT_SIZE</span><br><span class="line">        point5 = mmh3.<span class="built_in">hash</span>(url, <span class="number">45</span>) % BIT_SIZE</span><br><span class="line">        point6 = mmh3.<span class="built_in">hash</span>(url, <span class="number">46</span>) % BIT_SIZE</span><br><span class="line">        point7 = mmh3.<span class="built_in">hash</span>(url, <span class="number">47</span>) % BIT_SIZE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [point1, point2, point3, point4, point5, point6, point7]</span><br></pre></td></tr></table></figure><p><strong>参考文章：</strong><br><a href="https://www.cnblogs.com/cpselvis/p/6265825.html">布隆过滤器(Bloom Filter)的原理和实现</a><br><a href="https://www.163.com/dy/article/G55C599D05372639.html">聊聊Redis布隆过滤器与布谷鸟过滤器？一文避坑</a><br><a href="https://cloud.tencent.com/developer/article/1136056">Counting Bloom Filter 的原理和实现</a><br><a href="https://zhuanlan.zhihu.com/p/43263751">详解布隆过滤器的原理，使用场景和注意事项</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1 背景&quot;&gt;&lt;/a&gt;1 背景&lt;/h2&gt;&lt;p&gt;在实际工作中，我们经常涉及判断一个对象或者数据是否存在于内存或者数据库。往往大家会想到HashMap，但是这时候有一个问题,存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，可行性就差了。&lt;br&gt;另一方面，如果很多请求是在请求数据库根本不存在的数据,那么数据库就要频繁响应这种不必要的IO查询,如果再多一些,数据库大多数IO都在响应这种毫无意义的请求操作,为了解决这一个问题，过滤器由此诞生！&lt;/p&gt;
&lt;h2 id=&quot;2-布隆过滤器&quot;&gt;&lt;a href=&quot;#2-布隆过滤器&quot; class=&quot;headerlink&quot; title=&quot;2 布隆过滤器&quot;&gt;&lt;/a&gt;2 布隆过滤器&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;过滤原理：布隆过滤器(Bloom Filter)大概的思路就是，当你请求的信息来的时候，先检查一下你查询的数据我这有没有，有的话将请求压给数据库,没有的话直接返回。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="算法" scheme="https://www.xiemingzhao.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据结构" scheme="https://www.xiemingzhao.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Faiss 召回详解</title>
    <link href="https://www.xiemingzhao.com/posts/faissrecall.html"/>
    <id>https://www.xiemingzhao.com/posts/faissrecall.html</id>
    <published>2020-05-04T16:00:00.000Z</published>
    <updated>2025-04-04T10:13:21.891Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>向量检索普遍应用于搜索、推荐、以及CV领域，往往候选集合两集都在千万甚至上亿规模。那么，速度很容易成为瓶颈，这时候就需要牺牲一定的精度来换取速度。于是诞生了许多ANN（近邻检索）算法，例如HNSW就是其中一种。但是，不同的ANN具有各自的优劣势，本文主要介绍<code>faiss</code>这一工业界普遍使用的向量检索框架。</p><p>Faiss的是由FaceBook的AI团队公开的项目<a href="https://github.com/facebookresearch/faiss">Facebook AI Similarity Search</a>，是针对大规模相似度检索问题开发的一个工具，使用C++编写，有python接口，对10亿量级的索引可以做到毫秒级检索的性能。</p><p>其核心思想：<strong>把候选向量集封装成一个index数据库，加速检索TopK相似向量的过程，尽量维持召回率，其中部分索引支持GPU构建。</strong></p><span id="more"></span><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><p>Faiss框架中，需要了解<code>k-means</code>、<code>PCA</code>以及<code>PQ</code>等算法。但最需要了解的2个核心原理便是：</p><ul><li>Product Quantizer, 简称<code>PQ</code>.</li><li>Inverted File System, 简称<code>IVF</code>.</li></ul><h3 id="2-1-乘积量化-PQ-原理"><a href="#2-1-乘积量化-PQ-原理" class="headerlink" title="2.1 乘积量化(PQ)原理"></a>2.1 乘积量化(PQ)原理</h3><p>矢量量化方法，即<code>vector quantization</code>，其具体定义为: <strong>将向量空间的点用一个有限子集来进行编码的过程</strong>。常见的聚类算法，都是一种矢量量化方法。向量量化方法又以<code>乘积量化</code>(PQ, Product Quantization)最为典型。</p><p>乘积量化的<code>核心思想</code>:<strong>分段（划分子空间）和聚类，KMeans是PQ乘积量化子空间数目为1的特例。</strong></p><p>PQ乘积量化生成码本和量化的过程可以用如下图示来说明：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss0.png" alt="faissrecall0"></p><h5 id="在训练阶段"><a href="#在训练阶段" class="headerlink" title="在训练阶段:"></a>在训练阶段:</h5><ol><li>针对N个训练样本，假设样本维度为128维，我们将其切分为4个子空间，则每一个子空间的维度为32维;</li><li>然后我们在每一个子空间中，对子向量采用K-Means对其进行聚类(图中示意聚成256类)，这样每一个子空间都能得到一个码本，这步称为<code>Clustering</code>。</li><li>这样训练样本的每个子段，都可以用子空间的聚类中心来近似，对应的编码即为类中心的ID(8bit)，这步称为 <code>Assign</code>。</li><li>如图所示，通过这样一种编码方式，训练样本仅使用的很短的一个编码得以表示，从而达到量化的目的。</li><li>对于待编码的样本，将它进行相同的操作，在各个子空间里使用距离它们最近类中心的id来表示它们，即完成了编码。</li></ol><p>通过下图可以看到，作者做了相应的实验，最终发现，压缩后的类中心ID设置为<strong>m=8bit（即上述的256类）效果最好</strong>。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss1.png" alt="faissrecall1"></p><h4 id="在查询阶段"><a href="#在查询阶段" class="headerlink" title="在查询阶段:"></a>在查询阶段:</h4><p>下面过程示意的是查询样本来到时，以<code>非对称距离</code>的方式(红框标识出来的部分)计算到dataset样本间的过程：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss2.png" alt="faissrecall2"></p><ol><li>按生成码本的过程，将其同样分成相同的子段，然后在每个子空间中，计算子段到该子空间中所有聚类中心得距离，得到距离表（维度4x256）。</li><li>在计算库中某个样本到查询向量的距离时，比如编码为(124, 56, 132, 222)这个样本，我们分别到距离表中取各个子段对应的距离即可。</li><li>所有子段对应的距离取出来后，将这些子段的距离求和相加，即得到该样本到查询样本间的<code>非对称距离</code>。</li><li>所有距离算好后，排序后即得到我们最终想要的结果。（实际上距离计算节省了，但是依然要遍历排序查找）</li></ol><p>PQ乘积量化能够<code>加速索引</code>的原理：<strong>即将全样本的距离计算，转化为到子空间类中心的距离计算。</strong></p><ul><li>比如上面所举的例子，原本brute-force search的方式计算距离的次数随样本数目N成线性增长，但是经过PQ编码后，对于耗时的距离计算，只要计算4x256次，<strong>几乎可以忽略此时间的消耗。</strong></li><li>另外，从上图也可以看出，对特征进行编码后，可以用一个相对比较短的编码来表示样本，自然对于<strong>内存的消耗要大大小于 brute-force search 的方式</strong>。</li></ul><p>在某些特殊的场合，我们总是希望获得精确的距离，而不是近似的距离，并且我们总是喜欢获取向量间的余弦相似度（余弦相似度距离范围在[-1,1]之间，便于设置固定的阈值），针对这种场景，<strong>可以针对PQ乘积量化得到的前top@K做一个brute-force search的排序</strong>。</p><h3 id="2-2-倒排乘积量化（IVFPQ）原理"><a href="#2-2-倒排乘积量化（IVFPQ）原理" class="headerlink" title="2.2  倒排乘积量化（IVFPQ）原理"></a>2.2  倒排乘积量化（IVFPQ）原理</h3><p>如果向量比较多，虽然降低了距离的计算复杂度，但是依然要便利所有的向量，需要进一步优化。<code>倒排PQ乘积量化(IVFPQ)</code>是PQ乘积量化的更进一步加速版。</p><p>其加速的本质依然是<strong>加速原理：为了加快查找的速度，几乎所有的ANN方法都是通过对全空间分割，将其分割成很多小的子空间，在搜索的时候，通过某种方式，快速锁定在某一（几）子空间，然后在该（几个）子空间里做遍历</strong>。</p><p>仔细观察PQ乘积量化存在一定的<code>优化空间</code>：</p><ul><li>实际上我们感兴趣的是那些跟查询样本相近的样本（姑且称这样的区域为<code>感兴趣区域</code>），也就是说老老实实挨个相加其实做了很多的无用功。如果能够通过某种手段<strong>快速将全局遍历锁定为感兴趣区域，则可以舍去不必要的全局计算以及排序。</strong></li><li>倒排PQ乘积量化的”倒排“，正是这样一种思想的体现，在具体实施手段上，采用的是通过<strong>聚类的方式实现感兴趣区域的快速定位</strong>，在倒排PQ乘积量化中，聚类可以说应用得淋漓尽致。</li></ul><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss3.png" alt="faissrecall3"></p><p>如上图所示：<strong>在PQ乘积量化之前，增加了一个粗量化过程。</strong></p><h4 id="具体地"><a href="#具体地" class="headerlink" title="具体地:"></a>具体地:</h4><ol><li>先对N个训练样本采用<code>KMeans聚类</code>，这里聚类的数目一般设置得不应过大，<strong>一般设置为1024差不多</strong>，这种可以以比较快的速度完成聚类过程。</li><li>得到了聚类中心后，针对每一个样本$x_i$，找到其距离最近的类中心$c_i$后，两者相减得到样本$x_i$的<code>残差向量(x_i-c_i)</code>;</li><li>后面剩下的过程，就是<strong>针对$(x_i-c_i)$的PQ乘积量化过程</strong>。</li></ol><p>在查询的时候，通过相同的粗量化，可以快速定位到查询向量属于哪个$c_i$（即在哪一个感兴趣区域），也可以是多个感兴趣聚类中心，然后在该感兴趣区域按上面所述的 P Q乘积量化距离计算方式计算距离。整体流程如下图所示。</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss4.png" alt="faissrecall4"></p><h3 id="2-3-最优乘积量化（OPQ）"><a href="#2-3-最优乘积量化（OPQ）" class="headerlink" title="2.3 最优乘积量化（OPQ）"></a>2.3 最优乘积量化（OPQ）</h3><p>最优乘积量化（Optimal Product Quantization, OPQ）是PQ的一种改进版本。其改进体现在，<strong>致力于在子空间分割时，对各子空间的方差进行均衡</strong>。</p><p>用于检索的原始特征维度较高，所以实际在使用PQ等方法构建索引的时候，常会对高维的特征使用<strong>PCA等降维</strong>方法对特征先做降维处理。这样降维预处理，可以达到两个<code>目的</code>：</p><ul><li>一是<strong>降低特征维度</strong>；</li><li>二是利用PCA使得在对向量进行子段切分的时候要求特征<strong>各个维度尽可能不相关</strong>。</li></ul><p>但是这么做了后，在切分子段的时候，采用顺序切分子段仍然存在一定的问题，这个问题可以借用ITQ中的一个二维平面的例子加以说明：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss5.png" alt="faissrecall5"></p><p><strong>这个问题就是：</strong></p><ul><li>如上面a图所示，对于PCA降维后的二维空间，假设在做PQ的时候，将子段数目设置为2段，即切分成x和y两个子向量，然后分别在x和y上做聚类（假设聚类中心设置为2）。</li><li>对a图和c图聚类的结果进行比较，可以明显的发现，<strong>a图在y方向上聚类的效果明显差于c图</strong>，而PQ又是采用聚类中心来近似原始向量（这里指降维后的向量），也就是c图是我们需要的结果。</li></ul><blockquote><p>这个问题可以转化为数据方差来描述：<strong>在做PQ编码时，对于切分的各个子空间，我们应尽可能使得各个子空间的方差比较接近，最理想的情况是各个子空间的方差都相等。</strong></p></blockquote><p><strong>解决办法：</strong><br>OPQ致力于解决的问题正是对各个子空间方差的均衡。思想主要是<strong>在聚类的时候对聚类中心寻找对应的最优旋转矩阵，使得所有子空间中各个数据点到对应子空间的类中心的L2损失的求和最小</strong>。具体可以分为非参求解方法和带参求解方法，这里不再赘述。</p><h2 id="3-code"><a href="#3-code" class="headerlink" title="3 code"></a>3 code</h2><p>注意faiss包的安装：<code>conda install faiss-cpu -c pytorch</code></p><p><strong>Flat ：暴力检索</strong></p><blockquote><p>优点：最准确的，召回率最高；<br>缺点：速度慢，占内存大。<br>使用情况：向量候选集很少，在50万以内，并且内存不紧张。</p></blockquote><p><strong>IVFx Flat ：倒排暴力检索</strong></p><blockquote><p>优点：IVF主要利用倒排的思想，会大大减少了检索的时间。具体可以拿出每个聚类中心下的向量ID，每个中心ID后面挂上一堆非中心向量，每次查询向量的时候找到最近的几个中心ID，分别搜索这几个中心下的非中心向量。通过减小搜索范围，提升搜索效率。<br>缺点：速度也还不是很快。<br>使用情况：向量候选集很少，在50万以内，并且内存不紧张。</p></blockquote><p><strong>PQx ：乘积量化</strong></p><blockquote><p>优点：利用乘积量化的方法，改进了普通检索，将一个向量的维度切成x段，每段分别进行检索，每段向量的检索结果取交集后得出最后的TopK。因此速度很快，而且占用内存较小，召回率也相对较高。<br>缺点：召回率相较于暴力检索，下降较多。<br>使用情况：内存及其稀缺，并且需要较快的检索速度，不那么在意召回率</p></blockquote><p><strong>IVFxPQy 倒排乘积量化</strong></p><blockquote><p>优点：工业界大量使用此方法，各项指标都均可以接受，利用乘积量化的方法，改进了IVF的k-means，将一个向量的维度切成x段，每段分别进行k-means再检索。<br>缺点：集百家之长，自然也集百家之短<br>使用情况：一般来说，各方面没啥特殊的极端要求的话，最推荐使用该方法！</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> faiss</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.vq <span class="keyword">import</span> vq, kmeans2</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cdist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">vec, M, Ks</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param vec: 向量</span></span><br><span class="line"><span class="string">    :param M: 子向量组数</span></span><br><span class="line"><span class="string">    :param Ks: 每组向量聚类个数</span></span><br><span class="line"><span class="string">    :return: codeword: [M, Ks, Ds]，</span></span><br><span class="line"><span class="string">        codeword[m][k]表示第m组子向量第k个子向量所属的聚类中心向量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    Ds = <span class="built_in">int</span>(vec.shape[<span class="number">1</span>] / M)</span><br><span class="line">    codeword = np.empty((M, Ks, Ds), np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">        vec_sub = vec[:, m * Ds: (m + <span class="number">1</span>) * Ds]</span><br><span class="line">        <span class="comment"># 第m组子向量vec_sub聚成Ks类</span></span><br><span class="line">        <span class="comment"># kmeans2返回两个结果，第一个是原始向量归属类目的中心向量，第二个是类目ID</span></span><br><span class="line">        codeword[m], label = kmeans2(vec_sub, Ks)</span><br><span class="line">    <span class="keyword">return</span> codeword</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">codeword, vec</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param codeword: 码本，shape为[M, Ks, Ds]</span></span><br><span class="line"><span class="string">    :param vec: 原始向量</span></span><br><span class="line"><span class="string">    :return: pqcode: pq编码结果,</span></span><br><span class="line"><span class="string">        shape为[N, M]，每个原始向量用M组子向量的聚类中心ID表示</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    M, Ks, Ds = codeword.shape</span><br><span class="line">    <span class="comment"># pq编码shape为[N, M]</span></span><br><span class="line">    pqcode = np.empty((vec.shape[<span class="number">0</span>], M), np.int64)</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">        vec_sub = vec[:, m * Ds: (m + <span class="number">1</span>) * Ds]</span><br><span class="line">        <span class="comment"># 第m组子向量</span></span><br><span class="line">        <span class="comment"># 第m组子向量中每个子向量在第m个码本中查找距离最近的</span></span><br><span class="line">        pqcode[:, m], dist = vq(vec_sub, codeword[m])</span><br><span class="line">    <span class="keyword">return</span> pqcode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">codeword, pqcode, query</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :param codeword:</span></span><br><span class="line"><span class="string">    :param pqcode: pq编码结果, shape为[N, M]，每个原始向量用M组子向量的聚类中心ID表示</span></span><br><span class="line"><span class="string">    :param query: 查询向量[1, d]</span></span><br><span class="line"><span class="string">    :return: dist：查询向量与原始向量的距离，shape为[N,]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    M, Ks, Ds = codeword.shape</span><br><span class="line">    <span class="comment"># 距离向量表, [M, Ks]</span></span><br><span class="line">    dist_table = np.empty((M, Ks))</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">        query_sub = query[m * Ds: (m + <span class="number">1</span>) * Ds]</span><br><span class="line">        <span class="comment"># query_sub向量与第m个码本每个向量距离</span></span><br><span class="line">        dist_table[m, :] = cdist([query_sub], codeword[m], <span class="string">&#x27;sqeuclidean&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dist_table[range(M), pqcode] 为 query向量与原始向量在每个子向量的聚类，shape为[N, M]</span></span><br><span class="line">    <span class="comment"># 每组子向量距离相加</span></span><br><span class="line">    dist = np.<span class="built_in">sum</span>(dist_table[<span class="built_in">range</span>(M), pqcode], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">PQmain</span>():</span><br><span class="line">    <span class="comment"># 数据量</span></span><br><span class="line">    N = <span class="number">50000</span></span><br><span class="line">    <span class="comment"># 向量维度</span></span><br><span class="line">    d = <span class="number">128</span></span><br><span class="line">    <span class="comment"># 每组子向量聚类个数</span></span><br><span class="line">    Ks = <span class="number">32</span></span><br><span class="line">    <span class="comment"># 训练向量[N, d]</span></span><br><span class="line">    vec_train = np.random.random((N, d))</span><br><span class="line">    <span class="comment"># 查询向量[1, d]</span></span><br><span class="line">    <span class="comment"># mock 第100个是距离查询向量最近的</span></span><br><span class="line">    selected_vec = vec_train[<span class="number">100</span>]</span><br><span class="line">    query_vec = selected_vec + [np.random.uniform(-<span class="number">0.001</span>, <span class="number">0.001</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(d)]</span><br><span class="line">    query = np.random.random((<span class="number">1</span>, d))</span><br><span class="line">    <span class="comment"># 子向量组数</span></span><br><span class="line">    M = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对原始向量划分子向量组，并对每组子向量进行聚类</span></span><br><span class="line">    codeword = train(vec_train, M, Ks)</span><br><span class="line">    <span class="comment"># pq编码</span></span><br><span class="line">    pqcode = encode(codeword, vec_train)</span><br><span class="line">    <span class="comment"># 查询向量</span></span><br><span class="line">    dist = search(codeword, pqcode, query_vec)</span><br><span class="line"></span><br><span class="line">    sorted_dist = <span class="built_in">sorted</span>(<span class="built_in">enumerate</span>(dist), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(sorted_dist[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_IndexFlatL2</span>(<span class="params">vec_train, query, top_k=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    暴力检索</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N, d = vec_train.shape</span><br><span class="line">    <span class="comment"># 1. 创建索引</span></span><br><span class="line">    index = faiss.IndexFlatL2(d)</span><br><span class="line">    <span class="comment"># 2. 添加数据集</span></span><br><span class="line">    index.add(vec_train)</span><br><span class="line">    <span class="comment"># 3. 检索</span></span><br><span class="line">    dist_list, label_list = index.search(np.array([query]), k=top_k)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;FlatL2 recall top %d is&quot;</span> % top_k + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dist:&quot;</span> + <span class="built_in">str</span>(dist_list))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index:&quot;</span> + <span class="built_in">str</span>(label_list))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_IndexIVFFlat</span>(<span class="params">vec_train, query_vec, top_k=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通过创建倒排索引优化</span></span><br><span class="line"><span class="string">    流程：使用k-means对train向量进行聚类，查询时query_vec所归属的类目中进行检索</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    nlist = <span class="number">100</span>  <span class="comment"># 聚类中心的个数</span></span><br><span class="line">    N, d = vec_train.shape</span><br><span class="line">    quantizer = faiss.IndexFlatL2(d)  <span class="comment"># the other index</span></span><br><span class="line">    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)</span><br><span class="line">    <span class="comment"># 添加 训练集</span></span><br><span class="line">    index.train(vec_train)</span><br><span class="line">    index.add(vec_train)</span><br><span class="line">    <span class="comment"># 检索</span></span><br><span class="line">    query_vec = np.reshape(query_vec, [-<span class="number">1</span>,d])</span><br><span class="line">    D, I = index.search(query_vec, top_k)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">8</span> + <span class="string">&quot;IVFFlat recall top %d is&quot;</span> % top_k + <span class="string">&quot;=&quot;</span> * <span class="number">8</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dist:&quot;</span> + <span class="built_in">str</span>(D))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index:&quot;</span> + <span class="built_in">str</span>(I))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_IndexIVFPQ</span>(<span class="params">vec_train, query_vec, top_k=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    通过创建倒排索引优化</span></span><br><span class="line"><span class="string">    流程：使用k-means对train向量进行聚类，查询时query_vec所归属的类目中进行检索</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    nlist = <span class="number">100</span>  <span class="comment"># 聚类中心的个数</span></span><br><span class="line">    m = <span class="number">8</span></span><br><span class="line">    N, d = vec_train.shape</span><br><span class="line">    quantizer = faiss.IndexFlatL2(d)  <span class="comment"># the other index</span></span><br><span class="line">    index = faiss.IndexIVFPQ(quantizer, d, nlist, m, <span class="number">8</span>)</span><br><span class="line">    <span class="comment"># 添加 训练集</span></span><br><span class="line">    index.train(vec_train)</span><br><span class="line">    index.add(vec_train)</span><br><span class="line">    <span class="comment"># 检索</span></span><br><span class="line">    query_vec = np.reshape(query_vec, [-<span class="number">1</span>,d])</span><br><span class="line">    D, I = index.search(query_vec, top_k)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">8</span> + <span class="string">&quot;IVFPQ recall top %d is&quot;</span> % top_k+<span class="string">&quot;=&quot;</span>*<span class="number">8</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dist:&quot;</span> + <span class="built_in">str</span>(D))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;index:&quot;</span> + <span class="built_in">str</span>(I))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">faissmain</span>():</span><br><span class="line">    <span class="comment"># 数据量</span></span><br><span class="line">    N = <span class="number">50000</span></span><br><span class="line">    <span class="comment"># 向量维度</span></span><br><span class="line">    d = <span class="number">128</span></span><br><span class="line">    vec_train = np.ascontiguousarray(np.random.random((N, d)), np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># mock 第100个是距离查询向量最近的</span></span><br><span class="line">    selected_vec = vec_train[<span class="number">100</span>]</span><br><span class="line">    query_vec = selected_vec + [np.random.uniform(-<span class="number">0.001</span>, <span class="number">0.001</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(d)]</span><br><span class="line">    query_vec = np.ascontiguousarray(query_vec, np.float32)</span><br><span class="line">    <span class="comment"># 1. 暴力检索，全量检索</span></span><br><span class="line">    test_IndexFlatL2(vec_train, query_vec)</span><br><span class="line">    <span class="comment"># 2. 倒排索引</span></span><br><span class="line">    test_IndexIVFFlat(vec_train, query_vec)</span><br><span class="line">    <span class="comment"># 3. 倒排PQ</span></span><br><span class="line">    test_IndexIVFPQ(vec_train, query_vec)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    PQmain()</span><br><span class="line">    faissmain()</span><br></pre></td></tr></table></figure><h2 id="4-相关拓展"><a href="#4-相关拓展" class="headerlink" title="4 相关拓展"></a>4 相关拓展</h2><p>IndexIVFPQ（”IVFx,PQy”）的性能损失来自于向量压缩和倒排列表两部分。如果IndexIVFPQ的精度太低，可以：<strong>设置nprobe为nlist，以搜索整个数据集，然后查看其性能。请注意，默认nprobe值为1。</strong></p><p>单个向量检索的速度慢，Faiss针对批量搜索进行了优化：</p><ul><li>矩阵-矩阵乘法通常比对应数量的矩阵-向量乘法快得多</li><li>搜索并行化</li><li>采用多线程同时执行多个搜索，以完全占用计算机的cores</li></ul><p><strong>Faiss不支持字符串ID或in64以外的任何数据类型。</strong></p><p>不同框架的召回效果对比如下图，更全的对比可参考<a href="http://ann-benchmarks.com">ann-Benchmarking Results</a>：</p><p><img src="http://mzxie-image.oss-cn-hangzhou.aliyuncs.com/algorithm/recall/faiss6.png" alt="faissrecall6"></p><p><strong>参考文献：</strong></p><p><a href="https://www.jstage.jst.go.jp/article/mta/6/1/6_2/_pdf">A Survey of Product Quantization</a><br><a href="https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf">Product quantization for nearest neighbor search</a><br><a href="https://blog.csdn.net/weixin_42486623/article/details/121990806">Faiss原理介绍</a><br><a href="https://zhuanlan.zhihu.com/p/534004381">faiss原理（Product Quantization）</a><br><a href="https://zhuanlan.zhihu.com/p/432317877">搜索召回 | Facebook: 亿级向量相似度检索库Faiss原理+应用</a><br><a href="https://zhuanlan.zhihu.com/p/107241260">Fiass - 常见问题总结</a><br><a href="https://blog.csdn.net/sgyuanshi/article/details/119878434">推荐系统的向量检索工具: Annoy &amp; Faiss</a><br><a href="https://blog.csdn.net/luoyexuge/article/details/84235421?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-84235421-blog-124058746.pc_relevant_multi_platform_featuressortv2removedup&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3-84235421-blog-124058746.pc_relevant_multi_platform_featuressortv2removedup&amp;utm_relevant_index=6">topk相似度性能比较（kd-tree、kd-ball、faiss、annoy、线性搜索）</a><br><a href="https://zhongqiang.blog.csdn.net/article/details/122516942?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-122516942-blog-124058746.pc_relevant_multi_platform_featuressortv2removedup&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-122516942-blog-124058746.pc_relevant_multi_platform_featuressortv2removedup&amp;utm_relevant_index=2">annoy(快速近邻向量搜索包)学习小记 - pip命令学习与annoy基础使用</a></p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h2&gt;&lt;p&gt;向量检索普遍应用于搜索、推荐、以及CV领域，往往候选集合两集都在千万甚至上亿规模。那么，速度很容易成为瓶颈，这时候就需要牺牲一定的精度来换取速度。于是诞生了许多ANN（近邻检索）算法，例如HNSW就是其中一种。但是，不同的ANN具有各自的优劣势，本文主要介绍&lt;code&gt;faiss&lt;/code&gt;这一工业界普遍使用的向量检索框架。&lt;/p&gt;
&lt;p&gt;Faiss的是由FaceBook的AI团队公开的项目&lt;a href=&quot;https://github.com/facebookresearch/faiss&quot;&gt;Facebook AI Similarity Search&lt;/a&gt;，是针对大规模相似度检索问题开发的一个工具，使用C++编写，有python接口，对10亿量级的索引可以做到毫秒级检索的性能。&lt;/p&gt;
&lt;p&gt;其核心思想：&lt;strong&gt;把候选向量集封装成一个index数据库，加速检索TopK相似向量的过程，尽量维持召回率，其中部分索引支持GPU构建。&lt;/strong&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="学习笔记" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    <category term="算法总结" scheme="https://www.xiemingzhao.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="召回" scheme="https://www.xiemingzhao.com/tags/%E5%8F%AC%E5%9B%9E/"/>
    
    <category term="Faiss" scheme="https://www.xiemingzhao.com/tags/Faiss/"/>
    
  </entry>
  
</feed>
